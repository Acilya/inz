{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task_duration_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "S45sWDCIQBXK",
        "8spqirtFHQUN"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Acilya/inz/blob/master/task_duration_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx9xwkMBr_Rs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "04c64594-3258-4e82-8f0c-ed6ebd41918f"
      },
      "source": [
        "runOnColab = True\n",
        "if runOnColab:\n",
        "  # mount drive\n",
        "  from google.colab import drive\n",
        "  drivePath = '/content/drive'\n",
        "  drive.mount(drivePath)\n",
        "  !mkdir -p drive\n",
        "  drivePath += '/My Drive'\n",
        "else:\n",
        "  drivePath = ''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lUyo1WPsE2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "f98e3465-e3fb-49ea-c603-6a9de2173159"
      },
      "source": [
        "from numpy import genfromtxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "df_original = pd.read_csv(drivePath + '/userStories.csv', sep=';',header=0)\n",
        "df = df_original.copy(deep=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Project</th>\n",
              "      <th>Key</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Priority</th>\n",
              "      <th>Assignee</th>\n",
              "      <th>Reporter</th>\n",
              "      <th>Version</th>\n",
              "      <th>Story points</th>\n",
              "      <th>Created</th>\n",
              "      <th>Resolved</th>\n",
              "      <th>In Progress</th>\n",
              "      <th>Time in sec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-4183</td>\n",
              "      <td>Support rbenv usage</td>\n",
              "      <td>&lt;p&gt;I\\'m using aptana studio 3 in my mac, osx l...</td>\n",
              "      <td>Support rbenv usage</td>\n",
              "      <td>Critical</td>\n",
              "      <td>cwilliams</td>\n",
              "      <td>nebiros</td>\n",
              "      <td>Aptana Studio 3.0.7</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2012-01-18 21:56:20</td>\n",
              "      <td>2012-01-20 12:32:39</td>\n",
              "      <td>2012-01-26 09:56:41</td>\n",
              "      <td>138979.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-4281</td>\n",
              "      <td>As a developer I want to be able to turn on an...</td>\n",
              "      <td>&lt;p&gt;We need some way to turn off validators ind...</td>\n",
              "      <td>As a developer I want to be able to turn on an...</td>\n",
              "      <td>Critical</td>\n",
              "      <td>cwilliams</td>\n",
              "      <td>cwilliams</td>\n",
              "      <td>2012 Sprint 02</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2012-01-26 06:41:55</td>\n",
              "      <td>2012-01-31 12:05:54</td>\n",
              "      <td>2012-01-27 07:30:34</td>\n",
              "      <td>362120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-2816</td>\n",
              "      <td>Convert \"New From Template\" menu to create \"Un...</td>\n",
              "      <td>&lt;p&gt;Currently, the \"File &amp;gt; New From Template...</td>\n",
              "      <td>Convert \"New From Template\" menu to create \"Un...</td>\n",
              "      <td>High</td>\n",
              "      <td>mxia</td>\n",
              "      <td>ingo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011-06-29 02:14:12</td>\n",
              "      <td>2011-07-13 15:36:29</td>\n",
              "      <td>2011-07-12 17:01:26</td>\n",
              "      <td>81303.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-3699</td>\n",
              "      <td>\"Mark Occurrences\" freezes IDE on large files</td>\n",
              "      <td>&lt;p&gt;Steps to reproduce:&lt;/p&gt;&lt;ol&gt;\\t&lt;li&gt;Copy ext-a...</td>\n",
              "      <td>\"Mark Occurrences\" freezes IDE on large files</td>\n",
              "      <td>High</td>\n",
              "      <td>cwilliams</td>\n",
              "      <td>ingo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011-10-20 08:36:49</td>\n",
              "      <td>2011-10-27 06:26:13</td>\n",
              "      <td>2011-10-26 06:10:07</td>\n",
              "      <td>87366.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-3368</td>\n",
              "      <td>Add console.debug selector to default themes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Add console.debug selector to default themes</td>\n",
              "      <td>High</td>\n",
              "      <td>ingo</td>\n",
              "      <td>mstepanov</td>\n",
              "      <td>Aptana Studio 3.0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011-08-24 05:09:50</td>\n",
              "      <td>2011-08-24 12:37:53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26883.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Project          Key  ...          In Progress Time in sec\n",
              "0  APSTUD  APSTUD-4183  ...  2012-01-26 09:56:41    138979.0\n",
              "1  APSTUD  APSTUD-4281  ...  2012-01-27 07:30:34    362120.0\n",
              "2  APSTUD  APSTUD-2816  ...  2011-07-12 17:01:26     81303.0\n",
              "3  APSTUD  APSTUD-3699  ...  2011-10-26 06:10:07     87366.0\n",
              "4  APSTUD  APSTUD-3368  ...                  NaN     26883.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4MTu15UsIwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "878d686e-62a0-44c8-cdc7-881f47c428b6"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Story points</th>\n",
              "      <th>Time in sec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10139.000000</td>\n",
              "      <td>1.013900e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.096293</td>\n",
              "      <td>5.047195e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.960597</td>\n",
              "      <td>1.403254e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.553920e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.546480e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.361527e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>105.000000</td>\n",
              "      <td>1.559840e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Story points   Time in sec\n",
              "count  10139.000000  1.013900e+04\n",
              "mean       5.096293  5.047195e+06\n",
              "std        5.960597  1.403254e+07\n",
              "min        1.000000  0.000000e+00\n",
              "25%        2.000000  1.553920e+05\n",
              "50%        4.000000  9.546480e+05\n",
              "75%        6.000000  3.361527e+06\n",
              "max      105.000000  1.559840e+08"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUjWfbK9vgIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "91708227-62c3-4e66-dffc-8ed8d95cf665"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10139 entries, 0 to 10138\n",
            "Data columns (total 14 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Project       10139 non-null  object \n",
            " 1   Key           10139 non-null  object \n",
            " 2   Title         10139 non-null  object \n",
            " 3   Description   8754 non-null   object \n",
            " 4   Summary       10139 non-null  object \n",
            " 5   Priority      1234 non-null   object \n",
            " 6   Assignee      9722 non-null   object \n",
            " 7   Reporter      10138 non-null  object \n",
            " 8   Version       156 non-null    object \n",
            " 9   Story points  10139 non-null  float64\n",
            " 10  Created       10139 non-null  object \n",
            " 11  Resolved      10139 non-null  object \n",
            " 12  In Progress   6593 non-null   object \n",
            " 13  Time in sec   10139 non-null  float64\n",
            "dtypes: float64(2), object(12)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKnN58lxulfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "aea9e78d-4537-4116-9f15-a0278d7ae42d"
      },
      "source": [
        "for c in df.columns:\n",
        "  print(c, 'unique', len(df[c].unique()) / len(df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Project unique 0.0005917743367195976\n",
            "Key unique 0.9964493539796824\n",
            "Title unique 0.9751454778577769\n",
            "Description unique 0.847026333957984\n",
            "Summary unique 0.9760331393628563\n",
            "Priority unique 0.0009862905611993293\n",
            "Assignee unique 0.02258605385146464\n",
            "Reporter unique 0.021994279514745044\n",
            "Version unique 0.004339678469277049\n",
            "Story points unique 0.01410395502515041\n",
            "Created unique 0.9964493539796824\n",
            "Resolved unique 0.9844166091330506\n",
            "In Progress unique 0.6475983824834797\n",
            "Time in sec unique 0.9241542558437715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOeyVWiKIjCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "398d6fb2-a48a-4862-dee1-c9210e6445b5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "column_names = ['Project', 'Key', 'Title', 'Description', 'Summary', 'Priority', 'Assignee', 'Reporter', 'Version', 'Story points', 'In Progress', 'Created', 'Resolved', 'In Progress', 'Time in sec']\n",
        "f, ax = plt.subplots(figsize=(8, 8))\n",
        "corr = df[column_names].corr()\n",
        "sns.heatmap(corr, mask=np.zeros_like(df.corr(), dtype=np.bool),\n",
        "            square=True, ax=ax,annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4d7e9a8128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ2NU3r6OnuS",
        "colab_type": "text"
      },
      "source": [
        "Wnioski:\n",
        "- Atrybuty 'In Progress', 'Resolved', 'Created' muszą zostać usunięte, ponieważ dotyczą elementu czasowego, który mamy przewidzieć.\n",
        "- Atrybuty 'Version' i 'Priority' są bardzo rzadke ( < 10% ), więc prawdopodobnie warto się ich pozbyć. Nie są informatywne.\n",
        "- Jest tylko jeden atrybut liczbowy - 'Story Points'.\n",
        "- Nie zauważamy specjalnej korelacji pomiędzy atrybutem \"Story points\" a czasem wykonania zadania.\n",
        "\n",
        "- Czas trwania zadania jest różnicą pomiędzy rozpoczęciem, a zakończeniem, bez uwzględnienia innych zadań w między czasie! Mediana to ok. 263 godziny, czyli ok 10 dób, co na zadania informatyczne jest dużą liczbą!\n",
        "  Np. zadanie: \"Put simulator and ATHexpod into a docker container\" trwało 2 miesiące.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMvhWfeTRfFC",
        "colab_type": "text"
      },
      "source": [
        "# Część pierwsza (bez analizy semantycznej tytułów i opisów zadań)\n",
        "- Random Forest\n",
        "- SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXAKp7tMv0B8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a2ab8f5e-d5c3-4189-fc4d-b726e56e53be"
      },
      "source": [
        "# remove rare data\n",
        "df_rf = df.copy(deep=True)\n",
        "df_rf = df_rf.drop(['Priority', 'Title', 'Description', 'Summary', 'Version', 'In Progress', 'Resolved', 'Created'], axis=1)\n",
        "df_rf.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Project', 'Key', 'Assignee', 'Reporter', 'Story points',\n",
              "       'Time in sec'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PKHUxTq0v1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clear data\n",
        "df_rf['Story points'].fillna(0, inplace=True)\n",
        "# regularization\n",
        "df_rf['Story points'] = df_rf['Story points'] / max(df_rf['Story points'])\n",
        "df_rf.fillna('', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Maq0uvEsNaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cea29df9-3b26-4071-951e-8a60f5a0512c"
      },
      "source": [
        "x_rf_train = df_rf.iloc[:, 0:5].values.tolist()\n",
        "y_rf_train = df_rf.iloc[:, 5:6].values / 3600   #change time to hours\n",
        "print(len(x_rf_train))\n",
        "print(len(y_rf_train))\n",
        "print('mean of hours spent on task', y_rf_train.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10139\n",
            "10139\n",
            "mean of hours spent on task 1401.9986922335097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp4aMsGyt36Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode text attributes\n",
        "enc = preprocessing.OrdinalEncoder()\n",
        "enc.fit(x_rf_train)\n",
        "\n",
        "y_rf_train = y_rf_train.ravel()\n",
        "x = enc.transform(x_rf_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RYE11eTsNxY",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFEWeACxsSCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b6729973-5ef2-4a41-cf33-d5c46ff72d10"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor \n",
        "regressor = RandomForestRegressor(n_estimators = 5, random_state = 0, criterion='mae') \n",
        "regressor.fit(x, y_rf_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=5, n_jobs=None, oob_score=False,\n",
              "                      random_state=0, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77JJKA8JsUVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "5a6f461b-8cde-45e1-fa2d-6818352ecbfc"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "y_pred = regressor.predict(x)\n",
        "#print(np.sqrt(np.square(np.subtract(y_rf_train, y_pred))).mean())\n",
        "print(mean_absolute_error(y_rf_train, y_pred))\n",
        "print(y_rf_train)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "607.0516546585791\n",
            "[ 38.60527778 100.58888889  22.58416667 ... 448.47972222 865.25638889\n",
            " 213.65916667]\n",
            "[ 50.88877778  87.25111111  36.56611111 ... 835.10233333 863.62066667\n",
            " 465.22405556]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S45sWDCIQBXK",
        "colab_type": "text"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBH5tL3OHPfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b82425c5-ef92-4b23-b774-41d74663f4b8"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "regressor_svm = SVR() \n",
        "regressor_svm.fit(x, y_rf_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kki016-Hcfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b67898f1-b104-4891-8b17-d57a8dd7b514"
      },
      "source": [
        "y_pred = regressor_svm.predict(x)\n",
        "#print(np.sqrt(np.square(np.subtract(y_rf_train, y_pred))).mean())\n",
        "print(mean_absolute_error(y_rf_train, y_pred))\n",
        "print(y_rf_train)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1328.5742193838303\n",
            "[ 38.60527778 100.58888889  22.58416667 ... 448.47972222 865.25638889\n",
            " 213.65916667]\n",
            "[272.54319891 272.64018943 272.02211006 ... 270.04525081 271.52366153\n",
            " 273.62009134]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg3YgFh_JvKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2e3eded2-4a6e-4ac8-914f-361046ba9994"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def rfr_model(X, y):\n",
        "# Perform Grid-Search\n",
        "    gsc = GridSearchCV(\n",
        "        estimator=RandomForestRegressor(),\n",
        "        param_grid={\n",
        "            'max_depth': range(3,7),\n",
        "            'n_estimators': (1, 5, 10, 50, 100, 1000),\n",
        "        },\n",
        "        cv=10, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
        "    \n",
        "    grid_result = gsc.fit(X, y)\n",
        "    best_params = grid_result.best_params_\n",
        "    \n",
        "    rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"], criterion='mae', random_state=0, verbose=False)\n",
        "    rfr.fit(X, y)\n",
        "    y_pred = rfr.predict(X)\n",
        "    print(mean_absolute_error(y, y_pred))\n",
        "    # Perform K-Fold CV\n",
        "    scores = cross_val_score(rfr, X, y, cv=10, scoring='neg_mean_absolute_error')\n",
        "\n",
        "    return scores\n",
        "\n",
        "scores = (-1) * rfr_model(x, y_rf_train)\n",
        "print(max(scores), min(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1230.0231867028854\n",
            "1975.4480877972278 695.88799413215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7j9ZPoWr5fi",
        "colab_type": "text"
      },
      "source": [
        "Wnioski\n",
        "- Za miarę jakości rozwiązania przyjęto Mean Square Error, ze względu na to, że mamy do czynienia z regresją.\n",
        "- Random Forest osiąga błąd rzędu 600h\n",
        "- SVM ok. 1300h\n",
        "- Strojenie parametrów obu metod nie polepsza wyników na tyle, aby mogły być uznane jako zadowalające dla tego problemu. \n",
        "- Problem: jakość danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8spqirtFHQUN",
        "colab_type": "text"
      },
      "source": [
        "# Część druga (przetwarzanie języka naturalnego, analiza tytułów i opisów)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfg_InEHHX2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86d3c048-1b9f-4ab2-e202-8f977a1176a7"
      },
      "source": [
        "# !pip install gensim\n",
        "# !pip install nltk\n",
        "# !pip install tensorflow \n",
        "# !pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.2)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.12.39)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.15.39)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.28.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D5iLeMAd4Cp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "036c347e-866a-48df-8beb-a9ff122a922a"
      },
      "source": [
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQcwtQnbgJaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import nltk.stem\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "from spacy.lang import en\n",
        "from spacy.lang.en.examples import sentences\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJtuP2eS178s",
        "colab_type": "text"
      },
      "source": [
        "simple_prepocessing:\n",
        "\n",
        "*   usunięcie wszystkich fragmentów kodu html takich jak \"< p >\", \"< li >\"\n",
        "*   usunięcie nadmiernej ilości spacji\n",
        "*   usunięcie cyfr\n",
        "\n",
        "Wypadałoby dodać:\n",
        "\n",
        "*   usunięcie linków\n",
        "*   Sprawdzanie czy cyfyr w tytule są ważne\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Q_dptF5TvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "porter = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OayHCizTzFtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_preprocessing(text):\n",
        "  text = re.sub(r'<[a-z]>', '', text)\n",
        "  text = re.sub(r'^[a-zA-Z]+', ' ', text)\n",
        "  text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
        "  text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "  text = re.sub(r'\\^\"', '', text)\n",
        "  text = re.sub(r'\"$', '', text)\n",
        "  text = re.sub(r'<.*?>', '', text)\n",
        "  text = text.lower()\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UmqatQZFEO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "c65be2fa-f3ea-4e38-e9e5-90ab67508945"
      },
      "source": [
        "nlpdf = df.copy(deep=True)\n",
        "nlpdf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Project</th>\n",
              "      <th>Key</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Priority</th>\n",
              "      <th>Assignee</th>\n",
              "      <th>Reporter</th>\n",
              "      <th>Version</th>\n",
              "      <th>Story points</th>\n",
              "      <th>Created</th>\n",
              "      <th>Resolved</th>\n",
              "      <th>In Progress</th>\n",
              "      <th>Time in sec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-4183</td>\n",
              "      <td>rbenv usage</td>\n",
              "      <td>&lt;p&gt;I\\'m using aptana studio 3 in my mac, osx l...</td>\n",
              "      <td>Support rbenv usage</td>\n",
              "      <td>Critical</td>\n",
              "      <td>cwilliams</td>\n",
              "      <td>nebiros</td>\n",
              "      <td>Aptana Studio 3.0.7</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2012-01-18 21:56:20</td>\n",
              "      <td>2012-01-20 12:32:39</td>\n",
              "      <td>2012-01-26 09:56:41</td>\n",
              "      <td>138979.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-4281</td>\n",
              "      <td>developer want to be able to turn on and off ...</td>\n",
              "      <td>&lt;p&gt;We need some way to turn off validators ind...</td>\n",
              "      <td>As a developer I want to be able to turn on an...</td>\n",
              "      <td>Critical</td>\n",
              "      <td>cwilliams</td>\n",
              "      <td>cwilliams</td>\n",
              "      <td>2012 Sprint 02</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2012-01-26 06:41:55</td>\n",
              "      <td>2012-01-31 12:05:54</td>\n",
              "      <td>2012-01-27 07:30:34</td>\n",
              "      <td>362120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-2816</td>\n",
              "      <td>files by default</td>\n",
              "      <td>&lt;p&gt;Currently, the \"File &amp;gt; New From Template...</td>\n",
              "      <td>Convert \"New From Template\" menu to create \"Un...</td>\n",
              "      <td>High</td>\n",
              "      <td>mxia</td>\n",
              "      <td>ingo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011-06-29 02:14:12</td>\n",
              "      <td>2011-07-13 15:36:29</td>\n",
              "      <td>2011-07-12 17:01:26</td>\n",
              "      <td>81303.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-3699</td>\n",
              "      <td>freezes ide on large files</td>\n",
              "      <td>&lt;p&gt;Steps to reproduce:&lt;/p&gt;&lt;ol&gt;\\t&lt;li&gt;Copy ext-a...</td>\n",
              "      <td>\"Mark Occurrences\" freezes IDE on large files</td>\n",
              "      <td>High</td>\n",
              "      <td>cwilliams</td>\n",
              "      <td>ingo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011-10-20 08:36:49</td>\n",
              "      <td>2011-10-27 06:26:13</td>\n",
              "      <td>2011-10-26 06:10:07</td>\n",
              "      <td>87366.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>APSTUD</td>\n",
              "      <td>APSTUD-3368</td>\n",
              "      <td>console.debug selector to default themes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Add console.debug selector to default themes</td>\n",
              "      <td>High</td>\n",
              "      <td>ingo</td>\n",
              "      <td>mstepanov</td>\n",
              "      <td>Aptana Studio 3.0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011-08-24 05:09:50</td>\n",
              "      <td>2011-08-24 12:37:53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26883.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10134</th>\n",
              "      <td>DM</td>\n",
              "      <td>DM-1551</td>\n",
              "      <td>htm-based spatial binning to visualize large ...</td>\n",
              "      <td>&lt;p&gt;Currently we are using a generic 2-d binnin...</td>\n",
              "      <td>Prototype HTM-based spatial binning to visuali...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tatianag</td>\n",
              "      <td>tatianag</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2014-11-20 15:10:24</td>\n",
              "      <td>2015-02-27 16:05:16</td>\n",
              "      <td>2015-01-16 11:26:36</td>\n",
              "      <td>3645520.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10135</th>\n",
              "      <td>DM</td>\n",
              "      <td>DM-1544</td>\n",
              "      <td>up git hub for ipac firefly</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Set up GIT hub for ipac firefly</td>\n",
              "      <td>NaN</td>\n",
              "      <td>roby</td>\n",
              "      <td>roby</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2014-11-18 17:09:56</td>\n",
              "      <td>2014-12-25 20:02:28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3207152.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10136</th>\n",
              "      <td>DM</td>\n",
              "      <td>DM-1782</td>\n",
              "      <td>existing fits reader class needs to be refact...</td>\n",
              "      <td>&lt;ul class=\"alternate\" type=\"square\"&gt;\\t&lt;li&gt;FITS...</td>\n",
              "      <td>The existing FITS reader class needs to be ref...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>zhang</td>\n",
              "      <td>xiuqin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2015-01-15 16:51:50</td>\n",
              "      <td>2015-02-03 09:20:37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1614527.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10137</th>\n",
              "      <td>DM</td>\n",
              "      <td>DM-1652</td>\n",
              "      <td>existing fits reader class needs to be refact...</td>\n",
              "      <td>&lt;ul class=\"alternate\" type=\"square\"&gt;\\t&lt;li&gt;chec...</td>\n",
              "      <td>The existing FITS reader class needs to be ref...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>zhang</td>\n",
              "      <td>zhang</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2014-12-10 15:31:38</td>\n",
              "      <td>2015-01-15 16:47:01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3114923.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10138</th>\n",
              "      <td>DM</td>\n",
              "      <td>DM-1481</td>\n",
              "      <td>/learn what others are doing in astronomy sof...</td>\n",
              "      <td>&lt;p&gt;Attend the annual  ADASS conference to keep...</td>\n",
              "      <td>Discover/learn what others are doing in astron...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>xiuqin</td>\n",
              "      <td>xiuqin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2014-11-05 15:30:53</td>\n",
              "      <td>2014-11-14 13:10:26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>769173.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10139 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Project          Key  ...          In Progress Time in sec\n",
              "0      APSTUD  APSTUD-4183  ...  2012-01-26 09:56:41    138979.0\n",
              "1      APSTUD  APSTUD-4281  ...  2012-01-27 07:30:34    362120.0\n",
              "2      APSTUD  APSTUD-2816  ...  2011-07-12 17:01:26     81303.0\n",
              "3      APSTUD  APSTUD-3699  ...  2011-10-26 06:10:07     87366.0\n",
              "4      APSTUD  APSTUD-3368  ...                  NaN     26883.0\n",
              "...       ...          ...  ...                  ...         ...\n",
              "10134      DM      DM-1551  ...  2015-01-16 11:26:36   3645520.0\n",
              "10135      DM      DM-1544  ...                  NaN   3207152.0\n",
              "10136      DM      DM-1782  ...                  NaN   1614527.0\n",
              "10137      DM      DM-1652  ...                  NaN   3114923.0\n",
              "10138      DM      DM-1481  ...                  NaN    769173.0\n",
              "\n",
              "[10139 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSufFEdHt48U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "66d3dd77-249d-4278-f46e-d86a62f5201f"
      },
      "source": [
        "titles = nlpdf['Title']\n",
        "titles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                              rbenv usage\n",
              "1         developer want to be able to turn on and off ...\n",
              "2                                         files by default\n",
              "3                               freezes ide on large files\n",
              "4                 console.debug selector to default themes\n",
              "                               ...                        \n",
              "10134     htm-based spatial binning to visualize large ...\n",
              "10135                          up git hub for ipac firefly\n",
              "10136     existing fits reader class needs to be refact...\n",
              "10137     existing fits reader class needs to be refact...\n",
              "10138     /learn what others are doing in astronomy sof...\n",
              "Name: Title, Length: 10139, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYNKLWJ5t-3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "c5a7bc89-ea72-410f-88c7-d9bcf2e9a0e7"
      },
      "source": [
        "desc = nlpdf['Description']\n",
        "desc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        <p>I\\'m using aptana studio 3 in my mac, osx l...\n",
              "1        <p>We need some way to turn off validators ind...\n",
              "2        <p>Currently, the \"File &gt; New From Template...\n",
              "3        <p>Steps to reproduce:</p><ol>\\t<li>Copy ext-a...\n",
              "4                                                      NaN\n",
              "                               ...                        \n",
              "10134    <p>Currently we are using a generic 2-d binnin...\n",
              "10135                                                  NaN\n",
              "10136    <ul class=\"alternate\" type=\"square\">\\t<li>FITS...\n",
              "10137    <ul class=\"alternate\" type=\"square\">\\t<li>chec...\n",
              "10138    <p>Attend the annual  ADASS conference to keep...\n",
              "Name: Description, Length: 10139, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU8XYdOwEgSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "9ec369bf-3934-4ea2-b319-dfc1aaf9ca3a"
      },
      "source": [
        "titles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                             rbenv usage\n",
              "1        developer want to be able to turn on and off ...\n",
              "15       ability to specify jslint settings on global ...\n",
              "17                       js plugin into core and ui parts\n",
              "22       common meta-programming idioms that define me...\n",
              "                              ...                        \n",
              "1081                          usergrid graduation process\n",
              "1091     master to two-dot-o branches & rewrite tests ...\n",
              "1120     creation when using s3binarystore doesn't fun...\n",
              "1208     occuring when clicking link to activate organ...\n",
              "1210     data migration format lifecycle on initial setup\n",
              "Name: Title, Length: 86, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDlpCaEHfM2v",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing tytułów za pomocą wyrażeń regularnych, a także stemmizacji\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_MF_zcTX4VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title_processed = []\n",
        "for title in titles:\n",
        "  title_processed.append(porter.stem(simple_preprocessing(title)))\n",
        "# title_processed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1aE6scTex6_",
        "colab_type": "text"
      },
      "source": [
        "Zamiana sekund na godziny"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hESRPuNs5IXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "33933f2f-b964-4fb5-bce3-1c31b4d3ae26"
      },
      "source": [
        "time = nlpdf['Time in sec']\n",
        "time /= 3600\n",
        "time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          38.605278\n",
              "1         100.588889\n",
              "2          22.584167\n",
              "3          24.268333\n",
              "4           7.467500\n",
              "            ...     \n",
              "10134    1012.644444\n",
              "10135     890.875556\n",
              "10136     448.479722\n",
              "10137     865.256389\n",
              "10138     213.659167\n",
              "Name: Time in sec, Length: 10139, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahvDaAQPesIs",
        "colab_type": "text"
      },
      "source": [
        "Przykładowe tworzenie etykiet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gqpNGYAb_7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "for t in time:\n",
        "  if t < 10:\n",
        "    y.append(0)\n",
        "  elif t >= 10 and t < 50:\n",
        "    y.append(1)\n",
        "  elif t >= 50 and t < 500:\n",
        "    y.append(2)\n",
        "  else:\n",
        "    y.append(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTG5djyenj_",
        "colab_type": "text"
      },
      "source": [
        "Normalizacja czasu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPKNRUivVDjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = time.mean()\n",
        "s = time.std()\n",
        "time = (time - m) / s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRKHtnDYI69S",
        "colab_type": "text"
      },
      "source": [
        "Trenowanie z wykorzystaniem CountVectorizera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KZ1udOvERCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhBvxQZRJJVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2235fdc3-399b-46f2-d785-960bad608f04"
      },
      "source": [
        "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
        "vectorizer.fit(title_processed)\n",
        "X = vectorizer.transform(title_processed).toarray()\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10139, 7661)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 382
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZWlNSMZQ9Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=X.shape[1], activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7Xbhfg4ZapJ",
        "colab_type": "text"
      },
      "source": [
        "Model regresyjny o małej pojemności bazujący na samych tytułach tasków, korzystający z CountVectorizera, bez używania word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj2gkfJVRfNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "0597fa2b-a339-4088-bf0a-66c55753025f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=X.shape[1], activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9125 samples, validate on 1014 samples\n",
            "Epoch 1/10\n",
            "9125/9125 [==============================] - 1s 83us/step - loss: 17609006.2603 - val_loss: 13096058.3679\n",
            "Epoch 2/10\n",
            "9125/9125 [==============================] - 1s 73us/step - loss: 17608004.7671 - val_loss: 13094694.3895\n",
            "Epoch 3/10\n",
            "9125/9125 [==============================] - 1s 75us/step - loss: 17606068.0274 - val_loss: 13092114.2086\n",
            "Epoch 4/10\n",
            "9125/9125 [==============================] - 1s 75us/step - loss: 17602343.3973 - val_loss: 13087633.5459\n",
            "Epoch 5/10\n",
            "9125/9125 [==============================] - 1s 74us/step - loss: 17596247.3425 - val_loss: 13080371.7668\n",
            "Epoch 6/10\n",
            "9125/9125 [==============================] - 1s 75us/step - loss: 17586560.0000 - val_loss: 13069431.5187\n",
            "Epoch 7/10\n",
            "9125/9125 [==============================] - 1s 74us/step - loss: 17572649.5685 - val_loss: 13053710.0799\n",
            "Epoch 8/10\n",
            "9125/9125 [==============================] - 1s 75us/step - loss: 17552675.3493 - val_loss: 13032662.0291\n",
            "Epoch 9/10\n",
            "9125/9125 [==============================] - 1s 74us/step - loss: 17526320.6575 - val_loss: 13004772.0222\n",
            "Epoch 10/10\n",
            "9125/9125 [==============================] - 1s 75us/step - loss: 17491907.5342 - val_loss: 12968815.3501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f99d1676ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re-RuS-cc5T9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "fcab2287-dadd-4b3f-c2bd-aab0d4fd9ec1"
      },
      "source": [
        "model.fit(X, np.array(time), epochs=10, batch_size=1000, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9125 samples, validate on 1014 samples\n",
            "Epoch 1/10\n",
            "9125/9125 [==============================] - 1s 76us/step - loss: 17588147.3014 - val_loss: 13062669.8693\n",
            "Epoch 2/10\n",
            "9125/9125 [==============================] - 1s 77us/step - loss: 17529088.4658 - val_loss: 12986479.6055\n",
            "Epoch 3/10\n",
            "9125/9125 [==============================] - 1s 76us/step - loss: 17407168.3562 - val_loss: 12843447.2539\n",
            "Epoch 4/10\n",
            "9125/9125 [==============================] - 1s 76us/step - loss: 17197319.1507 - val_loss: 12619880.4665\n",
            "Epoch 5/10\n",
            "9125/9125 [==============================] - 1s 75us/step - loss: 16897653.9863 - val_loss: 12336543.5251\n",
            "Epoch 6/10\n",
            "9125/9125 [==============================] - 1s 76us/step - loss: 16532834.3699 - val_loss: 12037637.0192\n",
            "Epoch 7/10\n",
            "9125/9125 [==============================] - 1s 75us/step - loss: 16138965.2329 - val_loss: 11768227.4236\n",
            "Epoch 8/10\n",
            "9125/9125 [==============================] - 1s 75us/step - loss: 15779428.5479 - val_loss: 11568569.2125\n",
            "Epoch 9/10\n",
            "9125/9125 [==============================] - 1s 77us/step - loss: 15461267.2808 - val_loss: 11455400.6361\n",
            "Epoch 10/10\n",
            "9125/9125 [==============================] - 1s 74us/step - loss: 15222210.3699 - val_loss: 11409387.5503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f99d10e4c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZX3yGFCfW1q",
        "colab_type": "text"
      },
      "source": [
        "Model klasyfikacyjny o małej pojemności bazujący na samych tytułach tasków, korzystający z CountVectorizera, bez używania word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Na49W-c6Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mod = Sequential()\n",
        "mod.add(Dense(100, input_dim=X.shape[1], activation='relu'))\n",
        "mod.add(Dense(1, activation='relu'))\n",
        "mod.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBSvQsREdDUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "bd063b23-c456-42ed-86ce-c99ee334f586"
      },
      "source": [
        "mod.fit(X, y, validation_split=0.5, epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5069 samples, validate on 5070 samples\n",
            "Epoch 1/1\n",
            "5069/5069 [==============================] - 2s 374us/step - loss: 1.8977 - accuracy: 0.2304 - val_loss: 1.4829 - val_accuracy: 0.2168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f99d0cb88d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26EGcnWjbBUc",
        "colab_type": "text"
      },
      "source": [
        "Model  LSTM (tytuły)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTeTV9-pRlUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sen = []\n",
        "for t in title_processed:\n",
        "  sen.append(str(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seNpIljabqUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4kq6Sdal6Nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "9f8c348f-67fc-4da9-8b50-e720d0383005"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sen)\n",
        "title_sequences = tokenizer.texts_to_sequences(sen)\n",
        "\n",
        "data = sequence.pad_sequences(title_sequences, maxlen=200)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0, 4000, 1006],\n",
              "       [   0,    0,    0, ...,   27,  309, 4002],\n",
              "       [   0,    0,    0, ...,  274,   53,  126],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    6,  168,   16],\n",
              "       [   0,    0,    0, ...,    6,  168,   18],\n",
              "       [   0,    0,    0, ...,    4, 3967, 1000]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDcb0e6bl8Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = sequence.pad_sequences(X_train, 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoBBxmH2l-Hw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "49add0db-3c4b-4f96-e839-20bf1026862a"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   5,   25,  100, ...,   19,  178,   32],\n",
              "       [   0,    0,    0, ...,   16,  145,   95],\n",
              "       [   0,    0,    0, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4, 3586,    2],\n",
              "       [   0,    0,    0, ...,   12,    9,   23],\n",
              "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6oIb86OoT2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm = Sequential()\n",
        "lstm.add(Embedding(10000, 32, input_length=200))\n",
        "lstm.add(LSTM(100))\n",
        "lstm.add(Dense(1, activation='relu'))\n",
        "lstm.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucja0yhCorgX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "f0d8297f-6c1f-41ec-d0d6-0c6f5ec57a36"
      },
      "source": [
        "lstm.fit(data, np.array(time), epochs=10, batch_size=100, validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 7097 samples, validate on 3042 samples\n",
            "Epoch 1/10\n",
            "7097/7097 [==============================] - 25s 4ms/step - loss: 16707923.2810 - val_loss: 18087043.5431\n",
            "Epoch 2/10\n",
            "7097/7097 [==============================] - 24s 3ms/step - loss: 16678237.1174 - val_loss: 18062581.5528\n",
            "Epoch 3/10\n",
            "7097/7097 [==============================] - 25s 3ms/step - loss: 16658522.8081 - val_loss: 18039418.3245\n",
            "Epoch 4/10\n",
            "7097/7097 [==============================] - 25s 3ms/step - loss: 16640013.4308 - val_loss: 18017499.2957\n",
            "Epoch 5/10\n",
            "7097/7097 [==============================] - 24s 3ms/step - loss: 16622206.1250 - val_loss: 17995741.2765\n",
            "Epoch 6/10\n",
            "7097/7097 [==============================] - 25s 3ms/step - loss: 16604713.6601 - val_loss: 17974842.2763\n",
            "Epoch 7/10\n",
            "7097/7097 [==============================] - 25s 3ms/step - loss: 16587472.2952 - val_loss: 17953921.5994\n",
            "Epoch 8/10\n",
            "7097/7097 [==============================] - 25s 4ms/step - loss: 16570126.6317 - val_loss: 17932734.0105\n",
            "Epoch 9/10\n",
            "7097/7097 [==============================] - 24s 3ms/step - loss: 16553028.8767 - val_loss: 17912167.3529\n",
            "Epoch 10/10\n",
            "7097/7097 [==============================] - 24s 3ms/step - loss: 16536252.4276 - val_loss: 17891689.1543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f99d0509f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPidjMaGouAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstmClass = Sequential()\n",
        "lstmClass.add(Embedding(5000, 32, input_length=200))\n",
        "lstmClass.add(LSTM(100))\n",
        "lstmClass.add(Dense(1, activation='relu'))\n",
        "lstmClass.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCZVkM4rwE19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "7471a0ad-fe40-4bd8-ae22-cf4430da7726"
      },
      "source": [
        "lstm.fit(data, y, epochs=10, batch_size=10, validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7097 samples, validate on 3042 samples\n",
            "Epoch 1/10\n",
            "7097/7097 [==============================] - 97s 14ms/step - loss: 3.0518 - val_loss: 1.5331\n",
            "Epoch 2/10\n",
            "7097/7097 [==============================] - 97s 14ms/step - loss: 1.0161 - val_loss: 1.3835\n",
            "Epoch 3/10\n",
            "7097/7097 [==============================] - 96s 14ms/step - loss: 0.8807 - val_loss: 1.3918\n",
            "Epoch 4/10\n",
            "7097/7097 [==============================] - 98s 14ms/step - loss: 0.7565 - val_loss: 1.5836\n",
            "Epoch 5/10\n",
            "7097/7097 [==============================] - 97s 14ms/step - loss: 0.6622 - val_loss: 1.5737\n",
            "Epoch 6/10\n",
            "7097/7097 [==============================] - 97s 14ms/step - loss: 0.5858 - val_loss: 1.6101\n",
            "Epoch 7/10\n",
            "7097/7097 [==============================] - 100s 14ms/step - loss: 0.5282 - val_loss: 1.6679\n",
            "Epoch 8/10\n",
            "7090/7097 [============================>.] - ETA: 0s - loss: 0.4839"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S04cpFdJwOqN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54b24361-54f5-4e73-f683-fa3006c3aab9"
      },
      "source": [
        "for _ in desc:\n",
        "  print(_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<p>I\\'m using aptana studio 3 in my mac, osx lion, and I\\'m using rbenv to install rubies, but when I try to run the debugger in aptana I always got this error:</p><p>    /Users/nebiros/.rbenv/shims/ruby: line 4: exec: rbenv: not found</p><p>I already set some environment variables in the aptana ruby debug configuration window:</p><p>    RBENV_ROOT: /Users/nebiros/.rbenv <br/>    RUBYLIB: /Users/nebiros/.rbenv/versions/1.9.2-p290/lib/ruby/1.9.1</p><p>I\\'m trying to run this command:</p><ul class=\"alternate\" type=\"square\">\\t<li>Program: /Users/nebiros/.rbenv/shims/bundle</li>\\t<li>Interpreter Arguments: -d</li>\\t<li>Program Arguments: exec rake dreadful_dog:process_content --trace &#8211; -f ./assets/test_ssss_content.zip -d /tmp</li>\\t<li>Working Directory: /Users/nebiros/Projects/dreadful_dog</li></ul>\n",
            "<p>We need some way to turn off validators individually, and in particular between build vs reconcile. This stems from the poor performance of the JS validators during large builds. They should default to be on for reconcile (only the ones currently on by default) and off for build (likely the same for the CSS/HTML validators). We\\'ll need a preference page similar to the validator pref page we had before (maybe just re-use/fix it to work).</p><p>One suggestion is to reuse the existing pref page and instead have a table at the top with two checkbox columns, one for build and one for reconcile. A less-optimal solution is to have two separate lists, one for each type of interaction.</p><p>Perhaps we should say \"On Typing\" as opposed to \"Reconcile\"? Perhaps that is more user-friendly?</p><p>Tasks:</p><ul>\\t<li>Change the pref page</li>\\t<li>Add some methods/fields to the participants to mark them as validators</li>\\t<li>Use a more sane preference key scheme to store the enable/disable</li>\\t<li>Create a migration function to migrate the old pref keys to the new scheme</li>\\t<li>Some build participants need to be unchangeable or hidden from the end user (like indexing)</li></ul>\n",
            "<p>Currently, the \"File &gt; New From Template\" menu creates a new project-based file or a new file on the filesystem, depending on the active selection in project explorer (defaulting to the project-based behavior)</p><p>Many users want the ability to create a new untitled file. This is possible, but a user would then have to preselect the type of file (i.e. HTML, CSS, etc.). In order to achieve this in Studio 2, we had a selection of wizards that activated and deactivated based on the current selection. This worked, but was a clumsy solution.</p><p>A different proposal is that we, by default, make the \"New From Template\" menu adopt the following behavior:</p><ol>\\t<li>File &gt; New From Template. Creates a new untitled file of the specified type (new behavior)</li>\\t<li>Right-click on project in Project Explorer view. Creates a new project-based file (current behavior)</li>\\t<li>Right-click on file system node in Project Explorer. Creates a new file on the file system (current behavior)</li></ol><p>This links with another ticket to make it easier to save this file into a project or file depending on the user\\'s preference.</p>\n",
            "<p>Steps to reproduce:</p><ol>\\t<li>Copy ext-all-debug.js into a new Web project</li>\\t<li>Open up the file</li>\\t<li>Turn on \"Mark Occurrences\"</li>\\t<li>Click on the first instance of \"function\"</li>\\t<li>note that the annotations in the side bar come up quite quickly, but profiling, it shows a significant performance hit in ThemeingDamagerRepairer.</li>\\t<li>At this point the IDE is unusable for quite some time (10-30 seconds)</li></ol><p>See screenshots for details.</p><p>I noticed that if I only allowed 100 annotations to be created, performance seemed acceptable (though still kinda slow)</p>\n",
            "nan\n",
            "<p>We should display PHP nodes nested correctly inside HTML nodes, and vice-verse.</p>\n",
            "nan\n",
            "<p>Before adopting a newer version of CEF, we need to test whether it will fix the current issues. This can be done independent of Studio. The following steps should be used:</p><p>-Pull CEF/Chromium code<br/>-Run \"cef_create_project.sh\" to create the project<br/>-Run \"make -j4 cefclient BUILDTYPE=Release\" to build the project<br/>-Launch the generated executable</p>\n",
            "<p>Some file types (YAML for instance) don\\'t really have a default template. It basically consists of an empty document just so that we can make sure there is an entry in the New... menu.</p><p>Suggest instead scanning the bundles, and if a file type does not have a template attached, suggest creating a entry \"File Type &gt; Blank File\" for each. This will also make it easier once we convert File &gt; New From Template to create untitled files, and cut down on the number of unnecessary templates created.</p>\n",
            "nan\n",
            "<p>We need a hook into the project creation process to allow post project operations. Currently, we need the following for the extension point:</p><p>-Listener for project creation<br/>-Scoped to project nature<br/>-Prioritized so that multiple listeners will be performed in proper order</p>\n",
            "<p>Then saving a new untitled file, the default mechanism is to bring up the \"Save to File System\" dialog, allowing them to save a file somewhere on their drive.</p><p>This becomes confusing if instead they want to save it into a project.</p><p>Unfortunately, we can not universally add this option to all possible untitled files, but for those derived from our editor classes, we propose to do the following:</p><ol>\\t<li>override the default behavior in AbstractDecoratedTextEditor.performSaveAs()</li>\\t<li>For untitled files, pop up our own dialog asking is the user wishes to save on the file system or in a project (radio button selection). Depending on the choice, we can then pop up the correct subsequent Save As... dialog.</li></ol><p>Extra points if we can somehow embed the other Save as dialogs in the \"choice\" dialog, preventing the user from having to answer two subsequent dialogs.</p><p>Also suggest that we could have the user \"remember this choice\" if they almost always want to do one or the other.</p>\n",
            "<p>When debugging in Studio, it is useful to see more information about the current position of the cursor. Suggest updating the properties view with the following information:</p><p>Depending on the current cursor position, it would show the following:</p><p>Content Type: text/javascript<br/>Scope: source.js<br/>Text: appendPoints <br/>Offset Start: 531<br/>Offset End: 531<br/>Length: 12 characters</p>\n",
            "<p>We support go to declaration on things like type names, method calls, variables. We should support opening the related file on the loadpath for the paths mentioned in require/load calls.</p>\n",
            "\"<p>Attache the analytics ping to the portal 'dispatch'.<br/>The ping should indicate the portal's controller and action (e.g. 'portal.browser.openExternalBrowser')</p>\"\n",
            "<h3><a name=\"StepstoReproduce\"></a>Steps to Reproduce</h3><p>We just upgraded to Studio 3.1.3, and now we get a ton of JSLint errors in our code. (Seems to be because of changes to default settings?)</p><p>We could put the settings into jslint comments to make it work how we want it to, but that would require adding the settings to the 300+ JavaScript files that we have on our site. That is unacceptable.</p><p>We need a place to be able to specify JSLint\\'s settings on a global level. We use JSLint on \"reconcile\" mode, and seeing all of the errors (for things like supposedly \"messy\" whitespace, using multiple \\'var\\' statements, etc) makes the tool downright useless for the actual errors that we need it to catch.</p><h3><a name=\"ActualResult\"></a>Actual Result</h3><p>(See above)</p><h3><a name=\"Suggestedsolution\"></a>Suggested solution</h3><p>Remove the filter box from the validator main page and have the pencil icon open up a new window (similar to how formatting works). See screenshots. For JSLint (and all validators), we would keep a filter text box, as well as have another text box where a user can specify whatever JSLint commands they\\'d like to issue</p><p>I\\'m assuming this would be in the form of a string of options that would then be injected into the comments of a file before parsing.</p>\n",
            "\"<p>We've combined core and UI code in the CSS editor plugin. For proper separation we should split the two apart as we did with the JS plugin.</p>\"\n",
            "<p>We may need to move some NodeJS functionality from Titanium Studio down into Aptana Studio. We built that functionality properly separated into core and UI plugins, and joining them back may cause issues as well as actually breaks proper architecture. As a result, we should split the JS plugin into core and UI properly so we can eventually merge the node stuff down in.</p>\n",
            "\"<p>We've combined core and UI code in the XML editor plugin. For proper separation we should split the two apart as we did with the JS plugin.</p>\"\n",
            "\"<p>We've combined core and UI code in the DTD editor plugin. For proper separation we should split the two apart as we did with the JS plugin.</p>\"\n",
            "nan\n",
            "nan\n",
            "<p>Rails uses a number of class-level methods to attach other methods, such as \"delegate\", \"cattr_accessor\", \"cattr_writer\", \"cattr_reader\", and \"class_attribute\". We don\\'t currently handle these. We\\'ll need to look for calls to these and manually expand the type\\'s method list to include the generated methods that result from calling those.</p>\n",
            "<p>Related to <a href=\"https://jira.appcelerator.org/browse/APSTUD-4799\" title=\"Add portal controller to switch perspective\" class=\"issue-link\" data-issue-key=\"APSTUD-4799\"><del>APSTUD-4799</del></a>, this would be a call to return the currently active perspective.</p>\n",
            "<p>One feature that is sorely missed is Open Type in the Eclipse PHP PDT. Attached is a screenshot of the feature in Eclipse PDT.</p>\n",
            "<p>This ticket involves the investigation of the complexity in replacing JSLint with our own validation framework</p><p><a href=\"http://www.jslint.com/\" class=\"external-link\" rel=\"nofollow\">http://www.jslint.com/</a></p><ol>\\t<li>What rules do we need to encapsulate</li></ol><p>For ease in migration for existing users, it us suggested we accept the current comment-based options that JSLint allows.</p>\n",
            "<ul>\\t<li>Discuss the classes involved and their roles</li>\\t<li>Discuss the hacks put in place to get around issues exposed by jquery-style functions</li>\\t<li>Discuss possibilities for reducing indexing time (particularly not doing any reads during writes)</li>\\t<li>Discuss why the \"Function&lt;&gt;\" wrapper is bad and how it might be removed. This relates to the \"hacks\" mentioned above</li>\\t<li>Discuss the differences in handling of sdocml files during metadata loading versus during indexing. Ideally, these should be treated in the same way.</li></ul>\n",
            "\"<p>We have talked about having different outlines for JS. It may be that the current outline and the JS node in the Index View will cover this topic already, but it's probably worth capturing thoughts here to see how those fit with what we have already.</p>\"\n",
            "<p>We may have documentation on this already, but the most complicated area in the current implementation revolves around visibility events. These events are driven by changes in visibility of commands and such based on bundle precedence rules.</p><ul>\\t<li>We may want to consider removing all notions of augmentation, which would simplify this area a bit</li>\\t<li>Discuss how \"inputs\" and \"outputs\" should be pulled out into extensions to\\t<ul>\\t\\t<li>Improve code</li>\\t\\t<li>Allow other input/output types to be contributed</li>\\t</ul>\\t</li>\\t<li>Discuss a possible way to fix bundle loading issues we\\'ve seen on Windows.\\t<ul>\\t\\t<li>We need to be able to lock the loading of a bundle until its bundle.rb has been processed. This sounds easy, but I think it will have a big impact on the code, unfortunately</li>\\t</ul>\\t</li></ul>\n",
            "<ul>\\t<li>Briefly discuss the notion of \"location type\" and how that is calculated in HTML, CSS, and JS</li>\\t<li>Briefly discuss the notion of \"replacement range\" and how that is calculated in HTML, CSS, and JS</li>\\t<li>Briefly discuss how JS and CSS CA are hacked into HTML</li></ul>\n",
            "<ul>\\t<li>We may want to discuss how items in project build paths should be handled</li>\\t<li>Ideally, each library is indexed only once regardless of how many projects reference it</li>\\t<li>Metadata should be handled with the same system\\t<ul>\\t\\t<li>This may allow metadata files to auto-update on changes instead of relying on the JS index version number we maintain manually right now</li>\\t\\t<li>Then again, changes to the structure of the index content will still require a version number change</li>\\t</ul>\\t</li></ul>\n",
            "<ul>\\t<li>Discuss the recovery strategy interface used by JSParser. Note that these types of recoveries have been exposed in such a way as to make them available to all languages that use Beaver</li>\\t<li>Show examples of how discovery strategies are defined\\t<ul>\\t\\t<li>Discuss rules based on the last good token</li>\\t\\t<li>Discuss rules based on the current failed token</li>\\t</ul>\\t</li>\\t<li>Suggest how the parser can stand alone and be integrated into the IDE. The current stand alone version of JSParser was a quick-and-dirty extraction from Eclipse purely to allow Bryan to start working with it to see if it will work for his needs.</li></ul>\n",
            "<ul>\\t<li>Discuss the general structure of the Beaver files we have.</li>\\t<li>Briefly describe the process of generating a parser from a Beaver grammar. This is how you run it from the command-line or within Eclipse to generate the associated files.</li></ul>\n",
            "\"<p>We had tried to come up with a system for JSCA that was comparable to how our XML metadata works: SAX-like parsing and event driven handlers. However, the result is much too complicated and harder to maintain than it should be.</p><p>It's worth documenting how the handler works at a minimum. Additionally, it might be good to discuss an alternate approach, that, although tied directly to the JSCA structure, is easier to maintain and update.</p>\"\n",
            "<ul>\\t<li>Discuss the general structure of the jflex files we have. I think someone familiar with regular expressions could pick up jflex really quickly and this could be a good head start for them</li>\\t<li>Briefly describe the process of generating a scanner from a jflex file. This is how you run it from the command-line or within Eclipse to generate the associated Java file.</li>\\t<li>Discuss how jflex scanners are modified to work with Beaver</li></ul>\n",
            "<p>During the Aptana Studio and Titanium Studio build process, we need to create a set of JavaDocs to make it easier for end users to navigate and understand.</p><p>This ideally is placed into a \"javadocs\" folder in this area <a href=\"http://hudson-master.hdqt.appcelerator.com/hudson/job/studio3-feature-master/lastSuccessfulBuild/artifact/build-artifacts/\" class=\"external-link\" rel=\"nofollow\">http://hudson-master.hdqt.appcelerator.com/hudson/job/studio3-feature-master/lastSuccessfulBuild/artifact/build-artifacts/</a>, so that they can be uploaded as part of the nightly sync. There should be some set of ANT tasks we can use to generate the docs.</p><p>We also need to replace the default stylesheet with the JBoss one: <a href=\"https://community.jboss.org/wiki/JBossorgStylesheetsForJavadocAndJXRXrefReports?_sscc=t\" class=\"external-link\" rel=\"nofollow\">https://community.jboss.org/wiki/JBossorgStylesheetsForJavadocAndJXRXrefReports?_sscc=t</a></p>\n",
            "<p>We should add a command-line option to allow for sequential loading of bundles. It would make testing much easier.</p><p>It could either be to load all bundles sequentially, or it could enforce a maximum number of bundles that can be loaded at a time (which I would set to 1), something like:</p><p>studio.loadBundlesSequentially, or studio.bundleLoadConcurrency</p><p>Note, I also believe BundleManager.loadBundle() does not properly respect the wait parameter. Unless you are unit testing, it does nothing. </p>\n",
            "<p>In general, when logging a file, we most care about the product version (i.e. 3.0.8) as opposed to the version of the plugin (i.e. build 3.0.0.1326742432) which may not change as frequently as the product version. Update IdeLog to use the RCP/Plugin product version instead.</p>\n",
            "<p>Our current implementation of our JS parsing infrastructure does not allow the parser to be run outside of Eclipse. We need to extract the minimal set of classes that will de-couple our implementation from Eclipse and allow the parser to be run from the command-line. This code and any scaffolding should live in a separate repository.</p>\n",
            "<p>Given the following:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<thead>\\t\\t\\t<tr id=\"syntaxplugin_title\">\\t\\t\\t<td bgcolor=\"#f5f5f5\" style=\"font-family: Arial,sans-serif; color: #333; border-bottom: 1px solid #bbb; background-color: #f5f5f5 !important; font-weight: bold; line-height: 1em;\" >\\t\\t\\t\\t<p style=\"margin: 5px 10px; padding: 0;\">MyModule.js</p>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</thead>\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">exports.sayHello = function(name) {</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    Ti.API.info(\\'Hello \\'+name+\\'!\\');</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">};</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">exports.version = 1.4;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">var myModule = require(\\'MyModule\\');</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">myModule.sayHello(\\'Kevin\\'); //CA prompts \"sayHello\" and ContextInfo for \"name\" parameter</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>We present content assist against the functions and properties defined in the module file</p><ul>\\t<li>This would require changing the index to show what individual files require and filtering that in content assist.</li></ul>\n",
            "<p>It appears that the samples are being loaded twice from Rubles. I have my whole of samples list deleted (but then it\\'s re-added). Turn on the relevant troubleshooting items and restart Studio to see the following log messages:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:42.008</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.kitchensink.ipad; name = Kitchen Sink iPad</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:42.010</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.kitchensink; name = Kitchen Sink</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:42.010</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.kitchensink.nook; name = Kitchen Sink Nook</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:42.011</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.rss; name = RSS Reader</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:42.011</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.mapping; name = Geocoder</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:42.011</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.todo; name = Todo List</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:48.830</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Removed all existing samples</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:48.835</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager adding the list of samples</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:48.835</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.mapping; name = Geocoder</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:48.835</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.rss; name = RSS Reader</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:48.836</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.todo; name = Todo List</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:48.837</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.kitchensink; name = Kitchen Sink</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:48.849</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.kitchensink.nook; name = Kitchen Sink Nook</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!ENTRY com.aptana.samples 1 0 2012-04-14 05:08:48.850</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!MESSAGE (Build 3.0.0.qualifier) [INFO] com.aptana.samples/debug/manager Added sample: id = com.appcelerator.titanium.mobile.samples.kitchensink.ipad; name = Kitchen Sink iPad</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I get a script loaded event for /Users/ingo/Documents/Projects/Aptana/rubles/text.ruble/bundle.rb which deletes all my samples. It seems like we should only delete (and re-add) the samples associated with my bundle, not the whole lot.</p><p>FWIW, TemplateManager seems to only listen for ElementVisibility. When I comment out the load-cycle listener, it seems to still work fine and I don\\'t get the add/remove/add. Also, If it do the same ModelFilter and comment out the remove part of loadBundleSampleElements() (make it the same effectively as loadTemplatesFromBundles()) It also seems to work fine for me.</p>\n",
            "<p>This probably should be something both on the home page, in the views, and also perhaps a popup?</p><ol>\\t<li>Tell them about the new features</li>\\t<li>Direct them on how to install the new version</li>\\t<li>Show them the migration guide</li></ol>\n",
            "<p>When writing out the following to the log file, we should at least write out the name of the documentation file, and if possible <em>something</em> about where in the file the error occurs (line #, character count, anything)</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">(Build 3.0.3.qualifier) [ERROR]  An error occurred while parsing the documentation XML file. The value of attribute \"name\" associated with an element type \"null\" must not contain the \\'&lt;\\' character.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">java.lang.Exception: An error occurred while parsing the documentation XML file. The value of attribute \"name\" associated with an element type \"null\" must not contain the \\'&lt;\\' character.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat com.aptana.editor.common.contentassist.MetadataReader.loadXML(MetadataReader.java:216)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat com.aptana.editor.js.contentassist.index.SDocMLFileIndexingParticipant.index(SDocMLFileIndexingParticipant.java:52)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat com.aptana.core.internal.build.IndexBuildParticipant.buildFile(IndexBuildParticipant.java:83)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat com.aptana.core.build.UnifiedBuilder.buildFile(UnifiedBuilder.java:322)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat com.aptana.core.build.UnifiedBuilder.buildFiles(UnifiedBuilder.java:306)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat com.aptana.core.build.UnifiedBuilder.fullBuild(UnifiedBuilder.java:265)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat com.aptana.core.build.UnifiedBuilder.build(UnifiedBuilder.java:122)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.events.BuildManager$2.run(BuildManager.java:728)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:199)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:239)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.events.BuildManager$1.run(BuildManager.java:292)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:295)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.events.BuildManager.basicBuildLoop(BuildManager.java:351)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.events.BuildManager.build(BuildManager.java:374)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.resources.Workspace.buildInternal(Workspace.java:513)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.resources.Workspace.build(Workspace.java:422)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat com.aptana.editor.js.JSMetadataLoader$1.run(JSMetadataLoader.java:139)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tat org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "nan\n",
            "<p>Now that the servers view is back, we should hook up the rails application launching to use it as it used to in RadRails.</p>\n",
            "\"<p>Currently, we prompt the user for an install of Firefox if we can't find it at startup. We should instead do the check and install if they've chosen to debug with Firefox.</p>\"\n",
            "<p>PDT has an \"Open Method\" that allows the user to navigate to any method/class in any PHP file in a project/workspace.  This makes it a lot easier to locate a particular method or browse methods when looking the right method to use.  The list of methods is filterable (find as you type) and allows wildcards (<tt>*</tt>) as well to allow more flexible method listings.</p><p>Now that Aptana Studio 3 conflicts with PDT so that PDT\\'s editor no longer works properly, it would be great if Aptana Studio added this feature to further round out the workflow that was lost from PDT.</p><p>For reference, the \"Open Method\" feature in PDT is launched via the following shortcut by default: <tt>CTRL+SHIFT+M</tt></p>\n",
            "<p>Ctrl + Clicking on a function in JavaScript, or pressing F3 on a selected function should take the user to the definition. Suggest adopting similar functionality from Studio 2.</p>\n",
            "<p>We duplicate \"path\", \"scope\" and \"customProperties\" key values in bundle model elements. Using a StringPool to reuse equal strings would help bring down our memory usage quite a bit there. Long-term we may want to handle freeing the strings from the pool in a smarter way when the referring elements themselves are removed (say a bundle gets removed) - but the effort required given that unusual/unlikely use case may not warrant it.</p><p>Secondly, we should use  StringPool for a lot of the duplicated string values in PHP builtins. We\\'re already hanging onto the entire thing in memory, so having them live in a StringPool that lives as long as the plugin won\\'t actually make it any worse. We\\'d have to remove the pool if we ever refactored to persist the index to disk like we do in core. </p>\n",
            "<p>From <a href=\"https://wiki.appcelerator.org/display/tools/In-Studio+Documentation\" class=\"external-link\" rel=\"nofollow\">https://wiki.appcelerator.org/display/tools/In-Studio+Documentation</a></p><div class=\"panel\" style=\"border-width: 1px;\"><div class=\"panelHeader\" style=\"border-bottom-width: 1px;\"><b>Properties</b></div><div class=\"panelContent\"><p>@name: @type-of-property (i.e. Boolean)<br/>//description</p><p>Supported Platforms: browser/@platform: browser/@version</p></div></div><div class=\"panel\" style=\"border-width: 1px;\"><div class=\"panelHeader\" style=\"border-bottom-width: 1px;\"><b>Functions</b></div><div class=\"panelContent\"><p>@name(parameter/@name: parameter/@type, ...): @return-type-of-function<br/>//description</p><p>Supported Platforms: browser/@platform: browser/@version</p></div></div>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Let me choose them which I need!</p>\n",
            "<p>Hi friends,<br/>i just upgraded my computers to the new ubuntu release and now i have some troubles with the XULRunner based parts of Aptana. In all new releases of all major Linux distributions the XULRunner packages are disabled because of some seriously security issues. I asked in the #ubuntu irc why the package is removed from the current version and they told me that. They forwarded me to the Mozilla Website where they wrote that sience Firefox 4 the XULRunner is disables be default because of this security issues. (1.9.2 is only for Firefox 3.*)</p><p>I know it\\'s very much to ask, but i think it\\'s a good idea if Aptana could run without the XULrunner. It\\'s for advanced users not a big problem to reinstall the libs directly from the page, but if it\\'s a mayor security rist, i think twice about that. And if i don\\'t du that, the complete GIT integration is nut useable and i only got some error messages like that here:</p><blockquote><p>Unhandled event loop exception<br/>No more handles <span class=\"error\">&#91;Unknown Mozilla path (MOZILLA_FIVE_HOME not set)&#93;</span></p></blockquote><p>Here are the IRC logs</p><blockquote><p>(17:57:53) Leo Unglaub: hi, can someone please explain to me why the xulrunner ins available in natty, but in the new version not?<br/>(17:58:01) Leo Unglaub: <a href=\"http://packages.ubuntu.com/de/natty/xulrunner-1.9.2\" class=\"external-link\" rel=\"nofollow\">http://packages.ubuntu.com/de/natty/xulrunner-1.9.2</a><br/>(17:58:28) cajunspice: xul is a major security risk<br/>(17:58:48) Leo Unglaub: cajunspice: have you sources where i can read more about this?<br/>(17:59:50) cajunspice: I saw it on the mozilla site, leo-unglaub, xul was such a risk that in firefox 4.0 and above remoe xul is disabled<br/>(18:00:12) Leo Unglaub: cajunspice: ah, okay<br/>(18:01:13) cajunspice: leo-unglaub: it appears it will be staying disabled, because remote xul is too much of a backdoor<br/>(18:01:36) Leo Unglaub: cajunspice: okay, thanks !</p></blockquote><p>Greetings<br/>Leo</p>\n",
            "<p>Currently Samples view defines the actions programmatically using the old IAction mechanism, and they are not accessible through the command service.  We should update them to be defined through plugin.xml using commands and handlers.</p>\n",
            "\"<p>There are 1.9 syntax fixes int he latest jrubyparser source. I'll need to clone it, compile, put the new binaries in our plugin and then perform any fixes afterwards as a result of any API changes.</p>\"\n",
            "<p>From <a href=\"https://wiki.appcelerator.org/display/tools/In-Studio+Documentation\" class=\"external-link\" rel=\"nofollow\">https://wiki.appcelerator.org/display/tools/In-Studio+Documentation</a></p><div class=\"panel\" style=\"border-width: 1px;\"><div class=\"panelHeader\" style=\"border-bottom-width: 1px;\"><b>Properties/Variables</b></div><div class=\"panelContent\"><p>&#64;name: &#64;type - path/to/declaration/locationa, path/to/declaration/locationb, ... <br/>//description </p><p>Supported Platforms<br/>browser/&#64;platform: browser/&#64;version, ...</p><p>Remarks<br/>remarks</p><p>Example<br/>example[1]</p><p>Specification<br/>specification/&#64;name: specification/&#64;version</p></div></div><div class=\"panel\" style=\"border-width: 1px;\"><div class=\"panelHeader\" style=\"border-bottom-width: 1px;\"><b>Functions</b></div><div class=\"panelContent\"><p>&#64;name(parameter/&#64;name: parameter/&#64;type, ...): &#64;type - path/to/declaration/locationa, path/to/declaration/locationb, ... <br/>//description </p><p>Supported Platforms: browser/&#64;platform: browser/&#64;version</p><p>Remarks<br/>remarks</p><p>Example<br/>example[1]</p><p>Specification<br/>specification/&#64;name: specification/&#64;version</p></div></div>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "\"<p>Our current unit test coverage hovers around 30% (class, method, block, and line) We need to get this higher.</p><p>Here are the classes we need to test: Please create a sub-task for the class you want to test, and edit the document to indicate you've claimed that test. If there already is a task created for a particular class, it means someone else has claimed that one, so choose another. If there are a bunch of related classes, you can group that into one task.</p><p>Coverage goals for all classes below is a <em>minimum</em> of 100% class, 70% method, 80% block, 80% line (default Emma values in Jenkins)</p><ul>\\t<li>com.aptana.core.util\\t<ul>\\t\\t<li>KeepAliveObjectPool</li>\\t\\t<li>ObjectPool</li>\\t\\t<li>ReapingObjectPool</li>\\t\\t<li>StreamUtil</li>\\t\\t<li>URIUtil</li>\\t</ul>\\t</li></ul>\"\n",
            "<p>I have a feeling there\\'s plenty of low hanging fruit in terms of our memory usage. I read this article and it seems to be pretty easy to get a quick grasp of where we\\'re wasting RAM:</p><p><a href=\"http://www.ibm.com/developerworks/java/library/j-codetoheap/index.html\" class=\"external-link\" rel=\"nofollow\">http://www.ibm.com/developerworks/java/library/j-codetoheap/index.html</a></p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Related to bug <a href=\"https://jira.appcelerator.org/browse/APSTUD-3457\" title=\"[Speed Improvement] Cache scopes per partition at DocumentScopeManager.getTokenScopeFragments\" class=\"issue-link\" data-issue-key=\"APSTUD-3457\"><del>APSTUD-3457</del></a>, we need to confirm that all Token Scanners have been updated such that querying the scanner multiple times for the same token results in the same returned length and offset.</p>\n",
            "<p>We currently use JRuby 1.6.3 which has at least one bug causing issues for Turkish users.</p>\n",
            "nan\n",
            "\"<p>I use php editor, so everything below is about it.</p><p>In old Aptana there was a two great features, that I was using regulary:</p><ul>\\t<li>Ouline shows a parent methods and classes. And there was an possibility to find some method with search bar(in outline) and jump to it right from quick outline (new tab scrolled to the selected method or class was opened)</li>\\t<li>I was able to jump to parent method from the editor - a litle green triangle was displayed near the inherited method (on the left sidebar. Just right to the line numbers) and a new tab was opened when Ctrl+click on it (or just click, can't remember). Newly opened tab was scrolled to the selected method, just like the outline 'jump to parent' feature.</li></ul><p>Will this features return in the new Aptana Studio?</p>\"\n",
            "<p>A customer is requesting to add \"http\" git access in TiStudio.</p><p>Sometimes, if you are behind a firewall, git is inaccessible this way</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">git clone git@github.com:appcelerator/KitchenSink.git</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>but you can still use \"http\"</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">git clone http://github.com/appcelerator/KitchenSink.git</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The \"http\" is not currently working in Ti Studio.</p><p>This is a feature request to add it.</p>\n",
            "<p>The default PMD profile is too strict for our purposes. Create a default PMD profile all developers can use to validate code correctness before checkin. Please create a profile, run it against some of our current source code to see if it reports what is expected, and pass it around to the other developers for confirmation.</p>\n",
            "<p>This will give an overview of what it takes to build the product and watch its progress:</p><p><a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Build+Pipeline+Plugin\" class=\"external-link\" rel=\"nofollow\">https://wiki.jenkins-ci.org/display/JENKINS/Build+Pipeline+Plugin</a></p><ul>\\t<li>Install the build plugin</li>\\t<li>Configure it based on the studio3 build for master, release and development.</li></ul>\n",
            "<p>When using Subclipse to merge some revisions, there\\'s a view \"Merge Results\" where the merged files are listed. With Aptana 2.x it was possible to Upload the files directly from that view using the ftp connections. </p><p>In Aptana 3.x there\\'s no menu entry to upload the files from that view: You have to search each of the merged files or directories in the Project Explorer (or App Explorer) and upload it there.</p><p><b>There should be the \"Deploy\" Menu Entry in the context menu of the \"Merge Results\"-View.</b></p>\n",
            "<p>This is something that was shipped with 1.5 (skipped out on 2.0 so don\\'t know if it\\'s there). Don\\'t know if this is planned for 3.0 (on the product page I\\'ve seen that JS debugging is coming soon),<br/>yet it would be great if this were to be found into Aptana again (same goes for the ability to run a script through the PHP parser to get the output).</p><p>I\\'ve found the debugger to be one of the main Aptana features I use during my lectures (I\\'m a lecturer at a technical university), helping the students to understand what\\'s going on on \"the inside\" of a PHP process.</p>\n",
            "\"<p>Support watch expressions in ruby. Looks like we can just port the RDT impl over easily. It's a single class with a couple nested classes in it, and it gets registered via a debug.core extension point.</p>\"\n",
            "<p>Amend the current hover tooltip to add a link the HTML documentation for the specified item (if available).</p><p>For core HTML, JavaScript and CSS functionality where the documentation is provided by standard metadata files, the URL can be constructed to point to In-Studio help. See Studio 2 for an example of this:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/**</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">* </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">* @param topics</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">* @param lowerName</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">*/</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">private void addSelectorHelpTopics(ArrayList topics, ArrayList generalTopics, String lowerName) {</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tElementMetadata el = environment.getElement(lowerName);</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tString anchor = \"\"; //$NON-NLS-1$</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tif(el != null)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        {</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\t   anchor = el.getFullName();</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\t   String url = \"/com.aptana.ide.documentation/html/reference/api/CSS.element.\" + el.getFullName() + \".html\"; //$NON-NLS-1$ //$NON-NLS-2$</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">           HelpResource hr = new HelpResource(\"\\'\" + lowerName + \"\\' Selector\", url); //$NON-NLS-1$ //$NON-NLS-2$</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\t   topics.add(hr);</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\t}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\t\\t</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tHelpResource index = new HelpResource(\"CSS Selector Reference\", \"/com.aptana.ide.documentation/html/reference/api/CSS.index-elements.html#\" + anchor); //$NON-NLS-1$ //$NON-NLS-2$</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\tgeneralTopics.add(index);</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>For other elements (like Titanium properties) perhaps there is a mechanism by which we can provide a custom resolver to generate the URL. It could also be that this might be provided by an extension point or class property when the contribution happens.</p><p>See <a href=\"https://wiki.appcelerator.org/display/tools/In-Studio+Documentation\" class=\"external-link\" rel=\"nofollow\">https://wiki.appcelerator.org/display/tools/In-Studio+Documentation</a> for details.</p>\n",
            "<p>Related to <a href=\"https://jira.appcelerator.org/browse/APSTUD-7238\" title=\"Create &quot;push-studio3-stable&quot; Jenkins build\" class=\"issue-link\" data-issue-key=\"APSTUD-7238\"><del>APSTUD-7238</del></a>. As part of that build, (before the push):</p><ul>\\t<li>Find the version # in the version.txt file</li>\\t<li>See if that git tag has not already been created. If not, create a new tag of the form \"vX.X.X.XXXXX\" (note the additional \"v\" at the front)</li>\\t<li>Push the tag to the following repos:\\t<ul>\\t\\t<li>studio3</li>\\t\\t<li>studio3-rcp</li>\\t\\t<li>studio3-php</li>\\t\\t<li>studio3-ruby</li>\\t\\t<li>Pydev</li>\\t\\t<li>libraries_com</li>\\t\\t<li>swt-webkit</li>\\t\\t<li>aptana/*.ruble</li>\\t</ul>\\t</li></ul>\n",
            "<p>An analogue of <a href=\"http://hudson-master.hdqt.appcelerator.com/hudson/job/push-titanium-stable/\" class=\"external-link\" rel=\"nofollow\">http://hudson-master.hdqt.appcelerator.com/hudson/job/push-titanium-stable/</a>.</p><ul>\\t<li>Runs the hudson@hudson-master.hdqt.appcelerator.com/studio3-release script</li>\\t<li>Users will need to read the console log to copy the routes into download.aptana.com</li></ul>\n",
            "<p>This makes the latest version of Rubles available to all Studio users. This runs two git commands as part of the build script:</p><ul>\\t<li>Merge all aptana/*.ruble projects from the master to the stable branch</li>\\t<li>Push the results back to Github</li></ul>\n",
            "<p>On PHP editor the syntax highlighting disappears after some characters making all text white (I suppose the default text color).</p><p>Bug happens with any themes.<br/>Bug happens with / without word-wrap.</p>\n",
            "<p>Editor does not allow setting of ruby breakpoints in haml view templates on lines with ruby code (starting with = and -)</p><p>These ruby code lines should be breakpointable just like in erb templates.</p><p>If there is a workaround, please describe in detail.</p><p>Thanks,<br/>tv/</p>\n",
            "\"<p>We ran into an issue with PATH holding cygwin paths on Windows breaking git clones. I added a method to convert between the two, but we need to make sure we convert anywhere we're not executing inside the Terminal/bash.</p>\"\n",
            "\"<p>We are now generating Javadocs for the Studio and Titanium core plugins as part of our continuous 'release' builds. We should publish the latest versions out for nightlies.</p><p>The docs live in the build-artifacts/docs folders of the studio3-core-release and titanium-core-release builds.</p>\"\n",
            "<p>In Aptana Studio, we have various complains about how long it takes for Studio to index a set of files. Suggest adding trace-level logging for users to be able to turn on/off additional information about how long indexing is taking.</p>\n",
            "<p>Mac OS X Lion has a full screen feature for a lot of native apps. It would be great for Aptana to have a feature like this.</p>\n",
            "<p>We replaced the individual logError calls in plugins with calls to IdeLog.logError(). Some of the deprecated original calls still remain in the ScriptingActivator plugin.</p>\n",
            "\"<p>The MozillaJS validator simply runs the source through the Rhino parser. It appears to be giving us no extra benefit that we don't already get (or can't get) from our own parser. If that is the case, we can remove some deadweight code and possible performance issue.</p>\"\n",
            "<p>When sharing a local project with a new Github repo, a user is instructed to do the following:</p><ol>\\t<li>git remote add origin git@github.com:username/project.git</li>\\t<li>git push -u origin master</li></ol><p>The first one can be done inside studio with \"Add remote\" but not the second one, where the user is forced into the terminal. Chris suggested a \"Push new Branch to Remote\" menu option to help with this step.</p>\n",
            "<p>We pre-populate the additional info popup strings for every Javascript CA proposal. If we implement ICompletionProposalExtension5 we can return the additional proposal info for PropertyElementProposal on-demand, which saves us generating all of the strings in advance and instead populating it when the particular proposal is selected.</p>\n",
            "\"<p>Currently there is only an option to cloak file types from the deployment assistent. But very often it's not only file types with sould be excludet. For an example. I have a PHP project remote and local, i have for example local other usernames and passwords for the database connection. So i have to skip on every deployment the system/config/dbconfig.php or i would kill the live system. Currently there is no way, because cloaking *.php is not realy an option.</p><p>I think a textfield where i can store the complete path would be very useful. The syntax could be like in an .gitignore file.</p>\"\n",
            "<p>Hi friends,<br/>i would be very nice if Aptana would support multiple (scripting) languages in one file. In the current aptana version a *.php file supports syntax highliting and auto completion for php source. In *.html files we have the support for HTML. But very often you have template files where the markup is mixed. I addet you an example as attachment.</p><p>In this example i have a .html file and the full html support, but the php code is not realy good readable and i have no support for php functions, ... . So it would be very cool if aptana would see that in the html file the &lt;?php starts php code and switch to the php syntax mode for this part. The same think is possible with inline css code.</p><p>What do you think?<br/>thanks and greetings<br/>Leo</p>\n",
            "<p>Currently, when adding a remote, we default to:</p><p>git://github.com/username/project.git, which is read-only</p><p>Suggest instead we default to:</p><p>git@github.com:username/project.git, which is read-write</p><p>Alternately, we might ask the user if they are a contributor to the project, or just an observer, and perhaps offer a switch betwen the two optons</p>\n",
            "nan\n",
            "<p>Separation for PHP element colouring (Public, Private, Abstract, Static, etc., etc.)</p>\n",
            "{html}&lt;div&gt;&lt;p&gt;From the current system:&lt;/p&gt;<br/>&lt;pre&gt;<br/>&lt;code class=\"ruby\"&gt;template \"Custom Template\" do |t|<br/>  t.filetype = \"*.html\"<br/>  t.invoke do |context|<br/>    ENV<span class=\"error\">&#91;&#39;TM_DATE&#39;&#93;</span> = Time.now.strftime(\"%Y-%m-%d\")<br/>    raw_contents = IO.read(\"#{File.dirname(ENV[\\'TM_BUNDLE_SUPPORT\\'])}/templates/html5.html\")<br/>    raw_contents.gsub(/\\\\${(<span class=\"error\">&#91;^}&#93;</span>*)}/) {|match| ENV[match[2..-2]] }<br/>  end<br/>end&lt;/code&gt;<br/>&lt;/pre&gt;<br/>&lt;p&gt;bringing it inline with something like project templates:&lt;/p&gt;<br/>&lt;pre&gt;<br/>&lt;code class=\"ruby\"&gt;project_template \"Basic Web Template2\" do |t|<br/>  t.type = :web<br/>  t.location = \"templates/basic_web_template.zip\"<br/>  t.description = \"A basic template which includes only a default index.html file\"<br/>end&lt;/code&gt;<br/>&lt;/pre&gt;<br/>&lt;p&gt;i.e.:&lt;/p&gt;<br/>&lt;pre&gt;<br/>&lt;code class=\"ruby\"&gt;template \"Custom Template\" do |t|<br/>  t.filetype = \"*.html\"<br/>  t.location = \"templates/html5.html\"<br/>end&lt;/code&gt;<br/>&lt;/pre&gt;<br/>&lt;p&gt;By default this WOULD DO environment substitution.&lt;/p&gt;&lt;/div&gt;{html}<p>Also add a \"replace_parameters\" setting to allow turning on/off parameter substitution (identical to project templates)</p>\n",
            "<p>Currently, we sort of mix type info and lexical info in the JS outline. We should create a separate view that shows type information from the JS index for the currently active project. This would be separate from the outline view.</p>\n",
            "nan\n",
            "<p>We need to be able to explicitly push tags to a remote.</p>\n",
            "<p>It would be really nice to add the ability to Tag releases in GIT using the Aptana menu items. Currently you can add Branches, Push, Pull, Commit, etc. but there is no support for tagging.</p><p>The workaround right now is to open the terminal console and manually type in something like this:</p><p>git tag -a 1.23 -m \"1.23\"<br/>git push --tags</p><p>It would really save me time if we could just do this from the dialog menus.</p><p>Thanks for considering this feature!</p><p>Sincerely,<br/>Leighton Whiting</p>\n",
            "<p>The unit test build on development takes way too long. Typically over 40 minutes. We need to investigate to see if we can help speed it up at all, since the actual text execution appears to take less than 9 minutes.</p>\n",
            "\"<p>We currently have no action/command/UI support for doing cherry-picks for Git, so I have to resort to the command line for this. It'd be nice to add it.</p>\"\n",
            "<p>3.0.x/1.0.x are built against Eclipse 3.6.2.  For 3.1/1.1, it makes sense to move to Eclipse 3.7.1 and drop support for Eclipse 3.5.</p>\n",
            "\"<p>Improve these Unitests at the 'participant' branch:</p><ul>\\t<li>ParserPoolFactory - No coverage</li>\\t<li>ParseState - 78% (addProperty - 0%, toString - 0%)</li>\\t<li>ParserPool - 79.3% (create - 50%)</li>\\t<li>AbstractBuildParticipant - 94.3%</li>\\t<li>ReconcileContext - 43.9% (openInputStream - 0%)</li>\\t<li>UnifiedBuilder - 0%</li>\\t<li>BuildParticipantManager - 61.3% (getAllBuildParticipants - 0%)</li>\\t<li>IndexBuildParticipant - 44.8% (clean - 0%, deleteFile - 0%, getURI - 26.9%)</li>\\t<li>CSSFileIndexingParticipant - 97.1%</li>\\t<li>CSSTaskDetector - 78.4% (deleteFile - 0%)</li>\\t<li>CSSValidator - 89.3%</li>\\t<li>HTMLTidyValidator - 83%</li>\\t<li>HTMLTaskDetector - 92.7%</li>\\t<li>JSParserValidator - 87.5%</li>\\t<li>JSFileIndexingParticipant - 48.5% (processParseResults - 47.3%)</li>\\t<li>JSCAFileIndexingParticipant - 75.9% (index - 72.9%)</li>\\t<li>JSTaskDetector - 79.8% (deleteFile - 0%)</li>\\t<li>IndexManager - 83.8%</li>\\t<li>AbstractFileIndexingParticipant - 12.3% (almost all methods - 0%)</li>\\t<li>FileStoreBuildContext - 75.6% (getFile - 0%, getProject - 0%)</li>\\t<li>BuildContext - 85.3%</li>\\t<li>IndexContainerJob - 0% (all)</li>\\t<li>IndexProjectJob - 0% (all)</li>\\t<li>IndexFilesOfProjectJob - 58.2% (run - 45%)</li>\\t<li>IndexRequestJob - 44.1% (getFileContributors - 0%, belongsTo - 0%)</li></ul>\"\n",
            "\"<p>Hi,<br/>it would be very usefull if i could drag some files or folders from the remote view to a local folder on the desktop or any other folder in the fiel browser. The other way from the local folder to the remote view already works fine!</p><p>This would be very usefull if you have to download some files without to configure the ftp connection in filezilla or any other FTP Client.<br/>I searched for already reported tickets, but don't found anythink. If i missed it, sorry for that!</p><p>Greetings<br/>Leo</p>\"\n",
            "<p>I may be just missing the setting, but it there somewhere in Aptana where I can set the number of simultaneous file transfers to speed up FTPing folders or large numbers of files?  For example, in Filezilla, I can download/upload 5-7 files at once, which greatly speeds up transfer times.  Is this possible?</p>\n",
            "<p>As the title says, make the default setting off.</p>\n",
            "<p>Set the default for this setting as \"off\"</p>\n",
            "<p>Related fix for <a href=\"https://jira.appcelerator.org/browse/APSTUD-3390\" title=\"Snippet tab stops fail, cause IllegalStateException: model is already installed\" class=\"issue-link\" data-issue-key=\"APSTUD-3390\"><del>APSTUD-3390</del></a>....needs a set of unit tests.</p>\n",
            "<p>Should make it more similar to how project template is defined, where the local path is a zip file instead of the root of a directory where the samples reside.</p>\n",
            "<p>Create a \"quick\" button on the toolbar for Aptana option \"Show white space characters\", please<br/>Not easy go to the menu every time for Show/Hide white space characters</p>\n",
            "<p>The dependency is causing a lot of inconvenience on what com.aptana.index.core could depend on and should be removed.</p>\n",
            "<p>The default FindBugs profile is too strict for our current code base. We need to create a more limited profile that we can use to validate all committed code for possible errors. Please create a profile, run it against some of our current source code to see if it reports what is expected, and pass it around to the other developers for confirmation.</p>\n",
            "nan\n",
            "<p>Two different related scenarios here:</p><p>1- Steps to reproduce: Enter &lt;video /&gt; in an HTML edit window</p><p>Actual result: Errors window shows \"video is not recognized!\"<br/>Expected result: Errors window shows something like \"Self-closing syntax (/&gt;) used on a non-void HTML element.\"</p><p>2- Steps to reproduce: Enter &lt;div /&gt; in an HTML edit window</p><p>Actual result: No result (no error is displayed)<br/>Expected result: Errors window shows something like \"Self-closing syntax (/&gt;) used on a non-void HTML element.\"</p>\n",
            "<p>Add JS formatting options to control the spaces between the JS elements.</p>\n",
            "<p>Rather than having formatter settings apply to all projects globally, allow for per-project settings.</p>\n",
            "<p>Sometimes we have AST nodes which we want to denote structure or something internally but make no sense in the outline. We should have a field and code in common to easily \"skip\"/\"flatten\" these node types (i.e. Ruby\\'s blocks, we want the vars inside but we don\\'t want to show the block; if/for/else/switch) - in this case meaning, don\\'t show this node, but do show relevant children.</p>\n",
            "<p>In Studio 2, we could custom color the area where line numbers and folding markers site (see image). We seem to have lost this ability in Studio 3.</p>\n",
            "<p>Would be great to allow to manually change content assist delay to 0 (for JS and CSS editors).<br/>It\\'s very annoying to, for example, type \"b\", then wait for CA to apear, then type \"o\" to get to \"border\". And when typing \"bo\" quickly CA will not appear at all.</p><p>See this thread <a href=\"https://aptanastudio.tenderapp.com/discussions/problems/3318-306-cssjs-code-hinting-broken-after-update\" class=\"external-link\" rel=\"nofollow\">https://aptanastudio.tenderapp.com/discussions/problems/3318-306-cssjs-code-hinting-broken-after-update</a></p>\n",
            "<p>This comes from trying to close <a href=\"https://jira.appcelerator.org/browse/APSTUD-46\" title=\"Via Tender: Javascript click through leads to...WTF?\" class=\"issue-link\" data-issue-key=\"APSTUD-46\"><del>APSTUD-46</del></a>, which must have been a Studio 2.x ticket.</p><p>We should support Ctrl+Clicking to go to definition for Javascript functions, variables, properties.</p>\n",
            "<p>This would crib from the Titanium Studio start page with a few differences:</p><ul>\\t<li>The page should show on first startup, and after each update.</li>\\t<li>The page would contain the following content:\\t<ul>\\t\\t<li>Link to documentation</li>\\t\\t<li>Link to how to install SVN, DB, other plugins</li>\\t\\t<li>Link to how to install a JS library</li>\\t\\t<li>Link (or iframe) of release notes for latest released version</li>\\t\\t<li>Link/iframe of Stack Overflow questions</li>\\t</ul>\\t</li></ul>\n",
            "<p>The attached dialog below seems a tiny bit confusing. In order to <em>not</em> use a template, you can leave the \"Create the project using...\" box checked, but not choose a template.</p><p>Suggest two options:</p><ol>\\t<li>Leave the checkbox, but don\\'t check it until a user has actually selected a template from the list</li>\\t<li>Remove the checkbox, and instead add a \"No Template\" as the top option in the list, which is selected by default.</li></ol>\n",
            "<p>InstanceScope() and DefaultScope() constructors have been deprecated in Eclipse 3.7. However, the replacement methods (InstanceScope.INSTANCE) is only available in Eclipse 3.7, so we cannot universally switch to it yet. Adding @SuppressWarnings(\"deprecation\") to all usages is problematic, since it will display \"Unused annotation\" in Eclipse 3.6</p><p>Suggest making wrapper methods for the above items and adding a single @SuppressWarnings to those instances. Thus, we only have two warnings in the problems view rather than the hundred or so we have now.</p>\n",
            "<p>We should support using ftp URIs in the EFS filesystem API using our existing infrastructure. Forget handling passwords/prefs, just assume the URI contains the info needed to connect (i.e. login/password/port/host).</p><p>Users will be able to see/use this in the HTML editor by trying to get Content Assist on a public anonymous FTP site, by enter in:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&lt;a href=\"ftp://3dftp.com/|\"&gt;&lt;/a&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>and then hitting Ctrl+Space at the | (which is where the cursor should be, not something user actually types) and getting back the folders \"pub\", \"incoming\" and \"conf\" as options.</p>\n",
            "{html}&lt;div&gt;&lt;p&gt;This change should apply to &lt;em&gt;all&lt;/em&gt; new project wizards we<br/>support.&lt;/p&gt;<br/>&lt;p&gt;If a user unchecks the \"use default location\" checkbox, provide<br/>a warning message right below the location field indicating if the<br/>location in question already has pre-existing files. Since the path<br/>can be long, make sure it\\'s easy to see the full path to which the<br/>user is saving the project.&lt;/p&gt;&lt;/div&gt;{html}\n",
            "<p>I use \"Automatically sync my changes with the remote site\" -&gt; \"Automatically sync from my machine to the remote site\": if I use \"Save\", Aptana actually upload file on save, that\\'s what I need.</p><p>I often modify more files, before saving. So I always use \"Save all\" (I use a shortcut for it, and it is the only way I\\'m used to save) to save them all in once, but in this case Aptana does not upload any file.</p><p>I ask for \"Save all\" triggering \"Automatically sync...\" on each files that is saved; else I suggest a \"dedicated\" command, if most people don\\'t like the behavior I ask for.</p><p>Thank you for attention,<br/>Fabio.</p>\n",
            "{html}&lt;div&gt;&lt;p&gt;My project indicated that I didn\\'t have a python interpreter<br/>configured. I managed to eventually find the dialog, clicked<br/>\"auto-configure\" and everything appears to be fine.&lt;/p&gt;<br/>&lt;p&gt;Suggest two steps. Clicking on the error icon in the project<br/>brings up a dialog asking if you\\'d like to configure the<br/>interpreter. It would first try to auto-configure the interpreter,<br/>and then alert if it fails. It could then direct people to the<br/>normal preference page where they could fix the problem manually if<br/>necessary.&lt;/p&gt;&lt;/div&gt;{html}\n",
            "{html}&lt;div&gt;&lt;p&gt;To reproduce:&lt;/p&gt;<br/>&lt;pre&gt;<br/>&lt;code class=\"python\"&gt;class Eggs(object):<br/>  def spam():<br/>    from string import Template<br/>    return Template(\\'\\') + digits # Press CTRL+1 on this line. Hold down CTRL while selecting from string for \\'string.digits\\'&lt;/code&gt;<br/>&lt;/pre&gt;<br/>&lt;p&gt;result:&lt;br&gt;&lt;/p&gt;<br/>&lt;pre&gt;<br/>&lt;code class=\"python\"&gt;class Eggs(object):<br/>  def spam():<br/>    from string import Template<br/>  from string import digits<br/>    return Template(\\'\\') + digits&lt;/code&gt;<br/>&lt;/pre&gt;<br/>&lt;p&gt;expected:&lt;br&gt;&lt;/p&gt;<br/>&lt;pre&gt;<br/>&lt;code class=\"python\"&gt;class Eggs(object):<br/>  def spam():<br/>    from string import Template, digits<br/>    return Template(\\'\\') + digits&lt;/code&gt;<br/>&lt;/pre&gt;&lt;/div&gt;{html}\n",
            "\"<p>Currently at startup, we automatically try to migrate any Studio 2.x projects to Studio 3.  That's probably no longer necessary after one year and 7 releases later.  Removing it should help startup performance on a workspace with a lot of projects.</p>\"\n",
            "<p>EDT released a new update of the FTPPro library: <a href=\"http://www.enterprisedt.com/products/edtftpjssl/history.html\" class=\"external-link\" rel=\"nofollow\">http://www.enterprisedt.com/products/edtftpjssl/history.html</a>.</p>\n",
            "<p>Steps:</p><ol>\\t<li>Open the <b>Preferences &gt; Studio &gt; Themes</b>  page</li>\\t<li>Press the + button to make a copy of the existing theme</li>\\t<li>Note the default name of the new theme.</li></ol><p>Suggest that the name be Copy of ThemeName, Copy (2) of ThemeName (this follows duplicate naming conventions of Eclipse)</p>\n",
            "<p>When typing \"&lt;script language=...\" the code assist overlay pops up, however if I use quotations after the equals sign, the code assist fails to appear.</p><p>Aptana Studio 2 allows me to format the code here how I please.</p>\n",
            "\"<p>At the moment there is a setting found under Preferences &gt; Aptana Studio &gt; Editors in the 'Typing' page called 'Auto-close matching character pairs'.<br/>This auto closing quotes and brackets however I would like the ability control each of these separately so auto closing quotes could be disabled but auto closing brackets could be kept turned on.</p>\"\n",
            "\"<p>We don't currently format spacing between words, and various syntax like ':' ',' '(' ')' etc</p>\"\n",
            "{html}&lt;div&gt;&lt;p&gt;We should support syntax highlighting/coloring for coffeescript<br/>files: &lt;a href=<br/>\"http://jashkenas.github.com/coffee-script/\"&gt;<a href=\"http://jashkenas.github.com/coffee-script/\" class=\"external-link\" rel=\"nofollow\">http://jashkenas.github.com/coffee-script/</a>&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;{html}\n",
            "nan\n",
            "<p>When the code assist dropdown selector overlays the code, the 2nd overlay explaining the selector lays on top of the selector instead of out to the side.  I cannot see the possible choices because the 2nd overlay is in the way.</p>\n",
            "<p>Guice 4.0 has been released. Among the new features, probably the most significant is Java 8 support - in Guice 3.0 stack traces are obfuscated by <a href=\"https://github.com/google/guice/issues/757\" class=\"external-link\" rel=\"nofollow\">https://github.com/google/guice/issues/757</a>. As our code expands use of lambdas and method references this will become even more critical.</p>\n",
            "<p>Given that slave recovery has been stable in mesos for a very long time it\\'s worth reassessing the default value of this flag <span class=\"error\">&#91;1&#93;</span> (or maybe removing it altogether).</p><p><a href=\"https://github.com/apache/incubator-aurora/blob/master/src/main/java/org/apache/aurora/scheduler/DriverFactory.java#L75-L101\" class=\"external-link\" rel=\"nofollow\">https://github.com/apache/incubator-aurora/blob/master/src/main/java/org/apache/aurora/scheduler/DriverFactory.java#L75-L101</a></p>\n",
            "<p>0.21.0 introduced a TASK_ERROR state. Support this in the scheduler code (either by aliasing it to the existing TASK_LOST state or creating a new state machine entry).</p>\n",
            "<p>Follow-up from discussion on IRC:</p><p>Some docker labels are mutable, meaning the image a task runs in could change from restart to restart even if the rest of the task config doesn\\'t change. This breaks assumptions that make rolling updates the safe and preferred way to deploy a new Aurora job</p><p>Add a binding helper that resolves a docker label to an immutable image identifier at create time and make it the default for the Docker helper introduced in <a href=\"https://reviews.apache.org/r/28920/\" class=\"external-link\" rel=\"nofollow\">https://reviews.apache.org/r/28920/</a></p>\n",
            "\"<p>The current process for adding instances to a job is highly manual, and potentially dangerous.</p><p>1. Take a config for a job with 10 instances, update it to 20 instances.<br/>2. The batch size will be increased, and users will need to specify shards 10 to 19.<br/>3. After this update is complete, users will need to manually update shards 0-9 again.</p><p>There may be other changes pulled in as part of this update other than just increasing the number of instances, which could further complicate things.</p><p>One possible improvement would be to change the updater from 'under-provision' where it kills instances first, then schedules new instances, to an 'over-provision' where it adds on new instances, then backpedals and kills the old instances.</p><p>Overall, a single command or process for a user to take an already-existing job and increase the number of instances would reduce overhead and fat-fingering.</p>\"\n",
            "<p>We\\'re making a decent effort at reducing the <em>cost</em> of task scheduling operations, abut have not yet invested in reducing the working set in a way that causes task scheduling to scale better.  Each scheduling attempt for each task is an O<img class=\"emoticon\" src=\"https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/> operation, where n is the number of offers.</p><p>I would like to explore optimizations where we try to reduce the amount of redundant work performed in task scheduling.  Say, for example, we\\'re trying to schedule a task that needs 2 CPUs, and we only have offers with 1 CPU.  Each scheduling round will re-assess every offer, despite the fact that the offers have not changed shape, and will always be a mismatch (hereafter termed <em>static</em> mismatches).  Instead, we should try to skip over offers that are a static mismatch.  We could do this at the <tt>TaskGroup</tt> level, since every element in a task group is by definition statically equivalent.  This means that jobs with a large number of instances could be scheduled very efficiently, since the first task scheduling round could identify static mismatches, reducing the working set in the next round.</p><p>This is to contrast with <em>dynamic</em> mismatches, where a change in the tasks on a machine or other settings could make a previously-ineligible offer become a match.  The current sources of dynamic mismatches are limit constraints, host maintenance modes, and dedicated attributes.</p><p>I propose we proceed in several steps, re-evaluating after each:<br/>1. instrument the scheduler to better estimate the improvements<br/>2. avoid future (offer, task group) evaluations when static mismatches are found<br/>3. avoid future (offer, task group) evaluations when dynamic mismatches are found</p>\n",
            "<p>To expedite <a href=\"https://issues.apache.org/jira/browse/AURORA-610\" title=\"Job update orchestration in the scheduler\" class=\"issue-link\" data-issue-key=\"AURORA-610\"><del>AURORA-610</del></a> we accepted some technical debt by storing serialized thrift objects in the database.  Once the database is completely fronted by SQL, we need to go back and manage these objects with references to other tables.</p>\n",
            "<p>The scheduler web interface has a breadcrumb:</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>Home Role: www-data  Environment: devel  Job: hello_world</pre></div></div><p>And a large heading:</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>Job hello_world in role www-data and environment devel</pre></div></div><p>Consider removing the heading text, as it consumes a lot of real-estate, and is redundant to the breadcrumb.</p>\n",
            "\"<p>We optionally link to a job dashboard from the Job page (if <tt>viz_job_url_prefix</tt> is passed to the Scheduler on the command line). The icon for this is currently uses glyphicons halflings font stats glyph (depending on how you view it, a series of 3 vertical bars, or a series of hills). It's not at all obvious that this link takes you anywhere interesting. We should revisit the discoverability of this link.</p>\"\n",
            "<p>I want to send someone a link directly pointing to the \"Completed Tasks\" page on <a href=\"http://scheduler:8081/scheduler/jaybuff/devel/hello-world\" class=\"external-link\" rel=\"nofollow\">http://scheduler:8081/scheduler/jaybuff/devel/hello-world</a></p><p>Currently that will take them to active tasks, then they have to click \"completed tasks\" </p>\n",
            "<p>Our vagrant development box has docker installed, but we should take the extra steps to run docker commands without <tt>sudo</tt>.  </p><p>See commands required here: <a href=\"http://askubuntu.com/questions/477551/how-can-i-use-docker-without-sudo/477554#477554\" class=\"external-link\" rel=\"nofollow\">http://askubuntu.com/questions/477551/how-can-i-use-docker-without-sudo/477554#477554</a></p>\n",
            "<p>It would be great if we had a Jenkins job that vetted the current state of master and published a nightly build.</p><p>This would make life easier for folks deploying Aurora from master rather than the (currently anemic) released builds.</p>\n",
            "<p>The DbTaskStore implementation has so far only targeted behavioral compliance with InMemTaskStore.  Use benchmarks to determine areas that require perf improvements and address them.  Also address relevant TODOs that should be production showstoppers.</p>\n",
            "<p>Initially I thought this check should live in the admin client, but after discussing with <a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zmanji\" class=\"user-hover\" rel=\"zmanji\">Zameer Manji</a>, we believe the scheduler would be the right place to enforce this.</p>\n",
            "<p>Large/flapping scheduler job updates may generate too many events in the update store. The update settings are fully controlled by the user and there is a potential for a misconfigured job update to completely overwhelm our in-memory DB storage with job update instance events. </p><p>For example, a large flapping update with <tt>max_per_shard_failures</tt> and <tt>max_total_failures</tt> set to max INT when left unattended can quickly consume all available RAM and kill the scheduler. A manual cleanup of the scheduler log would be needed to bring the scheduler up.</p><p>This can be especially relevant with the introduction of update heartbeats  (<a href=\"https://issues.apache.org/jira/browse/AURORA-690\" title=\"Add support for external update coordination\" class=\"issue-link\" data-issue-key=\"AURORA-690\"><del>AURORA-690</del></a>) that can further exacerbate the problem (e.g. when <tt>blockIfNoPulseAfterMs</tt> set too low wrt the external service pulse rate).</p><p>We need to cap the max per-job lifetime count of <tt>JobUpdateEvent</tt> and <tt>JobInstanceUpdateEvent</tt> instances. A nice bonus would be providing a hint in the UI when the event sequence is cut off.</p>\n",
            "<p>Scheduler RPCs that were authenticated by Shiro show UNSECURE in their audit messages.</p>\n",
            "<p>This is an intermediate step necessary to retire the gc executor.  See <a href=\"https://issues.apache.org/jira/browse/AURORA-1024\" title=\"Implement API for dual reading Thermos checkpoints\" class=\"issue-link\" data-issue-key=\"AURORA-1024\"><del>AURORA-1024</del></a>.</p>\n",
            "<p>Gradle 2.4 is out.  Among other things, it claims to offer improved performance:</p><p><a href=\"http://gradle.org/docs/2.4/release-notes\" class=\"external-link\" rel=\"nofollow\">http://gradle.org/docs/2.4/release-notes</a></p>\n",
            "<p>In the vagrant environment, we perform a step where we copy the upstart configurations to /etc/init [1].  The way this is done makes it challenging to change the upstart configurations later, the easiest way being to destroy and re-create the environment.  Consider updating these files that their definitions are updated by rsync along with other code.</p><p>[1] <a href=\"https://github.com/apache/incubator-aurora/blob/ad211da2f2490722a10cce95a2bb4fb55fd1c16f/examples/vagrant/provision-dev-cluster.sh#L60-L61\" class=\"external-link\" rel=\"nofollow\">https://github.com/apache/incubator-aurora/blob/ad211da2f2490722a10cce95a2bb4fb55fd1c16f/examples/vagrant/provision-dev-cluster.sh#L60-L61</a></p>\n",
            "\"<p>Right now the scheduler exports general counters for preemption attempts that don't break out production vs. non-production attempts. Since the preemptor currently has no action available when asked to preempt a nonproduction task, it will show a 100% failure rate. Export counters for preemptions attempted in favor of production tasks and their successes and failures.</p>\"\n",
            "<p>When a task fails to schedule due not passing a resource or constraint <tt>Veto</tt> the entire <tt>TaskGroup</tt> is penalized but only the first task gets Veto reasons set. That leads to the UI displaying something like \"Insufficient disk\" veto reason only for one instance out of the similar pool of PENDING tasks. </p><p>Consider sharing a <tt>Veto</tt> reason for all tasks in a group for improved troubleshooting and visibility. </p>\n",
            "<p>See AURORA-2014.</p>\n",
            "<p>TBD by @wickman</p>\n",
            "<p>Use the source and reason fields that are included in status updates (circa mesos 0.21) to produce log messages and exported counters.</p><p><a href=\"http://mesos.apache.org/blog/mesos-0-21-0-released/\" class=\"external-link\" rel=\"nofollow\">http://mesos.apache.org/blog/mesos-0-21-0-released/</a></p>\n",
            "<p>See <a href=\"https://issues.apache.org/jira/browse/AURORA-1024\" title=\"Implement API for dual reading Thermos checkpoints\" class=\"issue-link\" data-issue-key=\"AURORA-1024\"><del>AURORA-1024</del></a>.</p>\n",
            "<p>We should generalize the approach of dealing with scheduler updates by always uniquely identifying them by a new composite key that includes both jobKey and the updateId, e.g.:</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>struct JobUpdateKey {  1: JobKey jobKey  2: string updateId}</pre></div></div><p>The above approach would benefit us long term when it comes to implementing a fully functional REST API. Having both job key and update ID components in the URL will help us logically split authorization and application data layers. </p><p>E.g.: in <tt>/api/updates/role/env/name/updateId</tt> the <tt>/role/env/name</tt> may be used for authorization whereas the <tt>updateId</tt> will remove the ambiguity from the data lookup.</p>\n",
            "<p>Right now you have to type some pretty verbose stuff to setup security.</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>-shiro_realm_modules=org.apache.aurora.scheduler.http.api.security.Kerberos5ShiroRealmModule,org.apache.aurora.scheduler.http.api.security.IniShiroRealmModule,com.example.CustomRealmModule</pre></div></div><p>This is ugly and not very refactor-safe. Consider adding mappings for well-known names, with fallback to FQCNs.</p><p>Thus, the previous example could become</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>-shiro_realm_modules=KERBEROS5_AUTHN,INI_AUTHNZ,com.example.CustomRealmModule</pre></div></div><p>This points out one possible weird misconfiguration:</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>-shiro_realm_modules=KERBEROS5_AUTHN,INI_AUTHNZ-http_authentication_mechanism=BASIC</pre></div></div><p>will leave the Kerberos code completely dark and pass the Basic auth credentials to IniRealm. Thus, as a followup we should probably create separate INI_AUTHN and INI_AUTHZ realms that will only participate in one phase.</p>\n",
            "<p>This feature is being deprecated in 0.8.0, removed in 0.9.0</p>\n",
            "<p>The <tt>aurora update status</tt> command is rather restrictive, only showing information about in-flight updates.  This command would be more useful if it could allow the same output for arbitrary updates (which can be discovered through <tt>aurora update list</tt>.</p><p>To make the name match the new behavior, i propose we name this command <tt>info</tt>.</p>\n",
            "<p>In the /updates endpoint, updates that are in ROLL_FORWARD_AWAITING_PULSE state are not included under in progress updates. </p>\n",
            "<p>Enabling API security involves minimally setting 2 args:</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>-enable_api_security=true-http_authentication_mechanism=BASIC</pre></div></div><p>This could open the possibility of confusing combinations of arguments that may behave in unexpected ways, or not work at all.  Remove <tt>enable_api_security</tt> in favor of <tt>-http_authentication_mechanism=NONE</tt>, to be the default value.</p>\n",
            "<p><a href=\"https://reviews.apache.org/r/31820/\" class=\"external-link\" rel=\"nofollow\">https://reviews.apache.org/r/31820/</a> added support for coarse-grained permissions based on the thrift API method name. Support finer-grained permissions scoped down to the job</p><p>For example calls to</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">auroraSchedulerManager.descheduleCronJob(JobKey(role=<span class=\"code-quote\">\\'ksweeney\\'</span>, environment=<span class=\"code-quote\">\\'prod\\'</span>, name=<span class=\"code-quote\">\\'download_lunch_menu\\'</span>), None, None)</pre></div></div><p>currently check for the <tt>thrift.AuroraSchedulerManager:descheduleCronJob</tt> Permission when they should check for the <tt>thrift.AuroraSchedulerManager:descheduleCronJob:ksweeney:prod:download_lunch_menu</tt> Permission.</p>\n",
            "nan\n",
            "<p>Mesos may append an optional message with task status update that is currently surfacing in the UI via TaskEvent. These messages may not be user friendly and add confusion. One example is \"Unregistered executor\" issued when Mesos kills an assigned task that did not have a chance to run yet. While this message does not constitute a failure it may create an illusion of abnormal behavior in an otherwise normal operation.</p><p>Consider filtering/formatting messages in the UI/scheduler to avoid adverse user experience. The ideal solution should also leverage TaskStatus.reason field to show additional status details.</p>\n",
            "<p>Mesos 0.23 was released on July 29th and contains a number of very interesting experimental features and fixes.</p><p><a href=\"http://mesos.apache.org/blog/mesos-0-23-0-released/\" class=\"external-link\" rel=\"nofollow\">http://mesos.apache.org/blog/mesos-0-23-0-released/</a></p>\n",
            "<p>We currently have 32  dependencies on libraries from Twitter commons.  </p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>$ grep com.twitter.common build.gradle  | wc -l      32</pre></div></div><p>While these libraries have generally served us well, this number of dependencies creates a transitive web that inhibits us from upgrading our direct dependencies.</p><p>Consider removing these dependencies and replacing our uses of them with forks of the code in our repository.  My hunch is that we use relatively insignificant portions of them overall.  However, if we end up just cloning the sources and maintaining them ourselves, we should back out.</p>\n",
            "<p>Currently Kerberos errors are presented as a stack trace to the user looking something like:</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>GSSError: ((\\'Unspecified GSS failure.  Minor code may provide more information\\', 851968), (\\'No Kerberos credentials available\\', -1765328243))401 Client Error: Authorization Required</pre></div></div><p>(And similar for expired tickets). It would be helpful to catch these and display more useful information, such as a suggestion to run <tt>kinit</tt>.</p>\n",
            "nan\n",
            "<p>When running our top-level build script (./build-support/jenkins/build.sh), style check results are reported for python files.  This output is too verbose, as it reports <tt>SUCCESS</tt> for all files that pass style check.  Change this output to only report errors.</p><p>In particular, this will make for more direct build result messages from build bot.  A counter-example is the current state, as seen in <a href=\"https://reviews.apache.org/r/36392/\" class=\"external-link\" rel=\"nofollow\">https://reviews.apache.org/r/36392/</a></p>\n",
            "<p>An updated PMD flagged this bug (see output below).</p><p>This line:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">index.remove(key, task);</pre></div></div><p>should be:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">index.remove(key, Tasks.id(task));</pre></div></div><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>Code\\tWarningGC\\torg.apache.aurora.scheduler.storage.entities.IScheduledTask is incompatible with expected argument type String in org.apache.aurora.scheduler.storage.mem.MemTaskStore$SecondaryIndex.remove(IScheduledTask)Bug type GC_UNRELATED_TYPES (click for details) In class org.apache.aurora.scheduler.storage.mem.MemTaskStore$SecondaryIndexIn method org.apache.aurora.scheduler.storage.mem.MemTaskStore$SecondaryIndex.remove(IScheduledTask)Actual type org.apache.aurora.scheduler.storage.entities.IScheduledTaskExpected StringCalled method com.google.common.collect.Multimap.remove(Object, Object)Invoked on org.apache.aurora.scheduler.storage.mem.MemTaskStore$SecondaryIndex.indextask passed as argumentorg.apache.aurora.scheduler.storage.entities.IScheduledTask.equals(Object) used to determine equalityAt MemTaskStore.java:[line 399]</pre></div></div>\n",
            "<div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>$ aurora update start devcluster/vagrant/test/http_example /vagrant/src/test/sh/org/apache/aurora/e2e/http/http_example.auroraFatal error running command: Pulse interval seconds must be at least 60 seconds.Traceback (most recent call last):  File \"/usr/local/bin/aurora/apache/aurora/client/cli/__init__.py\", line 307, in _execute    result = noun.execute(context)  File \"/usr/local/bin/aurora/apache/aurora/client/cli/__init__.py\", line 383, in execute    return self.verbs[context.options.verb].execute(context)  File \"/usr/local/bin/aurora/apache/aurora/client/cli/update.py\", line 158, in execute    resp = api.start_job_update(config, context.options.message, instances)  File \"/usr/local/bin/aurora/apache/aurora/client/hooks/hooked_api.py\", line 190, in start_job_update    config, message, instances=instances))  File \"/usr/local/bin/aurora/apache/aurora/client/hooks/hooked_api.py\", line 145, in _hooked_call    resp = api_call()  File \"/usr/local/bin/aurora/apache/aurora/client/api/__init__.py\", line 165, in start_job_update    raise self.UpdateConfigError(str(e))UpdateConfigError: Pulse interval seconds must be at least 60 seconds.</pre></div></div>\n",
            "<p>When `CommandError` is caught in the client, it prints a generic error prefix, which is not helpful.  We should strive to make our error messages contextual and stand on their own.</p>\n",
            "<p>Make the bindings keys of the scripting module consistent with the bindings of the EL.</p><p>\\xc2\\xa0</p><p>Ideally, reuse the same code to generate the bindings.</p>\n",
            "<p>Domain bundle consist of a domain artifact and the set of applications that belong to that it.<br/>Deployment service must support the deployment of domain bundles, this implies:</p><ul>\\t<li>Detecting new bundles</li>\\t<li>Redeploy domain/applications when a new domain bundle is found</li>\\t<li>Notify the deployment status of domain bundles</li>\\t<li>Provide an API to request deployment of domain bundles from the deployment service</li></ul>\n",
            "<p>Migrate Tests from JMS transport to JMS Extension</p>\n",
            "<p>Implement phase 1 of IBM MQ based on the initial spec</p>\n",
            "<p>Consistent with scatter-gather and using ForkJoinStrategies but operating on split parts instead of routes.</p>\n",
            "<p>All the packages exported on the Mule container must contain the api package.<br/>Currently, there are packages that do not say api. For example org.mule.runtime.module.artifact.<br/>This task is to fix only all the packages that are intended to be exported. Some internal packages are begin exported now, but just temporarily, so those packages will be manage in a different issue.</p>\n",
            "<p>Since a dw script can be quite large, it would be ideal to load them from a file.</p>\n",
            "\"<p>Cleanup MuleSession, moving anything that can be moved to compatibility module and ensure it's not exposed as part of mule-api.</p>\"\n",
            "<p>Define how to define EL functions from modules</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Redefine DW current components</li>\\t<li>set-payload vs dw:transform</li>\\t<li>Make DW components as part of core namespace.</li></ul>\n",
            "<p>Define a way to hook to the default EL in Mule</p>\n",
            "<p>Deprecate Services (and anything else we can)</p>\n",
            "<p><a href=\"http://corp.wiki.mulesource.com/display/WP/Simplified+REST+Service+Creation\" class=\"external-link\" rel=\"nofollow\">http://corp.wiki.mulesource.com/display/WP/Simplified+REST+Service+Creation</a></p>\n",
            "<p>This version works with 1.8.0 and there are some deprecated methods in 1.9.11, so there is a need for an upgrade.</p>\n",
            "<p>Multiple representation support for apikit</p>\n",
            "<p><a href=\"http://corp.wiki.mulesource.com/display/WP/Simplified+REST+Service+Creation\" class=\"external-link\" rel=\"nofollow\">http://corp.wiki.mulesource.com/display/WP/Simplified+REST+Service+Creation</a></p>\n",
            "<p>As a Mule user, I would like to use the dynamic lookup component within my flows.</p><p>Detailed specs defined here: </p><p><a href=\"http://corp.wiki.mulesource.com/display/WP/Dynamic+Router+%28supports+Registry+Dynamic+Endpoint+Resolution%29\" class=\"external-link\" rel=\"nofollow\">http://corp.wiki.mulesource.com/display/WP/Dynamic+Router+%28supports+Registry+Dynamic+Endpoint+Resolution%29</a></p>\n",
            "<p><a href=\"http://corp.wiki.mulesource.com/display/WP/Simplified+REST+Service+Creation\" class=\"external-link\" rel=\"nofollow\">http://corp.wiki.mulesource.com/display/WP/Simplified+REST+Service+Creation</a></p>\n",
            "<p>As a Mule user, I would like to configure my Mule instance to be paired with my Registry account through my registry key so that I may be able to manage my ESB instance\\'s endpoints with the registry. </p><p>User should be configure the registry key for their registry account for an ESB instance. From there on: The HTTP endpoints of all apps deployed to the ESB instance should be manageable with the paired registry instance.</p><p>Detailed specs described here: </p><p><a href=\"http://corp.wiki.mulesource.com/display/PRODMGMT/Registry+Interaction+and+License+Management+Support\" class=\"external-link\" rel=\"nofollow\">http://corp.wiki.mulesource.com/display/PRODMGMT/Registry+Interaction+and+License+Management+Support</a></p>\n",
            "<p>Update the version of Spring we are using to 3.2</p>\n",
            "\"<p>Today we show MySQL, Derby, and Oracle. However, MS SQL and DB2 are RDBMS's with very large footprints. As such, we should add these two databases to the set that shows up on the JDBC connector's configuration screen. </p>\"\n",
            "<ul>\\t<li>Packaged examples should be modified as per the following plan: <a href=\"https://docs.google.com/a/mulesoft.com/spreadsheet/ccc?key=0ArwrJmCfHowWdDNCdnJYeldHcDI5M0dYaTRsWUwxd2c#gid=2\" class=\"external-link\" rel=\"nofollow\">https://docs.google.com/a/mulesoft.com/spreadsheet/ccc?key=0ArwrJmCfHowWdDNCdnJYeldHcDI5M0dYaTRsWUwxd2c#gid=2</a></li></ul><ul>\\t<li>This requires the following additional work:</li></ul><ul class=\"alternate\" type=\"square\">\\t<li>Creation of the two new identified examples.</li>\\t<li>Modification of target examples to use latest 3.4 features. Beyond specifics identified on spreadsheet this includes adding in-studio documentation for all examples.</li>\\t<li>Modification of documentation for target examples.</li>\\t<li>Removal of examples tagged as Archive from Studio.</li>\\t<li>Modification of docs to reflect an Archived examples section.</li>\\t<li>Placement of all examples in GIT and tagging as active versus archived.</li>\\t<li>From the ESB stand-alone distribution point of view: Remove all examples except the new hello world and existing loan broker.</li></ul>\n",
            "<p>Create an example application to showcase apikit functionality</p>\n",
            "<p>In order to run user testing we need to integrate the current component to Mule.</p>\n",
            "<p>Basic requirements: </p><p><a href=\"http://corp.wiki.mulesource.com/pages/viewpage.action?pageId=27132117\" class=\"external-link\" rel=\"nofollow\">http://corp.wiki.mulesource.com/pages/viewpage.action?pageId=27132117</a></p>\n",
            "<p>As a Mule ESB user, I would like to be able to turn on the use of the NIO stack through a deploy.properties toggle. </p><p>As a Mule ESB user, I would like to be able to use the new WebSocket components within my flows. </p>\n",
            "<p>As a Mule user I would like to:</p><ul>\\t<li>Deploy a domain with mule API</li>\\t<li>Undeploy a domain and all its apps</li>\\t<li>Redeploy a domain and update all the apps</li></ul>\n",
            "<p>Define the UX for enricher that uses MEL. We need to review how now having the enricher affects us considering the 3.x use cases.</p>\n",
            "<p>Create new Transformation Service.</p><p>This issue should be updated and split into different stories once these improvements have been analyzed.</p>\n",
            "<p>Temporarilly adding spring-module\\xc2\\xa0as privileged enable to provide access to privileged classes.</p><p>This must be removed and make classes part of the API or avoid\\xc2\\xa0to use them from the plugin</p>\n",
            "\"<p>Support provisioning/replacement of configuration to the application when deploying.</p><p>When an application is getting promoted from one env to another (Dev -&gt; QA or QA -&gt; Prod), the devops need to be able to change connection provider configuration.</p><p>The idea is that the devops get a list of all the connection configurations and it's able to redefine the connection parameters during deployment.</p><p>This task is to define how the runtime manager (or any client) can get the set of connection providers that may require changing connection parameters and also to be able, during deployment, to provide those new parameters and the runtime must be able to apply them.</p>\"\n",
            "<p>Scripting plugin was added as privileged in order to provide access to privileged\\xc2\\xa0transformer classes as the plugin\\xc2\\xa0provide scripting\\xc2\\xa0transformer that requires access to it.</p><p>Scripting transformer must be removed and usages replaced by scripting component, after that, the scripting plugin can be removed from the privileged API</p><p>\\xc2\\xa0</p>\n",
            "<p>Allow users of spring-module to provide their own version of spring</p><p>Make those dependencies provided in the pom.</p><p>Remove the spring exported packages form the plugin.</p><p>Unignore ignored tests</p>\n",
            "<p>MEL expression language is currently provided by the runtime and available to every component without extra configuration.<br/>This implies that users can use MEL expressions everywhere by just adding the \"mel:\" prefix to their expressions.<br/>As MEL is provided for compatibility reasons, the right approach is to provide MEL support on the compatibility plugin instead of in the runtime. So users can onlyuse MEL on EE and only when they are migrating from 3.x.</p>\n",
            "<p>Upgrade ahc and grizzly to 1.13 and 2.3.31 respectively</p>\n",
            "<p>Add support on the SDK for receiving MEL expressions without getting the string evaluated.</p><p>This features was supported in DevKit as described here: <br/><a href=\"https://www.mulesoft.org/jira/browse/DEVKIT-245\" class=\"external-link\" rel=\"nofollow\">https://www.mulesoft.org/jira/browse/DEVKIT-245</a></p><p>This will be supported both for @Parameters and Operation arguments, when they are annotated with <em>@Literal</em><br/>When @Literal is used, ExpressionSupport should be <em>SUPPORTED</em>.</p>\n",
            "<p>Change the default value for output type field in the HTTP Request (advance &gt; other setting &gt; output type field) from Any to Stream</p>\n",
            "<p>Define bindings to use in Mule 4</p>\n",
            "<p>See here: <a href=\"http://corp.wiki.mulesource.com/pages/viewpage.action?pageId=27132117\" class=\"external-link\" rel=\"nofollow\">http://corp.wiki.mulesource.com/pages/viewpage.action?pageId=27132117</a></p><p>This will require some in-iteration investigation.</p>\n",
            "<p>AS A<br/>user</p><p>I WANT<br/>I want to be able to configure the transport in a single point</p><p>SO THAT<br/>I can configure the common transport attributes in a single reusable place</p>\n",
            "<p>Function typing</p>\n",
            "<p>Generic typing (List&lt;T&gt;)</p>\n",
            "<p>As a user of Mule 3.5.0, I would like Mule to depend on the latest version of MVEL (used for DataMapper and MVEL) to stay up-to-date with the latest MVEL bug fixes/enhancements.</p><p>The latest version seems to be 2.1.8</p>\n",
            "<p>Right now, when a poll needs to deal with updated objects, we use watermarks as an approach to filter out elements that were already processed. The only way to do that right now is to implement the logic manually which forces the user to deal with object stores, default values, repeated logic, dev time dependencies, etc.</p><p>This story is a container of all the features required for watermark</p>\n",
            "<ul>\\t<li>Move generated DevKit code to ESB and expose an interface that DevKit can use</li>\\t<li>Improve user experience when trying to configure an OAuth connector</li></ul><p><a href=\"http://corp.wiki.mulesource.com/display/WP/Making+OAuth+user+experience+smoother\" class=\"external-link\" rel=\"nofollow\">http://corp.wiki.mulesource.com/display/WP/Making+OAuth+user+experience+smoother</a></p>\n",
            "<p>AS A<br/>product owner or community member</p><p>I WANT<br/>to be able to review the specs </p><p>SO THAT<br/>I can and contribute with my feedback</p>\n",
            "<p>AS A<br/>developer</p><p>I WANT<br/>I want to have a base project skeleton</p><p>SO THAT<br/>there is a basement to build on with agreed placeholders for endpoints, connectors, transactions that should be stable.</p>\n",
            "<p>AS A<br/>user</p><p>I WANT<br/>I want to be able to rely on a defined schema to write my AMQP integrations </p><p>SO THAT<br/>I have exact knowledge of how I\\xe2\\x80\\x99m syntactically supposed to use the transport and to have help from my IDE to autocomplete and detect errors.</p>\n",
            "<p>This is related to consolidation of dataType in mule/ext-api/mule-commons.</p>\n",
            "<p>In order to upgrade to the latest Amazon SDK on Cloudhub, minimum Jackson version required is <b>2.6.6</b> </p>\n",
            "\"<p>Review new won't be supported in EL. Need to evaluate the impact and define how to approach the fact that 'new' won't be accepted in the EL.</p>\"\n",
            "<p>AS A<br/>user</p><p>I WANT<br/>I want to be able consume continuously amqp messages</p><p>SO THAT<br/>a MuleEvent is created and delivered to a flow when a messages arrives to a queue and is comsumed</p>\n",
            "<p>AS A<br/>user</p><p>I WANT<br/>I want to be able consume instantly amqp messages</p><p>SO THAT<br/>I can consume messages at any point of the flow</p>\n",
            "<p>AS A<br/>user</p><p>I WANT<br/>I want the transport to be tested against a real broker and a real application.</p><p>SO THAT<br/>I can be sure the transport works on real world usage.</p>\n",
            "\"<p>We have some places where we us a default data format specified as 'yyyy/MM/dd'. In Spring for Apache Hadoop we use 'yyyy-MM-dd' for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.</p>\"\n",
            "<p>The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. </p>\n",
            "\"<p>The messagebus implementations, upon registration of consumer and producer from/to messagebus the corresponding endpoints start. Instead of directly calling the start() on adapter/consumer we can call the corresponding Binding's start() which calls the underlying endpoint to start.<br/> This is in-line with the way the corresponding endpoints are stopped (using Binding's stop()) during undeploy/destroy.</p>\"\n",
            "<p>The expression currently appends \".\" + ${suffix} (where the default suffix is \\'out\\').</p><p>If the suffix value were an empty String, this would lead to the file name ending with a dot. We should update the expression so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.</p>\n",
            "<p>the value for --target is required (there is no default), but the hint for that option states otherwise:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">xd:&gt;http post --targethttp post --targetrequired --target: the location to post to; <span class=\"code-keyword\">default</span> <span class=\"code-keyword\">if</span> option not present: <span class=\"code-quote\">\\'http:<span class=\"code-comment\">//localhost:9000\\'</span></span></pre></div></div>\n",
            "<p>See <a href=\"https://github.com/spring-projects/spring-xd/issues/1924\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/issues/1924</a></p>\n",
            "\"<p>As a developer, I'd like to upgrade Spring XD's ambari plugin to 1.3 release.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to explore options to bootstrap and setup Lattice based infrastructure for s-c-d's bare metal deployment.</p>\"\n",
            "\"<p>As a developer, I'd like to submit a PR for existing work on Mesos SPI. </p>\"\n",
            "\"<p>As a developer, I'd like to move k8s SPI to it's own repo.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>gpfdist</tt> module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>shell</tt> module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>mongo</tt> module from XD to s-c-s-m repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>trigger</tt> module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a user, I'd like to use the latest release of <tt>gemfire</tt> sink, so I can create a streaming pipeline to land data in gemfire. </p>\"\n",
            "\"<p>As a developer, I'd like to port <tt>rich-gauge</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a developer, I'd like to port <tt>gauge</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>json-to-tuple</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>object-to-json</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>http-client</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>aggregator</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>splitter</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>script</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>shell</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>jdbc</tt> module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>tcp</tt> module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>splunk</tt> module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>mongo</tt> module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>null</tt> module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>mqtt</tt> module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>mail</tt> module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>tcp-client</tt> module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>reactor-ip</tt> module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>syslog</tt> module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>stdout</tt> module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>mail</tt> module from XD to s-c-s-m repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>jms</tt> module from XD to s-c-s-m repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>mqtt</tt> module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>mail</tt> module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>tcp</tt> module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to pass any overrides via external config file, so I can influence and override the default module configurations. (ex: module resolution from a different maven coordinate). </p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to move <tt>kafka</tt> module from XD to s-c-s repo, so I can use it as <tt>source</tt> to build streaming pipeline.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to move <tt>rabbit</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> to build streaming pipeline.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to move <tt>kafka</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> to build streaming pipeline.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to move <tt>rabbit</tt> module from XD to s-c-s repo, so I can use it as <tt>source</tt> to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>router</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>twittersearch</tt> module from XD to s-c-s repo, so I can use it as source modules to build streaming pipeline.</p>\"\n",
            "\"<p>As an s-c-d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF. I'd like to access REST APIs consistently across these platforms.</p>\"\n",
            "<p>we need a batching JDBC channel adapter (int-jdbc:outbound-channel-adapter is not batching statements AFAICT)</p>\n",
            "<p>User shall have the ability to get a listing of available named channels (order by name ascending) from the shell</p><ul>\\t<li>Add support to controllers</li>\\t<li>Add tests</li></ul>\n",
            "<p>We should provide a better shell integration when XD is run on Yarn.</p><p>1. yarn kill --id TAB completion<br/>2. yarn submit, more options like app name<br/>3. yarn list, filter by app states, etc<br/>4. admin config server TAB completion for running xd apps on yarn</p>\n",
            "<p>Just wanted to create story for this - so we can consider whether this should be addressed.</p><p>In at least 2 modules we use non-persisted states. We may want to consider making them persistent:</p><p><b>Twitter Search</b> uses an in-memory <b>MetadataStore</b> that keeps track of the twitter ids. There exists a corresponding issue for Spring Integration:</p><p>\"Create a Redis-backed MetadataStore\"<br/>See: <a href=\"https://jira.springsource.org/browse/INT-3085\" class=\"external-link\" rel=\"nofollow\">https://jira.springsource.org/browse/INT-3085</a></p><p><b>File Soure</b>\\'s File Inbound Channel Adapter uses a AcceptOnceFileListFilter, which uses an in-memory Queue to keep track of duplicate files.</p>\n",
            "nan\n",
            "<p>this would elminate dependencies that are currently in the codebase, such as:</p><ul>\\t<li>RESTModuleType and ModuleType enums</li>\\t<li>ModuleOption and DetailedModuleDefinitionResource.Option</li></ul>\n",
            "<p>The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.</p>\n",
            "nan\n",
            "<p>When a ModuleOption is backed by an enum, change the (currently String) type representation to be the possible values</p><p>ie java.lang.String -&gt; String<br/>but<br/>traffic.Light -&gt; Red | Green | Orange</p>\n",
            "<p>When doing dsl completion in a stream definition and a module option accepts a value that has a closed set of possible values (eg booleans, enums), we can provide completions for those.</p>\n",
            "<p>see discussion at <a href=\"https://github.com/spring-projects/spring-xd/commit/2f0e80b5e337b71c9c70de510a44d2f050d10fa7\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/commit/2f0e80b5e337b71c9c70de510a44d2f050d10fa7</a></p>\n",
            "<p>xd-shell is using the default spring-shell help command.  Need to create a help command specific to XD so that it can list the --hadoopDistro command line option.  Note, the hadoopDistro command line option is actually processed by the xd-shell bash script</p>\n",
            "\"<p>There are explicit Thread.sleep() calls after deploy() in some of the test methods in <br/>AbstractSingleNodeStreamDeploymentIntegrationTests.</p><p>Also, the test method deployAndUndeploy() doesn't have explicit Thread.sleep() and fails inconsistently with this error:</p><p>java.lang.AssertionError: stream test0 not undeployed <br/>\\tat org.junit.Assert.fail(Assert.java:88)<br/>\\tat org.junit.Assert.assertTrue(Assert.java:41)<br/>\\tat org.springframework.xd.dirt.stream.AbstractSingleNodeStreamDeploymentIntegrationTests.waitForUndeploy(AbstractSingleNodeStreamDeploymentIntegrationTests.java:332)<br/>\\tat org.springframework.xd.dirt.stream.AbstractSingleNodeStreamDeploymentIntegrationTests.deployAndUndeploy(AbstractSingleNodeStreamDeploymentIntegrationTests.java:221)<br/>\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br/>\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)<br/>\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br/>\\tat java.lang.reflect.Method.invoke(Method.java:601)<br/>\\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)<br/>\\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)<br/>\\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)<br/>\\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)<br/>\\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)<br/>\\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)<br/>\\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)<br/>\\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)<br/>\\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)<br/>\\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)<br/>\\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)<br/>\\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)<br/>\\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)<br/>\\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)<br/>\\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)<br/>\\tat org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)<br/>\\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)<br/>\\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)<br/>\\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)<br/>\\tat org.junit.runners.ParentRunner.run(ParentRunner.java:309)<br/>\\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)<br/>\\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)<br/>\\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)<br/>\\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)<br/>\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br/>\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)<br/>\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br/>\\tat java.lang.reflect.Method.invoke(Method.java:601)<br/>\\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)<br/>\\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)<br/>\\tat org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)<br/>\\tat org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)<br/>\\tat com.sun.proxy.$Proxy2.processTestClass(Unknown Source)<br/>\\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:103)<br/>\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br/>\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)<br/>\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br/>\\tat java.lang.reflect.Method.invoke(Method.java:601)<br/>\\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)<br/>\\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)<br/>\\tat org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)<br/>\\tat org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)<br/>\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)<br/>\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)<br/>\\tat java.lang.Thread.run(Thread.java:722)</p>\"\n",
            "nan\n",
            "<p>see discussion at <a href=\"https://github.com/spring-projects/spring-xd/pull/495#discussion-diff-9291037\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/pull/495#discussion-diff-9291037</a></p>\n",
            "<p>The analytics project has been used as a host for common repository classes because it was easily visible by both -dirt and other stuff (can\\'t remember which)</p><p>This should be cleaned and a dedicated project for \"core\", \"utility\", \"re-usable\", \"whatever\" classes should be created</p>\n",
            "<p>Thinking about the UBS<img class=\"emoticon\" src=\"https://jira.spring.io/images/icons/emoticons/help_16.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/> scenario that MP described. They want all their Cassandra modules to share a connection, leading to the need for a parent context for those modules. We could introduce a parent module for this purpose. The module declares a parent in its properties which likely ends up as a parent module definition in the module definition. When the child module is deployed, its parent must be deployed first if it is not already (i.e., parent is a singleton per container). The module sets that as it\\'s parent context.  We would have to make sure things happen in the correct order so the global context is the parent of the parent (ad infinitum). The alternative is to add a module parent context to the XD hierarchy which is extensible, but this is more elegant IMHO.</p><p>Also, in cases that don\\'t require singleton bean definitions, the parent could package and provide common jars to children, e.g., we set the parent module\\'s classloader as the parent classloader, eliminating the<br/>need to install common jars in an HDFS path (basically the approach I described <a href=\"https://jira.spring.io/browse/XD-2420\" class=\"external-link\" rel=\"nofollow\">https://jira.spring.io/browse/XD-2420</a>) </p><p>MP :<br/>&gt;&gt; Also, in cases that don\\'t require singleton bean definitions, the parent could package and provide common jars to children, e.g., we set the parent module\\'s classloader as the parent classloader<br/>This approach does not offer some of the advantages offered by a central yaml config noted in the JIRA . But it is simpler in many ways. The developer just installs a parent module containing dependent jars and sets that as a parent in the child modules. This requires no additional infrastructure. To address the hadoop scenario we discussed, we would need another level of indirection so the parent of the hdfs modules is bound to the configured hadoop distro.   e.g. something like</p><p>parent = ${xd.hadoop.distro} in module properties</p><p>MF:<br/>Possibly the parent modules could go in the \"common\" directory? They should be considered \"abstract\" also - in the same sense as abstract bean definitions in a Spring context (and they should only be started on demand when needed by at least one concrete child module - then destroyed when the last child module is destroyed).</p><p>Maybe this would also allow us to wrap up those xml files that currently live in \"common\" so that they are treated as parent modules?</p><p>MF: Yea, that sounds good wrt to common.</p><p>Also it might be a good idea to enable spring to throw an error if it finds more than one bean of the same name in the application context - i think that applies to searching in parent contexts as well.  this would avoid the \\'last one wins\\' rule and give more deterministic behavior.</p>\n",
            "<p>We should move the org.springframework.xd.batch.jdbc.ColumnRangePartitioner and org.springframework.xd.batch.item.jdbc.FieldSetSqlParameterSourceProvider to the spring-xd-extension-batch project</p>\n",
            "\"<p>As a user, I'd like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues/topics.</p>\"\n",
            "\"<p>As a user, I'd like to have the option of editing the deployed/undeployed stream so that I don't have to destroy to just change any deployment property.</p>\"\n",
            "<p>Currently it is necessary to specify mappedRequestHeaders=*  on the rabbit sink, otherwise no headers are mapped to AMQP.  This should be the default behavior.</p>\n",
            "<p>Some modules inherit <tt>application.yml</tt> / <tt>servers.yml</tt> via a properties file in <tt>/config/modules</tt> ; others have the values defined in the <tt>...OptionsMetadata</tt> classes.</p><p>Switch all modules to use the latter technique for consistency.</p>\n",
            "\"<p>As a user, I'd like to add the Hadoop <em>namenode</em> specifics in a config file so that I don't have to incur the hassle of pointing to the <em>namenode</em> location every time I open a new DSL session, but it is automatically configured. </p>\"\n",
            "\"<p>As a developer, I'd like to host/read Python script (file) from HDFS, so I can use the shell processor in XD (on CF) to delegate data science functionality to Py runtime and receive the feedback back in XD.</p>\"\n",
            "<p>Upload of module launcher bits is slow because we do not take into account the<br/>CC cache. To fix this we need to use an async upload, and to somehow generate<br/>the SHA, etc, for the Module Launcher so that CC can pre-empt uploading all<br/>the bits every time.</p>\n",
            "<p>Currently we handle only a single page response from CC SPI list requests, but potentially there could be multiple ones.</p>\n",
            "\"<p>As a developer, I'd like to optimize YARN deployer, so I can deploy stream and the modules part of the definition rapidly.</p>\"\n",
            "\"<p>Currently, module composition always guesses the correct type because we don't have a module with a given name N that is both a source and a processor, or a processor and a sink (we only have the case source and sink, as in jdbc/jdbc or file/file).</p><p>If it were the case, then the heuristics for guessing the resulting type of a composition would break.</p><p>This issue is about adding the option for the user to explicitly specify the expected type of the composition, /if needed/.</p>\"\n",
            "<p>Composed Module currently behave as \"white boxes\". As soon as a module is composed (say \"http | filter\") then all options of the children modules are available (as e.g. http.port and filter.expression in the example above).</p><p>Change this so that a composed module is a black box: user has to explicitly expose an option for it to be available (most certainly using a short name). Hardcoding of values would be retained (and possibly overridable).</p><p>Possible syntaxes :<br/>1)</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">module compose foo --definition <span class=\"code-quote\">\"http --port=${myport:1234} | filter\"</span></pre></div></div><p>2)</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">module compose foo --definition <span class=\"code-quote\">\"http | filter\"</span> --expose port</pre></div></div><p>2.1) in case of ambiguity (simulated in this particular example):</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">module compose foo --definition <span class=\"code-quote\">\"http | filter\"</span> --expose http.port</pre></div></div><p>2.2) for specifying a default:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">module compose foo --definition <span class=\"code-quote\">\"http | filter\"</span> --expose port=1234</pre></div></div><p>3) allow both 1) and 2), using 1) mainly for cases where we don\\'t map 1 to 1 with the underlying option, e.g.:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">filter --expression=${expr}+<span class=\"code-quote\">\\'foo\\'</span></pre></div></div>\n",
            "<p>Make it more clear what drivers need to be copied where. See - <a href=\"https://github.com/spring-projects/spring-xd/issues/1653\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/issues/1653</a></p>\n",
            "\"<p>As a user, I'd like Flo Graphs as screenshots while referring to the batch DSL, so it will be easy for me to relate to concepts. </p>\"\n",
            "\"<p>As a developer, I'd want to document the limitations of HSQL DB when using composed jobs. </p>\"\n",
            "<p>As a developer, I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module, so that I can take advantage of the native Kafka partitioning and message ordering support.</p>\n",
            "\"<p>As a developer, I'd like to upgrade to SI 4.2.2.GA release, so I can leverage the latest improvements.</p>\"\n",
            "\"<p>As a s-c-d user, I'd like to have the option to choose Hadoop distribution of choice, so I can load the right Hadoop libraries in the CP. </p>\"\n",
            "\"<p>As a developer, I'd like to port <tt>aggregate-counter</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a developer, I'd like to port <tt>field-value-counter</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> module to build streaming pipeline.</p>\"\n",
            "<p>See <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/issues/128\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-cloud/spring-cloud-dataflow/issues/128</a></p><p>This is needed to support \"channel &gt; channel\" type constructs</p>\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>hdfs-dataset</tt> module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>analytic-pmml</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>The spring-cloud-streams samples have module options classes copied over from XD.<br/>They should use a pure @ConfigurationProperties approach, making sure metadata is generated/hand written as appropriate.</p><p>@Mixins are still referenced there but obviously can't work, so provide an equivalent</p>\"\n",
            "\"<p>As a s-c-s user, I'd like to store module metadata in <tt>Eureka</tt>, so I can use the repository to determine the current state.</p>\"\n",
            "\"<p>As a s-c-s user, I'd like to have my modules add/update it's current state to Eureka, so I can use the repository to discover the current sate of the module as needed. </p>\"\n",
            "\"<p>As a s-c-s developer, I'd like to refactor the current <tt>ModuleLauncher</tt> contract with Boot's <tt>JarLauncher</tt> API, so we don't have to maintain duplicate functionality.</p>\"\n",
            "\"<p>As a user, I'd like to have the ability to use expressions, so I can dynamically name directories/files based on the timestamp or other intermediate data point.</p>\"\n",
            "\"<p>As a user, I'd like to have direct shell commands to scale up/down a given module instance, so I can avoid SPI specific CLI commands that needs run outside of data flow.</p>\"\n",
            "\"<p>As a user, I'd like to see the version and SPI type in the `about` section, so I can confirm which build of <tt>admin-ui</tt> I'm currently using. </p>\"\n",
            "\"<p>As a user, I'd like to use the admin-ui and flo with consistent look and feel. </p>\"\n",
            "\"<p>As a developer, I'd like to replace all <tt>Job(s)</tt> references with <tt>Task(s)</tt>. </p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to break the build lifecycle to bundle SPI deployers individually, so I don't have to build <tt>admin</tt> with all the deployer variations as one whole thing.</p>\"\n",
            "\"<p>As a developer, I'd like to replace all references of Spring XD with Spring Cloud Data Flow. </p>\"\n",
            "\"<p>As a developer, I'd like to add support for <tt>undeployed</tt> status consistently across all the deployers, so I can present the correct status instead of the current <tt>unknown</tt>. This is applicable for existing streams without any deployment context associated with it. </p>\"\n",
            "\"<p>As an s-c-d user, I'd like to have documentation on deployment manifest, so I could refer to the relevant bits on <tt>partitions</tt>. I'd like to understand how streams withe  </p>\"\n",
            "<p>As an s-c-d user, I\\'d like to refer to documentation on \"direct binding\", so I can use it as a reference to deploy a stream that includes directly bound modules. </p><p>Example:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">java -jar spring-cloud-stream-module-launcher/target/spring-cloud-stream-module-launcher-1.0.0.BUILD-SNAPSHOT.jar --modules=org.springframework.cloud.stream.module:time-source:1.0.0.BUILD-SNAPSHOT,org.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOT,org.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOT --args.0.fixedDelay=7 --args.1.expression=<span class=\"code-quote\">\\'payload.contains(<span class=\"code-quote\">\"6\"</span>)\\'</span> --aggregate=<span class=\"code-keyword\">true</span> --spring.cloud.stream.bindings.output=filtered</pre></div></div>\n",
            "\"<p>As a developer, I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family, so I can continuously evaluate functionalities on every commit.</p>\"\n",
            "\"<p>As a s-c-d user, I'd like to have <tt>runtime info</tt> as shell command, so I can use this to list the details about the module such as <tt>host</tt>, <tt>port</tt> and the like.</p>\"\n",
            "<p>There is a need to customize the ModuleLauncher behavior (itself, NOT pass options to modules that are launched, which is already supported) for example to set the location of the maven repository.</p>\n",
            "\"<p>As a developer, I'd like to create separate repo for Lattice SPI, so I don't have to bundle all SPI variants under one admin project.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to self-register <tt>xd-admin</tt> server with <tt>Eureka</tt>, so I could have admin server exposed as discoverable endpoint. </p>\"\n",
            "<p>Currently, s-c-s modules all come with baked in support for multiple cloud binding technologies:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-xml\">\\t\\t<span class=\"code-tag\"><span class=\"code-comment\">&lt;!-- Lattice core dependency that activates cloud,lattice profiles when running on Lattice --&gt;</span></span>\\t\\t<span class=\"code-tag\">&lt;dependency&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;groupId&gt;</span>org.springframework.cloud<span class=\"code-tag\">&lt;/groupId&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;artifactId&gt;</span>spring-cloud-lattice-core<span class=\"code-tag\">&lt;/artifactId&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;version&gt;</span>${spring-cloud-lattice.version}<span class=\"code-tag\">&lt;/version&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;optional&gt;</span>true<span class=\"code-tag\">&lt;/optional&gt;</span>\\t\\t<span class=\"code-tag\">&lt;/dependency&gt;</span>\\t\\t<span class=\"code-tag\"><span class=\"code-comment\">&lt;!-- Cloud connector dependencies --&gt;</span></span>\\t\\t<span class=\"code-tag\"><span class=\"code-comment\">&lt;!-- Lattice connector dependency to create services info from lattice --&gt;</span></span>\\t\\t<span class=\"code-tag\">&lt;dependency&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;groupId&gt;</span>org.springframework.cloud<span class=\"code-tag\">&lt;/groupId&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;artifactId&gt;</span>spring-cloud-lattice-connector<span class=\"code-tag\">&lt;/artifactId&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;version&gt;</span>${spring-cloud-lattice.version}<span class=\"code-tag\">&lt;/version&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;optional&gt;</span>true<span class=\"code-tag\">&lt;/optional&gt;</span>\\t\\t<span class=\"code-tag\">&lt;/dependency&gt;</span>\\t\\t<span class=\"code-tag\"><span class=\"code-comment\">&lt;!-- CF connector dependency to create services info from CF --&gt;</span></span>\\t\\t<span class=\"code-tag\">&lt;dependency&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;groupId&gt;</span>org.springframework.cloud<span class=\"code-tag\">&lt;/groupId&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;artifactId&gt;</span>spring-cloud-cloudfoundry-connector<span class=\"code-tag\">&lt;/artifactId&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;optional&gt;</span>true<span class=\"code-tag\">&lt;/optional&gt;</span>\\t\\t<span class=\"code-tag\">&lt;/dependency&gt;</span>\\t\\t<span class=\"code-tag\"><span class=\"code-comment\">&lt;!-- dependency to connect to detected cloud services --&gt;</span></span>\\t\\t<span class=\"code-tag\">&lt;dependency&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;groupId&gt;</span>org.springframework.cloud<span class=\"code-tag\">&lt;/groupId&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;artifactId&gt;</span>spring-cloud-spring-service-connector<span class=\"code-tag\">&lt;/artifactId&gt;</span>\\t\\t\\t<span class=\"code-tag\">&lt;optional&gt;</span>true<span class=\"code-tag\">&lt;/optional&gt;</span>\\t\\t<span class=\"code-tag\">&lt;/dependency&gt;</span></pre></div></div><p>Should the deployers add those at runtime instead?</p>\n",
            "\"<p>As a s-c-d developer, I'd like to add support for <em>profiles</em> to the core <tt>Admin</tt> application, so I can back the stream repository with respective backend strategy. For example: <tt>local</tt> profile would use in-memory strategy to store the metadata.</p>\"\n",
            "\"<p>As a developer, I'd like to revisit the existing design and identify known limitations and/or the gaps. </p>\"\n",
            "<p>As a user, I need a document covering our recommendations for deploying a XD cluster using Mesos with the Marathon Framework.</p>\n",
            "\"<p>As an s-c-d user, I'd like to deploy s-c-d on Mesos.</p>\"\n",
            "\"<p>As a developer, I'd like to upgrade to 2.2.1 GA release, so I can leverage the latest improvements without breaking backwards compatibility. SHDP 2.3.0 uses Boot 1.3 and HDP and CDH versions that drop older Hive support. To avoid breaking changes we should instead use SHDP 2.2.1 that has backported any improvements that we need as well as move Spring and Hadoop versions to more recent ones.</p>\"\n",
            "<p>When a problem occurs connecting to admin, we just get <tt>Unable to contact Data Flow Admin</tt> even if the connection is successful and some problem occurs when interpreting the result.</p><p>The exception is eaten.</p><p>Log an error including the exception.</p><p>Currently investigating an NPE in DataFlowTemplate @ line 77.</p>\n",
            "\"<p>As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions, so I can leverage the latest updates.</p>\"\n",
            "<p>I don\\'t recall why <a href=\"https://github.com/garyrussell/spring-xd/commit/ba15a1390f7e448dbc723ee76a45c2e239e0994e\" class=\"external-link\" rel=\"nofollow\">this commit </a> was not applied to master but having the timestamp for each step in the history will be useful.</p><p>See <a href=\"https://github.com/spring-projects/spring-xd-modules/issues/24#issuecomment-154436643\" class=\"external-link\" rel=\"nofollow\">this github issue </a>.</p>\n",
            "\"<p>As a developer, I'd like to add <tt>undeployed</tt> status for Mesos SPI, so I can represent the correct status instead of the current <tt>unknown</tt> state.</p>\"\n",
            "\"<p>As a developer, I'd like to add <tt>undeployed</tt> status for k8s SPI, so I can represent the correct status instead of the current <tt>unknown</tt> state.</p>\"\n",
            "\"<p>As a developer, I'd like to add <tt>undeployed</tt> status for Lattice SPI, so I can represent the correct status instead of the current <tt>unknown</tt> state.</p>\"\n",
            "\"<p>As a developer, I'd like to add <tt>undeployed</tt> status for CF SPI, so I can represent the correct status instead of the current <tt>unknown</tt> state.</p>\"\n",
            "\"<p>As a developer, I'd like to add <tt>undeployed</tt> status for YARN SPI, so I can represent the correct status instead of the current <tt>unknown</tt> state.</p>\"\n",
            "<p>Users want the ability to use Composed Jobs (specifically parallel Jobs) without having to update the configurations for the hsqldb and the Isolation Level for spring batch.  These should be set by default.</p>\n",
            "<p>Need to add the following instructions to setup the configurations for the Batch Repo to Composed Job Docs to support parallel jobs:<br/>1) uncomment and change the following from  :<br/>```spring:<br/>  batch:</p><ol>\\t<li>Configure other Spring Batch repository values.  Most are typically not needed<br/>    isolationLevel: ISOLATION_SERIALIZATION<br/>```<br/>to<br/>```spring:<br/>  batch:</li>\\t<li>Configure other Spring Batch repository values.  Most are typically not needed<br/>    isolationLevel: ISOLATION_READ_COMMITTED<br/>```  <br/>And update the hsqldb datasource to:<br/>spring:<br/>  datasource:<br/>    url: jdbc:hsqldb:hsql://${hsql.server.host:localhost}:${hsql.server.port:9101}/${hsql.server.dbname:xdjob};sql.enforce_strict_size=true;hsqldb.tx=mvcc</li></ol>\n",
            "<p>As a s-c-s-m developer, I\\'d like to move <tt>jdbc</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> to build streaming pipeline.</p><p>See also <a href=\"https://jira.spring.io/browse/XD-2250\" title=\"Improve type handling for jdbc sink\" class=\"issue-link\" data-issue-key=\"XD-2250\">XD-2250</a></p>\n",
            "\"<p>As a s-c-s user, I'd like to have <tt>Gemfire</tt> message-channel binder, so I can use <tt>Gemfire</tt> as the messaging middleware for low latency use-cases. </p>\"\n",
            "\"<p>As an s-c-d user, I'd like to <tt>tap</tt> the primary pipeline, so I can fork the same data and do some ad-hoc analysis without impacting the original stream.</p>\"\n",
            "<p>As a developer, I want to have a <tt>BinderFactory</tt> abstraction, so that I can support multiple binder types in the future.</p>\n",
            "\"<p>As a user, I'd like to use SpEL expressions inline at the stream definition level, so I can operate on the payload consistently while using any OOTB, including the custom modules. </p>\"\n",
            "<p>As a developer, I want to be able to connect to multiple external systems for the same binding type, so that I can read data from a system and write it to another.</p>\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>cassandra</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> to build streaming pipeline.</p>\"\n",
            "\"<p>As a developer, I'd like to split <tt>admin</tt> artifact packaged with hadoop distro specific libraries, so I could avoid adding all variations of hadoop libraries under one project. </p>\"\n",
            "\"<p>As a s-c-s user, I'd like to search the modules by it's name aside from the default <tt>spring.application.name</tt> offered by boot, so I can also fetch modules by it's name.</p>\"\n",
            "\"<p>As a developer, I'd like to study the state management requirements, so I can brainstorm and identify the design to natively add <em>stateful</em> stream processing support in XD. </p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to document the use of BOM templates, so the general audience can use it as a reference to include external libraries dynamically.</p>\"\n",
            "\"<p>As a s-c-s developer, I'd like to support XD-like features where modules bind to incoming messages via expressions or other mechanism, so I can bind message properties to every microservice modules. </p>\"\n",
            "<p>Enable spring cloud config for all modules </p><ul>\\t<li>Add spring cloud config client to pom dependencies.</li>\\t<li>Add bootstrap.yml to scs project</li></ul>\n",
            "\"<p>As a s-c-d developer, I'd like to add support for dependency resolution, so when two or more modules use different version of jars (ex: direct binding of two modules that include different versions of spring data), I have the capability to resolve and include the right bits at runtime.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to investigate how to include/exclude msg bus/binding jars, so I can decide the binding selection and fallback mechanism when there is none setup.</p>\"\n",
            "\"<p>As a s-c-s user, I'd like to have the modules self-register itself with <tt>Eureka</tt> whenever they're installed, so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines. </p>\"\n",
            "\"<p>As a user, I'd like to refer to 'job orchestration' documentation, so I can use it as guideline for building batch workflows.  </p>\"\n",
            "<p>In <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/README.md#running-on-cloud-foundry\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/README.md#running-on-cloud-foundry</a> the section starting \\'Now we can configure the app\\' needs to be revised - the information is both out of date and, even if up-to-date, misleading (it includes some values as if they are universal, when they are really just examples).</p>\n",
            "\"<p>As a s-c-d user, I'd like to deploy data flow on YARN, so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.</p>\"\n",
            "\"<p>As a Flo user, I'd like to have <tt>timeout</tt> and <tt>pollInterval</tt> as global options at the DSL level, so I can override the defaults at will. </p>\"\n",
            "\"<p>As a developer, I'd like to port <tt>file</tt> module from XD to s-c-s repo, so I can use it as <tt>source</tt> module to build streaming pipeline.</p>\"\n",
            "<p>The XML REST endpoints:</p><ul>\\t<li>are not working correctly</li>\\t<li>interfere with security</li>\\t<li>are not used</li></ul>\n",
            "\"<p>As a developer, I'd like to get rid off <tt>XDRuntimeException</tt> from XD.</p>\"\n",
            "<h2><a name=\"Narrative\"></a>Narrative</h2><p>As a XD user, I\\'d like to restart the composed job workflow from Shell/UI. </p>\n",
            "<h2><a name=\"Narrative\"></a>Narrative</h2><p>Verify that the job launch works as we expect for the composed job.</p>\n",
            "\"<p>As a developer, I'd like to enhance test coverage to capture DSL and XML generation variants. </p>\"\n",
            "\"<p>As a developer, I'd like to upgrade to SI 4.2.1 release, so I can take advantage of the latest improvements.</p>\"\n",
            "\"<p>As an XD user, I'd like to have a REST endpoint that returns job composition graph, so I can use it to build visual representation of parent-child relationship. </p>\"\n",
            "\"<p>As an XD user, I'd like to be able to visually differentiate between job-composition workflow and single job.</p>\"\n",
            "\"<p>As an XD user, I'd like to click to go the detail page of the job page whether or not the selected entity is singular or part of a composed job.</p>\"\n",
            "\"<p>As an XD user, I'd like to have a REST endpoint that returns job composition <tt>flag</tt>, so I can use it to differentiate visual representation between parent-child relationship and standalone jobs.</p>\"\n",
            "\"<p>As an XD developer, I'd like to explore options to remove composed job, so I can clean-up unused resources and memory footprints. </p>\"\n",
            "\"<p>As an s-c-d developer, I'd like to move rabbit <tt>@Rule</tt> to a separate repo, so I can consume the test fixtures in different projects.</p>\"\n",
            "\"<p>As an s-c-d developer, I'd like to move redis <tt>@Rule</tt> to a separate repo, so I can consume the test fixtures in different projects.</p>\"\n",
            "\"<p>As an s-c-d developer, I'd like to move kafka <tt>@Rule</tt> to a separate repo, so I can consume the test fixtures in different projects.</p>\"\n",
            "<p>As a user, I\\'d like to have an option to have the hdfs sink use \"Syncable\" writes to provide better resiliency in the case of sink/container failures. I\\'m willing to accept the performance penalty if I choose this option.</p>\n",
            "\"<p>As a developer, I'd like to review and refactor <tt>JobLaunchingTasklet</tt>, so I can improve performance characteristics. </p>\"\n",
            "<p>As a SCDF user, I want to be able to register artifacts as libraries, so that I can reference them in include and exclude statements.</p>\n",
            "nan\n",
            "<p>We need to make sure that JMX MBean names are unique, even in the case of labeled modules.</p><p>The following stream fails for example: \"http | filter | filter2: filter | log\"</p><p>A good candidate could be stream name (group) + module label.</p>\n",
            "\"<p>As an s-c-d user, I'd like to have tab completion on shell, so I can interact with the modules and its available options.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>FTP</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> modules to build streaming pipeline.</p>\"\n",
            "<p>As a user, I\\'d like to use SFTP source module, so I can create streaming pipeline with it. However, I cannot see SFTP as OOTB module listed on: <tt>module list</tt> and as well as the module bits are not available in <a href=\"http://repo.spring.io/libs-snapshot/org/springframework/cloud/stream/module/\" class=\"external-link\" rel=\"nofollow\">maven repo</a>. </p>\n",
            "<p>As an s-c-d user, I\\'d like to contribute modules that immediately reflects in module registry, so I can create stream or task definitions using the shell/rest-api\\'s. </p><p>Currently the registry isn\\'t flexible, as it is pretty much <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-admin/src/main/java/org/springframework/cloud/dataflow/admin/config/ModuleRegistryPopulator.java#L75\" class=\"external-link\" rel=\"nofollow\">hard-coded at registry bootstrap level</a>. </p>\n",
            "\"<p>As an s-c-d user, I'd like to upload custom modules using shell/rest-api, so I can contribute modules and create streaming/batch pipelines. </p>\"\n",
            "\"<p>As an XD user, I'd like have support restart an existing composed job, so I could re-launch it at will.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to move the external library to its own project, so we have a clear separation of functionalities in s-c-d repo.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>tcp</tt> module from XD to s-c-s repo, so I can use it as <tt>source</tt> module to build streaming pipeline.</p>\"\n",
            "<p>Spring Integration 4.2 changed the default SFTP session factory to <b>not</b> accept keys from unknown hosts by default. This is more secure.</p><p>You either have to provide a pre-populated <tt>known_hosts</tt> file or set <tt>allowUnknownKeys</tt> to true.</p><p>If you do both, the keys will be automatically added to the known hosts file.</p><p>When updating XD to 4.2.0.RC1 I simply set the boolean to true, to retain the previous behavior.</p><p>Add properties to the SFTP source to allow configuration of these properties at the stream level.</p>\n",
            "\"<p>As a spring-cloud-stream user, I'd like to build stream definitions using dot-delimited syntax for resolving properties for Tuple and JSON.</p>\"\n",
            "<h2><a name=\"Narrative\"></a>Narrative</h2><p>As the system, I would like a way to launch a previously deployed job module from another job module.</p><h2><a name=\"Backstory\"></a>Back story</h2><p>For the composed job story, we will have a driver job that consists of each step that represents the execution of a job.  This story is the creation of a <tt>Tasklet</tt> that will launch the child job, and upon it\\'s completion, set the results of the driver\\'s step to that of the slave job\\'s results.</p>\n",
            "\"<p>As a Spring XD developer, I'd like to port SFTP module from XD to s-c-s repo, so I can use it as source modules to build streaming pipeline.</p>\"\n",
            "<p>For example the generated value for the cassandra sink results in </p><p><tt>-$$entityBasePackages$$:: $$the base packages to scan for entities annotated with Table annotations$$ ($$String;$$, default: `[Ljava.lang.String;@2638011`)</tt></p><p>where the default value changes each time the build is run.</p>\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>gemfire</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> to build streaming pipeline.</p>\"\n",
            "\"<p>As a developer, I'd like to port <tt>Log</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> modules to build streaming pipeline.</p>\"\n",
            "<p>Described in <a href=\"https://github.com/spring-cloud/spring-cloud-stream/issues/144\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-cloud/spring-cloud-stream/issues/144</a></p><p>As a developer, I want Input enpoints to be started after all the beans in the context, so that received messages can be delivered to components. </p>\n",
            "\"<p>As an s-c-d user, I'd like to have the option to use <em>named channels</em>, so I can create streaming pipelines without source or sink modules. </p>\"\n",
            "\"<p>As a developer, I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo, so I could define the module <tt>artifactId</tt> from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to refactor current controller with SPI calls, so I can invoke the respective Admin SPI implementation based on the deployment. </p><p><b>Controllers to Refactor</b></p><ul>\\t<li>ContainersController</li>\\t<li>StreamsController</li>\\t<li>ModulesController</li>\\t<li>JobsController</li></ul>\"\n",
            "\"<p>As a s-c-d developer, I'd like to add test coverage for <tt>StreamController</tt>, so I can verify API contracts at build time. </p>\"\n",
            "\"<p>As a s-c-d user, I should be prevented from creating streams with duplicate name. I'd expect streams to have unique names all the time. </p>\"\n",
            "\"<p>As a XD user, I'd like to orchestrate composed jobs, so I can bring multiple jobs into single workflow and operationalize.</p>\"\n",
            "<p>As a XD developer, I\\'d like to explore repository options for \"composed jobs\", so I have the leverage to read/write composed job definitions.</p>\n",
            "<p>Can take from previous implementation in XD/SI/Boot.<br/>Should have a way to enforce not skipping tests based on an environment variable.</p><p>Consider moving this coverage to SI \"commons\" or equivalent. </p>\n",
            "<p>As a s-c-d developer, I\\'d like to create a new project to contain all the rules associated <tt>@RedisRule</tt> contract, so it is isolated from core functionalities and reusable by test coverage as needed.  </p><p>Consider moving this coverage to SI \"commons\" or equivalent. </p>\n",
            "\"<p>As a developer, I'd like to move 'serialization codec' from Spring XD repo into SI, so I can update Spring XD to inherit the features/functionalities via maven dependency.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>file</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> module to build streaming pipeline.</p>\"\n",
            "<p>As a s-c-s user, I\\'d like to have the option to use more than one binder connection factory, so I can mix and match where I consume and publish data. </p><p>More details <a href=\"https://github.com/spring-cloud/spring-cloud-stream/issues/140\" class=\"external-link\" rel=\"nofollow\">here</a>.</p>\n",
            "\"<p>As a s-c-d developer, I'd like to add support for having different binder types for module's channels, so I can plug <tt>rabbit</tt>, <tt>redis</tt>, or <tt>kafka</tt> as the source or sink to read and write respectively.</p>\"\n",
            "\"<p>As a Spring XD user, I'd like to use the latest releases of <tt>HDP</tt>/<tt>PHD</tt> distros, so I can leverage the latest features to create pipelines involving <tt>HDFS</tt>.</p>\"\n",
            "<p>We do set a default value in: xd/lib/spring-xd-dirt-1.2.1.RELEASE.jar/application.yml</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">...xd:  data:    home: file:${XD_HOME}/data  config:    home: file:${XD_HOME}/config  module:    home: file:${XD_HOME}/modules  customModule:    home: file:${XD_HOME}/custom-modules  ui:    home: file:${XD_HOME}/spring-xd-ui/dist/    allow_origin: http:<span class=\"code-comment\">//localhost:9889</span>...</pre></div></div><p>We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using *<b>servers.yml</b>*</p>\n",
            "<p>XD Developer does not want the the twitter stream acceptance tests to interfere with other tests.</p>\n",
            "<p>When a default value is an array, the current behavior (using toString()) not only produces useless results (like `[Ljava.lang.String;@2638011`) but also constantly changing results.</p>\n",
            "\"<p>As a developer, I'd like to move input/output type conversion from Spring XD repo to spring-cloud-dataflow, so I can implement a custom module which produces or consumes a custom domain object.</p>\"\n",
            "<p>The CF implementation requires that a route be created for each new app. This works fine on the happy path, but is brittle. For example, it will fail if the route required already exists.</p>\n",
            "\"<p>As a s-c-d developer, I'd like to refactor CC SPI deployer with CF java-client, so I can improve the overall design and performance. </p>\"\n",
            "\"<p>As a XD developer, I'd like to move header-enricher from modules repo to XD proper. </p>\"\n",
            "\"<p>As a Spring XD user, I'd like to create streaming pipelines, so I can take advantage of latest specs from both XD and Spark/Spark Streaming.</p>\"\n",
            "<p>As a user, I\\'m not able to shutdown <tt>container</tt> from Admin UI with the following stream definition deployed.</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">stream create swagataTestIssue --definition <span class=\"code-quote\">\"jdbc --query=<span class=\"code-quote\">\\'select employee_id, employee_name, employer from EMPLOYEE\\'</span> --url=<span class=\"code-quote\">\\'jdbc:oracle:thin:@<span class=\"code-comment\">//localhost:1521/orcl\\'</span>  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=<span class=\"code-keyword\">false</span> | hdfs --inputType=application/json \"</span> --deploy </span></pre></div></div><p>More details <a href=\"https://issuetracker.springsource.com/browse/VESC-504\" class=\"external-link\" rel=\"nofollow\">here</a>.</p>\n",
            "nan\n",
            "\"<p>As a XD developer, I'd like to upgrade to SI 4.2, Spring 4.2.1, and AMQP 1.5 dependencies, so I can take advantage of the latest improvements. </p>\"\n",
            "nan\n",
            "<p>This class should not know what the test app is. This means changing the constructors on CloudFoundryApplication.</p>\n",
            "\"<p>As a s-c-d developer, I'd like to resolve and then add module dependent JAR's to Boot loader, so I have an approach to handle external libraries (ex: database drivers) required by OOTB modules.</p>\"\n",
            "<p>Currently only the STARTED application (and application instance) status is recognised. This issue will look at the other possible states and report them as module instance states.</p><p>This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.</p>\n",
            "\"<p>As a s-c-d developer, I'd like to produce ref. documentation for s-c-d architecture, so I could define 1.x and 2.x deployment differences. </p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to setup <tt>gh_pages</tt> branch for s-c-d and s-c-s-m repos, so I can start pushing documentation with PR commits.</p>\"\n",
            "<p>As a s-c-d user, I\\'d like to create a new banner, so I can embed and display the banner when the shell server boots-up. </p><p>Perhaps use this <a href=\"http://patorjk.com/software/taag/#p=display&amp;f=Standard&amp;t=Spring%20Cloud%0AData%20Flow%20%20%3E%3E%3E%3E%3E%20\" class=\"external-link\" rel=\"nofollow\">banner generator</a>?</p>\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>twitterstream</tt> module from XD to s-c-s repo, so I can use it as source modules to build streaming pipeline.</p>\"\n",
            "<p>As a s-c-d developer, I\\'d like to document <a href=\"https://github.com/spring-cloud/spring-cloud-dataflow#running-on-cloud-foundry\" class=\"external-link\" rel=\"nofollow\">Running on Cloud Foundry</a> section in README, so it can be publicly available as deployment guideline.</p>\n",
            "\"<p>As a s-c-d developer, I'd like to add <em>hdfs</em> sink to module registry, so I can use this module to build streaming pipeline and write to Hadoop.</p>\"\n",
            "\"<p>As a s-c-s developer, I'd like to investigate the right approach to port <tt>PHD</tt> as the provider to support <tt>HDFS</tt> module from XD, so I can decide better handling of HDFS dependencies, which needs loaded and available in root CP at the runtime. </p>\"\n",
            "<p>As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.</p>\n",
            "<p>Currently we deploy a single instance, and ignore the ModuleDeploymentRequest instances setting.</p><p>It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher, so we hold off until that can be verified.</p>\n",
            "<p>Currently undeploy is a no-op.</p>\n",
            "<p>The current ModuleRunner is test app used for validation. This should be replaced by a real app.</p>\n",
            "\"<p>ModuleDefinition contains bindings that need to be passed to the ModuleRunner app. It appears these can be included in the application's environment.</p>\"\n",
            "\"<p>A ModuleDefinition contains parameters, which need to be passed to the CloudFoundry application. Currently these are put directly into the application's environment. This issue will verify they are correctly named.</p>\"\n",
            "<p>Remove all stubs and check all required information is returned accurately.</p>\n",
            "<p>Currently there is no ModuleInstanceStatus returned. This issue will fill in the details.</p>\n",
            "<p>The current implementation makes use of cf-java-client, which is relatively heavy for our needs. It should be removed in favour of a bespoke RestOperations wrapper. See <a href=\"https://github.com/Zteve/test-cc-oauth\" class=\"external-link\" rel=\"nofollow\">https://github.com/Zteve/test-cc-oauth</a> for sample code.</p>\n",
            "<p>We currently use fixed paths like `spring-cloud-data-yarn/spring-cloud-data-yarn-appmaster/target/spring-cloud-data-yarn-appmaster-1.0.0.BUILD-SNAPSHOT.jar` in yml files. Need to make define version during a build and allow to override location of those files.</p>\n",
            "<p>User can configure spring cloud data via  via Spring Cloud Config, data-admin.yml or Spring Cloud Connector</p><ul>\\t<li>Add bootstrap.yml to spring cloud data</li>\\t<li>create a default data-admin.yml and configure spring data to look for this vs application.yml.</li>\\t<li>Spring Cloud Data will have Spring Cloud Config enabled by default\\t<ul>\\t\\t<li>User has the ability to disable it via the bootstrap.yml</li>\\t</ul>\\t</li></ul>\n",
            "<p>As a module author, I would like to apply RxJava processor module with spring cloud stream. </p>\n",
            "\"<p>As a s-c-d developer, I'd like to add support to deploy YARN App into HDFS automatically, so I can have the <tt>xd-admin</tt> orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to make the deployer work asynchronously, so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.</p>\"\n",
            "\"<p>As a s-c-d user, I'd like to have the option to support passing definition parameters into YARN container, so I can effectively use those <em>params</em> within the module running inside the container.</p>\"\n",
            "\"<p>As an s-c-d developer, I'd like to add support to negotiate with the ResourceManager REST-APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as  <tt>appType=CLOUDDATA</tt> and <tt>appName=spring-cloud-data-yarn-app</tt>.</p>\"\n",
            "\"<p>As a s-c-s user, I'd like to have the option to direct bind <em>modules</em>, so I don't have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases. </p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to move <tt>redis</tt> module from XD to s-c-s repo, so I can use it as <tt>sink</tt> to build streaming pipeline.</p>\"\n",
            "\"<p>As a s-c-s developer, I'd like to fix the <tt>Kafka</tt> binder, so I can create messaging microservices apps and successfully bind them to an operational Kafka broker. </p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to have <tt>module info</tt>, <tt>module list</tt>, <tt>module register</tt>, and <tt>module unregister</tt> commands, so I can interact with <tt>ModuleRegistry</tt>.</p>\"\n",
            "<p>Create a timestamp job that will be used a a sample for users to create their own spring boot based jobs.  </p>\n",
            "<p>Improve Spring Cloud Stream module launcher/resolver properties:</p><p>1) Support comma separated remoteRepositories<br/>2) Classify/group the properties</p>\n",
            "<p>Instead of using real `moduleDeployer`, try using mocks so that the module deployer downloading the maven co-ordinates from repo can be avoided (for module deployment case).</p><p>Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.</p>\n",
            "<p>The s-c-s-module-launcher document requires update for running it on standalone, docker, lattice.<br/>Also, the docker-compose yml requires fix so that modules in there are bound together.</p>\n",
            "\"<p>As a s-c-d developer, I'd like to provide optional key-value pairs as deployment properties, so I could leverage them at the runtime to instruct how the modules will be deployed. </p><p><em>The scope of this story is to specifically support <tt>count</tt> to represent <tt>N</tt> instances of modules that share the same environment variables.</em></p>\"\n",
            "\"<p>As a developer, I'd like to create persistent repository for streams, so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to create foundation to support <em>processor</em> as OOTB modules, so I can use the processor modules from <tt>s-c-s-m</tt> repo to build streaming pipeline.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to create <tt>ModuleRegistry</tt> implementation, so I can use this infrastructure to lookup module coordinates by name.</p>\"\n",
            "\"<p>As a s-c-s developer, I'd like to enable <tt>offline</tt> mode for <tt>AetherModuleResolver</tt>, so I can pull the module artifacts from local instead of remote maven repo.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>http</tt> module from XD to s-c-s repo, so I can use it as <tt>source</tt> module in streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>FTP</tt> modules from XD to s-c-s repo, so I can use them as <tt>source</tt> modules to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>transform</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to port <tt>filter</tt> module from XD to s-c-s repo, so I can use it as <tt>processor</tt> module to build streaming pipeline.</p>\"\n",
            "\"<p>As a s-c-s developer, I'd like to create auto configuration for <tt>singlenode</tt> binder configuration/properties, so I can automatically configure the Spring application based on the dependencies.</p>\"\n",
            "<p>Make ChannelBindingAdapter implement SmartLifecycle so that it gets started with the highest precedence and before any other message producing bean.</p>\n",
            "\"<p>As a user, I'd like to have the option to delete the queues/topics so that we can include an <em>optional</em> attribute as part of the stream destroy command to also clean-up the associated queues/topics.</p><p><b>Notes:</b></p><ul>\\t<li>Spring-AMQP <tt>RabbitAdmin</tt> now has a <tt>getQueueProperties()</tt> method which returns the number of consumers so it may be possible to use it for this purpose.</li>\\t<li>Consider the possibility of <em>producers</em> and/or <em>queues</em> still containing data</li>\\t<li>Consider the scenario even after the topics/queues are cleaned-up, what to do with fanout exchange?</li></ul><p><b>Some Further Thoughts</b></p><ul>\\t<li>Consider using the upcoming Spring AMQP REST API <tt>RabbitManagementTemplate</tt> if the timing is not right, we could temporarily invoke the rabbit REST API directly.</li>\\t<li>Should be optional; perhaps via <tt>stream destroy foo --clean</tt></li>\\t<li>Should this be done by the admin? Or, via a new plugin handling module undeployments - in the rabbit case, undeploying a consumer would check for us being the last consumer and remove the queue/binding/exchange, since we undeploy left-&gt;right, everything can be cleaned up on the consumer side.</li>\\t<li>Third option would be new methods on the bus <tt>cleanConsumer</tt> etc invoked by the <tt>StreamPlugin</tt></li>\\t<li>Down side of doing it on the admin is that he wouldn't necessarily know which rabbit cluster a stream was deployed to - so it probably has to happen on the container - even so, we'd need the admin url(s) for the cluster.</li></ul>\"\n",
            "<p>As a developer, I\\'d like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. </p><p>This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality; hence, the current workaround with <a href=\"https://jira.spring.io/browse/XD-2486\" title=\"Context Deserialize Doesn&#39;t Use Parent First Classloader\" class=\"issue-link\" data-issue-key=\"XD-2486\"><del>XD-2486</del></a> needs reafctored. </p>\n",
            "\"<p>As an s-c-s developer, I'd like to brainstorm and design the foundation to port XD modules as s-c-s modules, so I can use it as the base and start migrating the modules.</p>\"\n",
            "<p>XD Module configured for component scanning classes (or methods?) annotated with @Source, (consider @Processor, and @Sink as well) and simply provide the POJOs and dependent jars in the module /lib directory. Custom processor is fairly straightforward currently, but still requires an XML module definition to wire up the POJO as a service activator or transformer to the input and output channel. A service activator works for a POJO backed sink. Writing a source that is not backed by an existing inbound channel adapter is a bit more involved and requires more than basic familiarity with SI. It should be possible for XD to automatically create a polling source by wiring a Java method to an inbound adapter configured with a poller. Ideally, we would require no XML, even to enable component scanning- this will require some changes to the module registry/module initializer.</p>\n",
            "\"<p>As a s-c-d developer, I'd like to experiment how do we resolve and then add module dependent JAR's to Boot loader, so I have an approach to handle external libraries required by OOTB modules. </p>\"\n",
            "<p>As a developer, I\\'d like to migrate module deployment from the \"repository\" abstraction (used for stream/job definitions), so I can create it as a pluggable runtime SPI.</p>\n",
            "\"<p>As a developer, I'd like to define pluggable runtime SPI, so I have the option to choose the implementation based on deployment targets such as CF, on-prem, Mesos etc.</p>\"\n",
            "<p>Build SCS and SCD projects upon change in github repo.<br/>Push docker image for SCD-Admin to docker hub</p>\n",
            "<p>As a module author, I want to be able to test my code in \"next to real world\" conditions (ie Integration Testing, but not really):</p><ul class=\"alternate\" type=\"square\">\\t<li>I want all my module wiring to be testable</li>\\t<li>I want all my module configuration (@ConfigurationProperties) to be in effect, and I want to be able to test various combination of props</li>\\t<li>I want to be able to send data to my module and assert what is coming at the other end</li>\\t<li>I want an idiomatic way of asserting the above (eg integration with Hamcrest, etc)</li>\\t<li>I DONT want to have to send data to an actual bus (redis, rabbit, etc)</li></ul>\n",
            "<p>As a s-c-d developer, I\\'d like to implement <em>undeploy</em> operation for <tt>singlenode</tt> (single JVM), so I can use this target to undeploy a running stream. More details in <a href=\"https://github.com/spring-cloud/spring-cloud-data/pull/19\" class=\"external-link\" rel=\"nofollow\">this PR</a>.</p><p><b>Note:</b> Its a prerequisite to determine consistent <em>undeploy</em> strategy for both <tt>jobs</tt> and <tt>streams</tt>. </p>\n",
            "<p>As a user I should be able to use the existing admin UI client for spring-cloud-data admin with the appropriate server configurations.</p>\n",
            "<p>Spring-cloud-data admin requires lattice connector and `spring-cloud-spring-service-connector` dependencies so that the admin controllers get access to any services while running on lattice.</p><p>One example is, CounterContoller using `redis` service for MetricRepository.</p>\n",
            "\"<p>As an s-c-d developer, I'd like to investigate the distributed deployment of s-c-s modules on YARN, so I can experiment the implementation of YARN SPI and derive the strategy for <tt>YARNModuleDeployer</tt>.</p>\"\n",
            "<p>Apply the same strategy for the Module Command Tests also to all other Shell integration tests.</p>\n",
            "<p>Currently the DSL parsing for tasks is a copy and paste of what it is for streams (minus the ability to parse multiple modules).  This results in a lot of duplication.  This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.</p>\n",
            "\"<p>As a s-c-d developer, I'd like to upgrade <tt>receptor-client</tt> to comply with latest <tt>Receptor</tt> API changes, so I can sync-up and take advantage of the recent improvements. </p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to add support to expose counter (metrics) endpoints, so I can consume to feed the dashboards to demonstrate <tt>firehose | counter</tt> pipe.</p>\"\n",
            "<p>This could focus only on the subset (Stream operations)</p>\n",
            "\"<p>As a s-c-s developer, I'd like to adapt redis <tt>counter</tt> from XD to s-c-s, so I can build streaming pipes using s-c-s modules with simple counters to feed dashboards. </p>\"\n",
            "\"<p>Currently, @EnableModule hardcodes references to both the redis and rabbit configuration classes, which trigger or don't trigger based on the presence of another jar (which itself has the meat of the configuration).<br/>This is typically what boot AutoConfiguration is for.</p><p>Moreover, adding a new binding (eg Kafka or a stub for module testing) would require to crack open @EnableModule</p>\"\n",
            "<p>Create Confguration and ConfigurationProperties. Configuration must support replacing the default Kryo Codec implementation with something else.</p>\n",
            "nan\n",
            "<p>replace with xd.messagebus prefix with spring.cloud.stream.binder</p>\n",
            "<p>As a user I would like to have shell interface to the spring-cloud-data rest API. The scope for this JIRA could be limited to stream commands.</p>\n",
            "<p>As a Spring XD on CF user, I\\'d like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules, so I can leverage the SPI to query for module status and health metrics.</p><p><b>Possible APIs:</b></p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">ModuleStatus getStatus(ModuleDescriptor descriptor);Collection&lt;ModuleDescriptor&gt; listModules();Map&lt;ModuleDescriptor.Key, ModuleStatus&gt;</pre></div></div>\n",
            "\"<p>As a Spring XD user, I'd like to make SPI implementation profile aware, so I can run <tt>java -jar admin</tt> or <tt>cf push</tt> admin or <tt>ltc create admin</tt> and the corresponding implementation gets wired-in automatically.</p>\"\n",
            "\"<p>As a s-c-d user, I'd like to add REST support for stream commands, so I can maneuver streaming pipeline backed by StreamController.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to publish the s-c-d image to DockerHub, so I can incrementally push the latest commits to the remote location.</p>\"\n",
            "<p>As a s-c-s developer, I\\'d like to setup a CI workflow to build, bundle and upload the <tt>module-launcher</tt> image to DockerHub, so I don\\'t have to worry about having a local-private docker registry for development/testing.</p><p>It could be nice to have the image uploaded to existing <a href=\"https://registry.hub.docker.com/repos/springcloud/\" class=\"external-link\" rel=\"nofollow\">spring-cloud</a> DockerHub location. </p>\n",
            "\"<p>As a s-c-d developer, I'd like to invoke REST APIs via shell, so I can validate <tt>StreamController</tt> operations.</p>\"\n",
            "\"<p>As a spring-cloud-data developer, I'd like to use an in-memory stream definition repository, so I don't have to spin up a store; obviously, this will not persist between application executions, but it will be useful for a simplified development experience.</p>\"\n",
            "<p>As a s-c-d developer, I\\'d like to setup CI infrastructure for <a href=\"https://github.com/spring-cloud/spring-cloud-data\" class=\"external-link\" rel=\"nofollow\">s-c-d repo</a>, so I can build the project continuously on every commits. </p>\n",
            "<p>As a Spring XD user, I\\'d like to use <tt>CloudController</tt> based implementation of XD Admin SPI (based on ModuleLauncher), so I can run data pipeline use-cases running on CF.</p><p>Relevant repos: <a href=\"https://github.com/spring-cloud/spring-cloud-data/tree/master/spring-cloud-data-module-deployers\" class=\"external-link\" rel=\"nofollow\">spring-cloud-data</a> | <a href=\"https://github.com/spring-cloud/spring-cloud-stream\" class=\"external-link\" rel=\"nofollow\">spring-cloud-stream</a></p><p>Please refer to <a href=\"https://jira.spring.io/browse/XD-3194\" title=\"Spike: Investigate spring-cloud-config and the XD fit\" class=\"issue-link\" data-issue-key=\"XD-3194\"><del>XD-3194</del></a> or <a href=\"https://jira.spring.io/browse/XD-3229\" title=\"Spike: XD Admin SPI to discover s-c-s modules\" class=\"issue-link\" data-issue-key=\"XD-3229\"><del>XD-3229</del></a> as sample spike-deliverables (<em>google doc</em>) that were completed in the last sprint. </p>\n",
            "\"<p>As a s-c-s developer, I'd like to <em>bootify</em> <tt>ModuleLauncher</tt>, so I can use Spring Boot's support for property, setting, as well as adding options and new functionality in the future, such as CP augmentation.</p>\"\n",
            "\"<p>As a s-c-s developer, I'd like to setup CI builds for s-c-s builds, so I can incrementally build and test code commits automatically.</p>\"\n",
            "\"<p>As a s-c-s developer, I'd like to move <tt>spring-cloud-stream-modules</tt> from s-c-s to s-c repo, so I can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to create {[ModuleRegistry}} stubs, so I can create mock streams by interacting with the registry APIs.</p>\"\n",
            "\"<p>As a s-c-d developer, I'd like to establish the foundation to expose REST-APIs to interact with the <tt>xd-admin</tt> and likewise perform CRUD operations to maneuver streaming and batch pipelines. </p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to have a permanent location of SPI implementations, so I could use the common repo every time I contribute or enhance the test coverage.</p>\"\n",
            "\"<p>As a Spring XD developer, I'd like to create initial version of the new module registry abstraction, so we could leverage the foundation to make progress and test the respective SPI (<tt>receptor</tt> or <tt>cloudcontroller</tt>) implementations.</p>\"\n",
            "\"<p>As a s-c-s developer, I'd like to setup CI infrastructure for <tt>spring-cloud-stream-modules</tt> (s-c-s-m) repo, so I can build the project continuously on every commits.</p>\"\n",
            "\"<p>As a user, I'd like to start multiple instances of <tt>xd-container</tt>'s through the RPM scripts, so I can easily spin-up instances on the same node/vm.</p>\"\n",
            "<p>Following the recent move of the doco to the main repo, it makes sense to have the doc generation be part of the \"main\" build, at an early stage, as an incentive for developers to push doc changes as soon as they change the code.</p>\n",
            "<p>Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle (if one decided to use upload) is quicker and edits can be done in place.</p>\n",
            "\"<p>As a developer, I'd like the <tt>publish-maven.gradle</tt> script to use values for dependencies (e.g. Spring Boot and <tt>hadoop-common</tt>) from our central dependency list (in this case <tt>dependencies.properties</tt>) so that I don't have to update them manually anymore.</p>\"\n",
            "\"<p>As a PM, I'd like to have XD and XD + Ambari RPM scripts into a single public repo, so that users can go to a single location to use the respective build scripts.</p>\"\n",
            "\"<p>As a developer, I'd like to revisit performance benchmarks with new improvements, so I can verify the optimizations around <em>jdbchdfs</em>.</p>\"\n",
            "\"<p>As a developer, I'd like to move 1.2.x branch to EC2 infrastructure, so I can reliably run CI test suites.</p>\"\n",
            "\"<p>As a developer, I'd like to develop a \\xe2\\x80\\x9csinglenode\\xe2\\x80\\x9d (in a single JVM) implementation of XD Admin SPI (based on Module Launcher), so I can run data pipeline use-cases locally.</p>\"\n",
            "\"<p>As a Spring XD user, I'd like to use Diego based Receptor implementation of XD Admin SPI (based on ModuleLauncher), so I can run data pipeline use-cases running on CF Lattice/Diego. </p>\"\n",
            "\"<p>As a s-c-s user, I'd like to investigate the possibility of s-c-s modules self-registering themselves to service discovery, so I could use Spring XD runtime (running on CF) to discover and orchestrate such modules through streams.</p>\"\n",
            "<p>Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.</p>\n",
            "<p>Currently we can only do plain inserts, should follow same logic from native gpfdist sink and add upserts.</p>\n",
            "\"<p>As a developer, I'd like to use spring-cloud-config server for spring-bus modules, so I can centrally manage external properties.</p>\"\n",
            "\"<p>As a developer, I'd like to document the Kryo optimization guidelines, so the end-users can refer to it while tuning to improve performance.</p>\"\n",
            "\"<p>We need to have some jars as part of the Sqoop job submission to YARN:</p><p>for Avro we need:<br/>  avro-1.7.6.jar<br/>  avro-mapred-1.7.6.jar</p><p>for Snappy we need:<br/>  snappy-java-1.0.5.jar (note: the 1.1.0.1 version from xd/lib doesn't work)<br/>  commons-compress-1.4.1.jar</p><p>We can either have these included using the --libjars option or automatically include them.</p>\"\n",
            "<p>The classes under test are pluralized. Therefore, the test classes themselves should reflect that. E.g. rename <b>JobCommandTests</b> to <b>JobCommandsTests</b> as it tests class <b>JobCommands</b>. Please check all tests in that package for correct naming.</p>\n",
            "\"<p>As a developer, I'd like to have a central place to manage external properties for applications across all the environments, so I can provide server and client-side support for externalized configuration for XD-Admin and XD-Container servers. </p>\"\n",
            "<p>Add Pagination to Containers Page</p>\n",
            "\"<p>As a developer, I'd like to create an annotation (<tt>@EnableModule</tt>) driven programming model for modules, so instead of explicitly defining I/O channels as beans on the module, for classes annotated with <tt>@EnableModule</tt>, the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types.</p><p>The <tt>@Input</tt> and <tt>@Output</tt> annotations will be used to indicate the input and output channels of the module. </p>\"\n",
            "\"<p>As a developer, I'd like to update Ambari installed Spring XD cluster to spin-up multiple instances of XD-Admin servers, so it is setup for HA. </p>\"\n",
            "\"<p>As a developer, I'd like to move message-bus from Spring XD repo into spring-bus, so I can update Spring XD to inherit the features/functionalities via maven dependency. </p>\"\n",
            "\"<p>As a developer, I'd like to move 'serialization codec' from Spring XD repo into spring-bus, so I can update Spring XD to inherit the features/functionalities via maven dependency.</p>\"\n",
            "<p>This apparently is not tested or used internally, but I expect it to fail having tried a similar approach to derive the class of a generic type in a different situation. This method does not always work due to type erasure <a href=\"http://stackoverflow.com/questions/3403909/get-generic-type-of-class-at-runtime\" class=\"external-link\" rel=\"nofollow\">http://stackoverflow.com/questions/3403909/get-generic-type-of-class-at-runtime</a>.  We need to verify if this is working, if not fix it. The API may require it, so possibly UnsupportedOperationException... </p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">/**   * Infers the type from <span class=\"code-keyword\">this</span> <span class=\"code-keyword\">class\\'</span>s <span class=\"code-keyword\">generic</span> type argument   * @param kryo   * @param input   * @<span class=\"code-keyword\">return</span> */<span class=\"code-keyword\">protected</span> T doDeserialize(Kryo kryo, Input input) {\\t<span class=\"code-object\">Class</span>&lt;T&gt; type = (<span class=\"code-object\">Class</span>&lt;T&gt;) (\\t\\t\\t\\t(ParameterizedType) <span class=\"code-keyword\">this</span>.getClass().getGenericSuperclass()).getActualTypeArguments()[0];\\t\\t<span class=\"code-keyword\">return</span> doDeserialize(kryo, input, type);}</pre></div></div>\n",
            "\"<p>As a developer, I'd like to complete the remaining Kryo optimization changes, so I can polish and get the guidelines documented appropriately. </p>\"\n",
            "\"<p>As a developer, I'd like to upgrade to Reactor 2.0.4 release, so I could leverage the latest improvements and bug-fixes.</p>\"\n",
            "\"<p>As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure, so that we can reliably run the CI builds and also assert over feature functionalities.</p><p><b>Scope:</b></p><ul>\\t<li>Enable 'distributed jvm test'</li>\\t<li>Change from using artifactory gradle task to a command task (that calls ./gradlew)</li>\\t<li>Test w/ embedded hadoop off</li>\\t<li>Turn on maxParallelForks</li></ul>\"\n",
            "<p>Also Spring Framework 4.2.0.RC2, Spring AMQP 1.5.0.M1</p><p>Also Batch 3.0.4</p>\n",
            "<p>Spring Boot 1.2.4 (and earlier) does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of (for example) <tt>vcap.services.rabbitmq.credentials.protocols.amqp.ssl</tt> it will fail, as that value returns a boolean.</p><p>Spring Boot 1.2.5 (as yet unreleased) contains a fix for this issue (<a href=\"https://github.com/spring-projects/spring-boot/pull/3237\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-boot/pull/3237</a>)</p>\n",
            "<p>As a user I would like to connect the Sqoop batch job to Teradata for import jobs. </p><p>I have tried the Teradata JDBC driver directly using:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">job create tdTest --definition <span class=\"code-quote\">\"sqoop --command=<span class=\"code-keyword\">import</span> --args=<span class=\"code-quote\">\\'--table Frequent_Flyers --connect jdbc:teradata:<span class=\"code-comment\">//tdexpress/DATABASE=transportation --driver com.teradata.jdbc.TeraDriver --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1\\'</span>\"</span></span></pre></div></div><p>but that results in an NPE.</p><p>The only way so far is to use the Hortonworks Connector for Teradata - <a href=\"http://public-repo-1.hortonworks.com/HDP/tools/2.2.4.2/hdp-connector-for-teradata-1.3.4.2.2.4.2-2-distro.tar.gz\" class=\"external-link\" rel=\"nofollow\">http://public-repo-1.hortonworks.com/HDP/tools/2.2.4.2/hdp-connector-for-teradata-1.3.4.2.2.4.2-2-distro.tar.gz</a></p><p>That one allows me to use the following:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">job create tdTest --definition <span class=\"code-quote\">\"sqoop --command=<span class=\"code-keyword\">import</span> --args=<span class=\"code-quote\">\\'--table Frequent_Flyers --connect jdbc:teradata:<span class=\"code-comment\">//tdexpress/DATABASE=transportation --connection-manager org.apache.sqoop.teradata.TeradataConnManager --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1\\'</span>\"</span></span></pre></div></div>\n",
            "<p>This better aligns with boot. Moreover, using Class was a bad design choice (one can always get a Class from a String <span class=\"error\">&#91;modulo knowing which CL to use&#93;</span>, while to converse is not always easy <span class=\"error\">&#91;CL not being available&#93;</span>)</p>\n",
            "<p>A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify/enhance property configuration.  With @Configuration modules, these may now be beans in the module context. </p>\n",
            "\"<p>The current jdbchdfs job does not take advantage of all the features available to write into HDFS provided by Spring Hadoop's DataStoreWriter implementations, such as partitioning.</p><p>Update the jdbchdfs job to use &lt;int-hadoop:store-writer/&gt; (similar to the HDFS Sink) inside a new ItemWriter implementation</p>\"\n",
            "<p>./gradlew install fails for spring-xd-extension-batch and spring-xd-extension-reactor. The first case is a simple update to gradle/build-extensions.gradle. The 2nd causes several compilation errors that are not trivial for a Reactor noob.  </p>\n",
            "<p>Similar to Sqoop where we move data from RDBMS to HDFS we should look at integrating with Camus to load data from Kafka to HDFS.</p>\n",
            "<p>As a user, I\\'d like to have an optional  arbitrary \"side channels\" created so that when creating a module channels other than the primary stream channels (input, output) could be added to the bus (i.e. creating a tap channel <b>within</b> a flow). The optional \"side channels\" can be used to trace/track module progress.</p>\n",
            "<p>As a user, I\\'d like to have an optional <em>trace</em> as inline deployment properties for <em>stream</em> so that I can declare which <em>module</em> in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules.</p><p><b>Example:</b></p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-xml\">xd:&gt; stream create foo <span class=\"code-quote\">\"http | log\"</span>xd:&gt; stream deploy foo --properties <span class=\"code-quote\">\"module.http.trace,module.log.trace\"</span>(or)xd:&gt; stream deploy foo --properties <span class=\"code-quote\">\"module.*.trace\"</span></pre></div></div><p>Wildcard wiretap config: <a href=\"http://docs.spring.io/spring-integration/reference/html/messaging-channels-section.html#channel-global-wiretap\" class=\"external-link\" rel=\"nofollow\">http://docs.spring.io/spring-integration/reference/html/messaging-channels-section.html#channel-global-wiretap</a></p>\n",
            "<p>Since the refactoring of the module registry that does not \"look inside\" a module, it can\\'t know that the scripts directory is not a module.</p><p>Everything that is a direct child of source, processor, sink, job should be a module archive. Everything else supporting that should be moved out, e.g. in modules/common</p>\n",
            "<p>To be added in AbstractMetricsController, as well as the various shell commands (\"counter all delete\", etc...)</p>\n",
            "\"<p>As a developer, I'd like to create a example to demonstrate JDBC to HDFS data movement.</p>\"\n",
            "<p>See original report here <a href=\"https://github.com/spring-projects/spring-xd/issues/1300\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/issues/1300</a></p><p>\"I\\'ve created a module with a custom Metric, Handler and Repository patterned after the AggregateCounter but then it appears that there doesn\\'t seem to be a way to add anything to the Admin Context.</p><p>The diagram at <a href=\"https://github.com/spring-projects/spring-xd/wiki/Extending-XD\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/wiki/Extending-XD</a> shows the Plugin Context as a sibling to the Admin Context which seems to verify my fears.</p><p>It would be convenient to be able to add custom Metrics/Controllers/Repositories into the Admin Context so that they can be accessed through the same REST api as the other Metrics.\"</p>\n",
            "\"<p>As a developer, I'd like to build batch sample using <em>Sqoop</em> so that we can demonstrate some of the capabilities.</p><p><b>Use cases to consider:</b></p><ul>\\t<li>JDBC to HDFS</li>\\t<li>HDFS to JDBC</li></ul>\"\n",
            "\"<p>As a developer, I'd like to build data pipeline using <em>Kafka</em> as as message bus in XD so that we can demonstrate some of the capabilities.</p><p><b>Use case to consider:</b></p><ul>\\t<li>Log aggregation and analysis</li>\\t<li>Lambda architecture\\t<ul>\\t\\t<li>how to avoid code duplication</li>\\t\\t<li>how to eliminate tight coupling of business logic</li>\\t\\t<li>how Kafka can be used for reliable reprocessing</li>\\t</ul>\\t</li></ul>\"\n",
            "<p>We need a generic script that can do JSON to tab-delimited text transformation for data written to HDFS/HAWQ external tables. Users should be able to specify columns/fields to be included.</p>\n",
            "<p>We should be able to write a script that can examine the table structure for a given HAWQ table and then extract the data from JSON without the custom script we are using now.</p>\n",
            "nan\n",
            "<p>Following merge of <a href=\"https://github.com/spring-projects/spring-xd/pull/601\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/pull/601</a>, expose a unique id under which a module is known inside a stream. That id (which defaults to the module name) is what should be used as the qualifier for an option name inside a composed module, ie</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>module compose foo --definition \"f1: filter | filter\"==&gt;f1.expression and filter.expression are available</pre></div></div>\n",
            "<p>Currently the parser returns a List&lt;ModuleDeploymentRequest&gt;, and the deployer works with that list directly. We need a higher level parser result (e.g. DeployableStream - or probably a better name after some thought) that can encapsulate that list while also enabling metadata to be added. That metadata may be helpful for composite module information as well as the module dependencies of a given stream (including any composed modules within that stream).</p>\n",
            "<p>See report at <a href=\"https://github.com/spring-projects/spring-xd/issues/661\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/issues/661</a></p><p>It would be good indeed to allow this (eg by having a WeakHashMap&lt;Classloader, type+name&gt; map in the global context).<br/>The caveat though, is that any statics used by the module would be shared too.<br/>We can make this an opt-out though (I think that sharing by default makes sense) by having a flag in the module .properties manifest</p>\n",
            "<p>Currently, the XD container uses embedded tomcat only to support management server that acts as the RESTful server for boot\\'s actuator MVC and jolokia endpoints.</p><p>If the configuration is set to use a specific management port (using the fixes addressed via <a href=\"https://jira.spring.io/browse/XD-1122\" title=\"Add jmxPort to list of coerced cmd line options\" class=\"issue-link\" data-issue-key=\"XD-1122\"><del>XD-1122</del></a>), then we don\\'t need to have embedded tomcat servlet container in XD container. </p>\n",
            "<p>HATEOAS 0.9 introduced some support for templated links. This should be leveraged to properly handle eg /streams/</p>{id}<p> instead of using string concatenation</p>\n",
            "<p>Will likely involve having the module identity (type+name) be part of the OptionsMetadata identity/cache key</p>\n",
            "<p>Currently, if we want to bind values to script variables we need to put them in a properties file like so:</p><p>xd:&gt; stream create --name groovyprocessortest --definition \"http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log</p><p>Ideally it should be:</p><p>xd:&gt; stream create --name groovyprocessortest --definition \"http --port=9006 | script --location=custom-processor.groovy --foo=bar --baz=boo | log</p>\n",
            "<p>The Gemfire CQ source needs some enhancements:</p><ul>\\t<li>enable locator configuration</li>\\t<li>consider decoupling from JSON. Currently designed to work with gemfire-json-server to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance(s) stored in the cache.</li></ul>\n",
            "<p>We should standardize on the options between modules:</p><p>idleTimeout - timeout<br/>rolloverSize - rollover</p><p>Also, need to standardize on unit used for timeout - should this be s or ms?</p>\n",
            "<p>Instead of using jobExecutionId and stepExecutionId as two separate options for the \"job execution step progress\" command, we can have a single option with id mentioned as (jobExecutionId:stepExecutionId)</p>\n",
            "<p>For several Batch Job related JSON endpoints, we serialize too much information.</p>\n",
            "\"<p>ApplicationContext ID generation is difficult in general.  Cloud Foundry solves this problem for us by providing unique instance ids to all running instances of an app. I don't suppose that helps much in the general case though, and we need something (a rule of thumb) that is unique and preferably deterministic, so that nodes retain their ID across process and connector restarts.</p><p>In Cloud Foundry the instance id plays a vital role (and will be automatically picked up by the app and applied - need to look at how that plays in a context hierarchy). User can set the context id manually using <tt>spring.application.name</tt> and <tt>spring.application.index</tt>.</p>\"\n",
            "<p>On clicking a specific job name in the deployed jobs list, we need to redirect the user to show the list of all the job executions on that job.</p><p>User should be able to navigate back to the deployed jobs list.</p>\n",
            "<p>Writing POJOs using Kite SDK </p>\n",
            "<p>Support for using compression when writing Sequence Files</p><p>Either block or record-based compression.</p>\n",
            "<p>Support for writing Sequence Files</p><p>Without Compression</p><p>Need a means to specify the key/value to be used</p>\n",
            "<p>The aggregate counter query result currently returns the interval that is passed in, whether it is aligned with the bucket resolution requested or not. It would be more intuitive if the time values returned are rounded (down) to the resolution of the query (i.e. whole minutes, hours, days or whatever).</p>\n",
            "\"<p>Enhance the stream parser to take message conversion into account in order to validate or automatically configure converters. For example: </p><p><pre> source   --outputType=my.Foo  | sink --inputType=some.other.Bar   is likely invalid since XD doesn't know how to convert Foo-&gt;Bar.  </pre></p>\"\n",
            "<p>We should support <b>java.io.file</b> payloads in order to support non-textual file and large text file payloads being uploaded to HDFS. </p><p>Currently text file payloads are converted to a text stream in memory and, non-String payloads are converted to JSON first, using an \"object-to-json-transformer\". </p><p>Ultimately we need to support streams such as \"file | hdfs\" where the actually payload being copied to HDFS is not necessarily JSON or textual.</p><p>Need to be able to support headers in the message that will indicate which HDFS file the data should be stored in.</p>\n",
            "<p>See discussion at <a href=\"https://github.com/SpringSource/spring-xd/pull/240#discussion_r6045724\" class=\"external-link\" rel=\"nofollow\">https://github.com/SpringSource/spring-xd/pull/240#discussion_r6045724</a></p>\n",
            "<p>See discussion at <a href=\"https://github.com/SpringSource/spring-xd/pull/250/files#r6034885\" class=\"external-link\" rel=\"nofollow\">https://github.com/SpringSource/spring-xd/pull/250/files#r6034885</a></p>\n",
            "<p>Use a profile or similar to only include the <tt>Environment</tt> conditionally (currently in module-common.xml.</p><p>Also</p><p>Jon Brisbin<br/>one thing to keep in mind: we talked about having a properties file for XD that configured the RingBuffer et al in a non-default way</p><p>Jon Brisbin<br/>e.g. no event loop Dispatchers\\xe2\\x80\\xa6a ThreadPoolDispatcher with a large thread pool size (50 threads? 100?)\\xe2\\x80\\xa6and maybe even two RingBufferDispatchers: input and output</p><p>Jon Brisbin<br/>so we might want to change from strictly a default Environment bean to an EnvironmentFactoryBean with a specific configuration\\xe2\\x80\\xa6thinking about it now I maybe should add a namespace element for the Environment</p>\n",
            "<p>1. We\\'ll need a system which give better control of what yarn/xd containers are out there and what is a status of those containers.<br/>2. We also need grouping of containers order to choose, prioritize and scale tasks.<br/>3. We need heartbeating of the grid nodes. Hadoop Yarn itself doesn\\'t give enough tools to know if container is \"alive\".</p>\n",
            "<p>support of the alpha parameter is awkward and can confuse people who are expecting a simple average mean.</p><p>Consider splitting RichGauge in two flavors: arithmetic and exponential.</p><p>Involves quite some work at the repository, handler and REST level though... </p>\n",
            "<p>There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers (CounterResource, GaugeResource). The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.</p>\n",
            "<p>This is in reference to the investigation done as part of <a href=\"https://jira.spring.io/browse/XD-2548\" title=\"Investigate why CPU startup is high for admin and container servers\" class=\"issue-link\" data-issue-key=\"XD-2548\"><del>XD-2548</del></a></p>\n",
            "<p>MongoDb driver is present on DIRT\\'s classpath, while it should not (should be present on mongo-related modules though).</p><p>This is blocked by the shortcoming described here: <a href=\"https://github.com/spring-projects/spring-xd/pull/1116\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/pull/1116</a></p>\n",
            "<p>Determine a better package name for the following packages once we have a common model that applies to both stream/job:</p><p>`org.springframework.xd.dirt.stream`  <br/>`org.springframework.xd.dirt.stream.zookeeper` </p>\n",
            "nan\n",
            "<p>Create a load generator script which can generate messages at specific</p><p>1) Rate<br/>2) Payload<br/>3) Concurrency</p><p>to a specific tcp/udp port where a syslog adapter is listening.</p>\n",
            "<p>I wanted to have a rollover feature when I was streaming tweets to a file overnight, just to avoid dealing with a single enormous file (in case I collected more data than my demo could handle and needed to split it up).</p>\n",
            "<p>Filter, Transform, and Script modules all assume the provided script is written in Groovy. </p><p>This is partly due to the fact that the \"lang\" attribute of &lt;int-script:script&gt; can\\'t be set to a property value (i.e. lang=\"${lang:groovy}\"), which would allow users to pass in the expected language. Or perhaps we could use a SPEL expression or script to pick the language based on the file extension?</p>\n",
            "<p>*<a href=\"http://localhost:9393/admin-ui/#/streams/definitions/test/deploy*\" class=\"external-link\" rel=\"nofollow\">http://localhost:9393/admin-ui/#/streams/definitions/test/deploy*</a></p>\n",
            "\"<p>As a user, I'd like to use Boot-based <tt>ModuleRunner</tt> for use in container-managed environments, so I can run XD without <em>xd-containers</em>.</p><p>Scope:</p><ul>\\t<li></li></ul>\"\n",
            "\"<p>As a developer, I'd like to complete the remaining work with DEBS challenge, so I can submit by the deadline.</p>\"\n",
            "<p>As a user, I\\'d like to have the module/app specific metrics consumed directly from Boot actuator <a href=\"https://github.com/spring-projects/spring-boot/blob/master/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/MetricRepositoryAutoConfiguration.java\" class=\"external-link\" rel=\"nofollow\">export()</a> API, so I can have insight on how it is performing, being used and that it works etc.</p>\n",
            "\"<p>As a developer, I'd like to migrate the current MASTER branch CI builds to EC2 instances, so I can manage them all in one-place reliably.</p>\"\n",
            "nan\n",
            "<p>As a developer, I\\'d like to handle module options via pure boot property source management, so I can leverage Boot\\'s module <a href=\"http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#configuration-metadata\" class=\"external-link\" rel=\"nofollow\">METADATA</a> option to inject module options as opposed to maintaining them in core Spring XD runtime CP.</p>\n",
            "<p>Currently kryo class registration is hard coded in spring-xd-codec. Users may register their own classes using an extension mechanism, but it is possible to conflict with internal XD class registration, e.g., Tuple. Exposing this using the same extension mechanism will make it more transparent. </p>\n",
            "<p>This is an enhancement to KryoClassRegistrar or a related mechanism to initialize codecs using custom serializers to improve serialization performance. Currently XD will support POJOs that implement the kryo Serializable interface to gain a 2x performance improvement, however initial benchmarks show that custom serializers are about 10% more performant than Serializable.</p>\n",
            "\"<p>As a developer, I'd like to investigate channel performance issues in SI 4.2, so I can determine the bottlenecks and take corrective actions to improve overall channel performance. </p>\"\n",
            "\"<p>As a spring-bus lead, I'd like to review the current spring-bus architecture and the design specs, so I can address any foundation level gaps.</p>\"\n",
            "\"<p>As a developer, I'd like a job module to be bootstrapped when the job is launched and shut down once it is complete instead of the current behavior of bootstrapping the context when the module is deployed regardless of if it's being used so that I can achieve better resource utilization.</p>\"\n",
            "\"<p>As a user, I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin, so I can work on the latest release bits. I'd like to refer to the documentation to do so.</p>\"\n",
            "<p>We need to add the settings needed to run XD on YARN when using Hortonworks HDP 2.2.6.0 which is the version you now get when installing with Ambari.</p>\n",
            "<p>As a developer, I want to be able to override Kafka bus defaults for module consumers and producers, so that I can finely tune performance and behaviour. </p><p>Such properties should include</p><ul class=\"alternate\" type=\"square\">\\t<li>autoCommitEnabled,queueSize,maxWait,fetchSize for consumers</li>\\t<li>batchSize,batchTimeout for producers</li></ul>\n",
            "\"<p>User's need ability to wait for user specified time in millis for a file to be created in the XD directory.  If file is not created in allotted time then return false else return true.  Also check to see if a file exists in the XD directory.  </p>\"\n",
            "<p>Need acceptance tests to run on the 1.2.X branch.  Needs to be setup as a child of the Publish 1.2.x</p>\n",
            "\"<p>As a user, I'd like to use the Java receptor client, so I can interact with Diego runtime using the Java receptor REST APIs.</p>\"\n",
            "\"<p>As a developer, I'd like to publish performance benchmarks along with the infrastructure specifics, so the users can use it as a reference while setting up Spring XD cluster.</p>\"\n",
            "\"<p>As a user, I'd like to have the option of <em>Cassandra</em> sink, so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.</p>\"\n",
            "<p>See:<br/><a href=\"http://docs.spring.io/spring-xd/docs/current-SNAPSHOT/reference/html/#_introduction_26\" class=\"external-link\" rel=\"nofollow\">http://docs.spring.io/spring-xd/docs/current-SNAPSHOT/reference/html/#_introduction_26</a></p><p>There should be chapter/section title before this.</p>\n",
            "nan\n",
            "nan\n",
            "<p>As a user, I\\'d like to include the deployment manifest from the file so that I don\\'t have spend time typing as \"inline properties\".</p>\n",
            "\"<p>As a user, I'd like to run the sqoop jobs against secured hdfs cluster, so I can restrict access to only authorized users. </p>\"\n",
            "<p>Depends on <a href=\"https://jira.spring.io/browse/INT-3727\" title=\"SOF/EOF with FileSplitter\" class=\"issue-link\" data-issue-key=\"INT-3727\"><del>INT-3727</del></a></p>\n",
            "<p>Provide unit tests</p>\n",
            "\"<p>As a developer, I'd like to update to Spring Hadoop 2.2.0 GA release, so I can leverage the latest improvements. </p>\"\n",
            "<p>As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated.<br/>The documentation also needs some more information on `Reliable` receiver.</p>\n",
            "<p>When the bus is used outside of the XD container (e.g. spring-bus), the inheritance from Spring Boot configuration is broken (no application.yml or servers.yml on the cp).</p><p>Make the bus properties optional (Add \":\")</p>\n",
            "\"<p>As a user, I'd like to refer to the analytics tab docs, so I can understand how to use various widgets from streaming pipeline.  </p>\"\n",
            "<p>Sort alphabetically, nest \"Available modules\" section appropriately. Optionally, move to a whole different \"PART\" in reference doc</p>\n",
            "\"<p>As a developer, I'd like to update to the 4.1.5 SI release, so I can pickup the latest improvements to message channels.</p>\"\n",
            "\"<p>As a developer, I'd like to update to SI Kafka extension 1.2.0, so I can leverage the latest performance improvements.</p>\"\n",
            "<p>For example, how to specify the partition count for topics that are created by the message bus.</p>\n",
            "\"<p>As a user, I'd like to parameterize all Import Options, so I can eliminate the need for <tt>\\xe2\\x80\\x94args</tt> option since it gets confusing.</p>\"\n",
            "<p>Some info is obsolete and add more content re. dependency management</p>\n",
            "\"<p>As a developer, I'd like to document how to nest batch jobs and workflows in XD, so it will be easy for end-users to use it as reference. </p>\"\n",
            "<p>The stream definition example uses old style syntax, should be --mode=ref instead of --ref=true </p>\n",
            "\"<p>As a user, I'd like to have a landing page with higher-order links for sources, processors, sinks and jobs, so I can jump to right section from one place. </p>\"\n",
            "<p>RPM scripts will need to change.</p>\n",
            "\"<p>As a developer, I'd like to document performance benchmark results along with the infrastructure specifics, so I can publish the blog for customers/users to use it as a reference while setting up Spring XD cluster.</p>\"\n",
            "\"<p>As a developer, I'd like to rerun <em>baseline</em>, <em>Tuple</em>, and <em>Serialized</em> payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. </p><p>Sinks to be included in test:<br/>In-Memory Transport &gt; Hdfs sink<br/>Direct Binding Transport &gt; Hdfs Sink<br/>Kafka &gt; Hdfs Sink</p>\"\n",
            "<p>This type is used in password field in the jdbc sink module provided by Spring XD (defined in org.springframework.xd.jdbc.JdbcConnectionMixin class). It seems that Spring XD Admin UI is always displaying the password in plain text please see attached screen shot.<br/>Is there a way to somehow hide the passwords used as module properties in streams from being displayed in Spring XD Admin UI?<br/>This is similar issue as below and fixed in batch jobs but not in streams.<br/><a href=\"https://github.com/spring-projects/spring-xd/pull/1325\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/pull/1325</a></p>\n",
            "<p>This addresses The plugin issue <a href=\"https://www.jfrog.com/jira/browse/GAP-172\" class=\"external-link\" rel=\"nofollow\">https://www.jfrog.com/jira/browse/GAP-172</a> to disable spring-xd/pom.xml</p>\n",
            "\"<p>As a user, I'd like to refer to OOTB batch jobs and the documentation, so I can jump to the right job section and review details. </p>\"\n",
            "\"<p>As a performance tester, I'd like to investigate why there's high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. </p><p><b>Scope:</b></p><ul>\\t<li>Identify the bottlenecks</li>\\t<li>Document reasons</li>\\t<li>List pros/cons</li></ul>\"\n",
            "nan\n",
            "<p><a href=\"https://sonar.spring.io/drilldown/issues/org.springframework.xd:spring-xd?severity=CRITICAL\" class=\"external-link\" rel=\"nofollow\">https://sonar.spring.io/drilldown/issues/org.springframework.xd:spring-xd?severity=CRITICAL</a></p>\n",
            "<p>The current build ships everything that is found in the modules directory, including build artifacts such as build/ or IDEA *.iml files.</p><p>Restrict the build to only include config/, lib/ at the moment.</p>\n",
            "\"<p>As a developer, I'd like to clean-up compiler and javadoc warnings from the build, so we don't see  the warnings in build sysout.</p>\"\n",
            "\"<p>Removed  various TODO comments in code and put here for proper triage.</p><p>DefaultTuple</p><ul>\\t<li>Error handling.  When delegating to the conversion service, the ConversionFailedException does not have the context of which key caused the failure.  Need to wrap ConversionFailedException with IllegalArgumentException and add that context back in.  (see method convert)</li>\\t<li>Ctor visibility.  Consider making ctor final and package protect the ctor so as to always use TupleBuilder</li>\\t<li>check for no duplicate values when initializing names/values list</li></ul><p>tuple.</p><ul>\\t<li>top level methods to add.<br/>  String getComponentName... somethign that would indicate which stream or job this tuple is being processed in....</li></ul><ul>\\t<li>TupleFieldSetMapper</li></ul><p>Only one date format?</p><ul>\\t<li>JsonStringtoTupleConverter/JsonNodetoTupleConverter</li>\\t<li>do we want to not map id and timestamp (believe the answer is don't map, preserve original)</li></ul>\"\n",
            "<p>Occasional CI test build failures:</p><blockquote><p>Caused by: java.lang.IllegalStateException: Container cache not initialized (likely as a result of a ZooKeeper connection error)<br/>\\tat org.springframework.util.Assert.state(Assert.java:385)<br/>\\tat org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.ensureCache(ZooKeeperContainerRepository.java:184)<br/>\\tat org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findOne(ZooKeeperContainerRepository.java:263)</p></blockquote><p>e.g. <a href=\"https://build.spring.io/browse/XD-JDK8-JOB1-1514\" class=\"external-link\" rel=\"nofollow\">https://build.spring.io/browse/XD-JDK8-JOB1-1514</a></p><p>Add logging to <tt>ensureCache()</tt> (e.g. in <tt>childEvent()</tt> ) and <tt>closeCache()</tt> to log that the cache was closed; it appears that\\'s the only way the \"cache not initialized\" message can be emitted.</p>\n",
            "\"<p>As a developer, I'd like to benchmark a stream with and without <tt>JMX</tt> enabled, so I can test in isolation, and document the differences in performance.</p>\"\n",
            "<p>As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file.</p><p>Add an alternative <tt>--nameExpression</tt> option, allowing complete control over the <tt>finename-generator-expression</tt> attribute.</p><p>See: <a href=\"http://stackoverflow.com/questions/28466477/issue-with-file-sink-and-filename-expression/28467069#28467069\" class=\"external-link\" rel=\"nofollow\">http://stackoverflow.com/questions/28466477/issue-with-file-sink-and-filename-expression/28467069#28467069</a></p>\n",
            "nan\n",
            "nan\n",
            "<p>The incremental load introduced with <a href=\"https://jira.spring.io/browse/XD-2309\" title=\"Incremental data import with jdbchdfs job\" class=\"issue-link\" data-issue-key=\"XD-2309\"><del>XD-2309</del></a> should be added to the batch docs</p>\n",
            "nan\n",
            "<p>Characters line \\\\t, \\\\n, etc. should be either escaped, or rendered as human readable variants in module info (eg &lt;newline&gt;)</p>\n",
            "\"<p>As a XD build master, I'd like to fix (local ./gradlew dist and distZip targets) the outstanding build issues, so I can evaluate that publish builds works as expected. </p>\"\n",
            "\"<p>As a developer, I'd like to have JMX turned-off by default, so I can take advantage of the performance throughput benefits. </p>\"\n",
            "<p>XD-EC2 needs  to allow user to set the XD_JMX_ENABLED flag in the environment prior to admin or container  startups. </p>\n",
            "\"<p>As a developer, I'd like to upgrade to 2.0.3 release of Reactor, so I can inherit the latest optimizations to further improve XD performance characteristics. </p>\"\n",
            "\"<p>As a developer, I'd like to rerun <em>baseline</em>, <em>Tuple</em>, and <em>Serialized</em> payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. </p><p>Note:<br/>1.1.1 &gt; Benched against 0.8.1 <br/>1.2 &gt; Benched against 0.8.2 </p>\"\n",
            "nan\n",
            "<p>There are a range of issues (such as <a href=\"https://jira.spring.io/browse/XD-3083\" title=\"Creating multiple Stream/Job definitions from command file is broken\" class=\"issue-link\" data-issue-key=\"XD-3083\"><del>XD-3083</del></a>, <a href=\"https://jira.spring.io/browse/XD-2671\" title=\"Support rapid creation and deletion of streams\" class=\"issue-link\" data-issue-key=\"XD-2671\"><del>XD-2671</del></a>) that are caused by asynchronous deployments issued by the REST API. The flow of events is:</p><ul>\\t<li>deploy/undeploy request received by REST API</li>\\t<li>controller queues up request to be processed by supervisor</li>\\t<li>controller returns HTTP 2xx</li></ul><p>This proposal is to have the thread executing the deploy/undeploy request block until the request has been processed by the supervisor. This will have the side effect of deploys appearing to take longer, but when the HTTP request completes, the deployment/undeployment will have been fulfilled. </p>\n",
            "<p>Also provide better lifecycle (shutdown) mgmt of handler.</p>\n",
            "<p>This is a source module for video ingestion: the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image (encoded with JPEG) as the payload.   </p>\n",
            "nan\n",
            "<p>As a user, I\\'d like to use the GF source along with native GF authentication enabled, so I can consume data from GF in a secured way. I\\'d like to refer to documentation on where the GF specific native and security properties needs configured. </p><p>See this <a href=\"https://gopivotal-com.socialcast.com/messages/24377202\" class=\"external-link\" rel=\"nofollow\">SC post</a> for more details.</p>\n",
            "<p>As a user, I\\'d like to use the <em>Mail</em> source to connect to secured IMAP and/or SMTP mail servers. </p><p><em>Mail</em> source config file requires a &lt;util:properties/&gt; bean (with ssl/tls properties), provided to the adapter via the java-mail-properties attribute. <a href=\"http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html\" class=\"external-link\" rel=\"nofollow\">Ref. Example</a>.</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-xml\">   <span class=\"code-tag\">&lt;beans:beans profile=<span class=\"code-quote\">\"default\"</span>&gt;</span>        <span class=\"code-tag\">&lt;util:properties id=<span class=\"code-quote\">\"javaMailProperties\"</span>&gt;</span>            <span class=\"code-tag\">&lt;beans:prop key=<span class=\"code-quote\">\"mail.imap.socketFactory.class\"</span>&gt;</span>javax.net.ssl.SSLSocketFactory<span class=\"code-tag\">&lt;/beans:prop&gt;</span>            <span class=\"code-tag\">&lt;beans:prop key=<span class=\"code-quote\">\"mail.imap.socketFactory.fallback\"</span>&gt;</span>false<span class=\"code-tag\">&lt;/beans:prop&gt;</span>            <span class=\"code-tag\">&lt;beans:prop key=<span class=\"code-quote\">\"mail.store.protocol\"</span>&gt;</span>imaps<span class=\"code-tag\">&lt;/beans:prop&gt;</span>            <span class=\"code-tag\">&lt;beans:prop key=<span class=\"code-quote\">\"mail.debug\"</span>&gt;</span>false<span class=\"code-tag\">&lt;/beans:prop&gt;</span>        <span class=\"code-tag\">&lt;/util:properties&gt;</span>    <span class=\"code-tag\">&lt;/beans:beans&gt;</span></pre></div></div><p><a href=\"https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html\" class=\"external-link\" rel=\"nofollow\">List of all java-mail properties</a></p>\n",
            "<p>If you have a an option <b>--mode=textLine</b>, presently the enum MUST be named <b>textLine</b>.</p><p>I think it would improve the user-experience if we allowed users to pass in values such as:</p><ul>\\t<li>--mode=textLine</li>\\t<li>--mode=text_line</li>\\t<li>--mode=TEXT_LINE</li></ul>\n",
            "\"<p>As a Flo developer, I'd like to add improvements to existing Flo parser endpoints, so I can streamline the error reporting strategy.</p>\"\n",
            "\"<p>As a developer, I'd like to bench Rabbit on rackspace infrastructure, so I can have a sense on how it scales as we add more <em>xd-container</em> nodes.</p>\"\n",
            "nan\n",
            "\"<p>As a developer, I'd like to default to HDFS as distributed remote location for custom module registry, so I can use xd-shell or the REST-API directly to upload the custom module bits. I would also like to remove custom-modules.zip artifact from YARN distribution.</p>\"\n",
            "<p>Polled message sources return only one message per poll by default.</p><p>When polling, say, a file directory with many files, files will be emitted once per <tt>fixedDelay</tt>.</p><p>As a user I need to configure a limit for the number of messages that will be emitted per poll.</p>\n",
            "\"<p>As a developer, I'd like to use an efficient approach to read files, so I don't have to read line-by-line and keep it in-memory in order to consume/write the file content. </p><p>Would the <em>tasklet</em> approach be better as opposed to transmitting data via message bus (as streams)? </p>\"\n",
            "\"<p>As a developer, I'd like to upgrade to Kafka 0.8.2, so I can leverage the latest features in order to test the performance characteristics.</p>\"\n",
            "\"<p>As a developer, I would like to connect to the broker that hosts the Rabbit queue, so I can connect to a Rabbit cluster that's setup for HA/FT. Perhaps consider having this feature natively supported in spring amqp itself.</p>\"\n",
            "<p>Spring Data Gemfire is version 8.0.0 in Folwer, which is the same as in BDS (Should check minor version number in BDS).  ATM we are using gemfire 7.0.x</p>\n",
            "<p>4.1.4 and 1.4.5 respectively.</p>\n",
            "<p>As a developer, I\\'d like to move the project reactor based <a href=\"https://github.com/spring-projects/spring-xd-modules/tree/master/gpfdist\" class=\"external-link\" rel=\"nofollow\">gpfdist</a> from spring-xd-module repo to the core, so I can natively use this sink to write to GPDB/HAWQ.</p>\n",
            "<p>See discussion at <a href=\"https://github.com/spring-projects/spring-xd/pull/1311\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/pull/1311</a></p><p>1) there seems to be unused SimpleDateFormat in TupleBuilder which hurst perf<br/>2) More generally, should take some time to profile / micro-benchmark TupleBuilder</p>\n",
            "\"<p>As a developer, I'd like to handle the non-default <tt>ConfigurableConversionService</tt> tuples in an uniform manner, so they're not reset after deserialization. </p>\"\n",
            "<p>As a user, I\\'d like to have a REST-API to get all the <em>counters</em>, <em>gauges</em>, and <em>rich-gauges</em> in a single request, so I don\\'t have to issue multiple request to fetch each one of the metrics by name/id for custom dashboards.</p><p><b>Example:</b></p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">/metrics/counters/all (fetches all available counters)/metrics/gauges/all (fetches all available gauges)/metrics/rich-gauges/all (fetches all available rich-gauges)</pre></div></div>\n",
            "<p>As a developer, I\\'d like to move the project reactor based <a href=\"https://github.com/spring-projects/spring-xd-modules/tree/master/spring-xd-reactor\" class=\"external-link\" rel=\"nofollow\">data processor module</a> from <em>spring-xd-module</em> repo to the core, so I can natively use Reactor\\'s Stream API to build processor modules. </p>\n",
            "\"<p>As a developer, I'd like revisit the design to determine the necessity for <em>ID</em> and <em>TimeStamp</em> attributes in <tt>Tuple</tt>, so I can refactor in order to improve performance throughput.</p>\"\n",
            "<p>Profile TupleCodec and implement performance optimizations</p>\n",
            "\"<p>As a Flo developer, I'd like to have a new DSL parser, so I can easily  detect incorrect module/option values when supplied from the Flo UI.</p><p>Example:<br/>MyStream = mail | log<br/>tap:stream:MyStream.bar &gt; log</p><p>If parsed separately (which Flo UI does), the current parser endpoint will barf on the second stream because it doesn\\xe2\\x80\\x99t know about the first stream (MyStream). </p>\"\n",
            "<p>Not going to integrate with Reactor for stream processing.</p>\n",
            "<p>As a user, I\\'d like to refer to the documentation, so I can configure HDFS backed module registry (<a href=\"https://jira.spring.io/browse/XD-2287\" title=\"Have ResourceModuleRegistry transparently proxy a remote root thru filesystem\" class=\"issue-link\" data-issue-key=\"XD-2287\"><del>XD-2287</del></a>) as recommended. </p>\n",
            "<p>Identify and report hotspots while running the load-generator source and the throughput sink on :</p><ol>\\t<li>Singlenode -&gt; In Memory Transport</li>\\t<li>Singlenode -&gt; Kafka Transport</li>\\t<li>Admin/Container -&gt; Kafka Transport</li></ol>\n",
            "<p>Currently, hsqldb, postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.</p>\n",
            "<p>Gradle 2.x is required for the latest Sonar version (sonar.spring.io)</p><p>We may need to wait for a fix in Groovy itself (2.4.1) - Please see the following links for details:</p><ul>\\t<li><a href=\"http://forums.gradle.org/gradle/topics/after_upgrade_gradle_to_2_0_version_the_maven_pom_not_support_build_property\" class=\"external-link\" rel=\"nofollow\">http://forums.gradle.org/gradle/topics/after_upgrade_gradle_to_2_0_version_the_maven_pom_not_support_build_property</a></li></ul><ul>\\t<li><a href=\"http://jira.codehaus.org/browse/GROOVY-7023\" class=\"external-link\" rel=\"nofollow\">http://jira.codehaus.org/browse/GROOVY-7023</a></li></ul>\n",
            "<p>File source should output either the File itself (serialized File object) or the contents as a byte[]. This option is configured by a parameter --contents=true.  The byte[] may be converted to a String using XD Message Conversion, e.g., --output = text/plain;charset=UTF-8</p>\n",
            "\"<p>As a user, I'd like to consume multiple topic-partitions, so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.</p>\"\n",
            "<p>As a user, I\\'d like to have the option to change the default Sqoop <em>metastore</em>, so I can implement a DB of my choice and not tied to default specifications.</p><p>Refer to this <a href=\"http://stackoverflow.com/questions/24078668/how-to-change-sqoop-metastore\" class=\"external-link\" rel=\"nofollow\">thread</a> for more details. </p>\n",
            "\"<p>As a developer, I'd like to continue XD-on-Lattice/Diego PoC, and will be focused on the design of a pluggable SPI, so it is more generally applicable than Lattice, with the Receptor API being just one implementation option. </p>\"\n",
            "<p>As a follow up to <a href=\"https://jira.spring.io/browse/XD-2877\" title=\"Refactor deployment interfaces/class hierarchy\" class=\"issue-link\" data-issue-key=\"XD-2877\"><del>XD-2877</del></a>, experiment with the removal of the list of modules from BaseDefinition and reparse as needed.</p><p>Branch is here: <a href=\"https://github.com/pperalta/spring-xd/tree/deploy-refactor-2\" class=\"external-link\" rel=\"nofollow\">https://github.com/pperalta/spring-xd/tree/deploy-refactor-2</a></p>\n",
            "nan\n",
            "\"<p>As a user, I'd like to use Boot-based <tt>ModuleRunner</tt> for use in container-managed environments, so I can run XD without <em>xd-containers</em>.</p><p>Scope:</p><ul>\\t<li>Complete the remaining deployment properties work</li></ul>\"\n",
            "<p>There are a few places in the doc we can reference regarding overall lifecycle of jobs but this should provide a basic recipe for a single step job.</p><p>The focus should be on creating a job item processor.</p><p>In particular how List&lt;Message&lt;Tuple&gt;&gt; as the payload.</p><p>this should link back to a new section in the aggregator that also mentions List&lt;Message&lt;Tuple&gt;&gt;</p><p>Change title from  Creating a Job Item Processor to Creating a Job Module</p>\n",
            "\"<p>As a user, I would like to be able disable snappy compression when using hdfs-dataset sink with Avro files. I'd also like to be able to provide a different codec.</p>\"\n",
            "nan\n",
            "\"<p>As a user, I need a 'sandbox' Docker Image so that I can get started to experiment XD deployment with the following setup:</p><ul>\\t<li>Ubuntu OS</li>\\t<li>Full XD Jar</li>\\t<li>Java 7.x</li>\\t<li>Redis</li>\\t<li>RabbitMQ</li></ul>\"\n",
            "<ul>\\t<li>The workaround explicitly updates spring-core (latest boot needs it)</li>\\t<li>merges all application.yml documents that are not profile-specific under on spring: key (the latest boot requires it, at least for now. Boot may go back, see spring-projects/spring-boot#2022</li></ul>\n",
            "<p>Create processor and sink modules that can execute a shell command using stdin and stdout to stream data.</p>\n",
            "\"<p>As a user, I'd like to have a <em>reactor-stream</em> processor module so that I can ingest data using XD source modules and process them as time-window operations. </p><p><b>Example 1:</b><br/>http | reactor-stream --timeWindow=10s --field=payload.sensorData --expressions=min,avg</p><p>This would give you 10 second time window of the min and avg values.</p><p><b>Example 2:</b><br/>Reactor as a module</p><p><b>Example 3:</b><br/>Integration with Spark streaming and reactor</p>\"\n",
            "nan\n",
            "\"<p>As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features, bug-fixes and enhancements. </p><p><b>Following XD dependencies needs upgraded to sync-up with Boot 1.2.0 RELEASE:</b></p><p>&lt;activemq.version&gt;5.10.0&lt;/activemq.version&gt;<br/>&lt;aspectj.version&gt;1.8.4&lt;/aspectj.version&gt;<br/>&lt;commons-dbcp2.version&gt;2.0.1&lt;/commons-dbcp2.version&gt;<br/>&lt;h2.version&gt;1.4.182&lt;/h2.version&gt;<br/>&lt;hibernate.version&gt;dd4.3.7.Final&lt;/hibernate.version&gt;<br/>&lt;hibernate-validator.version&gt;5.1.3.Final&lt;/hibernate-validator.version&gt;<br/>&lt;hikaricp.version&gt;2.2.5&lt;/hikaricp.version&gt;<br/>&lt;hornetq.version&gt;2.4.5.Final&lt;/hornetq.version&gt;<br/>&lt;httpasyncclient.version&gt;4.0.2&lt;/httpasyncclient.version&gt;<br/>&lt;httpclient.version&gt;4.3.6&lt;/httpclient.version&gt;<br/>&lt;jackson.version&gt;2.4.4&lt;/jackson.version&gt;<br/>&lt;janino.version&gt;2.6.1&lt;/janino.version&gt;<br/>&lt;jetty.version&gt;9.2.4.v20141103&lt;/jetty.version&gt;<br/>&lt;jetty-jsp.version&gt;2.2.0.v201112011158&lt;/jetty-jsp.version&gt;<br/>&lt;joda-time.version&gt;2.5&lt;/joda-time.version&gt;<br/>&lt;jolokia.version&gt;1.2.3&lt;/jolokia.version&gt;<br/>&lt;junit.version&gt;4.12&lt;/junit.version&gt;<br/>&lt;liquibase.version&gt;3.3.0&lt;/liquibase.version&gt;<br/>&lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt;<br/>&lt;log4j2.version&gt;2.1&lt;/log4j2.version&gt;<br/>&lt;mockito.version&gt;1.10.8&lt;/mockito.version&gt;<br/>&lt;mongodb.version&gt;2.12.4&lt;/mongodb.version&gt;<br/>&lt;mysql.version&gt;5.1.34&lt;/mysql.version&gt;<br/>&lt;reactor.version&gt;1.1.5.RELEASE&lt;/reactor.version&gt;<br/>&lt;reactor-spring.version&gt;1.1.3.RELEASE&lt;/reactor-spring.version&gt;<br/>&lt;servlet-api.version&gt;3.1.0&lt;/servlet-api.version&gt;<br/>&lt;spring.version&gt;4.1.3.RELEASE&lt;/spring.version&gt;<br/>&lt;spring-batch.version&gt;3.0.2.RELEASE&lt;/spring-batch.version&gt;<br/>&lt;spring-data-releasetrain.version&gt;Evans-SR1&lt;/spring-data-releasetrain.version&gt;<br/>&lt;spring-hateoas.version&gt;0.16.0.RELEASE&lt;/spring-hateoas.version&gt;<br/>&lt;spring-mobile.version&gt;1.1.3.RELEASE&lt;/spring-mobile.version&gt;<br/>&lt;spring-security.version&gt;3.2.5.RELEASE&lt;/spring-security.version&gt;<br/>&lt;tomcat.version&gt;8.0.15&lt;/tomcat.version&gt;<br/>&lt;undertow.version&gt;1.1.1.Final&lt;/undertow.version&gt;</p>\"\n",
            "nan\n",
            "<p>As a continuation, we would like to further investigate Spark, develop POC and identify the best appropriate design and implementation for XD.</p>\n",
            "\"<p>As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don't have to manually move and set it up.</p><p><b>Scope of this spike:</b></p><ul>\\t<li>Assess customer requirement, brainstorm, and document options</li>\\t<li>Socialize with the team to collect feedback</li>\\t<li>Identify phases</li>\\t<li>Create new stories</li></ul>\"\n",
            "<p>Rerun test <a href=\"https://jira.spring.io/browse/XD-2278\" title=\"Vary queue number (ECB-7)\" class=\"issue-link\" data-issue-key=\"XD-2278\"><del>XD-2278</del></a> on a EC2 32 core machine and see when we max out.</p>\n",
            "\"<p>As an user, I'd like to have a native <em>JDBC</em> source module to ingest data directly from various databases. </p>\"\n",
            "\"<p>As an user, I'd like to have the ability to ingest data into <em>Redis</em> sink.</p>\"\n",
            "<p><a href=\"https://jira.spring.io/browse/AMQP-453\" class=\"external-link\" rel=\"nofollow\">https://jira.spring.io/browse/AMQP-453</a> Added support for compression with RabbitMQ.  XD should expose configuration options to enable and configure compression on the message bus.  Note, some options may be specific for brokers or require additional functionality in XD.  </p><p>This issue should not address adding additional functionality to make the feature set as common as possible across msg bus implementations, but expose what makes sense with the current code base for rabbitmq   As an example, Kafka supports compressed.topics which lets you pick a subset of topics to be compressed.  </p>\n",
            "<p>Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI<br/>Paravirtual is being phased out by Amazon.  Also so we can utilize VPC and placement groups in the future.</p>\n",
            "\"<p>As a user, I'd like to have the flexibility to change the namespace so that I can isolate ZK <em>metadata</em> based on each <em>tenant</em> profile. </p>\"\n",
            "<p>As a user, I\\'d like to override the default \"commit-interval\" so that I can configure commit interval depending on data volume.</p><p><b>Note:</b><br/>This would apply for all OOTB jobs that has partition support. The property could be part of <em>servers.yml</em> file.</p>\n",
            "\"<p>The acceptance tests cover the entire suite of script tests.  Thus they are no longer needed.  The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn't get an error.  This test (httpbash) was never called from the scripts CI build.</p>\"\n",
            "nan\n",
            "<p>Similar to <tt>time | log</tt>, we should ship a simple batch job that appends a timestamp to a file. This will make it much easier to validate job functionality, especially in automated tests.</p>\n",
            "\"<p>Test is failing since Kafka isn't installed on the CI server.  Using an embedded server will make the testing more robust vs. needing an external server.</p>\"\n",
            "<p>Provide for retry and/or dead-lettering for the rabbit source (similar to the rabbit message bus).</p>\n",
            "<p>Implement pagination for:</p><p><a href=\"http://localhost:9393/jobs/executions\" class=\"external-link\" rel=\"nofollow\">http://localhost:9393/jobs/executions</a></p>\n",
            "<p>When answering support questions, the first step is to determine what version of the software the customer is using. This question can be easily answered if we log the version as one of the fields in the log file. For example:</p><div class=\"preformatted panel\" style=\"border-width: 1px;\"><div class=\"preformattedContent panelContent\"><pre>10:44:21,212 1.0.2.BUILD-SNAPSHOT  INFO DeploymentSupervisorCacheListener-0 server.ContainerListener - Container arrived: Container{name=\\'431baa56-b23b-48fc-b37d-18b52231e799\\', attributes={ip=192.168.25.177, host=Patrick-Peralta-MacBook-Pro.local, groups=, pid=38004, id=431baa56-b23b-48fc-b37d-18b52231e799}}</pre></div></div><p>This way when we receive log snippets (initial support inquires rarely include the entire log file) we can immediately determine if the issue has already been fixed in a later release.</p>\n",
            "nan\n",
            "nan\n",
            "<p>After deploying stream (such as \"time | log\"), the xd-container emits the following stacktrace(s) if the stream is in a deployed state when that xd-container process is halted via CTRL-C:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">20:15:31,415  INFO main-EventThread module.ModuleDeployer:215 - removed SimpleModule [name=log, type=sink, group=s, index=1 @128936ff]20:15:31,417 ERROR main-EventThread imps.CuratorFrameworkImpl:512 - Watcher exceptionjava.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@7bf4bc83 has been closed already\\tat org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)\\tat org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)\\tat org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:214)\\tat org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:140)\\tat org.springframework.xd.dirt.plugins.stream.StreamPlugin.beforeShutdown(StreamPlugin.java:74)\\tat org.springframework.xd.dirt.module.ModuleDeployer.beforeShutdown(ModuleDeployer.java:267)\\tat org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:217)\\tat org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:197)\\tat org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:169)\\tat org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:252)\\tat org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:580)\\tat org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:56)\\tat org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)\\tat org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)20:15:31,420  INFO main-EventThread server.ContainerRegistrar:250 - Undeploying module time-0: time type=source, deploymentProperties={count=1}20:15:31,420  INFO main-EventThread module.ModuleDeployer:215 - removed SimpleModule [name=time, type=source, group=s, index=0 @51a42578]20:15:31,420 ERROR main-EventThread imps.CuratorFrameworkImpl:512 - Watcher exceptionjava.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@6d223732 has been closed already\\tat org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)\\tat org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)\\tat org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:214)\\tat org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:144)\\tat org.springframework.xd.dirt.plugins.stream.StreamPlugin.beforeShutdown(StreamPlugin.java:74)\\tat org.springframework.xd.dirt.module.ModuleDeployer.beforeShutdown(ModuleDeployer.java:267)\\tat org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:217)\\tat org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:197)\\tat org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:169)\\tat org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:252)\\tat org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:580)\\tat org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:56)\\tat org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)\\tat org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)</pre></div></div>\n",
            "<p>Currently, the job module\\'s batch job\\'s bean id should be \"job\". This also causes the job name to be \\'actual-job-name + \".job\"\\' and the batch job controllers require to search for job with suffix \".job\". </p><p>Removing this constraint would help us avoiding these.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Currently, XD hast \"testCompile\" dependency to use org.codehaus.groovy:groovy-all:2.2.1. </p><p>The spring-integration-groovy uses \"2.2.2\" and it is what spring IO platform uses as well. To keep it all same, we can change this \"testCompile\" dependency to use \"2.2.2\"</p>\n",
            "<p>As a consequence of not fixing <a href=\"https://jira.spring.io/browse/XD-1289\" title=\"Use descriptive texts for some module options defaults\" class=\"issue-link\" data-issue-key=\"XD-1289\"><del>XD-1289</del></a>, we should document keys of the form ${xd.stream.name} that are available to users</p><p>${xd.<span class=\"error\">&#91;stream|job&#93;</span>.name} and ${xd.container.???} come to mind, there may be others</p>\n",
            "<p>This change has to be facilitated because of the <a href=\"https://jira.spring.io/browse/XD-1456\" title=\"Allow user to configure tests with DI \" class=\"issue-link\" data-issue-key=\"XD-1456\"><del>XD-1456</del></a> and <a href=\"https://jira.spring.io/browse/XD-1455\" title=\"Environment checkers in acceptance tests should use Asserts\" class=\"issue-link\" data-issue-key=\"XD-1455\"><del>XD-1455</del></a> stories.</p>\n",
            "<p>Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD.  And to allow for faster downloads.  However XD Jars are already placed on S3, so this feature is no longer needed.</p>\n",
            "nan\n",
            "nan\n",
            "<p>all state about the running system (containers, streams, and jobs) should be available via ZK, and ultimately the --store option should not be needed</p><p>1. Refactor ModuleDefinitionRepository to use ZooKeeper</p><ul>\\t<li>remove RedisModuleDefinitionRepository</li>\\t<li>remove InMemoryModuleDefinitionRepository</li></ul><p>2. Refactor ModuleDependencyRepository to use ZooKeeper</p><ul>\\t<li>remove RedisModuleDependencyRepository</li>\\t<li>remove InMemoryModuleDependencyRepository</li></ul><p>3. Refactor RuntimeModuleInfoRepository to use ZooKeeper (rename ModuleMetadata...)</p><ul>\\t<li>remove RedisRuntimeModuleInfoRepository</li>\\t<li>remove AbstractRedisRuntimeModuleInfoRepository</li>\\t<li>remove InMemoryRuntimeModuleInfoRepository</li></ul><p>4. Refactor RuntimeContainerModuleInfoRepository to use ZooKeeper (rename ContainerMetadata...)</p><ul>\\t<li>remove RedisRuntimeContainerModuleInfoRepository</li>\\t<li>remove InMemoryRuntimeContainerModuleInfoRepository</li></ul><p>5. Remove support for --store</p><ul>\\t<li>remove the memory-store.xml and the redis-store.xml</li>\\t<li>instead include just one repositories.xml in shared server config</li>\\t<li>remove the associated property key and the *Options properties</li></ul><p>6. Remove the events and listeners that were being used</p>\n",
            "<p>After some discussion and voting, we decided to remove \"jmxEnabled\" as a command line option and have JMX enabled by default.<br/>This can be disabled from xd-config.yml externally.</p>\n",
            "<p>While the current setting work while running from your laptop to local deployments.  Or running from your laptop to ec2, they are not long enough for CI to Ec2.<br/>This should have good defaults and have CI set them to what it needs.</p>\n",
            "<p>See also <a href=\"https://jira.spring.io/browse/XD-451\" title=\"Add a Access-Control-Allow-Origin header to responses in order to support cross-origin requests\" class=\"issue-link\" data-issue-key=\"XD-451\"><del>XD-451</del></a> as reference.</p>\n",
            "<p>Some boot classes we compile against have changed or been replaced.</p>\n",
            "<p>Currently these implementations are in the spring-xd-dirt module, but they should be moved into spring-integration-redis. We are already depending upon Spring Integration 3.0 snapshots since the ChannelRegistry implementation is not yet at a milestone, so this should be okay for the Redis Channel Adapters also - until Spring Integration M2 is released.</p>\n",
            "<p>create enough of a design to develop additional stories.</p>\n",
            "\"<p>When building on a branch, the docs should be defaulting to build from origin/master, but that doesn't seem to be happening.  Instead an explicit -Pwikibranch=origin/master is required to be specified on the command line.</p>\"\n",
            "\"<p>As a user, I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.</p>\"\n",
            "\"<p>As a field engineer, I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step.</p>\"\n",
            "<p>As a developer, I\\'d like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event-based systems in the context of real-time analytics using Spring XD.</p><p><a href=\"http://www.debs2015.org/call-grand-challenge.html\" class=\"external-link\" rel=\"nofollow\">Challenge Details</a></p>\n",
            "nan\n",
            "\"<p>As a user, I'd like to parameterize Merge Options, so I can incrementally consume the delta with the help of megastore. </p>\"\n",
            "<p>The call to /modules?detailed=true that was introduced for Flo proves to be a performance hog, most certainly because of all the metadata resolution that has to occur there (and no caching takes place)</p>\n",
            "<p>The file and ftp sources allow working with either the java.io.File or its contents.<br/>For consistency, the sftp source should support the same mechanism.</p>\n",
            "<p>As a user, I\\'d like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes.</p><p>We should also sync-up the following dependency updates to <a href=\"https://github.com/spring-projects/spring-boot/blob/master/spring-boot-dependencies/pom.xml\" class=\"external-link\" rel=\"nofollow\">synchronize with Boot</a>:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">&lt;logback.version&gt;1.1.3&lt;/logback.version&gt;&lt;jackson.version&gt;2.5.1&lt;/jackson.version&gt;&lt;gemfire.version&gt;8.0.0&lt;/gemfire.version&gt;&lt;h2.version&gt;1.4.185&lt;/h2.version&gt;&lt;javax-mail.version&gt;1.5.3&lt;/javax-mail.version&gt;&lt;undertow.version&gt;1.2.3.Final&lt;/undertow.version&gt;&lt;joda-time.version&gt;2.7&lt;/joda-time.version&gt;&lt;nekohtml.version&gt;1.9.21&lt;/nekohtml.version&gt;&lt;activemq.version&gt;5.11.1&lt;/activemq.version&gt;&lt;antlr2.version&gt;2.7.7&lt;/antlr2.version&gt;&lt;commons-dbcp2.version&gt;2.0.1&lt;/commons-dbcp2.version&gt;&lt;tomcat.version&gt;8.0.21&lt;/tomcat.version&gt;&lt;aspectj.version&gt;1.8.5&lt;/aspectj.version&gt;&lt;groovy.version&gt;2.4.3&lt;/groovy.version&gt;&lt;crashub.version&gt;1.3.1&lt;/crashub.version&gt;&lt;jetty.version&gt;9.2.9.v20150224&lt;/jetty.version&gt;&lt;elasticsearch.version&gt;1.4.4&lt;/elasticsearch.version&gt;&lt;flyway.version&gt;3.2.1&lt;/flyway.version&gt;&lt;freemarker.version&gt;2.3.22&lt;/freemarker.version&gt;&lt;jdom2.version&gt;2.0.6&lt;/jdom2.version&gt;&lt;liquibase.version&gt;3.3.2&lt;/liquibase.version&gt;&lt;mockito.version&gt;1.10.19&lt;/mockito.version&gt;mongodb.version&gt;2.13.0&lt;/mongodb.version&gt;&lt;slf4j.version&gt;1.7.11&lt;/slf4j.version&gt;&lt;spring-cloud-connectors.version&gt;1.1.1.RELEASE&lt;/spring-cloud-connectors.version&gt;&lt;spring-security.version&gt;4.0.1.RELEASE&lt;/spring-security.version&gt;&lt;jedis.version&gt;2.6.2&lt;/jedis.version&gt;&lt;spring-ws.version&gt;2.2.1.RELEASE&lt;/spring-ws.version&gt;</pre></div></div>\n",
            "<p>Code that is in there could be moved to the SparkStreamingModule.</p><p>Then, as part of a later refactoring, that plugin should be made part of the module (and loaded by the module classloader)</p>\n",
            "\"<p>As a developer, I'd like to add documentation on escape quotes, so when someone using Sqoop job can double escape <tt>\\\\\\\\\\\\\\\\N</tt> instead of sending quotes <tt>'\\\\N'</tt> to successfully submit the job.</p>\"\n",
            "\"<p>As a user, I'd like to refer to the documentation to configure the properties file, so I can use it as recommended to represent the deployment manifest.</p>\"\n",
            "\"<p>As a developer, I'd like to measure performance numbers for a simple stream so that I can characterize the overall throughput.</p>\"\n",
            "\"<p>As a user, I'd like to clean-up stale queues/topics associated with the stream so when the stream gets destroyed I can clean-up resources. </p>\"\n",
            "<p>We should update to use spring-data-hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there (syncable writes, timeout).</p><p>A few things to keep in mind:</p><ul class=\"alternate\" type=\"square\">\\t<li>this updates Cloudera CDH to 5.3.3</li>\\t<li>Kite version is now 1.0 - need to test the hdfs-dataset sink</li></ul>\n",
            "<p>See: </p><p><a href=\"https://sonar43.spring.io/drilldown/measures/7173?metric=package_tangle_index\" class=\"external-link\" rel=\"nofollow\">https://sonar43.spring.io/drilldown/measures/7173?metric=package_tangle_index</a></p>\n",
            "\"<p>As a developer, I'd like to setup a performance testing infrastructure (rackspace), so I can start benching Kafka baselines and continue with XD use-cases.</p>\"\n",
            "\"<p>As a build manager, I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit-trigger new builds. </p><p><b>Scope:</b></p><ul>\\t<li>Use the environment where Bamboo is running</li>\\t<li>Gain access to powershell</li>\\t<li>Setup services (redis, rabbit, etc.)</li>\\t<li>Kick-off CI task</li></ul>\"\n",
            "\"<p>As a QA, I'd like to benchmark <em>Sqoop</em> vs. <em>jdbchdfs</em> batch job so that I can compare and contrast performance stats. </p>\"\n",
            "\"<p>As a user, I'd like to build XD in Windows machine so that I can develop, test,  and contributed to OSS.</p>\"\n",
            "\"<p>As a developer, I'd like to build <em>Spark Streaming</em> as data processors in XD so that we can demonstrate some of the capabilities.</p><p><b>Implement using:</b></p><ul>\\t<li>Java / Java Lambdas</li>\\t<li>Scala</li></ul>\"\n",
            "\"<p>As a field engineer, I'd like to have a comparison of Storm examples in Spring XD so that it is easy to relate from implementation standpoint.</p>\"\n",
            "\"<p>As a PM, I'd like to have the Smart Grid demo (from s1-2014) ported into Spring XD samples repo.</p>\"\n",
            "<p>Upload payload conversion demo such that a user can use the module upload feature against the sample.</p>\n",
            "<p>The scope is to address the sub-tasks linked with this story.</p>\n",
            "\"<p>As a developer, I'd like to benchmark Rabbit performance so that I can use the results as reference to setup XD cluster.</p>\"\n",
            "nan\n",
            "nan\n",
            "<p>As a developer, I\\'d like to bench Kafka as message bus using in-built perf-testing producer/consumer utilities so that I can use that as a foundation to build XD use-cases and measure performance. </p><p>I\\'d like to reproduce baseline performance metrics as identified by the Kafka <a href=\"https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines\" class=\"external-link\" rel=\"nofollow\">engineering team</a>.</p>\n",
            "nan\n",
            "\"<p>As a developer, I'd like to research and Identify the EC2 infrastructure required  so that I can run performance tests on Kafka.</p>\"\n",
            "\"<p>As a developer, I'd like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing.</p>\"\n",
            "\"<p>As a developer, I'd like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests.</p>\"\n",
            "\"<p>As a developer, I'd like to add load receiving <em>sink</em> module so that I can measure received throughput</p>\"\n",
            "\"<p>As a developer, I'd like to continue Lattice/Diego POC so that I can identify the scope, risks, and the overall design for a pluggable SPI in XD runtime.</p>\"\n",
            "\"<p>As a developer, I'd like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc. </p>\"\n",
            "<p>Thanks to Gary I found this little gem of documentation to be able to use xpath expression in XD. Only hiccup is that I had to also add the spring-xml.jar to the classpath (otherwise it is missing XPathException class). </p><p><a href=\"http://stackoverflow.com/questions/29110757/spring-xd-work-with-xml-payload\" class=\"external-link\" rel=\"nofollow\">http://stackoverflow.com/questions/29110757/spring-xd-work-with-xml-payload</a></p>\n",
            "<p>As a developer, I\\'d like to create a custom job module using Java Config so that I don\\'t have to deal with XML configurations. While deploying/launching the following job, I get the error attached below.</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-xml\">job create --name CDK_Global --definition <span class=\"code-quote\">\"customBatchJob\"</span> --deploymodule upload --type job --name customBatchJob --file /Users/mminella/Documents/IntelliJWorkspace/CustomBatchModule/build/libs/CustomBatchModule-1.1.0.RELEASE.jarjob launch --name CDK_Global</pre></div></div><p><b>Error:</b><br/>I\\'m getting an exception that the job doesn\\'t exist asking if it\\'s deployed</p>\n",
            "\"<p>As a developer, I'd like to update all the module docs to also include <em>shortDescription</em> so that it's available for users to learn more about the module.</p>\"\n",
            "\"<p>As a user, I'd like to have the OOTB <em>gpfdist</em> sink module, so I can use this module to do ultra fast data movement from various sources into GPDB/HAWQ.</p>\"\n",
            "<p>As a developer, I\\'d like to add support for dynamic classpath for modules, so we can have the flexibility to load the right dependencies either based on module options (0) or via other properties such as including the dependencies from a specific location (1). </p><p>(0):</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">/lib/*.jar:lib/${distro}/*.jar</pre></div></div><p>(1):</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">${xd.home}/lib/hadoop/${distro}/*.jar</pre></div></div><p><b>Example:</b></p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">http | hdfs --distro=PHD22http | myCustomModule --classpath=/my/funky/dirhttp | jpa --provider=eclipsejpa:/config//lib/something-that-is-common.jar    /eclipse/eclipse-link-3.2.jar    /hibernate/hibernate-core-5.0.jarmodule.classpath = /lib/*.jar:/lib/${provider}/*.jar</pre></div></div>\n",
            "\"<p>Initial support for partitioned batch jobs (initially tested with a local bus) had an <tt>ExecutorChannel</tt> in the job context to enable multiple partitions to run. Otherwise, with a local bus, only one partition would run at a time.</p><p>When further work was done to support other buses, this was removed and the bus was used to control partition concurrency.</p><p>The <tt>LocalMessageBus</tt> was changed to use an unbounded task executor; this was wrong because now all partitions ran at once.</p><p>Further changes to the local bus changed the task executor to be pooled, but with default properties that mean only one thread is used.</p><p>Further, the pool configuration is bus-wide so you can't use that configuration to select the concurrency for an individual job.</p><p>The bottom line is that the local bus is not suitable for partitioned batch jobs; it was not anticipated that it would be used for this scenario. With 1.0.x too many partitions run (all); with 1.1.x only one thread runs (by default).</p><p>In the local bus, we need to use a configurable, dedicated, bounded task executor for each batch job. </p>\"\n",
            "nan\n",
            "\"<p>As a developer, I'd like to bench test cases around <tt>TupleBuilder</tt>, so I can identify the bottlenecks and tune for performance optimizations. </p>\"\n",
            "<p>As a build manager, I\\'d like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA. </p><p><b>Location for 1.1.0 RELEASE:</b><br/><a href=\"http://repo.spring.io/libs-release-local/org/springframework/xd/spring-xd/1.1.0.RELEASE/\" class=\"external-link\" rel=\"nofollow\">http://repo.spring.io/libs-release-local/org/springframework/xd/spring-xd/1.1.0.RELEASE/</a></p>\n",
            "\"<p>As a build manager, I'd like to schedule CI builds for windows so that I can verify XD runtime features/functionality.</p><p>The scope is to isolate the remaining test failures; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.</p>\"\n",
            "<p>This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings.<br/>load-generator should be used as the foundation for this test with the following settings:<br/>module.load-generator.count=10,module.throughput.consumer.concurrency=10</p><p>An environment should be provisioned to support the containers, Zookeeper and Kafka.</p>\n",
            "\"<p>As a user, I'd like to parameterize CodeGen Options, so I can generate code on the fly as needed. </p>\"\n",
            "nan\n",
            "\"<p>As a developer, I'd like to refactor the programmatic means by which the MessageBus transforms the Message so throughput performance can be optimized.</p>\"\n",
            "\"<p>As a developer, I'd like to upgrade to SI milestone/GA release, so I can synchronize with JMX improvements.  </p><p>This is dependent on SI Milestone and GA release timelines.</p>\"\n",
            "\"<p>As a developer, I'd like to upgrade to SI Kafka release, so I can synchronize with latest improvements and bug fixes.  </p>\"\n",
            "\"<p>As a developer, I'd like to certify Spring XD against PHD 3.0, so I can synchronize with the latest ODP based bits. </p>\"\n",
            "<p>If automatic binding of dead letter is enabled for rabbit mq and taps are deployed, anytime the tap is undeployed, the dead letter for that tap still remains.  The tap uses a unique name and the queue for that is automatically deleted, but the dead letter queue for it is not.  This problem becomes worse when containers are running in yarn and may not live for long periods of time.  Many dead letter queues for taps can become overwhelming.</p>\n",
            "<p>When using the rest interface to create a Job with an empty description, used to generate the following exception, \"Definition can not be empty\".   Now generates \"XD112E:(pos 0): Unexpectedly ran out of input^\". <br/>The correct error should be, \"definition cannot be blank or null\"</p>\n",
            "\"<p>As a developer, I'd like to add a new CI build to include <em>install</em> target, so I can verify the target expectations, as it is often time consuming to verify it in the development environment.</p>\"\n",
            "\"<p>As a user, I'd like to have the configuration option to use an alternative DLQ, so I can publish the message this time with additional headers, including one that contains the exception (and stack trace).</p>\"\n",
            "<p>As a developer, I\\'d like to create a <a href=\"https://github.com/markfisher/receptor-client\" class=\"external-link\" rel=\"nofollow\">java client</a> for Receptor, so I can interact with Diego runtime via Receptor API calls from XD. </p>\n",
            "\"<p>As a developer, I'd like to build isolated Boot-based <tt>ModuleRunner</tt> for use in container-managed environments, so I can run XD without the hard requirement for running <em>xd-containers</em>.</p>\"\n",
            "nan\n",
            "\"<p>As a developer, I'd like to create a <em>gpload</em> tasklet, so I can ingest data from various sources into GPDB in an efficient manner.</p>\"\n",
            "\"<p>As a developer, I'd like to setup UI infrastructure, so I can integrate admin_ui and Flo.</p>\"\n",
            "\"<p>As a user, I'd like to use a <em>jdbchdfs</em> batch job as a passthrough (without chunk processing) so that I don't have to incur the batch read/write overhead.</p>\"\n",
            "<p>When uploading a new version of a module the admin container if there is already an existing module, the behavior should be to delete the existing contents of the module directory and replace it with that of the new upload jar.</p><p>This would be an optional parameter.</p>\n",
            "\"<p>As a developer, I'd like to add support for explicit partition count configuration, so I can use this option to cleverly route the payload to the intended consumer (module).</p>\"\n",
            "<p>Similar to the DetailedModuleDefinitionResource that is returned when querying a single module, but would be returned when listing (provided a ?full flag has been turned on)</p>\n",
            "\"<p>As a user, I logged in with ROLE_CREATE and I get an error while trying job creation from admin_ui. I can create job from the shell successfully. Trying the same workflow with ROLE_ADMIN results with the same error as well. I don't see anything in the admin/container logs about the error itself. </p>\"\n",
            "<p>This keeps coming up as an issue that prevents us from publishing to maven central.</p>\n",
            "<p>I had a custom module with a typo:<br/>base_packages=base_packages=com.acme.config</p><p>The module deploys without error but the stream hangs since the channels, etc. are not found in the stream plugin. Very hard to debug. </p>\n",
            "<p>The spark streaming message bus receiver isn\\'t reliable yet. The receiver needs to handle data loss in case of worker node that has it running.</p><p>We currently handle the driver failure automatically by re-deploying spark streaming module. But, this is about the data loss when the worker node dies.</p><p>Please see the documents here:</p><p><a href=\"https://databricks.com/blog/2015/01/15/improved-driver-fault-tolerance-and-zero-data-loss-in-spark-streaming.html\" class=\"external-link\" rel=\"nofollow\">https://databricks.com/blog/2015/01/15/improved-driver-fault-tolerance-and-zero-data-loss-in-spark-streaming.html</a></p><p><a href=\"http://spark.apache.org/docs/latest/streaming-custom-receivers.html\" class=\"external-link\" rel=\"nofollow\">http://spark.apache.org/docs/latest/streaming-custom-receivers.html</a></p>\n",
            "nan\n",
            "<p>Mask out all properties for XD-EC2</p>\n",
            "\"<p>As a developer, I'd like to fix the offset management with Kafka <em>source</em> module so that I can efficiently perform fetch operation from the given offsets.</p>\"\n",
            "\"<p>As a user, I'd like to mass ingest data from databases (and others) into HDFS/HAWQ/GPDB so that I don't have to write custom code and as well as be able to ingest in an efficient way.</p>\"\n",
            "<p>Should be part of the daily build.<br/>One \"easy\" way to do it would be to use the \"hardcoded\" authentication scheme as described here (bamboo should mask a property whose name contains password)<br/>We may want to create a dedicated github user though</p>\n",
            "nan\n",
            "<p>The build has some inconsistencies that should be taken care of.<br/>Amongst the one I know:</p><ul>\\t<li>The UI project is always getting cleaned, for no apparent reason (there might have been one before), thus triggering a rebuild of everything downstream, most notably DIRT</li>\\t<li>The \\xe2\\x80\\x9cexec\" task is not used anymore</li>\\t<li>Lots of projects are getting the boot plugin applied to them. I\\'m not sure 100% what that plugin does, but we don\\'t need the repackage bit for example.</li></ul>\n",
            "\"<p>As a user, I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition).</p>\"\n",
            "\"<p>As a user, I'd like to have the custom module (built as uber-jar) hosted in HDFS so that I can deploy the module to newly arriving containers. </p>\"\n",
            "<p>Currently when modules are composed to a single application context, properties are not inherited.</p><p><a href=\"https://github.com/spring-projects/spring-xd/wiki/Modules#placeholders-available-to-all-modules\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/wiki/Modules#placeholders-available-to-all-modules</a></p>\n",
            "<p>As a consequence, </p><ul>\\t<li>change gradle script regarding generation of documentation</li>\\t<li>remove pushGeneratedDocs task, etc</li>\\t<li>remove link rewriting that is no longer needed</li></ul>\n",
            "\"<p>As a developer, I'd like to upgrade to Reactor 2.0 RC1 release so that we can synchronize with stable dependencies.</p>\"\n",
            "nan\n",
            "<p>Spring IO Compatibility</p>\n",
            "<p>Currently, you have to set the default name node every time your start the shell. We should do 2 things: </p><ul class=\"alternate\" type=\"square\">\\t<li>Provide a default Name node Set Default Hadoop Name Node for Shell: hdfs://localhost:8020</li>\\t<li>Should we provide some form of persistence? It kind of sucks that you have to re-specify the name node every time the shell starts up</li></ul><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">xd:&gt;hadoop fs ls /You must set fs URL before run fs commands</pre></div></div>\n",
            "<p>Currently this works:<br/>stream create foo --definition \"tap:baz.time &gt; log\"<br/>stream create baz --definition \"time | file\"</p><p>But this doesn\\'t:<br/>stream create foo --definition \"tap:baz &gt; log\"<br/>stream create baz --definition \"time | file\"</p><p>This is because the parser translates references to \"tap:baz\" to named channel \"tap:baz.time\" (the name of the stream\\'s first module). If the stream is not yet created, the parser cannot perform this translation. A fix for this will likely be related to the fix needed for <a href=\"https://jira.spring.io/browse/XD-812\" title=\"Re-enable support for tapping labels and named channels\" class=\"issue-link\" data-issue-key=\"XD-812\"><del>XD-812</del></a>.</p>\n",
            "<p>There is no point in providing completion with something that will fail when the user tries it. The information about a module being a composed is now available at the REST layer, so should be used</p>\n",
            "<p>It should be possible to configure a (short) description for a module that is display above the module options <br/>via <tt>module info --name ....</tt>.</p><p>The description could contain a few lines describing the core functionality and potentially hyperlinks <br/>to additional information for a module.</p><p>This information should be exposed via the REST interface as well.</p><p>Currently only the module options are printed.</p>\n",
            "<p>stream create foo --definition \"label: bar | xxxx\"<br/>stream deploy foo --properties \"module.label.yyy=zzz\" seems to work but it does not. The pre-validation is correct, but downstream, deployment logic still looks for module.bar (instead of module.label)</p>\n",
            "\"<p>As a user, I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios. </p>\"\n",
            "\"<p>As a user, I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios. </p>\"\n",
            "\"<p>As a developer, I'd like to have the high-level description for each of the modules so that I can use the description (presumably what is captured in javadoc for the module definition) to understand the purpose of the module itself.</p>\"\n",
            "<p>Maybe only have it run after the publish build instead of triggering builds directly from jdk6-&gt;7-&gt;8.</p>\n",
            "\"<p>Once the container's management server is secured, the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.</p>\"\n",
            "\"<p>Once the container's management server is secured, the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.</p>\"\n",
            "\"<p>Once the container's management server is secured, the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.</p>\"\n",
            "\"<p>As a developer, I'd like to add load generator <em>source</em> module so that I could use it for performance testing use-cases. </p>\"\n",
            "nan\n",
            "<p>Currently all message bus implementations are removed from the runtime classpath and loaded on demand from the file system according to the transport setting. Custom module projects that include in container testing must install messagebus-local on the local file system. This is currently configured as a task for module build scripts. This is also a dependency for testing in the IDE and developers need to execute the build task or configure the messagebus manually. Embedding the local MB for the singlenode application (local is not a valid transport for distributed) eliminates this step.</p>\n",
            "<p>Create a load-generator source module that  will generate messages and dispatch messages to a XD stream.  </p>\n",
            "<p>The configuration for the redis sink must be provided for explicitly instead of falling back to values defined in servers.yml.  The default behavior configuration should be address in a manner consistent with the default behavior of module config for rabbit source/sink, jdbc sink....</p>\n",
            "<p>As a developer, I\\'d like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch-jobs in 1.1 release.</p><p>Perhaps this could be part of <a href=\"https://github.com/spring-projects/spring-xd/wiki/Deployment#troubleshooting\" class=\"external-link\" rel=\"nofollow\">troubleshooting</a> section in our wiki.</p>\n",
            "<div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">logger.error(<span class=\"code-quote\">\"Failed to deliver message; retries exhausted; message sent to queue <span class=\"code-quote\">\\'ERRORS:name\\'</span>\"</span>,\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcontext.getLastThrowable());</pre></div></div><p>Should be:</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">logger.error(<span class=\"code-quote\">\"Failed to deliver message; retries exhausted; message sent to queue <span class=\"code-quote\">\\'ERRORS:\"</span> + name + \\'</span>\",\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcontext.getLastThrowable());</pre></div></div><p>So the actual name is logged.</p>\n",
            "nan\n",
            "<p>The AggregateCounterTests were created to satisfy <a href=\"https://jira.spring.io/browse/XD-1462\" title=\"Validate time field processing with AggregateCounter\" class=\"issue-link\" data-issue-key=\"XD-1462\"><del>XD-1462</del></a>, but currently they only have a couple tests to validate the time field processing. More comprehensive tests need to be added (including the testing of the Redis-based implementation in addition to in-memory).</p><p>For more info, see the comment here:<br/><a href=\"https://github.com/spring-projects/spring-xd/pull/1087#issuecomment-49638189\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/pull/1087#issuecomment-49638189</a></p>\n",
            "<p>This is a parallel implementation to the RxJava </p><p><a href=\"https://github.com/spring-projects/spring-xd/blob/master/spring-xd-rxjava/src/main/java/org/springframework/xd/rxjava/SubjectMessageHandler.java\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/blob/master/spring-xd-rxjava/src/main/java/org/springframework/xd/rxjava/SubjectMessageHandler.java</a></p><p>That will allow multiple threads to broadcast an event but allow processing to occur one at a time on any thread.</p>\n",
            "<p>As a user, I\\'d like to have the option to implement <em>bindRequestor</em> and <em>bindReplier</em> so that I can \"bind a producer that expects async replies\" and \"bind a consumer that handles requests from a requestor and asynchronously sends replies\" respectively. </p>\n",
            "\"<p>As a user, I'd like to refer to a Pig script/job sample so that I can use that as a reference to integrate Pig jobs in XD.</p>\"\n",
            "<p>Test basic functionality (hdfs sink, jdbchdfs job) on hadoop26, hdp22, cdh5, phd21</p><p>Test XD on YARN on hadoop26, hdp22, cdh5 and phd21</p>\n",
            "<p>remove spark and hadoop requirements from spring-xd-module-parent and gradle module plugin</p>\n",
            "<p>As a developer, I want to have to run Kafka tests on an external broker, so that I reduce the footprint of the build process. </p>\n",
            "\"<p>As a developer, I'd like to review the current sonar violations so that I can fix the relevant and update the irrelevant ones as invalid.</p>\"\n",
            "<p>see <a href=\"https://github.com/spring-projects/spring-boot/issues/2454\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-boot/issues/2454</a></p>\n",
            "nan\n",
            "<p>As a developer, I\\'d like to refer to wiki so that I can configure machines with recommended <em>ulimit</em> setting for XD\\'s distributed setup.</p><p><b>Note:</b><br/>Recommended <em>ulimit</em> setting is 10K under \"Troubleshooting\" (new) section</p><p><b>Exception:</b> (reason to increase <em>ulimit</em>)<br/>8:25:52,266 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module<br/>java.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/data/packages/springxd/ee02bd3482eeb620a65862fb54e1f23fcece8022.1-bd<br/>a341640a5de2f922fd3db906ce504b85819c1e/spring-xd-1.1.0.BUILD-SNAPSHOT/xd/config/modules/modules.yml (Too many open files)</p>\n",
            "<p>As a scala developer, someone could easily deploy the spark streaming module developed using scala.</p>\n",
            "<p>Run a clean gradle build to identify all warnings.</p>\n",
            "<p>As a user, I\\'d like to see the \\'date\\' in logs so that I can troubleshoot issues that had occurred on a specific day and time.</p><p>Property that needs adjusted:<br/><a href=\"https://github.com/spring-projects/spring-xd/blob/master/config/xd-container-logger.properties#L11\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/blob/master/config/xd-container-logger.properties#L11</a></p>\n",
            "\"<p>As a developer, I'd like to upgrade to Kafka's SI GA release so that I can sync -up with the latest bits. </p><p>The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.</p>\"\n",
            "\"<p>As a PM, I'd like to have the copyright message in the reference guide (PDF) updated to include 2015 instead of 2014. </p>\"\n",
            "\"<p>As a developer, I'd like to upgrade to SHDP GA release so that I can sync -up with the latest bits. </p>\"\n",
            "\"<p>As a developer, I'd like to run Kafka tests with Kafka Server as a separate running process so that I can improve build experience.</p>\"\n",
            "\"<p>As a QA, I'd like to include acceptance test coverage for <em>spark-app</em> batch job so that I can validate the functionality as part of every CI build. </p>\"\n",
            "<p>Use latest version, might need to exclude version from other dependencies, e.g. SI, in build-common.gradle.</p>\n",
            "\"<p>As a user, I'd like to use <em>partitionResultsTimeout</em> attribute for jobs that inherit singlestep-partitioning strategy but it is not exposed as a metadata attribute in the wiki. </p><p><b>Note:</b><br/>The property should be available for all the jobs that import; 3 OOTB jobs have it imported (ref. attachment)</p>\"\n",
            "<p>When available</p>\n",
            "<p>Upgrade in 1.0.x branch what was done in this commit on master.</p><p><a href=\"https://github.com/spring-projects/spring-xd/commit/16062d771e23187a1d9e8d549abc646ff44e435b\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/commit/16062d771e23187a1d9e8d549abc646ff44e435b</a></p>\n",
            "<p>Create one or more Sample module projects in the Spring XD Examples repo to serve as templates for Spring XD module projects. Similar to <a href=\"https://github.com/dturanski/siDslModule\" class=\"external-link\" rel=\"nofollow\">https://github.com/dturanski/siDslModule</a>, these should include unit and single node integration tests, and demonstrate the use of Spring XD build and packaging tools, and other module development support. This may be split out into separate tasks, but should include a sample for source, processor, sink, and job, using @Configuration or XML configuration (either as separate samples or using build profiles). </p>\n",
            "\"<p>This doesn't follow the conventions we have with other modules and it also means it isn't easy to override via environment variables etc.  This is in HDFS and some others.</p>\"\n",
            "<p>See <tt>RedisSingleNodeStreamDeploymentIntegrationTests</tt> etc.</p>\n",
            "nan\n",
            "<p>The EXAMPLE in the documentation (and the paragraph preceding the example) for the \"script\" processor uses both \"location\" and \"properties-location\" options, but these are in actuality \"script\" and \"locationProperties\" according to \"module info processor:script\" and the text of the documentation.</p><p>See: <a href=\"http://docs.spring.io/spring-xd/docs/1.0.2.RELEASE/reference/html/#script\" class=\"external-link\" rel=\"nofollow\">http://docs.spring.io/spring-xd/docs/1.0.2.RELEASE/reference/html/#script</a></p><blockquote><p>To use the module, pass the location of a Groovy script using the location attribute. If you want to pass variable values to your script, you can optionally pass the path to a properties file using the properties-location attribute. All properties in the file will be made available to the script as variables.</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">xd:&gt; stream create --name groovyprocessortest --definition <span class=\"code-quote\">\"http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log\"</span> --deploy</pre></div></div></blockquote>\n",
            "<p>As a user, I\\'d like to refer to the wiki so that I can create a job with \\'partitions\\' that in turn expects <em>tableName</em> and <em>columns</em> be explicitly included in the job definition. </p><p>It is also beneficial to call-out <em>sql</em> and <em>tableName</em> metadata options are mutually exclusive. Following logic in <em>JdbcHdfsOptionsMetadata</em> needs documented.</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">@AssertTrue(message = <span class=\"code-quote\">\"Use (<span class=\"code-quote\">\\'tableName\\'</span> AND <span class=\"code-quote\">\\'columns\\'</span>) when using partition column\"</span>)<span class=\"code-object\">boolean</span> isPartitionedWithTableName() {\\t<span class=\"code-keyword\">if</span> (StringUtils.hasText(partitionColumn)) {\\t\\t<span class=\"code-keyword\">return</span> StringUtils.hasText(tableName) &amp;&amp; !StringUtils.hasText(sql);\\t}\\t<span class=\"code-keyword\">else</span> {\\t\\t<span class=\"code-keyword\">return</span> <span class=\"code-keyword\">true</span>;\\t}}</pre></div></div>\n",
            "nan\n",
            "<p>As a user, I\\'d like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for \\'MODULE\\' layout and other boilerplate build configuration.</p><p>This is dependent on Boot\\'s module layout scoping issue: <a href=\"https://github.com/spring-projects/spring-boot/issues/2187\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-boot/issues/2187</a></p>\n",
            "<p>As a user, I want Spring XD\\xe2\\x80\\x99s message bus to be able to pre-allocate partitions between nodes when a stream is deployed, so that rebalancing doesn\\xe2\\x80\\x99t happen when a container crashes and/or it\\xe2\\x80\\x99s redeployed.</p>\n",
            "<p>This fix for RichGauge should go into the 1.0.x line.</p>\n",
            "\"<p>This should include lifecycle management, so that when the module's stream is undeployed, the Spark Streaming application should be stopped, etc.</p><p>Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata.</p>\"\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>As a user, I want Spring XD to pre-allocate a set of partitions between the Kafka source modules when a stream is deployed, so that deployment is simpler, and rebalancing doesn\\xe2\\x80\\x99t take place. </p>\n",
            "<p>As a user, I want to be able to control the starting offset of the Kafka source when a stream is deployed, so that I can replay a topic if necessary.</p><p>Note:</p><ul class=\"alternate\" type=\"square\">\\t<li>starting offset is only considered when the stream is deployed</li>\\t<li>progress made by modules must survive their crash for a running stream</li>\\t<li>undeploying and redeploying a stream with a specific start offset will cause the stream to read again from the start</li></ul><p>TBD: what happens when streams are undeployed/redeployed - where do they resume from?</p>\n",
            "<p>Multiple threads invoke the shell processor result in I/O errors and/or data corruption. send() and receive() should be synchronized. </p>\n",
            "nan\n",
            "\"<p>Expecting &lt;module-name&gt; in module configuration is brittle, especially in conjunction with module upload command which permits the module to be registered under a different name.  The convention should be dropped in favor of any file name. This requires at most one foo.xml, foo.groovy, and/or foo.properties in the top level config folder. It is an exception if multiples are found. <br/>Accepting any file name provides the most flexibility without sacrificing backward compatibility (except in rare cases in which a module developer may have violated the multiple xml or properties files condition). An alternate approach requiring a well known file name such as 'spring-module' were rejected over concerns that it would break any existing custom module implementations.</p>\"\n",
            "<p>As a user, I\\'d like to have the option to extend compression support so that I can override the defaults and customize as needed.</p><p>Follow-up from this PR: <a href=\"https://github.com/spring-projects/spring-xd/pull/1346\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd/pull/1346</a></p>\n",
            "\"<p>As a user, I'd like to have an option to track history so that I get the visibility of stream name, module name etc. added as part of the message header.</p>\"\n",
            "<p>Update spring-data-hadoop version to 2.1.0.RC1. This also includes updating the following:</p><ul class=\"alternate\" type=\"square\">\\t<li>adding hadoop26 (Apache Hadoop 2.6.0) as distro</li>\\t<li>adding hdp22 (Hortonworks HDP 2.2) as distro</li>\\t<li>set default distro to hadoop26</li>\\t<li>update cdh5 to version 5.3.0</li>\\t<li>remove older distros - hadoop24, hdp21</li></ul>\n",
            "<p>As a user, I\\'d like to have the option to extend the default message handling behavior for HTTP source-module so that I can override the settings via <em>servers.yml</em> to control the default message size.</p><p><b>Notes:</b><br/>The adapter currently has that hard-coded (1MB limit) in the HttpChunkAggregator. We will have to expose this property for overrides. <a href=\"https://github.com/spring-projects/spring-xd/pull/1367\" class=\"external-link\" rel=\"nofollow\">Related PR</a>.</p>\n",
            "<p>Ensure build works in Windows environments</p>\n",
            "<p>The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation.  The current handler shares a single broadcast stream.  Change to create a new one per thread usage.</p>\n",
            "\"<p>As a developer, I'd like to have acceptance test coverage for XD + YARN on EC2 so that I can verify simple XD features running on YARN on every build cycle.</p>\"\n",
            "\"<p>As a user, I'd like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively. </p><p>We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.</p>\"\n",
            "nan\n",
            "<p>Create port of <a href=\"https://github.com/spring-projects/spring-xd-samples/tree/master/reactor-moving-average\" class=\"external-link\" rel=\"nofollow\">https://github.com/spring-projects/spring-xd-samples/tree/master/reactor-moving-average</a> based on RxJava</p>\n",
            "\"<p>Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for 'MODULE' layout and other boilerplate build configuration. This should include a similar feature for gradle.</p>\"\n",
            "\"<p>As a user, I'd like to have the option to setup <em>batching</em> so that I can ingest data in batches as opposed to payload-at-a-time.</p>\"\n",
            "\"<p>As a user, I'd like to refer to documentation so that I can build the custom module based on recommended standards and patterns.</p>\"\n",
            "<p><a href=\"https://github.com/EsotericSoftware/kryo#pooling-kryo-instances\" class=\"external-link\" rel=\"nofollow\">https://github.com/EsotericSoftware/kryo#pooling-kryo-instances</a></p>\n",
            "nan\n",
            "\"<p>As a user, I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.</p>\"\n",
            "\"<p>As a user, I'd like to have a flexible RxJava module so that it can as a processor. </p>\"\n",
            "\"<p>As a user, I'd like to have the option to <em>stop</em> an existing Sqoop job so that I can clean-up resources at the time of completion.</p>\"\n",
            "nan\n",
            "<p>That method is actually currently never called, but :</p><ul class=\"alternate\" type=\"square\">\\t<li>The case where a mapping already exists is not covered (outstanding TODO comment)</li>\\t<li>the semantics of the method should just be to \"save and override\"</li></ul>\n",
            "nan\n",
            "<p>HA Configuration, async sends.</p><p><a href=\"http://docs.spring.io/spring-integration/reference/html/whats-new.html#4.1-mqtt\" class=\"external-link\" rel=\"nofollow\">http://docs.spring.io/spring-integration/reference/html/whats-new.html#4.1-mqtt</a></p>\n",
            "\"<p>As a developer, I'd like to isolate the Hadoop tests in a different project so that the DIRT project doesn't have to depend upon, thus eliminating the incorrect CP file generation in eclipse. </p>\"\n",
            "<p>Create an 2.6 Yarn Environment on EC2 for which XD can be deployed for acceptance tests.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Based on the POC from <a href=\"https://jira.spring.io/browse/XD-2124\" title=\"Research integration options for Sqoop &#39;tasklet&#39;\" class=\"issue-link\" data-issue-key=\"XD-2124\"><del>XD-2124</del></a> we should create the actual implementation.</p><p>Things to consider to store in step context:</p><ul class=\"alternate\" type=\"square\">\\t<li>capture Log output/MapReduce job counters</li>\\t<li>capture last-value from incremental imports</li></ul>\n",
            "<p>A sample, perhaps taken from Pivotal Labs use-case in Denver, that would calculate some time window averages for a many individual senor values .</p>\n",
            "<p>The module should be flexible to act as a sink as well as a processor.  ErrorHandling will be considered as part of another JIRA</p>\n",
            "\"<p>As a user, I'd like to have the option to <em>ACK</em> messages so that I can guarantee that the message/request sent is successful. </p>\"\n",
            "<p>As a user, I\\'d like to have concurrency and compression support for Kafka so that I can increase performance throughput and/or increase responsiveness</p><p><b>Things to consider:</b></p><ul>\\t<li>make global configuration options be \"defaults\" and allow per-deployment overrides</li>\\t<li>add options for\\t<ul>\\t\\t<li>concurrency</li>\\t\\t<li>compression support</li>\\t</ul>\\t</li></ul>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>A pause means that a trigger will wait to fire its job until after the pause is removed.  It does not apply the misfire behavior.</p>\n",
            "<p>  Commonly called Calendar support</p>\n",
            "<p> In the case that there are not enough resources to fire a trigger, the highest priority will be fired first.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>2 options are:<br/>1) Fire the trigger immediate - Launch the job when trigger can gather the resources necessary start the job<br/>2) Do nothing - Ignore this job fire time and catch </p><p>this scenario can occur if XD is down or resources (threads) are not available at the time a job is to be launched. </p>\n",
            "nan\n",
            "<p>Some cleanup to make the tests a bit easer to read.</p>\n",
            "\"<p>As a QA, I'd like to include acceptance test coverage for <em>Kafka</em> as a message bus so that I can validate the functionality as part of every CI build.</p>\"\n",
            "\"<p>As a user, I'd like to have the option to configure default access control for endpoints so that I can grant access by <em>Admin</em> or <em>Viewer</em> roles.</p>\"\n",
            "\"<p>As a user, I'd like to have the option to <em>compress</em> messages so that I can influence the performance throughput. It'd be beneficial to have support for gzip, zip compression, and decompression.</p>\"\n",
            "<p>The code base is changing a bit, so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed.  Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.</p>\n",
            "<p>The tests that use HDFS currently require an external Hadoop installation and is hard to set up/update version in all the environments where we want to run tests, e.g. bamboo, travis.</p><p>See if the mini-cluster described in </p><p><a href=\"http://docs.spring.io/spring-hadoop/docs/2.0.0.RC1/reference/html/testing.html#testing:yarn:minicluster\" class=\"external-link\" rel=\"nofollow\">http://docs.spring.io/spring-hadoop/docs/2.0.0.RC1/reference/html/testing.html#testing:yarn:minicluster</a></p><p>can be used in the test cases instead.</p>\n",
            "<p>Looks like upgrade to Gradle 2.2 is not a simple version change, e.g. I see: </p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">FAILURE: Build failed with an exception.* Where:Build file <span class=\"code-quote\">\\'/Users/hillert/dev/git/spring-xd/build.gradle\\'</span> line: 219* What went wrong:A problem occurred evaluating root project <span class=\"code-quote\">\\'spring-xd\\'</span>.&gt; Could not find method forceDependencyVersions() <span class=\"code-keyword\">for</span> arguments [project <span class=\"code-quote\">\\':documentation-toolchain\\'</span>] on root project <span class=\"code-quote\">\\'spring-xd\\'</span>.</pre></div></div>\n",
            "<p>In order to improve the build reliability, we should be using the NPM repo provided by <b>repo.spring.io</b> </p><p>See <b>spring-xd-ui/README.md</b> for further details.</p>\n",
            "<p>Using single-node deployment of Spring XD 1.0 GA, we needed to redefine several batch jobs. We deleted the jobs (\"job destroy all\"). When attempting to re-add, we received an error that a job with the name already exists. Performing \"job list\" confirms the jobs were gone.<br/>To workaround, I needed to terminate the instance (server) of Spring XD and restart it. Since this was the single-node deployment without a live stream of data coming in this was okay, but would have been a major problem if bouncing the Spring XD server was not acceptable (i.e., live data being actively received).</p>\n",
            "<p>As a user, I\\'d like to have <em>microbatching</em> capability so that I can ingest based on batch intervals for enhanced performance throughput. </p><p><b>Example:</b><br/>\"http --batchInterval=10 | log\"</p>\n",
            "<p>Kafka lends itself well as a message bus, and kafka partitioning maps to MB partitioning.</p><p>Implement KafkaMessageBus and supporting classes and UT/IT.</p>\n",
            "<p>As a user, I\\'d like to use Kafka source through simple consumer API (as opposed to high-level) so that I can gain full control to offsets and partition assignment deterministically.</p><p><b>Spike scope</b>:</p><ul class=\"alternate\" type=\"square\">\\t<li>Study simple consumer API functionality</li>\\t<li>Document findings, approach and next steps</li></ul>\n",
            "<p><b>Refactoring scope:</b> (<em>spring-xd-dirt</em>)</p><ul>\\t<li>Message bus dependencies</li></ul><p>The goal is to decouple them from startup phase to further enhance initialization time. </p>\n",
            "<p>While there is a server endpoint to logout, we don\\'t have that ability yet from the UI. As indicated by <a href=\"https://jira.spring.io/browse/XD-2122\" title=\"Secure endpoints using either ROLE_VIEWER and ROLE_ADMIN\" class=\"issue-link\" data-issue-key=\"XD-2122\"><del>XD-2122</del></a> we will also need a meta-data REST endpoint  so we can interrogate whether security is enabled, whether the user is logged etc. So we can fulfill the requirements: </p><ul>\\t<li>Show a logout button only if a) security is enabled and b) user is logged in</li>\\t<li>Show the username and/or full name of the user being logged in</li></ul>\n",
            "nan\n",
            "\"<p>Travis CI recently introduced docker based builds.<br/>This prevents root access (which we don't need), but allows caching (which we could not use before) and seems to come with beefier machine specs</p>\"\n",
            "nan\n",
            "\"<p>As a PM, I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds. </p>\"\n",
            "nan\n",
            "<p>Given an App ID, we need to be able to wipe the data from Cassandra.  This can be standalone.</p>\n",
            "<p>This entity is not fully indexed with the error message below.  It does not have a (direct) 2-d array.  It does have nested arrays, however.</p><p>2015-09-18 03:20:28,190 <span class=\"error\">&#91;Usergrid-RxIOPool-151&#93;</span> WARN  org.apache.usergrid.persistence.index.impl.EntityMappingParser- Encountered 2 collections consecutively.  N+1 dimensional arrays are unsupported, only arrays of depth 1 are supported<br/>{<br/>   \"type\" : \"example\",<br/>   \"name\" : \"8980031\",<br/>   \"created\" : 1442527975706,<br/>   \"modified\" : 1442547269098,<br/>   \"FacilityName\" : \"ALICES RESTAURANT\",<br/>   \"LastUpdateOn\" : \"9/17/2015\",<br/>   \"Locations\" : [ {<br/>     \"Addresses\" : [ </p>{       \"Zip\" : \"94062\",       \"AddressLine1\" : \"17288 Skyline Blvd\",       \"LatNbr\" : \"37.386916\",       \"LongNbr\" : \"-122.265383\",       \"State\" : \"CA\",       \"AddrUseCd\" : \"PH\",       \"City\" : \"WOODSIDE\"     }<p> ],<br/>     \"Phones\" : [ </p>{       \"PhnUseCd\" : \"PH\",       \"PhoneNbr\" : \"123-456-3534\"     }<p> ],<br/>     \"LocSeq\" : \"1\",<br/>     \"PracLocStrtDt\" : \"1/1/9999\",<br/>     \"PracLocEndDt\" : \"3/31/9999\",<br/>     \"Accepting\" : false,<br/>     \"PracLocSpecialties\" : [ </p>{       \"SpcltyPrimInd\" : \"Y\",       \"SpcltyDsc\" : \"PANCAKES\",       \"SpcltyCd\" : \"BRKF\"     }<p> ]<br/>   } ],<br/>   \"TheId\" : 8980031,<br/>   \"ProviderType\" : \"FAC\",<br/>   \"PvdrEndDt\" : \"3/31/2008\",<br/>   \"PvdrSpecialties\" : [ </p>{     \"SpcltyPrimInd\" : \"Y\",     \"SpcltyDsc\" : \"PANCAKES\",     \"SpcltyCd\" : \"BRKF\"   }<p> ]<br/> }</p>\n",
            "<p>Occasionally Cassandra multi-region replication lags during high load.  During this high load, messages fail to process because it cannot read the entity from Cassandra.  Rather than fail, we should retry with a high consistency level of quorum in all regions to ensure we replicate the data correctly.</p>\n",
            "<p>select * where title contains \\'ta*\\' does not work (at all) as documented here:<br/><a href=\"http://apigee.com/docs/app-services/content/working-queries\" class=\"external-link\" rel=\"nofollow\">http://apigee.com/docs/app-services/content/working-queries</a></p>\n",
            "<p>When no query is specified, we should read by graph edges, and not read via elasticsearch.  The low level seek logic exists.  The relationManager simply needs to wire this functionality in.  A new Graph I/O interface should be created to cleanly implement and test this.</p>\n",
            "<p>2015-08-25 00:01:10,246 <span class=\"error\">&#91;http-bio-8080-exec-313&#93;</span> ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- org.apache.usergrid.rest.exceptions.UncaughtException Server Error (500)<br/>org.apache.usergrid.rest.exceptions.UncaughtException: java.lang.StackOverflowError<br/>        at org.apache.usergrid.rest.exceptions.AbstractExceptionMapper.toResponse(AbstractExceptionMapper.java:59)<br/>        at org.apache.usergrid.rest.exceptions.ThrowableMapper.toResponse(ThrowableMapper.java:37)<br/>        at com.sun.jersey.spi.container.ContainerResponse.mapException(ContainerResponse.java:480)<br/>        at com.sun.jersey.spi.container.ContainerResponse.mapMappableContainerException(ContainerResponse.java:417)<br/>        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1477)<br/>        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)<br/>        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)<br/>        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)<br/>        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)<br/>        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:927)<br/>        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)<br/>        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)<br/>        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)<br/>        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)<br/>        at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)<br/>        at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)<br/>        at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)<br/>        at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)<br/>        at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)<br/>        at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)<br/>        at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)<br/>        at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:343)<br/>        at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:260)<br/>        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)<br/>        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)<br/>        at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)<br/>        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)<br/>        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)<br/>        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)<br/>        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)<br/>        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)<br/>        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)<br/>        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)<br/>        at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)<br/>        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)<br/>        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)<br/>        at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1074)<br/>        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)<br/>        at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:314)<br/>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)<br/>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)<br/>        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)<br/>        at java.lang.Thread.run(Thread.java:745)<br/>Caused by: java.lang.StackOverflowError<br/>        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)<br/>        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)<br/>        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)<br/>        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)<br/>        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)</p>\n",
            "\"<p>We'll want to load test this with our existing entity writes during heavy load.  We need to ensure shard allocation can keep up, and that we have a consistent view of the shards.  We need to test the following scenarios</p><ol>\\t<li>Write over 10 million entities in a single collection, single region only</li>\\t<li>Write over 10 million entities concurrently in 2 regions</li>\\t<li>Write over 10 million entities concurrently in 2 regions, and fail 1 of the regions.  The system should still function, just not allocate new shards.</li></ol>\"\n",
            "<p>Implement locks and a lock manager using Astyanax driver.</p>\n",
            "\"<p>Please investigate and propose a few different options for explicit indexing.</p><p>Things to consider:<br/>1) How other databases handle this<br/>2) Ability to index all occurrences of a given field name - for example, index 'cat' whether it is a root property, pets.cat, owners.cat, etc.</p>\"\n",
            "nan\n",
            "<p>We need to migrate our counters from Hector to a more reliable counter framework.  Use counter column and leverage Datastax Java Driver for time being assuming Cassandra 2.1 improvements are solid.</p>\n",
            "<p>If the qparam is not there, use current/default behavior.  If the qparam is there then skip pulling the extra data which will result in better performance.</p>\n",
            "nan\n",
            "\"<p>Todd's spaghetti comments on write path which results in 2x writes to cassandra ops.</p>\"\n",
            "<p>We need to audit the TODO statements in the code.  For each we must:</p><p>1) Check if there is an existing ticket</p><ul class=\"alternate\" type=\"square\">\\t<li>If there is no ticket create one<br/>2) Update the TODO statement with the link to the ticket<br/>3) Prioritize based on:</li>\\t<li>Will this generate a P1 case with a customer?</li>\\t<li>What is the usability impact of the product?</li></ul><p>Once we have audited these we will prioritize and schedule fixes</p>\n",
            "nan\n",
            "<p>We need to characterize the performance of 2.1.  This will involve using:</p><ul class=\"alternate\" type=\"square\">\\t<li>Varying numbers of tomcats\\t<ul class=\"alternate\" type=\"square\">\\t\\t<li>we can start with 20 and progressively add more into a load balancer to see the performance impact</li>\\t</ul>\\t</li>\\t<li>Varying ES cluster size - starting with 6 and going up to 20\\t<ul class=\"alternate\" type=\"square\">\\t\\t<li>we can start with 20 nodes and only have the indexes targeted to a subset</li>\\t</ul>\\t</li>\\t<li>Varying ES bucket/shard counts - starting with 10</li>\\t<li>Varying Cassandra sizes - starting with 6 and going up to 12</li></ul><p>General approach should be:<br/>1) Start with 2 tomcats, 6 ES and 6 C*<br/>2) Add +2 Tomcats iteratively until the performance starts to not increase (implying that either ES or C* is the limiting factor)<br/>3) Add +3 ES nodes and test again.  Document impact.<br/>4) Add +3 C* nodes, remove -3 ES nodes and test again.  Document impact.<br/>5) Add +3 C* nodes and +3 ES nodes and test again.  Document impact.<br/>6) Add +2 Tomcats and see the slope of the TPS graph<br/>7) Add +3 C* - (now at 12) and test again<br/>8) Test iteratively with +2 Tomcats until performance plateaus, up to 20 Tomcats</p>\n",
            "<p>One of the problems we have faced is uneven distribution in the ES cluster.  We have made changes for document routing that seemed to help, but we are still getting hot nodes in the cluster.  We need to have a test that hits ES directly with load as UG would do to test our cluster distribution.</p>\n",
            "<p>Please add a setting that can prevent the qparams from being returned in a response, and/or add a filter for accessToken and ClientID/ClientSecret to not be returned in a response.</p>\n",
            "<p>Currently, our dynamic mapping causes several issues with elastic search.  We should change our mapping to use a static structure, and resolve this operational pain.</p><p>We need to make the following changes.</p><h2><a name=\"ModifyourIndexScope\"></a>Modify our IndexScope</h2><p>This should more closely resemble the elements of an edge since this represents an edge. It will simplify the use of our query module and make development clearer.  This scope should be refactored into the following objects.  </p><ul>\\t<li>IndexEdge - Id, name, timestamp, edgeType (source or target)</li>\\t<li>SearchEdge - Id, name, edgeType</li></ul><p>Note: edgeType is the type of the Id within the edge.  Does this Id represent a source Id, or does it represent a targetId?  The entity to be indexed will implicitly be the opposite of the type specified.  I.E if it\\'s a source edge, the document is the target.  If it\\'s a target edge, the document is the source.</p><p>These values should also be stored within our document, so that we can index our documents.  Note that we perform bidirectional indexing in some cases, such was users, groups etc.  When we do this, we need to ensure that mark the direction of the edge appropriately.</p><h2><a name=\"Changedefaultsortordering\"></a>Change default sort ordering</h2><p>When sorting is unspecified, we should order by timestamp descending from our index edge.  This ensures that we retain the correct edge time semantics, and will properly order collections and connections</p><h2><a name=\"Removethelegacyqueryclass\"></a>Remove the legacy query class</h2><p>We don\\'t need the Query class, it has far too many functions to be a well encapsulated object.  Instead, we should simply take the string QL, the SearchEdge and the limit to return our candidates.  From there, we should parse and visit the query internally to the query logic, NOT externally.</p><h2><a name=\"Createastaticmapping\"></a>Create a static mapping</h2><p>The mapping should contains the following static fields.</p><ul>\\t<li>entityId - The entity id</li>\\t<li>entityType - The entity type (from the id)</li>\\t<li>entityVersion - The entity version</li>\\t<li>edgeId - The edge Id</li>\\t<li>edgeName - The edge name</li>\\t<li>edgeTimestamp - The edge timestamp</li>\\t<li>edgeType - source | target</li>\\t<li>edgeSearch - edgeId + edgeName + edgeType</li></ul><p>It will then contain an array of \"fields\"  Each of these fields will have the following formation.</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">{ <span class=\"code-quote\">\"name\"</span>:<span class=\"code-quote\">\"[entity field name as a path]\"</span>, <span class=\"code-quote\">\"[field type]\"</span>:[field value}</pre></div></div><p>We will define a field type for each type of field.  Note that each field tuple will always contain a single field and a single value.  Possible field types are the following.</p><ul>\\t<li>string - This will be mapped into 2 mapping with multi mappings.  It will be a string unanalyzed, and an analyzed string.  The 2 fields will then be \"string_u\" and \"string_a\".  The Query visitor will need to update the field name appropriately</li>\\t<li>long - An unanalyzed long</li>\\t<li>double - An unanalyzed double</li>\\t<li>boolean - An unanalyzed boolean</li>\\t<li>location - A geolocation field</li>\\t<li>uuid - A UUID stored as an unanalyzed string</li></ul><p>The entity path will be a flattened path from the root json element to the max json element.  It can be though of as a path through the tree of json elements.  We will use a dot \\'.\\' to delimit the fields.  X.Y.Z for nested objects.  Primitive arrays will contain a field object for each element in the array.</p><h2><a name=\"Indexing\"></a>Indexing</h2><p>  When indexing entities, we will no longer modify or prefix field names.  They will be inserted into the value exactly as their path appears after lower case.</p><h2><a name=\"Querying\"></a>Querying</h2><p>  When querying, the \"contains\" operation for a string will need to use the \"string_a\" data type.  When using =, we will need to use the string_u data type.  Each criteria will need to use nested object querying, to ensure the property name and property value are both part of the same field tuple.</p><h3><a name=\"References\"></a>References</h3><p>Multi Field Mapping: <a href=\"http://www.elastic.co/guide/en/elasticsearch/reference/current/_multi_fields.html\" class=\"external-link\" rel=\"nofollow\">http://www.elastic.co/guide/en/elasticsearch/reference/current/_multi_fields.html</a><br/>Nested Objects: <a href=\"http://www.elastic.co/guide/en/elasticsearch/guide/current/nested-objects.html\" class=\"external-link\" rel=\"nofollow\">http://www.elastic.co/guide/en/elasticsearch/guide/current/nested-objects.html</a><br/>Nested Object Search: <a href=\"http://www.elastic.co/guide/en/elasticsearch/guide/master/nested-sorting.html\" class=\"external-link\" rel=\"nofollow\">http://www.elastic.co/guide/en/elasticsearch/guide/master/nested-sorting.html</a></p>\n",
            "<p>We need to replicate and test the reindex oscillation issue in the e2e environment.</p>\n",
            "<p>Support for Raw Push Notifications for Windows platform needs to be added to the 1.0 code base.  A separate task can be created/assigned for 2.0.</p>\n",
            "<p>Currently many of the NotificationsServiceIT and NotifiersServiceIT test are either broken or incomplete because we were unable to create the mocks we need to test the code. We should revisit this and figure out how to get better test coverage for notifications in general.</p><p>Search the code for <a href=\"https://issues.apache.org/jira/browse/USERGRID-1113\" title=\"Improve NotificationsService test coverage\" class=\"issue-link\" data-issue-key=\"USERGRID-1113\"><del>USERGRID-1113</del></a> to find the tests that should be unignored, fixed, replace or deleted.</p>\n",
            "<p>Instead of requiring that clients first validate tokens obtained from an external \"Central SSO\" system, when Usergrid is configured for using Central SSO, it should attempt to verify any unknown token itself.</p><p>This can be implemented by moving the validate external token logic from the ManagementResource and into the TokenService.</p>\n",
            "<p>The best place for this would be in the metadata of the results, in metadata.distance perhaps.</p>\n",
            "<p>Doing PUT creates a duplicate edge on /management/orgs/org/users/email</p><p>for existing users who were already on the org, the POST command to /management/orgs/org/users/email creates a duplicate edge</p>\n",
            "\"<p>Currently, using caches with the proposal phase for new shards has caused large numbers of tombstones.  Review the algorithm, and determine the cause of the additional shard proposals.</p><p>Usergrid currently performs 5 shard lookups on write and most miss the cache.  We'll change the following</p><p><b>Shard allocation</b></p><p>Shard allocation will not perform a propose + check phase. The following algorithm will occur.  This must occur at EACH_QUORUM to ensure that we have consensus across regions.  </p><p>Any node will propose a new shard pivot.  This pivot will have compacted set to false, and will have a column timestamp of a new timeuuid in micros</p><p>The proposing node will then read back all compacted = false shard pivots.  The shard pivot with the minimum timestamp will be retained, all others will be deleted as proposals.  This will function similarly to distributed read locks in Cassandra.  Lowest proposed value always wins. </p><p>Allocation is complete</p><p><b>Shard compaction</b></p><p>After a successful proposal allocation, the allocating node will copy all edges from the previously compacted shard into the new shard.  It will continue to copy until no new edges are returned on read.</p><p>Once read has been completed, all edges that were copied can be deleted from the previous shard.  </p><p>This target shard will be marked as compacted</p><p><b>Consistency</b></p><p>When performing consistency, we will need a higher consistency level.  To ensure that shards exist worldwide, proposal + selection should occur at EACH_QUORUM.  Standard reads can occur as LOCAL_QUORUM</p>\"\n",
            "<p>Customer requests that we have the ability to view and/or replace an existing APN certificate without having to delete the existing one.  This approach would minimize downtime for notification services.</p><p>Ability to view the certificate, or at more likely only the certificate details) will provide the ability for an operations team to monitor its validity. </p>\n",
            "nan\n",
            "nan\n",
            "<p>Add queue length (SQS, akka, etc.) to the data returned by /status</p>\n",
            "<p>Currently if the search queue is full a 200 response is returned with an empty entity array.</p>\n",
            "<p>Fix all the broken asset tests</p>\n",
            "<p>How will a cache help improve performance?</p><ul>\\t<li>Reduce load on Tomcat, ES and C* caused by permissons calculation.</li></ul><p>Do we need a distributed cache?</p><ul>\\t<li>YES: Todd says we tried non-distributed cache (w/EhCache) and the caching was not effective (bad hit/mss ratio).</li></ul><p>Implementation ideas:</p><ul>\\t<li>Use Cassandra column family implementation</li>\\t<li>Use Hazelcast cache</li>\\t<li>Use EhCache configured for distributed operation</li></ul><p>How much should we expect performance to improve? How can we test this?</p><ul>\\t<li>JUnit + metrics collection in our cache implementation</li></ul><p>Simplest approach seems to be Cassandra. Here\\'s a design:</p><h1><a name=\"AddnewCorePersistenceCachemodule\"></a>Add new Core Persistence Cache module</h1><p>This is a new module that depends only on the Core Persistence Common module (and maybe Model?) and provides a generic cache interface that is \"segmented\" by a cache scope. When you put or get things you specify the cache scope, and it is possible to invalidate all things within a cache scope with one call.</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\"><span class=\"code-keyword\">public</span> <span class=\"code-keyword\">interface</span> SegmentedCache&lt;K,V&gt; {   <span class=\"code-comment\">/** Put value into segment with ttl */</span>   void put( CacheScope scope, K key, V value, <span class=\"code-object\">long</span> ttl );   <span class=\"code-comment\">/** Get value from segment */</span>   V get( CacheScope segment, K key );   <span class=\"code-comment\">/** Delete all cache data of all types and of all scopes */</span>   void invalidate();   <span class=\"code-comment\">/** Delete all cache data within specified segment */</span>   void invalidate( CacheScope segment );}</pre></div></div><p>Caches are stored in Cassandra <b>Usergrid_Cache</b> column family:</p><ul>\\t<li>Row-key is applicationId</li>\\t<li>Column key is toString() of K key</li>\\t<li>Value is serialized V value object</li></ul><h1><a name=\"PluginourCacheintoShiroattheRESTmodulelevel\"></a>Plugin our Cache into Shiro at the REST module level</h1><p>To plugin to Shiro, we provide implementations of the Shiro <b>CacheManager</b> and <b>Cache</b> interfaces that are backed by the Cache module. </p><p>When permissions are updated, we need need to ensure that the old cached permissions are invalidated. So we will modify the <b>EntityManager</b> revoke and grant methods to call invalidate for the application\\'s cache scope.</p>\n",
            "nan\n",
            "\"<p>Hopefully there's nothing bad in there.</p>\"\n",
            "<p>With the new shard proposal algorithm, we need the ability to either </p><p>1)  Perform routing aware shard allocation across multi regions.  This ensures that we </p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>As we move to separate keyspaces for each tenant we need to have an endpoint to monitor storage consumed for the keyspace.  This will be followed by the ability to show data consumed in the console and notifications when storage consumed is at X%.</p><p>1. add size to entities<br/>2. add size to index.<br/>3. migrate field mapping in index<br/>4. add endpoint for getting storage by app</p><p>api is management/orgs/orgname/applications/appname/size<br/>or management/orgs/orgname/applications/appname/size/collectionName</p>\n",
            "<p>Depends on counters getting fixed</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>The EventsResource was broken during two-dot-o development and the tests in EventsResourceIT were marked ignore.</p><p>Fix the EventsResource and re-enable the tests.</p>\n",
            "nan\n",
            "nan\n",
            "<p>By using an distributed Actor System, we can ensure that only one thread accesses any one unique value at a time. I have a working proof of concept of this that writes to Cassandra (via Java Native Driver).</p><p>Initial design is here:<br/><a href=\"https://docs.google.com/document/d/1o9okFgNb_c1RY0eIcZMhijhxE9v7BxHYDiuI8BqkLgU/edit#\" class=\"external-link\" rel=\"nofollow\">https://docs.google.com/document/d/1o9okFgNb_c1RY0eIcZMhijhxE9v7BxHYDiuI8BqkLgU/edit#</a></p><p>Proof of Concept (POC) code is here:<br/><a href=\"https://github.com/snoopdave/akka_poc1\" class=\"external-link\" rel=\"nofollow\">https://github.com/snoopdave/akka_poc1</a></p><p>Presentation that explains the POC is here:<br/><a href=\"https://docs.google.com/presentation/d/11ARSPZ6IAxOYSTo4jcmEdnzXvOgVGNGslznmVtLOZjY/edit?usp=sharing\" class=\"external-link\" rel=\"nofollow\">https://docs.google.com/presentation/d/11ARSPZ6IAxOYSTo4jcmEdnzXvOgVGNGslznmVtLOZjY/edit?usp=sharing</a></p>\n",
            "<p>2015-09-04 22:34:01,420 <span class=\"error\">&#91;http-bio-8080-exec-22&#93;</span> ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- Uncaught Exception<br/>java.lang.IllegalArgumentException: JSON source MUST not be null<br/>        at com.sun.jersey.api.json.JSONWithPadding.&lt;init&gt;(JSONWithPadding.java:90)<br/>        at org.apache.usergrid.rest.applications.ApplicationResource.getAPMConfig(ApplicationResource.java:613)<br/>        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br/>        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)<br/>        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br/>        at java.lang.reflect.Method.invoke(Method.java:483)<br/>        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)<br/>        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)<br/>        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)<br/>        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)<br/>        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)<br/>        at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)<br/>        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)<br/>        at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)<br/>        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)<br/>        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)<br/>        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)<br/>        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)<br/>        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)<br/>        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)<br/>        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)<br/>        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)<br/>        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)<br/>        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)<br/>        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:927)<br/>        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)<br/>        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)<br/>        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)<br/>        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)<br/>        at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)<br/>        at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)<br/>        at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)<br/>        at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)<br/>        at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)<br/>        at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)<br/>        at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)<br/>        at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:343)<br/>        at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:260)<br/>        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)<br/>        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)<br/>        at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)<br/>        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)<br/>        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)<br/>        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)<br/>        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)<br/>        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:503)<br/>        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)<br/>        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)<br/>        at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)<br/>        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)<br/>        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)<br/>        at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)<br/>        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)<br/>        at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:314)<br/>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)<br/>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)<br/>        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)</p>\n",
            "nan\n",
            "nan\n",
            "<p>We need to create a 2.1 release for Apache.  Would be nice to have a binary WAR distribution.</p>\n",
            "\"<p>There are a lot of remnant column families from 1.0 that are causing bloat in our system.  We need to audit each 1.0 column family.  If it is no longer used, it should be removed.  If it is more complicated to remove these column families (such as queues) we'll need to open tickets for them and address them later.</p>\"\n",
            "<p>These errors/failed index events do not seem to cause any operating issues with Usergrid, but cause messages to fall into dead letter queue and increase in ERROR log statements.</p><p>2015-10-30 22:31:48,552 <span class=\"error\">&#91;Usergrid-RxIOPool-152&#93;</span> ERROR org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService- Received empty index sequence message:(6c53a75c-6351-4f2b-8e86-e0176c0bebcd), body<img class=\"emoticon\" src=\"https://issues.apache.org/jira/images/icons/emoticons/sad.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/>{\"edgeIndexEvent\":{\"creationTime\":1446244308487,\"sourceRegion\":\"us-east-1\",\"applicationScope\":{\"application\":{\"uuid\":\"b6768a08-b5d5-11e3-a495-11ddb1de66c8\",\"type\":\"application\"}},\"entityId\":</p>{\"uuid\":\"b6768a08-b5d5-11e3-a495-11ddb1de66c8\",\"type\":\"org_application\"}<p>,\"edge\":{\"sourceNode\":</p>{\"uuid\":\"b6768a08-b5d5-11e3-a495-11ddb1de66c8\",\"type\":\"application\"}<p>,\"type\":\"zzzcollzzz|org_applications\",\"targetNode\":</p>{\"uuid\":\"b6768a08-b5d5-11e3-a495-11ddb1de66c8\",\"type\":\"org_application\"}<p>,\"timestamp\":136655371084730107}}})<br/>2015-10-30 22:31:48,553 <span class=\"error\">&#91;Usergrid-RxIOPool-152&#93;</span> ERROR org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService- Failed to index message: 6c53a75c-6351-4f2b-8e86-e0176c0bebcd<br/>java.lang.Exception: Received empty index sequence.<br/>        at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService.lambda$callEventHandlers$21(AmazonAsyncEventService.java:357)<br/>        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)<br/>        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374)<br/>        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)<br/>        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)<br/>        at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)<br/>        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)<br/>        at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)<br/>        at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService.callEventHandlers(AmazonAsyncEventService.java:372)<br/>        at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService.lambda$null$23(AmazonAsyncEventService.java:695)<br/>        at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)<br/>        at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:46)<br/>        at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:35)<br/>        at rx.Observable$2.call(Observable.java:162)<br/>        at rx.Observable$2.call(Observable.java:154)<br/>        at rx.Observable.unsafeSubscribe(Observable.java:7710)<br/>        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:62)<br/>        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:55)<br/>        at rx.schedulers.ExecutorScheduler$ExecutorSchedulerWorker.run(ExecutorScheduler.java:98)<br/>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)<br/>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)<br/>        at java.lang.Thread.run(Thread.java:745)</p>\n",
            "<p>500 null pointer exceptions return when data is present in an entity reference but not returned from cassandra while this may be a data consistency issue an investigation needs to be done. That said in the mean time a tool should be created that either can retrieve the data and restore it ( update ) or to delete the left over entity reference. </p>\n",
            "nan\n",
            "nan\n",
            "<p>Test migration from v2 to v3 for the upcoming release</p>\n",
            "<p>We shouldn\\'t encode a UUID as a specific UUID field type, since we\\'re encoding it as a string.  To keep our index tuples simple, and support both queries, we should store it as a string type.  We should support the following formats.</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">select * where myUuid = <span class=\"code-quote\">\\'aaa65d8a-16a6-11e5-86ea-7b4f7ff44431\\'</span></pre></div></div><p>As well as </p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">select * where myUuid = aaa65d8a-16a6-11e5-86ea-7b4f7ff44431</pre></div></div><p>Notice the addition of single quotes in the first query, vs the parsing as a UUID type in the second query.  This will enable users to use both versions, but does not affect performance.</p>\n",
            "<p>Currently this test is ignored in Usergrid master branch:<br/>ApplicationResourceIT.clientCredentialsFlowWithHeaderAuthorization()</p><p>If it is still relevant we should fix it and un-ignore it.</p>\n",
            "<p>The Usergrid QueueManager is pluggable. <br/>We would like to add an SQS implementation.</p>\n",
            "\"<p>When read repair is triggered, it is possible that there are now deIndexRequests to be queued.  Currently we're queueing empty operations and need to filter this properly.</p>\"\n",
            "<p>Test migration from old index format to new</p>\n",
            "<p>Create a python script that will allow users to upgrade from 2.0 to 2.1 per application.  This will ultimately allow an incremental deployment across an existing 2.0 cluster, without user impact.  </p><p>Template for full system script that already exists: <a href=\"https://github.com/apache/usergrid/blob/2.1-release/stack/scripts/migrate_entity_data.py\" class=\"external-link\" rel=\"nofollow\">https://github.com/apache/usergrid/blob/2.1-release/stack/scripts/migrate_entity_data.py</a></p><p>It should allow for the following migration process:</p><p>tenant 1<br/>1) setup new 2.1 tomcat<br/>2) run migration bootstrap<br/>3) migrate appinfo<br/>4) reindex mgmt app only<br/>5) run de-dup for whatever APP<br/>6) reindex whatever APP<br/>7) add 2.1 tomcats to customer ELB after 1-6 completed for all customer apps<br/>8) run delta re-index/migration for all customer apps</p><p>tenant 2<br/>1) reset appinfo version<br/>2) migrate app info<br/>3) reindex mgmt app<br/>4) run de-dup for whatever APP<br/>5) reindex whatever app<br/>7) add 2.1 tomcats to customer ELB after 1-6 completed for all customer apps<br/>8) run delta re-index/migration for all customer apps</p><p>after all apps migration<br/>1) migrate entity data</p>\n",
            "<p>A call to /system/database/setup currently performs a database setup, ES setup, and then proceeds to migrate data.  This should be split into 2 separate events.  They should be the following.</p><p> /system/database/setup creates all column families and ES indexes</p><p>/system/database/bootstrap <br/>runs a datamigration manager, then  creates all bootstrap data required for usergrid to function</p>\n",
            "<p>Some older Usergrid systems may have multiple accounts with the same username or email address, something which is not allowed and problematic now. </p><p>When such users are imported into a new system by the ImportAdmins program we can \"repair\" such users by merging the duplicates and ensure that the resulting single user account has the union of organization in the one or more duplicate users.</p>\n",
            "nan\n",
            "\"<p>We need to test the following issues to verify they've been fixed.</p><p>Multi region writes and index syncing</p><p>Multi region mass collection deletes: Delete the entire collection, then ensure that seek times are fast with no query language.</p>\"\n",
            "nan\n",
            "<p>move all serialization down to low levels</p>\n",
            "nan\n",
            "nan\n",
            "\"<p>It is currently possible to migrate from a 1.0 installation to a 2.1 installation via a RESTful client.  However, due to the inability to securely move password hashes, application user's passwords are not retained.   Add the following.</p><ol>\\t<li>In the 1.x branch, add the ability to retrieve the password hash.   This should only be allowed by the superuser.</li></ol><ol>\\t<li>In 2.1-release, add the ability to write the password hash to an application user.  This should only be allowed by the superuser.</li></ol><p>Note that the reason this is only allowed as a superuser is that we want to disable this functionality by default.  Any UG installation that is public facing should not have superuser enable.  This allows us to disable this functionality in environments that are publicly available environments.</p>\"\n",
            "nan\n",
            "<p>Need to investigate and decide on an approach.  In addition, do we support arrays with elements of varying types?</p><p>\\tat org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)</p>\n",
            "nan\n",
            "<p>We have a superuser endpoint that only works with a system access token. The problem is it can only be accessed with a system access token! Thus when we start up a tomcat we want a flag that can set the superuser access. Also fix the tools so that we can use the superuser admin tool from the command line.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Validate that <a href=\"https://github.com/apache/incubator-usergrid/blob/two-dot-o-dev/stack/scripts/migrate_entity_data.py\" class=\"external-link\" rel=\"nofollow\">https://github.com/apache/incubator-usergrid/blob/two-dot-o-dev/stack/scripts/migrate_entity_data.py</a> produces consistent entity data migrations. </p><p>1) put data into UG build from latest in two-dot-o<br/>2) stand up UG build from two-dot-o-dev pointing to same keyspace (different queue names) and run /system/database/setup<br/>3) from UG running two-dot-o-dev, run migrate_entity_data.py<br/>4) read data from UG two-dot-<br/>4) once finished,  read entities from UG two-dot-o and UG two-dot-o-dev and ensure there is an exact match</p>\n",
            "<p>In addition to separate Jacoco reports for each module, we should also be able to generate a master Jacoco report.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Currently superuser access does not allow access to all resources, as a superuser this should be allowed.</p><p>If SuperUser is evaluated as a Role, this may be a more optimal solution from a management perspective.</p>\n",
            "nan\n",
            "<p>Six of the AdminUsersIT tests are ignored because they interfere with other tests and other reasons.  Figure out how to run those tests serially or some other way to test admin user features.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Ensure code makes it in to prevent wide rows in unique_values CF due to old versions not getting cleaned up</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>In order to support NIO.  Current version is ancient.</p>\n",
            "<p>So I\\'m getting responses like the following:</p><p>com.sun.jersey.api.client.UniformInterfaceException: POST <a href=\"http://localhost:10003/management/token\" class=\"external-link\" rel=\"nofollow\">http://localhost:10003/management/token</a> returned a response status of 403 Forbidden<br/>\\tat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)<br/>\\tat com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)<br/>\\tat com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)<br/>\\tat org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)<br/>\\tat org.apache.usergrid.rest.test.resource2point0.AbstractRestIT.getAdminToken(AbstractRestIT.java:167)<br/>\\tat org.apache.usergrid.rest.management.OrganizationsIT.testCreateOrgUserAndReturnCorrectUsername(OrganizationsIT.java:332)</p><p>testCreateDuplicateOrgEmail(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.988 sec  &lt;&lt;&lt; ERROR!<br/>com.sun.jersey.api.client.UniformInterfaceException: POST <a href=\"http://localhost:10003/management/token\" class=\"external-link\" rel=\"nofollow\">http://localhost:10003/management/token</a> returned a response status of 403 Forbidden<br/>\\tat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)<br/>\\tat com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)<br/>\\tat com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)<br/>\\tat org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)<br/>\\tat org.apache.usergrid.rest.management.OrganizationsIT.testCreateDuplicateOrgEmail(OrganizationsIT.java:172)</p><p>testOrgPOSTForm(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.819 sec  &lt;&lt;&lt; ERROR!<br/>com.sun.jersey.api.client.UniformInterfaceException: POST <a href=\"http://localhost:10003/management/token\" class=\"external-link\" rel=\"nofollow\">http://localhost:10003/management/token</a> returned a response status of 403 Forbidden<br/>\\tat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)<br/>\\tat com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)<br/>\\tat com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)<br/>\\tat org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)<br/>\\tat org.apache.usergrid.rest.management.OrganizationsIT.testOrgPOSTForm(OrganizationsIT.java:277)</p><p>createOrgAndOwner(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.774 sec  &lt;&lt;&lt; ERROR!<br/>com.sun.jersey.api.client.UniformInterfaceException: POST <a href=\"http://localhost:10003/management/token\" class=\"external-link\" rel=\"nofollow\">http://localhost:10003/management/token</a> returned a response status of 403 Forbidden<br/>\\tat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)<br/>\\tat com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)<br/>\\tat com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)<br/>\\tat org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)<br/>\\tat org.apache.usergrid.rest.management.OrganizationsIT.createOrgAndOwner(OrganizationsIT.java:80)</p><p>testCreateDuplicateOrgName(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.975 sec  &lt;&lt;&lt; ERROR!<br/>com.sun.jersey.api.client.UniformInterfaceException: POST <a href=\"http://localhost:10003/management/token\" class=\"external-link\" rel=\"nofollow\">http://localhost:10003/management/token</a> returned a response status of 403 Forbidden<br/>\\tat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)<br/>\\tat com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)<br/>\\tat com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)<br/>\\tat org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)<br/>\\tat org.apache.usergrid.rest.management.OrganizationsIT.testCreateDuplicateOrgName(OrganizationsIT.java:118)</p><p>So Calls to management/token are failing with 403 errors. I suspect it might be due to the new testing framework but further investigation is needed</p>\n",
            "<p>1) Test locally<br/>2) Confirm in e2e</p>\n",
            "nan\n",
            "<p>A bug in 2.0 has led to multiple edges on a connection.  We need a job that scans all connections, and keeps the lowest timestamp on the connection.  Other edges should be deleted.</p>\n",
            "<p>1. update status page to include all users<br/>2. create DRAFT Top Level Project resolution<br/>3. start discussion on dev list</p>\n",
            "<p>TBD</p>\n",
            "nan\n",
            "<p>Provide new tool that exports an app:<br/>1. Writes two types of files: entities and connections<br/>2. Each line of output files will be one complete JSON object<br/>3. Use RxJava for multithreading of reads and of writes</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Currently the email address appears to be the same for approving new orgs and new admins.  We need a separate configurable email address for each.</p><p>If this setting is blank, the admin email can be used instead.</p><p>This needs to be fixed in 2.0 as well as 2.1.  2.0 first please <img class=\"emoticon\" src=\"https://issues.apache.org/jira/images/icons/emoticons/smile.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></p>\n",
            "nan\n",
            "<p>An entity can only exist in a single scope. However, this makes it impossible to batch fetch entities from multiple scopes in a single network request.  This interface needs changed.  Our EntityCollectionManagerFactory needs to change to return an EntityCollectionManager by ApplicationScope.  Further read/write requests would then need to take an encapsulating CollectionScope.  This would allow us to batch write and batch fetch multiple entities across different collections in a single request.</p>\n",
            "\"<p>There's one new test from master that needs to be rewritten using the new framework: ApplicationResourceIT.applicationCollectionWithAppToken()</p>\"\n",
            "<p>Currently our test harnesses are a mess of spaghetti.  We need to decouple this mess, and allow us to cleanly define the rules and requirements of our system.  I think we need to break it down into the following behaviors.</p><h1><a name=\"TestExecutionEnvironments\"></a>Test Execution Environments</h1><h2><a name=\"ParallelExecution\"></a>Parallel Execution</h2><p>This should be the default behavior.  All tests are assumed to be parallel</p><h2><a name=\"SerialExecution\"></a>Serial Execution</h2><p>This should be the exception, and only used when parallel execution cannot be accomplished.  Tests in this classification should run in a method at a time, with no concurrency</p><h1><a name=\"Externalresources\"></a>External resources</h1><h2><a name=\"Cassandra\"></a>Cassandra</h2><ol>\\t<li>Configure the runtime</li>\\t<li>Pre invocation hook\\t<ol>\\t\\t<li>Create default implementation of truncating column families.  This should be manually added, and not execute by default.</li>\\t</ol>\\t</li>\\t<li>Post invocation hook</li></ol><h2><a name=\"ElasticSearch\"></a>ElasticSearch </h2><ol>\\t<li>Configure the runtime</li>\\t<li>Pre invocation hook\\t<ol>\\t\\t<li>Create default implementation of truncating column families.  This should be manually added, and not execute by default.</li>\\t</ol>\\t</li>\\t<li>Post invocation hook</li></ol><h1><a name=\"Lifecycle\"></a>Lifecycle</h1><p>A test itself can have numerous lifecycle operations.  These should be set up as rules, both class and instance, and should NOT be done via inheritance of abstract tests.  This is the old Junit3 way of operating, and needs removed.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "\"<p>It's not possible to perform standard collection/connection walking from org/app/import endpoints.  Fix this using overridden services.</p>\"\n",
            "<p>move cleanup to before tests run in stack</p>\n",
            "<p>Make same as 2.1 branch</p>\n",
            "<p><a href=\"https://issues.apache.org/jira/browse/USERGRID-530\" class=\"external-link\" rel=\"nofollow\">https://issues.apache.org/jira/browse/USERGRID-530</a>.  Make sure it gets in 2.0</p>\n",
            "nan\n",
            "<p>This can become a coordination task with other teams as well as executing it ourselves - for example with Kris Bhandare</p>\n",
            "<p>Things that need to be addressed when they are found.</p><p>EntityManagerImpl.java line 1135</p><p>                if ( properties == null ) {<br/>                    logger.error( \"Error deserializing entity with key {} entity probaby doesn\\'t exist, where did this key come from?\", key );<br/>                    continue;<br/>                }</p><p>                UUID id = uuid( properties.get( PROPERTY_UUID ) );<br/>                String type = string( properties.get( PROPERTY_TYPE ) );</p><p>                if ( ( id == null ) || ( type == null ) ) {<br/>                    logger.error( \"Error retrieving entity with key {}, no type or id deseriazable, where did this key come from?\", key );<br/>                    continue;<br/>                }</p><p>Then in EntityManagerImpl getUUIDsForUniqueProperty</p><p>        //shouldn\\'t happen, but it\\'s an error case<br/>        if ( cols.size() &gt; 1 ) {<br/>            logger.error( \"INDEX CORRUPTION: More than 1 unique value exists for entities in ownerId {} of type {} on \"<br/>                    + \"property {} with value {}\",<br/>                    new Object[] </p>{ ownerEntityId, collectionNameInternal, propertyName, propertyValue }<p> );<br/>        }</p><p>^ Need to address both issues on read repair path such that we no longer need to worry about users seeing them. </p><p>For the second issue we should be able to just call delete UniqueProperty with the entity unique value in question. Just make this happen in the backend. </p>\n",
            "<p>2015-04-01 18:57:54,440 ERROR (http-bio-8080-exec-224) AbstractExceptionMapper - Server Error (500):</p>{\"error\":\"hystrix_runtime\",\"timestamp\":1427929074440,\"duration\":0,\"error_description\":\"ConsistentReplayCommand failed and failed retrieving fallback.\",\"exception\":\"com.netflix.hystrix.exception.HystrixRuntimeException\"}<p>2015-04-01 18:57:54,440 ERROR (hystrix-user-94) WriteUniqueVerify - Could not get uniqueValue from the field name.<br/>2015-04-01 18:57:54,440 ERROR (http-bio-8080-exec-325) ThrowableMapper - An uncaught exception occurred during HTTP invocation<br/>com.netflix.hystrix.exception.HystrixRuntimeException: ConsistentReplayCommand failed and failed retrieving fallback.<br/>        at com.netflix.hystrix.HystrixCommand.getFallbackOrThrowException(HystrixCommand.java:1660)<br/>        at com.netflix.hystrix.HystrixCommand.executeCommand(HystrixCommand.java:1341)<br/>        at com.netflix.hystrix.HystrixCommand.access$2300(HystrixCommand.java:103)<br/>        at com.netflix.hystrix.HystrixCommand$5.call(HystrixCommand.java:1186)<br/>        at com.netflix.hystrix.strategy.concurrency.HystrixContextCallable.call(HystrixContextCallable.java:51)<br/>        at java.util.concurrent.FutureTask.run(FutureTask.java:262)<br/>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)<br/>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)<br/>        at java.lang.Thread.run(Thread.java:745)<br/>Caused by: java.lang.RuntimeException: Could not retrieve unique value for field name, unable to verify<br/>        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify$ConsistentReplayCommand.executeStrategy(WriteUniqueVerify.java:207)<br/>        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify$ConsistentReplayCommand.run(WriteUniqueVerify.java:178)<br/>        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify$ConsistentReplayCommand.run(WriteUniqueVerify.java:159)<br/>        at com.netflix.hystrix.HystrixCommand.executeCommand(HystrixCommand.java:1281)<br/>        ... 7 more<br/>Caused by: java.lang.Throwable: Calling Thread included as the last \\'caused by\\' on the chain.<br/>        at sun.misc.Unsafe.park(Native Method)<br/>        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)<br/>        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1033)<br/>        at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326)<br/>        at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:282)<br/>        at rx.internal.operators.BlockingOperatorToFuture$2.get(BlockingOperatorToFuture.java:111)<br/>        at com.netflix.hystrix.HystrixCommand$1.performBlockingGetWithTimeout(HystrixCommand.java:623)<br/>        at com.netflix.hystrix.HystrixCommand$1.get(HystrixCommand.java:522)<br/>        at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:431)<br/>        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:151)<br/>        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:68)<br/>        at rx.Observable$12.onNext(Observable.java:4036)<br/>        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:61)<br/>        at rx.Observable$3.call(Observable.java:1551)<br/>        at rx.Observable$3.call(Observable.java:1546)<br/>        at rx.Observable.unsafeSubscribe(Observable.java:6839)<br/>        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:60)<br/>        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:43)<br/>        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)<br/>        at java.util.concurrent.FutureTask.run(FutureTask.java:262)<br/>        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)<br/>        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)<br/>        ... 3 more<br/>Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: CollectionIoEvent.class<br/>        at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)<br/>        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:63)<br/>        ... 12 more</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Will need superuser credentials.</li>\\t<li>Will delete admin user.</li>\\t<li>Will remove all connections from said admin user. ( might automatically be done. needs verifying. )<br/>-Verify can be recreated</li></ul>\n",
            "<p>Find a way to resolve the state where a user may still have an entity ref but is not able to be queried or retrieved without uuid.</p>\n",
            "<p>We need a system job that audits edges and ensures they point to an entity.  If not, the edge should be removed.</p>\n",
            "nan\n",
            "nan\n",
            "<p>1) Ensure that the indexes (including buckets) can get created in region n+1<br/>2) Ensure that read/write aliases get created in region n+1<br/>3) Ensure that queries in both regions return the same data<br/>4) Attempt to quantify the latency of a PUT in region A making it to Region B and being indexed in region B</p><p>Coming out of this we need a guide for setting up region N+1</p>\n",
            "<p>Validate JMS Meters / Timers are the ones we want to be in place for measuring/monitoring performance</p>\n",
            "nan\n",
            "<p>Lets say you have two values </p>{\"name\":\"cow\"}<p> and </p>{\"name\":\"Cow\"}<p>When you do a query on name = \"cow\".</p><p>We get both \"cow\" and \"Cow\" back in the results. Equals should be a case sensitive search. ergo we should only be returning \"cow\"</p>\n",
            "<p>Currently we merge all shards together with every page seek in usergrid 1.0. This means we select 20k columns, and discard 19k with each page selection.  Instead, I propose that we create an AST per shard, and execute the iterator on these shards concurrently.  We then merge on the last step, greatly reducing the amount of network I/O and discarded data on queries of large data sets.</p><p>Proposed Changes:<br/>1 AST instance per shard, evaluated concurrently via some worker pool.</p><p>Change final gather of concurrent iterators.</p><p>Change cursor generation to create the cursor from the merged trees.</p>\n",
            "<p>We need a script which executes API calls to test an installation given a set of test cases to confirm that it \\'works\\' with a bare minimum of functionality.</p><ul class=\"alternate\" type=\"square\">\\t<li>CRUD on entity</li>\\t<li>Query entities</li>\\t<li>CRUD on connections</li></ul><p>Add queries from here: <a href=\"http://apigee.com/docs/app-services/content/working-queries\" class=\"external-link\" rel=\"nofollow\">http://apigee.com/docs/app-services/content/working-queries</a> as test cases.</p>\n",
            "<p>We need the ability to resume re-indexing.  To do this, we should make the AllEntitiesObservable allow for resume by default.  This way if the node performing the migration fails, it can be restarted on another node.</p><p>Note that we also need a way to clear state via REST, so that we can restart our indexing.</p>\n",
            "<p>for example</p><p>get /sandbox/users/non-exist-username throws 401 error code</p><p>this is because below code</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">@Provider<span class=\"code-keyword\">public</span> <span class=\"code-keyword\">class </span>ServiceResourceNotFoundExceptionMapper <span class=\"code-keyword\">extends</span> AbstractExceptionMapper&lt;ServiceResourceNotFoundException&gt; {    @Override    <span class=\"code-keyword\">public</span> Response toResponse( ServiceResourceNotFoundException e ) {        <span class=\"code-keyword\">if</span> ( SubjectUtils.getSubjectUserId() == <span class=\"code-keyword\">null</span> ) {            <span class=\"code-keyword\">return</span> toResponse( UNAUTHORIZED, e );        }        <span class=\"code-keyword\">else</span> {            <span class=\"code-keyword\">return</span> toResponse( NOT_FOUND, e );        }    }}</pre></div></div>\n",
            "nan\n",
            "<p>When creating an asset the following call works in 1.0 usergrid.</p><p>curl -X POST -F name=\\'example\\' -F file=@example.jpg \\'https://localhost:8080/temp/test?access_token=&lt;token&gt;\\'</p><p>properly uploading the asset. In 2.1 however the following gets returned. </p>{\"error\":\"uncaught\",\"timestamp\":1437415007666,\"duration\":0,\"error_description\":\"Internal Server Error\",\"exception\":\"org.apache.usergrid.rest.exceptions.UncaughtException\",\"error_id\":\"b0c5930c-2f08-11e5-818e-060beb1b9051\"}<p>%</p>\n",
            "nan\n",
            "<p>SQS Queue Manager should be updated to use Observable and emit a stream of messages.</p>\n",
            "<p>Would be nice to add metrics and counters at the lower level for bytes in/out Cassandra and latency</p>\n",
            "<p>This tool is designed to export from 1.0 with the intent of using the resulting entities and collections in 2.x and higher.  However, this data will be imported using the API so it is not import-to-2.x specific.</p>\n",
            "<p>We need a script which does testing of a Usergrid instance to confirm a set of functionality works.</p>\n",
            "\"<p>We are seeing a large number of fetches/queries when we are doing PUT by name.  This creates load on ES and therefore makes indexing take longer.  We should make sure we're not hitting ES for PUT by name.</p>\"\n",
            "nan\n",
            "\"<p>Doesn't work in 2.0 but can't reproduce in 2.1. Try to reproduce. </p>\"\n",
            "nan\n",
            "<p>When indexes are created on setup, as well as aliases assigned on application creation, this is only performed in the local region.  We need to create indexes in all regions during an index administration operation, as well as create aliases. </p><p>We will also probably want to make our aliases and underlying indexes identical, in order to allow for ease of administration regardless of region.</p><p>We need to account for two cases:<br/>1) Secondary region does not already have ES indexes configured - need to create the indexes and aliases<br/>2) Secondary region already has ES installed and configured (indexes existing) - only need to create aliases</p>\n",
            "<p>Test load with the frankenloader in e2e for the upcoming release</p>\n",
            "nan\n",
            "<p>Publish to SNS<br/>Consume from SQS</p><p>Complete the SQS indexing impl with the new message endpoint</p><p>add new interface for sqs vs in memory service </p>\n",
            "nan\n",
            "<p>The first pass of the re-index with is complete.  Testing in a system to ensure that re-index works as expected still needs to be completed.</p>\n",
            "<p>Currently, we move our index aliases in multiple steps.  This can lead to inconsistent alias state if fail during one of these operations.  Our alias operation should perform a single swap command.  We should perform the following during index allocation.</p><ol>\\t<li>Create the target index successfully</li>\\t<li>Issue a single http call that will move the write alias, and add the read alias to the new index, per this HTTP command equivalent.</li></ol><p><a href=\"http://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html#indices-aliases\" class=\"external-link\" rel=\"nofollow\">http://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html#indices-aliases</a></p>\n",
            "nan\n",
            "<p>PerformanceEntityRebuildIndexTest.rebuildOneCollectionIndex:228 null</p>\n",
            "<p>querying es for all edges<br/>deleting in bulk<br/>async using async index service</p>\n",
            "<p>We should consider implementing a proxy which provides the index being used for an application.  This proxy should provide both the Index strategy and the entity type mapping strategy.</p><p>The goal is to provide a point where we can implement a strategy function that could do one (or more) of the following strategies for indexes:</p><ul class=\"alternate\" type=\"square\">\\t<li>Single index per cluster (static index allocation)</li>\\t<li>Index per org/app (dynamic index allocation)</li>\\t<li>Index per org (dynamic index allocation)</li>\\t<li>Index per cluster (dynamic index allocation)</li>\\t<li>Index per customer (dynamic index allocation)</li>\\t<li>Hash/bucketing across a fixed range of indexes (static index allocation)</li>\\t<li>Per environment (TBD)</li>\\t<li>Static (for the management app, should always match the Cassandra keyspace name as the index)</li></ul><p>In order to do this we need to update EntityIndexFactory.createApplicationEntityIndex.</p><p>For Entity Type Mapping, the goal is to enable bucketing of entity types (collections) in a manner that can be more optimal for the indexing strategy that is chosen.  For example, a single index strategy might have a single entity type but for the index per org/app it might have a separate entity type.  Looking up the management index would have a strategy where the index name matches the cassandra keyspace name</p>\n",
            "<p>When allocating an index alias to one of the physical indexes a bucketing strategy should be used with ranges based off the number of indexes in elasticsearch.</p><p>For example, if there are 10 physical indexes then there would be 10 buckets based on a hash of the Application ID which would result in the assignment of an app alias to a physical index based on the range in which it falls.</p>\n",
            "<p>Create configurable re-index buffer property and implement in ReIndexService.</p>\n",
            "<p>There is currently no way to remove older indexes and retain only a single index after allocating a new index. We can build this functionality out of our index rebuild, but by adding an upper bound to stop indexing.  This should perform the following high level operations.</p><ol>\\t<li>Find the lowest entity version in the current write alias</li>\\t<li>Perform an index rebuild on all collections, stopping at the lowest version from the previous step</li>\\t<li>After a rebuild has been complete, remove all indexes that are not on the current write alias</li></ol>\n",
            "<p>Convert</p>\n",
            "nan\n",
            "<p>Ensure we create &gt;11 apps and that it works.</p>\n",
            "<p>We need to create a simple stress testing framework for our query module to perform profiling of our indexing scheme.  We can do so easily with the following.</p><p>Re-use our existing gattling cloud formation and usergrid cloud formation<br/>Create integration tests that can have an overridden URL to elasticsearch<br/>Run these via maven and parallel ssh to get performance results.<br/>Use metrics to report throughput, possibly to graphite so we can compare results.</p>\n",
            "nan\n",
            "\"<p>We're significantly behind our in our RX java implementation.  Before work on the EM/RM refactor work starts, we should upgrade to Java 8 to clean up our functional syntax, as well as upgrade to the latest RxJava for performance improvements.</p><p>We should evaluate missing functions we use in RX as Java 8 streams.  If we can re-create our operations as Java 8 streams, we should evaluate the performance of RX Java vs Java 8 streams, and pick the most performant solution.</p>\"\n",
            "nan\n",
            "<p>\"dynamic\": \"strict\"</p><p>We should ensure this is not used per <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-dynamic-mapping.html\" class=\"external-link\" rel=\"nofollow\">https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-dynamic-mapping.html</a></p>\n",
            "<p>Currently we only do search results and parse those results under the assumption that we will only do one search. As we query elasticsearch we want to be able to use the scrolling api to batch pull all the results we can find from elasticsearch. </p>\n",
            "nan\n",
            "<p> EntityConnectionsIT.testEntityConnectionsMembership:271 null<br/>  EntityConnectionsIT.testEntityConnectionsSimple:79 null</p><p>are failing</p>\n",
            "<p>Currently our event system originates from too may points.  Both GraphManager and CollectionManager fire events for compaction.  This is causing issues with our event orchestration when we aggregate events in the core tier. A quick refactor needs to occur.  The following will need to happen.</p><p>1) Define new compaction interfaces on the EntityCollectionManager and GraphManager</p><p>2) Refactor the existing code to be invoked on these events</p><p>3) Invoke the compaction at a higher level.  Mark will sill occur, compaction will be deferred to the runtime. This allows a separate distributed subsystem to be created. </p>\n",
            "<p>can o worms</p><p>refactor cp relation manager into async service</p><p>async == async event service starts process</p><p>look at indexingservice</p>\n",
            "nan\n",
            "<p>This should fix the broken test in the EntityManagerIt labeled: ownershipScopeCorrect</p>\n",
            "nan\n",
            "<p>add interface to index appid and entity</p><p>1. read entity state out of cass.<br/>2. read all edges <br/>3. if bidirectional -&gt; index from source to target<br/>4. submit batch<br/>5. wait for batch -&gt; return future</p>\n",
            "<p>when mark node in graph is called the compact needs to be called before you add the same relationship back to the graph.  this should not be the case</p>\n",
            "<p>JMX Metrics have varying names and formats.  It would be helpful to standardize them.  Lets take a pass and rename them to have an \"x.y\" pattern.  <br/>Where x=object/concept and y=attribute/action.  If there is no explicit y, y should be \\'base\\'.</p><p>Here is an example:<br/>this.deleteApplicationMeter = metricsFactory.getMeter(EsApplicationEntityIndexImpl.class, \"application.delete\");</p><p><a href=\"https://github.com/apache/incubator-usergrid/pull/269\" class=\"external-link\" rel=\"nofollow\">https://github.com/apache/incubator-usergrid/pull/269</a></p>\n",
            "<p>Deploy 2.1 Branch into an End-to-End (e2e) testing environment, including:</p><p>1) Cassandra<br/>2) ElasticSearch<br/>3) Tomcat<br/>4) Portal</p>\n",
            "<p>Settings which are used in a production environment should be the default in the Figs.  This will simplify the configuration management required when running Usergrid at scale.</p>\n",
            "<p>Currently we use SMILE binary serialization to serialize our column values.  During production debugging, this makes it extremely difficult to debug.  I propose we remove the SMILE binary serialization, and instead use json serialization with the following formation</p><div class=\"code panel\" style=\"border-width: 1px;\"><div class=\"codeContent panelContent\"><pre class=\"code-java\">{  <span class=\"code-quote\">\"version\"</span>: [serialization implementation version number as an <span class=\"code-object\">int</span>],  <span class=\"code-quote\">\"entity\"</span>: {... entity as a nested json object }}</pre></div></div><p>If the entity is present, then the entity has not been deleted.  If the entity field is not present, then the entity should be read as a marked for deletion.</p>\n",
            "nan\n",
            "<p>Keyspaces should be customizable for the usergrid system.  We need to implement the ability to set the keyspace based on system properties, as well as the current defaults.  We should implement this in the following way.</p><ol>\\t<li>Add these properties to the Cassandra Fig (or create a new fig configuration)</li>\\t<li>Add the fig to the injector</li>\\t<li>Reference the injector and the fig in the current EntityManager and CassandraService setup classes</li></ol>\n",
            "<p>This has already been done in the two-dot-o branch.</p><p>Fixing it in 1.0 will be a little different. </p><p>These keyspace names are hard-coded into Java code:</p><ul class=\"alternate\" type=\"square\">\\t<li>Usergrid</li>\\t<li>Usergrid_Applications</li></ul><p>and the Locks keyspace name is hardcoded into a Spring config.</p>\n",
            "<p>The requirement is to have multiple Usergrid systems, each with its own Cassandra cluster, be able to authenticate Admin Users with one central Usergrid system &#8211; giving Admin Users Single-Sign-On (SSO) across all of those systems.</p><p>We can do this by adding just one new end-point to Usergrid.</p><p>This Google Doc explains a complete design for \"Usergrid Central SSO\":</p><p><a href=\"https://docs.google.com/document/d/12kXgaYcB6L9JoTyRGn0ZHEMg3vL1LJDqvtnltIBDa1Y/edit?usp=sharing\" class=\"external-link\" rel=\"nofollow\">https://docs.google.com/document/d/12kXgaYcB6L9JoTyRGn0ZHEMg3vL1LJDqvtnltIBDa1Y/edit?usp=sharing</a></p><p>The design is based on earlier work by Ed Anuff and Nate McCall.</p>\n",
            "<p>When external token validation is enabled (see Usergrid-567) and a Usergrid system is delegating authentication to some other central Usergrid for SSO purposes, then new Admin Users should register ONLY with that central Usergrid.</p>\n",
            "<p>Use the MetricsFactory to add metrics for successful token validations,  unsuccessful token validations and local admin user creation.</p><p>For more about external token validation see Usergrid-567</p>\n",
            "nan\n",
            "<p> AdminEmailEncodingIT.getTokenDash:73-&gt;doTest:116 \\xc2\\xbb UniformInterface POST http:...<br/>  AdminEmailEncodingIT.getTokenPlus:53-&gt;doTest:116 \\xc2\\xbb UniformInterface POST http:...<br/>  AdminEmailEncodingIT.getTokenUnderscore:63-&gt;doTest:116 \\xc2\\xbb UniformInterface POST...</p>\n",
            "<p>When running the following code in indexEntity         final Observable&lt;IndexOperationMessage&gt;  batches =  observable.buffer( indexFig.getIndexBatchSize() )</p><p>            //map into batches based on our buffer size<br/>            .flatMap( buffer -&gt; Observable.from( buffer )<br/>                //collect results into a single batch<br/>                .collect( () -&gt; ei.createBatch(), ( batch, indexEdge ) -&gt; {<br/>                    logger.debug( \"adding edge {} to batch for entity {}\", indexEdge, entity );<br/>                    batch.index( indexEdge, entity );<br/>                } )<br/>                    //return the future from the batch execution<br/>                .flatMap( batch -&gt; batch.execute() ) );</p><p>When run with more than one SearchEdge only one SearchEdge is indexed into elasticsearch. Despite both search edges having the same document id. The batch executes but only one connection gets indexed in elasticsearch. </p>\n",
            "<p>This call returns an empty iterator</p><p>storageEdgeSerialization.getEdgeVersions( scope,<br/>                        new SimpleSearchByEdge( edge.getSourceNode(), edge.getType(), edge.getTargetNode(),<br/>                            Long.MAX_VALUE, SearchByEdgeType.Order.ASCENDING, Optional.absent() ) );</p><p> when we go to delete the edge. So since its empty it returns null and fails the test. </p><p>        final Edge toBeDeletedEdge = graphManager.deleteEdge( connectionSearch ).toBlocking().firstOrDefault( null );</p><p>Need to resolve this so we can fix graph tests. </p>\n",
            "nan\n",
            "nan\n",
            "<p>If Central Usergrid then the Portal should redirect the user to the central Usergrid instance for login/registration.</p><p>And, when the Portal gets an Admin User token from the Central Usergrid SSO system, the Portal must validate it against the Usergrid system with which it is configured to work.</p><p>This is a spike to design a possible solution for SSO support in portal.</p>\n",
            "nan\n",
            "\"<p>Task for writing up how the current REST test framework behaves and what expectations are for new tests.</p><p>We should have 90 minutes web conf where we record how we go about doing the tests, to review a 'good' test, a 'bad' test and a test that is not on the current framework.</p>\"\n",
            "nan\n",
            "<p>Design forthcoming.</p>\n",
            "<p>Make sure that the export process outputs the password hashes. This will allow people who want to import user accounts able to by using the api. </p>\n",
            "<p>Take a look at REST and CORE tests to see what needs to be cleaned up to stabilize for upcoming release.</p>\n",
            "nan\n",
            "<p>Currently, performing a continuous PUT in 2.0 under heavy load causes a hotspot in our cassandra data.  </p><p>Cause:</p><ol>\\t<li>Under load, entities can be PUT continuously</li>\\t<li>Asynchronous cleanups run and delete previous versions</li>\\t<li>These versions are retained in cassandra for long periods of time.  This causes severe row bloating before compaction occurs.</li></ol><p>Solution:</p><p>For entity data, we only care about the current max version.  We should change this column family to store only the maximum data format.  We will need to keep the log of previous versions, so that we can bring ES into a consistent state</p>\n",
            "nan\n",
            "<p>Implement Superuser methods in Management Class for REST tests</p><p>Implement superuser token methods also</p>\n",
            "<p>Current instance of tools don\\'t work correctly with 2.0. </p><p>This should have a RESTful endpoint that is trigged with a PUT.  We should have something like this endpoint.</p><p>Check all unique values across the entire system =&gt; PUT /system/database/unqiuecheck<br/>Check all unique values across a single applications =&gt; PUT /system/database/uniquecheck/<span class=\"error\">&#91;appid&#93;</span><br/>Check all unique values in a single collection =&gt; PUT /system/database/uniquecheck/<span class=\"error\">&#91;appid&#93;</span>/<span class=\"error\">&#91;collectionname&#93;</span></p><p>Check a specific unique value for a collection.</p><p>PUT=&gt; <br/>system/database/uniquecheck/<span class=\"error\">&#91;appid&#93;</span>/<span class=\"error\">&#91;collectionname&#93;</span>/<span class=\"error\">&#91;unique value&#93;</span></p><p>The unique check will need to audit the unique index, and ensure that the unique value exists for the entity specified. If the entity does not exist, they should be removed.</p><p>I think we should implement specific property cleanup first, then implement the other operations as an input of Observables</p>\n",
            "nan\n",
            "<p>Create Service integration tests</p><ul class=\"alternate\" type=\"square\">\\t<li>error checking</li>\\t<li>send bad data</li>\\t<li>check http status codes</li>\\t<li>check exception codes</li></ul>\n",
            "nan\n",
            "<p>Refactor the data migrations to move from Core to Core Persistence for Entity Storage </p>\n",
            "<p>Implement Admin User methods in Management Class for REST tests. <br/>Ensure that AdminUsersIT test works.</p>\n",
            "nan\n",
            "\"<p>Fix the endpoint to return ok even if the test-app already exists. This isn't really an error and should be swallowed so we don't confuse users. </p>\"\n",
            "nan\n",
            "nan\n",
            "<p>2015-02-16 05:33:23,590 <span class=\"error\">&#91;http-bio-8080-exec-313&#93;</span> ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- java.lang.RuntimeException Server Error (500)<br/>java.lang.RuntimeException: Could not retrieve unique value for field name, unable to verify<br/>        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:167)<br/>        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:58)<br/>        at rx.Observable$12.onNext(Observable.java:4036)<br/>        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:61)<br/>        at rx.Observable$3.call(Observable.java:1551)<br/>        at rx.Observable$3.call(Observable.java:1546)<br/>        at rx.Observable.unsafeSubscribe(Observable.java:6839)<br/>        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:60)<br/>        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:43)<br/>        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)<br/>        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)<br/>        at java.util.concurrent.FutureTask.run(FutureTask.java:166)<br/>        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)<br/>        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)<br/>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)<br/>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)<br/>        at java.lang.Thread.run(Thread.java:722)<br/>Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: CollectionIoEvent.class<br/>        at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)<br/>        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:63)<br/>        ... 13 more<br/>2015-02-16 05:33:23,590 <span class=\"error\">&#91;http-bio-8080-exec-313&#93;</span> ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- Server Error (500):</p>{\"error\":\"runtime\",\"timestamp\":1424064803590,\"duration\":0,\"error_description\":\"Could not retrieve unique value for field name, unable to verify\",\"exception\":\"java.lang.RuntimeException\"}<p>2015-02-16 05:33:23,600 <span class=\"error\">&#91;http-bio-8080-exec-488&#93;</span> ERROR org.apache.usergrid.rest.exceptions.ThrowableMapper- An uncaught exception occurred during HTTP invocation<br/>java.lang.RuntimeException: Could not retrieve unique value for field name, unable to verify<br/>        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:167)<br/>        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:58)<br/>        at rx.Observable$12.onNext(Observable.java:4036)<br/>        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:61)<br/>        at rx.Observable$3.call(Observable.java:1551)<br/>        at rx.Observable$3.call(Observable.java:1546)<br/>        at rx.Observable.unsafeSubscribe(Observable.java:6839)<br/>        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:60)<br/>        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:43)<br/>        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)<br/>        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)<br/>        at java.util.concurrent.FutureTask.run(FutureTask.java:166)<br/>        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)<br/>        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)<br/>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)<br/>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)<br/>        at java.lang.Thread.run(Thread.java:722)<br/>Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: CollectionIoEvent.class<br/>        at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)</p>\n",
            "nan\n",
            "<p>We should update our cloudformation scripts to use a dedicated master node for ES to more closely mirror suggestion production usage during stress testing.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Refactor of UG-454 where we move the timers into the constructor instead of being initialized in methods. </p>\n",
            "<p>We want to add a way for UG to get metrics about calls being made to Cassandra and ES so we can measure where we have performance bottlenecks.</p><p>In order to accomplish this we need to wrap our Cassandra execution calls with graphite timers. <br/>We could also set timers to check when Cassandra calls are being started or loaded up.</p><p>For ES we already have timers around index updates and index deletes. We just want to check the other ES calls ( index creations, delete by queries and the rest )</p>\n",
            "\"<p>The following call doesn't work </p><p>management().orgs().organization( clientSetup.getOrganizationName() )<br/>                        .app().addToPath( clientSetup.getAppName())</p><p>but this call does</p><p>management().orgs().organization( clientSetup.getOrganizationName() )<br/>                        .app().addToPath( clientSetup.getAppUuid())</p><p>The reason being it seems like the application name under the management side also includes the org name as part of its identify but when forming rest calls it doesn't work. Thats why when the name doesn't work the uuid still does . Ideally it should just have the application name as part of its identity. </p>\"\n",
            "<p>Currently there are no rest tests that check that the system/database/setup completed correctly. We use test utils that automatically call the service endpoints. We should implement a way to disable/move it so that we can check that the system is being properly initialized using rest tier calls.</p>\n",
            "<p>Getting an email when trying to activate an organization:</p>{\"error\":\"unauthorized\",\"timestamp\":1405399644281,\"duration\":0,\"exception\":\"org.apache.usergrid.rest.exceptions.SecurityException\",\"error_description\":\"No organization access authorized\"}<p>Steps to reproduce - sign up for an account, then click activation link in email that goes to sys admin</p><p>When the link is clicked then the following message pops up. Ideally it should be a rest response that denotes show the activation was successful.</p>\n",
            "nan\n",
            "<p>During our initial setup, we perform the following phases.</p><ol>\\t<li>Setup keyspaces and column families</li>\\t<li>Set up the root application</li></ol><p>Admins then have to run the migration via PUT /system/migrate/run</p><p>This causes an unnecessary migration from V0 to current.  Instead, on our initial setup in CPSetup.java, we should perform the following.</p><ol>\\t<li>Create keyspaces and column families</li>\\t<li>Perform the data migration, which will simply set the current max version BEFORE data is written</li>\\t<li>Write the initial root application state</li></ol>\n",
            "\"<p>This should be documented, it's a nice new feature for Usergrid 1.0.2.</p>\"\n",
            "<p>Currently our Sphinx-generated docs adopt the look and feel of the ReadTheDocs website, which is not bad but it does not look like the rest of our website. </p><p>We should style the docs so that the use the same header and footer as our existing website and use the same colors, fonts, etc.</p>\n",
            "nan\n",
            "<p>They both use the AWS sdk but have the possibility to use different versions. This possibility should be eliminated in the future by consolidating which sdk is pulled.</p>\n",
            "nan\n",
            "<p>we have some entities that are having indexing issues, with 6,011 at this time in a dead letter queue.  we need to understand why these are having indexing issues.</p>\n",
            "<p>When we added routing to ES, we were experiencing ES hotspots.  This appears to have been caused by uneven shard allocation.  We should remove the routing on new indexes, and test this under load.</p>\n",
            "<p>Create scripts that will run for a period of time and generate data/load.  Start scripts and run for a week.</p>\n",
            "<p>Current email verification is hard to do and requires some messy code. See if there is a better way to integrate that into the rest layer tests.</p>\n",
            "<p>Migrate relevant ImportCollectionIT and ImportServiceIT tests to the rest tier such that we have better end to end coverage of the system. Having all of our integration tests in the service tier means that there is still room for error when we go back up into the REST tier.</p>\n",
            "\"<p>The no aws creds rule call doesn't work outside of core. It fails in service and rest when using the one based in core. </p>\"\n",
            "nan\n",
            "<p>ApplicationResourceIT.updateAccessTokenTtl() is broken because of the added funcitonality of app delete. The way it was implemented added a executePut method into the ApplicationResource which overrides the service resource executePut method thus breaking this test. What we want to decide moving forward is up to the person who works on this ticket. </p>\n",
            "<p>Currently using the SearchRequestBuilder add on some custom fields. This was fine when we just needed to do a \"one size fits all \" to our search method but now that there are more methods being introduced we need a better way to create queries that are efficient for the type of processing that is going to be done. </p>\n",
            "<p>Add message-id to the smtp logs.</p><p><a href=\"http://stackoverflow.com/questions/5555119/sending-email-using-smtp-and-setting-the-message-id\" class=\"external-link\" rel=\"nofollow\">http://stackoverflow.com/questions/5555119/sending-email-using-smtp-and-setting-the-message-id</a></p><p>This will help us track whether usergrid is failing to send registration email or if it is the mail service. There also needs to be additional logging enabled to track what stages the emails goes through if it is needed.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "\"<p>As we discussed we'd like to see about using Spark for things such as:<br/>1) migrating orgs from one keyspace to another<br/>2) deleting all records for an app from Cassandra</p>\"\n",
            "nan\n",
            "<p>When an uncaught exception happens in stack\\'s rest layer, we throw the java error in response to the user. Such responses could just say internal server error. And as <a href=\"https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tnine\" class=\"user-hover\" rel=\"tnine\">Todd Nine</a> suggested, we could add a time uuid to the error response, so we can correlate the error in logs and track the error down for the user. </p>\n",
            "<p>While updating the API in scarlet some of the tests related to PSF normalization broke. Since I am the one who wrote the tests it will be easiest for me to diagnose the cause of the differences and the code and or the tests to give the correct results.</p>\n",
            "<p>Currently, the SQuaSH password for <tt>dispatch_verify.py</tt> is supplied via environment variable or command line option.</p><p>On shared systems, neither mechanism is very secure.  This ticket will add an option to prompt for the password when the script is run interactively.</p>\n",
            "<p>The AT Dome vendor provided a new version based on comments provided as part of <a href=\"https://jira.lsstcorp.org/browse/DM-18454\" title=\"Test ATDome vendor interface \" class=\"issue-link\" data-issue-key=\"DM-18454\"><del>DM-18454</del></a>. This ticket is to test this new version both at the TCP/IP vendor interface level and the CSC level.</p>\n",
            "<p>Write a simple pure OpenSplice dds example that shows the problem of occasional duplicated samples when a writer with TRANSIENT durability writes to a reader using VOLATILE durability.</p><p>Make sure the reader waits at least 10 seconds for the data, since it likely is due to historical data and the wait_for_historical_data cal can easily take 10 seconds or more.</p><p>If possible also demonstrate the issue of dds complaining of an invalid read condition, since the case above seems to exacerbate that problem.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-19382\" title=\"Refactor and reorder ISR steps to support writing pre-interpolated pixels\" class=\"issue-link\" data-issue-key=\"DM-19382\"><del>DM-19382</del></a> changed the name of a keyword in <tt>ip_isr.interpolateFromMask</tt> from <tt>growFootprints</tt> to <tt>growSaturatedFootprints</tt>, but did not update <tt>obs_lsstSim.processEimage</tt> which calls it, breaking it.</p>\n",
            "nan\n",
            "<p>Prepare a template in a shared presentation for all participants to add one slide about either themselves or their team</p>\n",
            "\"<p>I'll have to make some updates do the docker and compose files to accomplish this task. I'll create this task to capture the work. </p>\"\n",
            "nan\n",
            "nan\n",
            "<p>As specified by LSE-209, there are two detailed states in offline that should be published. The ATCamera XML contains the appropriate information and can be used as an example. </p><p>The CAP ticket is here:<br/><a href=\"https://jira.lsstcorp.org/browse/CAP-224\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/CAP-224</a></p>\n",
            "<p>The top-level detailed enumeration is unnecessary as CSCs should not repeat summary states in detailed states and should be removed from the XML.</p><p>This captures the work from:<br/><a href=\"https://jira.lsstcorp.org/browse/CAP-225\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/CAP-225</a></p>\n",
            "<p>Remove old style defects from ap_verify datasets. These include ap_verify_hits2015, ap_verify_ci_hits2015, and ap_verify_testdata. I think that\\'s it?</p><p>This split off from <a href=\"https://jira.lsstcorp.org/browse/DM-19857\" title=\"Update ap_verify to use new DECam defect ingestion\" class=\"issue-link\" data-issue-key=\"DM-19857\"><del>DM-19857</del></a> and should be done afterwards. It\\'s not essential to have these files removed for us to support the new defects in ap_verify, and \"support the new obs_decam defects in ap_verify so we can merge <a href=\"https://jira.lsstcorp.org/browse/DM-19730\" title=\"Convert obs_decam defects to new form\" class=\"issue-link\" data-issue-key=\"DM-19730\"><del>DM-19730</del></a>\" is the real goal of <a href=\"https://jira.lsstcorp.org/browse/DM-19857\" title=\"Update ap_verify to use new DECam defect ingestion\" class=\"issue-link\" data-issue-key=\"DM-19857\"><del>DM-19857</del></a>.</p>\n",
            "<p>Update containers and write documentation on deploying docker containers.\\xc2\\xa0<a href=\"https://confluence.lsstcorp.org/pages/viewpage.action?pageId=110233227\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/pages/viewpage.action?pageId=110233227</a></p><p>\\xc2\\xa0</p><p>Specific CSCs included are Electrometer, LinearStage, Monochromator, ATSpectrograph (built by Tiago deployed by Eric, but remains untested).</p>\n",
            "<p>Transfer\\xc2\\xa0<a href=\"https://confluence.lsstcorp.org/display/SYSENG/SAL+constraints+and+recommendations\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/SYSENG/SAL+constraints+and+recommendations</a>\\xc2\\xa0from confluence markup to RST and push changes to ts_xml.lsst.io.</p>\n",
            "<p>Currently, there is no licensing or copyright information in either of the alert_stream or sample-avro-alert repositories.</p><p>Since this code (or, possibly, some ZTF-derived variation of the same) is now popping up in <a href=\"https://github.com/lsst-uk/lasair/blob/e6baca8a68a43de0f66a9a5848697dfb11545023/src/alert_stream_ztf/python/lsst/alert/stream/alertProducer.py\" class=\"external-link\" rel=\"nofollow\">various</a> <a href=\"https://github.com/astrolabsoftware/fink-broker/blob/1378d4066d4540e05632e1c9b5a872d3ba4b2013/fink_broker/alertProducer.py\" class=\"external-link\" rel=\"nofollow\">places</a> (apparently in some cases with copyright claims added and released under an Apache license!), we should make sure that it is properly attributed and licensed so that this is all above board.</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Update the milestones repository with data extracted from PMCS <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update LDM-503, LDM-564, images repository <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update milestone dates loaded into Jira <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update skeleton Apr 2019 monthly report <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Circulate upcoming milestone list to dm-cams <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Audit and update <a href=\"https://confluence.lsstcorp.org/display/DM/DM+PMCS+Update+Requests\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/DM+PMCS+Update+Requests</a> <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li></ul>\n",
            "\"<p>Since we didn't have a refcat with coordinate errors, I couldn't write a test of jointcal's use of them. And thus I got it wrong: disabling <tt>config.astrometryReferenceErr</tt> resulted in an exception because the error field is <tt>coord_raErr</tt> not <tt>coord_ra_err</tt>!</p><p>Unrelatedly, but I might as well fix it as part of this work: it looks like jointcal is trying to apply colorterms when loading the astrometry reference catalog. That is both not necessary, and unhelpful when the astrometry refcat doesn't have useful photometry (e.g. Gaia). Might as well fix that on this ticket, too.</p>\"\n",
            "<p>Now that <a href=\"https://jira.lsstcorp.org/browse/DM-19290\" title=\"Create an lsst.utils.deprecated that works with pybind11\" class=\"issue-link\" data-issue-key=\"DM-19290\"><del>DM-19290</del></a> is available, use it for the Calib deprecations.</p>\n",
            "<p>Per <a href=\"https://github.com/lsst-dm/alert_stream/issues/24\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/alert_stream/issues/24</a>, the latest release of fastavro is incompatible with the serialized alert data in lsst-dm/alert_stream.</p><p>Long term, we need to fix the data. Short term, pin the version of fastavro to one that works in the Dockerfile.</p>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/RFC-575\" title=\"Convert old refcats to nJy for RFC-549\" class=\"issue-link\" data-issue-key=\"RFC-575\"><del>RFC-575</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-17029\" title=\"Update LoadReferenceObjectsTask to output fluxes in nanojansky\" class=\"issue-link\" data-issue-key=\"DM-17029\"><del>DM-17029</del></a>, Update the 5 reference catalogs in <tt>/datasets/refcats/htm/</tt> to have nJy fluxes using meas_algorithms/bin/convert_refcat_to_nJy.py</p><p>More details at <a href=\"https://community.lsst.org/t/photocalib-has-replaced-calib-welcoming-our-nanojansky-overlords/3648\" class=\"external-link\" rel=\"nofollow\">https://community.lsst.org/t/photocalib-has-replaced-calib-welcoming-our-nanojansky-overlords/3648</a> </p><p>The code convert_refcat_to_nJy.py updates the catalogs from <tt>v0</tt> to <tt>v1</tt> refcats in place.  So before converting, make a copy of all directories remained in <tt>v0</tt>, and keep those copies around for people using the stack older than w_2019_14. </p><p>For consistency of the HSC-RC2 <a href=\"https://jira.lsstcorp.org/browse/DM-18300\" title=\"Reprocess RC2 with w_2019_14\" class=\"issue-link\" data-issue-key=\"DM-18300\"><del>DM-18300</del></a> run, don\\'t start the actual converting before the w_2019_14 run is done. </p>\n",
            "nan\n",
            "<p>Work on task\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/TSS-3196\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/TSS-3196</a></p>\n",
            "<p>Begin reviewing the EFD Writer generators.\\xc2\\xa0</p>\n",
            "<p>The HeaderService is now writing FITS headers to raw data that include header cards using 8 blank characters as the special comment keyword.  This is completely within the standard but the reader code in afw.fits is confused and stores them as keyword <tt>\"\"</tt> and value <tt>None</tt>.<br/>This confuses things when output files are written.</p><p>Fix the reader. It may be simpler to move these blank keyword comments into <tt>COMMENT</tt> fields in PropertyList.  Since the order is lost once comments are read there is nothing to be gained from retaining the distinction between the two types of comments.</p>\n",
            "<p>Zipping the bboxes only works if objects are same length, so check that first.</p>\n",
            "<p>The QS working group recommended to adopt the definitions of QA-related terms in the DMTN-085 glossary subsystem-wide  in QAWG-REC-1.  At the DMLT F2F meeting, this recommendation was accepted. </p><p>This glossary should be audited for correctness and for clashes with higher LSST glossaries. </p>\n",
            "<p>At DMLT meeting in early June I was told to prepare LDM-635 for RFC. This mainly requires I fix the sort order of the requirements.</p>\n",
            "<p>The header service failed yesterday whilst operating because a deferred import to Astropy could not be completed. The header service should do all required imports at launch time so that we can detect problems early.</p>\n",
            "<p>When looking at a header created yesterday from AuxTel the first two blank keyword comments  are shifted one character to the right:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ fitsheader tests/data/ticket20143.fits  | grep \\'\\\\-\\\\-\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">         ---- Date, night and basic image information ----                      </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">         ---- Telescope info, location, observer ----                           </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        ---- Pointing info, etc. ----                                           </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        ---- Image-identifying used to build OBS-ID ----                        </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        ---- Information from Camera                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        ---- Geometry from Camera ----                                          </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        ---- Filter/grating information ----                                    </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        ---- Exposure-related information ----                                  </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        ---- Header information ----                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        ---- Checksums ----                     </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Address security alerts in LTD Keeper as of 2019-07-13:</p><ul>\\t<li>Upgrade flask to version 0.12.3 or later</li>\\t<li>Upgrade requests to version 2.20.0 or later</li></ul>\n",
            "\"<p>Our current options for a new persistence framework are Cereal, FlatBuffer, and/or Avro. I've already looked into Cereal and FlatBuffer; examine the suitability of Avro for the same work.</p>\"\n",
            "\"<p>In order to test auth, all of our lower case j's need to be dotted.\\xc2\\xa0 This means fixing our returned IVOA capabilities from the TAP service to use the right urls, with https instead of http, since this matters for auth things.\\xc2\\xa0 (For example, not doing basic auth over http, but maybe allowing it over https)</p><p>Should be a simple change.\\xc2\\xa0 Discovered this as a part of doing the auth work.\\xc2\\xa0 It detects the hostname automatically, but not the http/https, or at least it doesn't work because it is behind so many levels of proxy.</p>\"\n",
            "<p>I was tasked with coordinating the Release of SAL and XML v3.10.0.\\xc2\\xa0 This task is to track that work.</p>\n",
            "<p>SLAC needs a copy of the Hexapod Rotator management pc software</p>\n",
            "<p>Add the logic discussed in ticket\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-18642\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/DM-18642</a>\\xc2\\xa0:</p><p>\\xc2\\xa0<br/>So we should certainly add a SAL command, regardless. (To do a position reference)<br/>We should avoid movement in the disabled state, so on the start command, check the reference. If it\\'s good, then continue as normal without re-referencing. If the reference is bad, then on enable, execute a reference and tell the user a reference is happening and therefore it might take more time.</p><p>Also add a reference event that checks and announce if the controller is properly referenced.</p>\n",
            "<p>Test:\\xc2\\xa0\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-19601\" title=\"Update ATHexapod reference logic and add init command\" class=\"issue-link\" data-issue-key=\"DM-19601\"><del>DM-19601</del></a></p>\n",
            "\"<p>The topic Alias must match the last part of the EFDB_Name, otherwise the SAL can't properly build the libraries.\\xc2\\xa0 Add a test to robotframework_ts_xml to verify this.</p>\"\n",
            "<p>Update the atptg_ataos integration test to include getting target status from the atmcs instead of the atptg component for the ataos.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mgower\" class=\"user-hover\" rel=\"mgower\">Michelle Gower</a> has sent me an initial set of requirements for the Data Backbone Services. I will put them in the model and upload an initial draft to DocuShare.</p>\n",
            "<p>Ensure that the identified weekly build identified to start the 18.0 release process has no scientific regressions and is a good starting point for the first release candidate.</p>\n",
            "<p>Put simulator and ATHexpod into a docker container</p>\n",
            "<p>Compiled C++ program does not detect the USB Spectrograph (FiberSpectrograph) connected to the Linux machine. Debugging to figure out if its a hardware or software issue</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2019_22 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-19244\" title=\"Reprocess RC2 with w_2019_22\" class=\"issue-link\" data-issue-key=\"DM-19244\"><del>DM-19244</del></a></p>\n",
            "\"<p>Node headers by default capped at 8K.  It's configurable, so find a way to pass a larger value down to the proxy.</p>\"\n",
            "<p>In the process of trying to plumb through the UDFs for scisql and qserv, I\\'ve noticed that the lack of a return type of qserv_areaspec functions is really, really painful.\\xc2\\xa0 It should return something, even if that is only a 1, or bit, or whatever.</p><p>In the various sql parsers, if you have a function, it is expected to return something.\\xc2\\xa0 Without a return to compare against something else, it will fail.</p><p>For example, the JSQLParser (which CADC uses) allows you to specify UDFs with a name, and you say the return type.\\xc2\\xa0 This is how I\\'ve been able to pass through the scisql_angSep function, since it returns a double.</p><p>I have tried to do the same for the qserv_areaspec functions, but the parsing always fails because we aren\\'t comparing it against something in the WHERE part of the clause.\\xc2\\xa0 If I tell it that qserv_areaspec_ returns an int (and just compare it against 1) it seems to work.\\xc2\\xa0 But then qserv won\\'t accept that query.</p><p>TOPCAT also has query hints that will pop up a warning flag (although it still allows you to submit), since it also tries to parse the ADQL.\\xc2\\xa0 It\\'s fine without having to tell it what the function names are, but it says that it was expecting an =, not equal, in, not, between, etc.\\xc2\\xa0 Since a lot of astronomers will be using this, it seems better to allow TOPCAT to help us with its ADQL parsing hints.\\xc2\\xa0 If you make it = 1 at the end, all is well in the world of TOPCAT.</p><p>I have tried to test passing the scisql_angSep function down to qserv with a query, but I think the lack of qserv_areaspec has made the query get denied:</p><p>MariaDB <span class=\"error\">&#91;(none)&#93;</span>&gt; SELECT o1.id AS id1, o2.id AS id2, scisql_angSep(o1.ra1, o1.dec1, o2.ra1, o2.dec1) as distance FROM wise_00.allsky_2band_p1bm_frm WHERE scisql_angSep(o1.ra1, o1.dec1, o2.ra1, o2.dec1) &lt; 0.02 AND o1.id &lt;&gt; o2.id;<br/>ERROR 4120 (Proxy): Unable to return query results:<br/>&#8211; WARN multiple errors</p><p>Unfortunately, I think with the moving of the qserv containers around, I don\\'t seem to be able to find the proxy logs to help give me the errors, and the mysql command line client doesn\\'t tell me what they are, so it might just be my bad query writing that is at fault here.</p>\n",
            "<p>For some reason our MySql grammar causes antlr4 to parse -1 and 2 differently than other negative integers (-3 is a constant, but -2 is a UnaryExpressionAtom). This needs to be researched &amp; fixed.</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-19873\" title=\"Implement PropertySet.getitem and return get()\" class=\"issue-link\" data-issue-key=\"DM-19873\"><del>DM-19873</del></a> is changing the API of PropertySet.get() such that it will now return a default value rather than raising KeyError. Before that can happen, all extant calls to <tt>get()</tt> must be replaced to avoid any surprises.</p><p>The approach I will take is to change get() so that it always throws an exception and then wait for tests to fail. This may lead to some remaining usage of <tt>get()</tt> in code that is not used.</p>\n",
            "<p>There was a misspelling on salpytools that named a function\\xc2\\xa0 DDSSubcriber, it has been changed to to DDSSubscriber. The HeaderService need to be updated to reflect this simple change.</p>\n",
            "<p>The consensus on <a href=\"https://jira.lsstcorp.org/browse/RFC-597\" title=\"Update return value policy text in Pybind11 Style Guide\" class=\"issue-link\" data-issue-key=\"RFC-597\"><del>RFC-597</del></a> was that the <a href=\"https://developer.lsst.io/pybind11/style.html#the-reference-internal-policy-shall-be-used-for-functions-or-properties-giving-write-access-to-internal-data-members\" class=\"external-link\" rel=\"nofollow\">return value policy rule</a> in the pybind11 style guide is unneccessary, so remove it. Developers will be expected to directly apply the pybind11 documentation concerning return value policies.</p>\n",
            "<p>Make a \"stub\" ts_sal package for RPMS, something we can use eups to setup but that only includes SALPY libraries, not SAL itself.</p><p>It must include the following directories:</p><ul>\\t<li>lib</li>\\t<li>python</li>\\t<li>ups</li></ul>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "\"<p>The generation of Quantum Graphs is currently taking enough time that we'll need the ability to start with an existing Quantum Graph.\\xc2\\xa0 This will greatly speed up debugging BPS bugs as well as help the current milestone since the generation of RC2 sized Quantum Graphs is currently taking multiple hours.</p>\"\n",
            "nan\n",
            "<p>Action from QAWG - to set up a group to look into needs for image display.</p>\n",
            "<p>All activities as the DM liaison to Strong Lensing science collaboration<br/> \\xc2\\xa0</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>We should do new ap_pipe reruns on the HiTS2015 dataset approximately monthly with the latest weekly stack. In this case, we will not regenerate the coadd templates and will just use the CompareWarp coadds which are a few months old.</p>\n",
            "nan\n",
            "\"<p>Please document, and note in this ticket where it's documented, all URLs currently in use in any Firefly application that is in use or planned to be in use in LSST (default data portal, slate, time series viewer, etc.).</p><p>Before our closeout I want to be sure that we have a coherently laid out scheme for these.</p>\"\n",
            "nan\n",
            "<p>Attend the ComCam MIE Pre-ship Review:</p><p><a href=\"https://confluence.lsstcorp.org/display/LTS/MIE+Pre-ship+Review\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/LTS/MIE+Pre-ship+Review</a></p>\n",
            "<p>Using a bleed version of the conda environment,\\xc2\\xa0meas_modelfit test\\xc2\\xa0TruncatedGaussianTestCase is failing</p><p>\\xc2\\xa0</p><h3><a name=\"ErrorMessage\"></a>Error Message</h3><p>AssertionError: True is not false : 1/4 elements differ with rtol=2.220446049250313e-16, atol=2.220446049250313e-16 2.500000000000001 != 2.5 (diff=8.881784197001252e-16/2.500000000000001=3.5527136788004996e-16)</p><h3><a name=\"Stacktrace\"></a>Stacktrace</h3><p><tt>self = &lt;test_truncatedGaussian.TruncatedGaussianTestCase testMethod=test2d&gt; def test2d(self): if scipy is None: return for i in range(5): x = numpy.linspace(-1, 1, 5) model = numpy.zeros((x.size, 2), dtype=float) model<span class=\"error\">&#91;:, 0&#93;</span> = x model<span class=\"error\">&#91;:, 1&#93;</span> = x**2 + x data = numpy.random.randn(x.size) + model<span class=\"error\">&#91;:, 0&#93;</span>*0.9 + model<span class=\"error\">&#91;:, 1&#93;</span>*1.1 q0 = 0.5*float(numpy.dot(data, data)) gradient = -numpy.dot(model.transpose(), data) hessian = numpy.dot(model.transpose(), model) sigma = numpy.linalg.inv(hessian) &gt; self.assertFloatsAlmostEqual(numpy.linalg.inv(sigma), hessian) tests/test_truncatedGaussian.py:161: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../../stack/Linux64/utils/16.0-18-g0a50484+1/python/lsst/utils/tests.py:735: in assertFloatsAlmostEqual testCase.assertFalse(failed, msg=\"\\\\n\".join(errMsg)) E AssertionError: True is not false : 1/4 elements differ with rtol=2.220446049250313e-16, atol=2.220446049250313e-16 E 2.500000000000001 != 2.5 (diff=8.881784197001252e-16/2.500000000000001=3.5527136788004996e-16)</tt><br/>{{ \\xc2\\xa0}}<br/>{{ \\xc2\\xa0}}</p>\n",
            "<p>In <tt>smoothArray</tt> multiplying the convolved image by numerator/denominator, was supposed to correct the roll-off produced by padding the input image with zeros. </p><p>See the last comment on <a href=\"https://jira.lsstcorp.org/browse/DM-17426?focusedCommentId=196713&amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-196713\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/DM-17426?focusedCommentId=196713&amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-196713</a></p><p>And conversation on #subaru_hsc:</p><p>Sogo Mineo <span class=\"error\">&#91;8:42 PM&#93;</span> These lines <a href=\"https://github.com/lsst/pipe_drivers/blob/master/python/lsst/pipe/drivers/background.py#L869\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/pipe_drivers/blob/master/python/lsst/pipe/drivers/background.py#L869</a></p><p>should be fixed (naively) as:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">convolved = gaussian_filter(numpy.where(bad, 0.0, array), sigma, mode=\"constant\", cval=0.0)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-numerator = gaussian_filter(numpy.ones_like(array), sigma, mode=\"constant\", cval=0.0)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+numerator = gaussian_filter(numpy.ones_like(array), sigma, mode=\"constant\", cval=1.0)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> denominator = gaussian_filter(numpy.where(bad, 0.0, 1.0), sigma, mode=\"constant\", cval=0.0)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> return convolved*numerator/denominator</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Let me explain: we set bad pixels to 0 in computing <tt>convolved</tt>. Doing it wrongly lowers the pixels around the bad pixels in <tt>convolved</tt> . We compensate this effect with <tt>*numerator/denominator</tt>. In computing <tt>convolved</tt> , pixels outside the input image are also set to 0 ( <tt>cval=0.0</tt> ). It is that these pixels are regarded as a kind of bad pixels, and their effect should have been compensated together with the effect of the bad pixels inside the input image. This is why the <tt>numerator</tt> needs the fix above.</p><p>But if we compute <tt>numerator</tt> according to this fix, all elements of <tt>numerator</tt> are 1. Therefore, we can drop it altogether, hence Koike-san\\'s proposal:</p> <p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">convolved = gaussian_filter(numpy.where(bad, 0.0, array), sigma, mode=\"constant\", cval=0.0)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-numerator = gaussian_filter(numpy.ones_like(array), sigma, mode=\"constant\", cval=0.0)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> denominator = gaussian_filter(numpy.where(bad, 0.0, 1.0), sigma, mode=\"constant\", cval=0.0)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-return convolved*numerator/denominator</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+return convolved/denominator</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p><a href=\"https://developer.lsst.io/team/onboarding.html#data-facility-resources\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/team/onboarding.html#data-facility-resources</a> states (or, at least, heavily implies) that everybody being onboarded to DM automatically gets issued with an account which provides access to Nebula.</p><p>Apparently, that\\'s not actually the case: Nebula accounts are only available following the procedures at <a href=\"https://developer.lsst.io/services/nebula/index.html\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/services/nebula/index.html</a> and are not issued automatically.</p><p>Please update the Dev Guide to make this clear.</p>\n",
            "<p><a href=\"https://developer.lsst.io/coding/intro.html#stringency-levels\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/coding/intro.html#stringency-levels</a> currently refers to the TCT and the \\xe2\\x80\\x9clead developer\\xe2\\x80\\x9d, neither of which are meaningful.</p>\n",
            "<p>This task covers time needed to setup and configure the TSSW Jenkins environment.</p><ul>\\t<li>Install and run Docker on the host</li>\\t<li>Get the ts_xml job configured and running</li></ul>\n",
            "<p>Similar to <a href=\"https://jira.lsstcorp.org/browse/DM-18176\" title=\"March LDF Gen2 ci_hsc weekly running\" class=\"issue-link\" data-issue-key=\"DM-18176\"><del>DM-18176</del></a> but for May 2019.</p><p>Currently, the gen3.sqlite3 output of the Gen2 ci_hsc run is needed to bootstrap running in Gen3.    Run ci_hsc with the weekly software releases.  Give gen3.sqlite3 file to database admins for loading into Oracle.</p>\n",
            "<p>The <tt>RunIsrConfig</tt> class was omitted when <tt>_<em>all</em>_</tt> was added to <tt>isrTask.py</tt>.  This breaks running `RunIsrTask` more than once with the same rerun but different data ids.  Adding the configs fixes this.</p>\n",
            "nan\n",
            "<p>Tony Johnson has started working on Rotator and has sent us a bunch of questions. This task will be used to support SLAC and also to backup harddrive of Management PC without which Tony would not be able to operate the rotator.\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>My time has been requested to help prepare the team for the TMA workshop visit in June.\\xc2\\xa0 This task covers the time needed to attend meetings, read documentation and other efforts, as needed.</p>\n",
            "<p>The bootstrap scripts added on <a href=\"https://jira.lsstcorp.org/browse/DM-19638\" title=\"Create parent task/script for bootstrapping Gen3 repos\" class=\"issue-link\" data-issue-key=\"DM-19638\"><del>DM-19638</del></a> upgrade Gen2\\'s dates to Gen3\\'s datetimes without adding one day to the end dates.\\xc2\\xa0 Because those intervals are inclusive instead of half-open, that means we end up with a day-long gap between adjacent intervals.</p>\n",
            "nan\n",
            "<p>Per <a href=\"https://github.com/lsst-dm/alert_stream/issues/23\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/alert_stream/issues/23</a>, when <tt>sendAlertStream.py</tt> tries to read a file which contains no data, it throws a <tt>ValueError</tt> with a pretty obscure traceback. Please handle this more gracefully.</p>\n",
            "\"<p>We need to get SODA and metaserv and maybe image serve running in the new clusters.\\xc2\\xa0 Now that we've agreed to new namespaces, I also need to fix that.\\xc2\\xa0 There are also unused PVs in places that need to be cleaned up.</p>\"\n",
            "<p>It looks like we lost the Jacobian from the meas_mosaic photometric solution with this deletion from <a href=\"https://jira.lsstcorp.org/browse/DM-10156\" title=\"Replace all uses of Calib with PhotoCalib\" class=\"issue-link\" data-issue-key=\"DM-10156\"><del>DM-10156</del></a>:<br/> <a href=\"https://github.com/lsst/meas_mosaic/commit/6e395ac11a625c877374f99e2bed771b427835b6#diff-ad69537790bfe1f2b36095cbbc6f80a9L709\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/meas_mosaic/commit/6e395ac11a625c877374f99e2bed771b427835b6#diff-ad69537790bfe1f2b36095cbbc6f80a9L709</a><br/> I noticed this in comparing meas_mosaic-calibrated magnitudes between the w_2019_10 and w_2019_14 RC2 reprocessings, which look like:<br/> <span class=\"image-wrap\" style=\"\"><img src=\"https://jira.lsstcorp.org/secure/attachment/37638/37638_compareVisit-v1228-diff_base_GaussianFlux-sky-gals.png\" width=\"450\" style=\"border: 0px solid black\" /></span></p><p>\\xc2\\xa0</p>\n",
            "<p>Go from dax-int to\\xc2\\xa0lsst-lsp-int-dax, dax-stable to lsst-lsp-stable-dax</p>\n",
            "\"<p>We've done some work with figuring out the ingress rule for auth, so I'm checking that in (which did work) before the migration today.\\xc2\\xa0 There's also some helper scripts to turn it on and off and replace it with the other rule.</p>\"\n",
            "<p>Please add a readme file to <tt>datasets/comCam</tt>.  Content is described <a href=\"https://developer.lsst.io/services/datasets.html#responsibilities-on-ingest-or-maintenance\" class=\"external-link\" rel=\"nofollow\">here</a>.</p>\n",
            "<p>Please add a readme file to <tt>datasets/ctio0m9</tt>.  Content is described <a href=\"https://developer.lsst.io/services/datasets.html#responsibilities-on-ingest-or-maintenance\" class=\"external-link\" rel=\"nofollow\">here</a>.</p>\n",
            "<p>Please add a readme file to <tt>datasets/lsstCam</tt>.  Content is described <a href=\"https://developer.lsst.io/services/datasets.html#responsibilities-on-ingest-or-maintenance\" class=\"external-link\" rel=\"nofollow\">here</a>.</p>\n",
            "<p>Please add a readme file to <tt>datasets/auxTel</tt>.  Content is described <a href=\"https://developer.lsst.io/services/datasets.html#responsibilities-on-ingest-or-maintenance\" class=\"external-link\" rel=\"nofollow\">here</a>.</p>\n",
            "<p>Sometime in the next month, I will be replacing <tt>Calib</tt> with <tt>PhotoCalib</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10153\" title=\"Replace Calib with finished PhotoCalib\" class=\"issue-link\" data-issue-key=\"DM-10153\"><del>DM-10153</del></a>). We need a note in the Release Notes for v17 to prepare people (the transition is not fully backwards compatible).</p>\n",
            "<p>Older HSC files can have incorrect DATA-TYP headers, causing some science frames to be ingested as calibrations and probably vice versa.\\xc2\\xa0 The OBJECT headers seem to provide values that could be used instead if we can completely enumerate the values used for calibrations; given the finite time duration of the problem.\\xc2\\xa0 <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=furusawa.hisanori\" class=\"user-hover\" rel=\"furusawa.hisanori\">Hisanori Furusawa</a> also reports that the STARS database at NAOJ should be updated with correct values for these, so we could also query that to obtain more complete corrections for all potentially-incorrect files.</p><p>Priority for this ticket should be to get in a fix that enables the correct Gen3 Butler ingestion of all affected science frames in the RC2 dataset, which I can provide a complete list of later.\\xc2\\xa0 We can create a new ticket for a more thorough fix if the solution here is more localized.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=tjenness\" class=\"user-hover\" rel=\"tjenness\">Tim Jenness</a>, please steal this if you think you\\'ll have time to work on it today.\\xc2\\xa0 If not I\\'ll be bugging you about the best way to approach putting the corrections in astro_metadata_translator.</p>\n",
            "<p>Setup the linux desktop returned by IT. The system OS was re-installed. This task will install the needed application and personal settings for the software development environment.</p>\n",
            "<p>Take a free course (<a href=\"https://classroom.udacity.com/courses/ud615\" class=\"external-link\" rel=\"nofollow\">Scalable Microservices with Kubernetes)</a>\\xc2\\xa0on Udacity to learn the Kubernetes with the microservice.</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Update the milestones repository with data extracted from PMCS <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update LDM-503, LDM-564, images repository <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update milestone dates loaded into Jira <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update skeleton Mar 2019 monthly report <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Circulate upcoming milestone list to dm-cams <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Audit and update <a href=\"https://confluence.lsstcorp.org/display/DM/DM+PMCS+Update+Requests\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/DM+PMCS+Update+Requests</a> <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li></ul>\n",
            "<p>NOAO/Tucson CIS is planning to re-plumb the core network on Saturday, 2019-05-18.\\xc2\\xa0 DM Jenkins OSX builds will need to be disabled/reenabled before/after this work and a console cable will need to be connected to the SQRE layer3 switch for manual reconfiguration.</p>\n",
            "<p>Add the proper functionality to extend _<em>init</em>_ methods in meas_extensions_scarlet.</p>\n",
            "<p>Docs are past column 79, fix</p>\n",
            "<p>Wrong unit in meas_extensiosns_scarlet.</p>\n",
            "<p>Test new release for the cRio software for ATDome. This should stop shutter commands when using the emergency stop.</p>\n",
            "<p>With stack <tt>w_2019_19</tt> and a <tt>ci_hsc</tt> repo, I can run the \"processCcd\" of one CCD:  </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">pipetask -d \"visit=903334 and detector=22\" -j 1 -b /project/hchiang2/bps_ci_hsc/w_2019_19/ci_hsc/DATA/butler.yaml -p lsst.ip.isr -p lsst.pipe.tasks  -i raw,calib,ref/ps1_pv3_3pi_20170110  -o out run -t isrTask.IsrTask:isr -C isr:$OBS_SUBARU_DIR/config/hsc/isr.py -t characterizeImage.CharacterizeImageTask:cit -C cit:$OBS_SUBARU_DIR/config/charImage.py -C cit:$OBS_SUBARU_DIR/config/hsc/charImage.py -t calibrate.CalibrateTask:ct -C ct:$OBS_SUBARU_DIR/config/calibrate.py -C ct:$OBS_SUBARU_DIR/config/hsc/calibrate.py</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This finishes without problems.  </p><p>Using <a href=\"https://jira.lsstcorp.org/browse/DM-19638\" title=\"Create parent task/script for bootstrapping Gen3 repos\" class=\"issue-link\" data-issue-key=\"DM-19638\"><del>DM-19638</del></a> we now can build a Gen3 HSC-RC2 repo. I got a repo with sqlite registry, and did the equivalent for another CCD: </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">pipetask -d \"visit=1228 and detector=40\" -j 1 -b /project/hchiang2/gen3repos/w_2019_19/lite/repo/butler.yaml -p lsst.ip.isr -p lsst.pipe.tasks  -i raw/hsc,calibs/hsc/default,refcats/ps1_pv3  -o out run -t isrTask.IsrTask:isr -C isr:$OBS_SUBARU_DIR/config/hsc/isr.py -t characterizeImage.CharacterizeImageTask:cit -C cit:$OBS_SUBARU_DIR/config/charImage.py -C cit:$OBS_SUBARU_DIR/config/hsc/charImage.py -t calibrate.CalibrateTask:ct -C ct:$OBS_SUBARU_DIR/config/calibrate.py -C ct:$OBS_SUBARU_DIR/config/hsc/calibrate.py</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>After the log messages </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">calibrate INFO: Loaded 1474 reference objects</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">calibrate WARN: Catalog pm_ra field is not an Angle; not applying proper motion</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>it failed with </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/meas_astrom/17.0.1-8-g7a3d54a+18/python/lsst/meas/astrom/astrometry.py\", line 152, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = self.solve(exposure=exposure, sourceCat=sourceCat)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/17.0.1-2-g3e5d191+31/python/lsst/pipe/base/timer.py\", line 150, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/meas_astrom/17.0.1-8-g7a3d54a+18/python/lsst/meas/astrom/astrometry.py\", line 196, in solve</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    epoch=expMd.epoch,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/meas_algorithms/17.0.1-13-g1d86082b+1/python/lsst/meas/algorithms/loadReferenceObjects.py\", line 324, in loadPixelBox</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return self.loadRegion(outerSkyRegion, filtFunc=_filterFunction, epoch=epoch, filterName=filterName)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20190330/stack/miniconda3-4.5.12-1172c30/Linux64/meas_algorithms/17.0.1-13-g1d86082b+1/python/lsst/meas/algorithms/loadReferenceObjects.py\", line 415, in loadRegion</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    if not hasNanojanskyFluxUnits(refCat.schema) or not getFormatVersionFromRefCat(refCat) &gt;= 1:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">TypeError: \\'&gt;=\\' not supported between instances of \\'NoneType\\' and \\'int\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Don\\'t think this has to block the merging of <a href=\"https://jira.lsstcorp.org/browse/DM-19638\" title=\"Create parent task/script for bootstrapping Gen3 repos\" class=\"issue-link\" data-issue-key=\"DM-19638\"><del>DM-19638</del></a> tomorrow, hence a separate ticket. </p>\n",
            "<p>Write the DM Science Monthly report for April</p>\n",
            "<p>For the dds version of salobj I am presently using one dds.WaitSet per topic, which takes one thread per topic. However, it may be possible to use dds select to have a single thread that reads all topics. That should be more efficient and scale better for the Watcher. Look into this and implement it if practical.</p>\n",
            "<p>Test the performance of writing the EFD data to the Kafka brokers<br/>provided by the DM test setup, use the M1M3 simulator to generate the maximum<br/>data rate</p>\n",
            "<p>Similar to <a href=\"https://jira.lsstcorp.org/browse/DM-18176\" title=\"March LDF Gen2 ci_hsc weekly running\" class=\"issue-link\" data-issue-key=\"DM-18176\"><del>DM-18176</del></a> but for April 2019.</p><p>Currently, the gen3.sqlite3 output of the Gen2 ci_hsc run is needed to bootstrap running in Gen3.    Run ci_hsc with the weekly software releases.  Give gen3.sqlite3 file to database admins for loading into Oracle.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2019_18 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-19151\" title=\"Reprocess RC2 with w_2019_18\" class=\"issue-link\" data-issue-key=\"DM-19151\"><del>DM-19151</del></a></p>\n",
            "<p>\\xc2\\xa0<br/> \\xc2\\xa0Improve Electrometer documentation inside python</p>\n",
            "<p>Downloaded control software from thorlabs which contains the libraries necessary for the .net framework. Followed their example for the MFF101 flipper to flip back and forth, setup .net framework using mono(a cross platform implementation of the .net framework). Flipper example would not compile because native c dll were only compatible with a windows c library.</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2019_14 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-18300\" title=\"Reprocess RC2 with w_2019_14\" class=\"issue-link\" data-issue-key=\"DM-18300\"><del>DM-18300</del></a></p>\n",
            "<p>\\xc2\\xa0<br/>\\xc2\\xa0Improve Electrometer documentation in the XML</p>\n",
            "<p>Update logging on the salpytools section of ATHS to be directed to a file in addition that to the screen.</p>\n",
            "<p>Take new dataset for monochromator characterization using new configuration values for calsys_takedata.py to see if an issue with an earlier data set is fixed.</p><p>Fixing calsys_takedata.py as it somehow became broken. Code was added to finish writing a csv file to user supplied directory that downloaded electrometer and fiber spectrograph fits files. The code was copy and pasted from the narrowband version of the script and was not completely changed over.</p><p>\\xc2\\xa0</p><p>Fixes were implemented as part of the following PR -\\xc2\\xa0<a href=\"https://github.com/lsst-ts/ts_externalscripts/pull/4\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-ts/ts_externalscripts/pull/4</a></p>\n",
            "<p>Write a conda recipe that works for the ts_tunablelaser.</p>\n",
            "<p>Since moving Jenkins to NCSA one of the ci_hsc tests fails because the clean up code attempts to clear out a directory but some files are still open and owned by the process. On local filesystems this works fine but on NFS deleted but open files become temporary files and <tt>rmtree</tt> gets upset when they hang around.  tempfile.TemporaryDirectory does not know about those open files and does not run rmtree with the flag to ignore errors.</p><p>The fix is either to move the clean up code to tearDown or else see if a <tt>del</tt> works.</p>\n",
            "<p>Sometimes the near neighbor queries in the query monkey timeout, and we think this is because the entropy allows for too big of a range sometimes.\\xc2\\xa0 This means that NN queries might return too many results or take too long to run.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rhl\" class=\"user-hover\" rel=\"rhl\">Robert Lupton</a> reported that the gen2 butler dayObs quantity is not being calculated correctly. It is always assumed to be calculated from the date and not from the DAYOBS header. This needs to be fixed to only use the date if DAYOBS is missing.</p><p>Additionally, since this is a gen2 ingest model parameter and not part of the gen3 data model, the value does not get corrected if there is a FITS header correction file. Update ingest so that header fixups occur on ingest even outside of metadata translation.</p>\n",
            "<p>take a file every N second s and put it in another directory</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=dinob\" class=\"user-hover\" rel=\"dinob\">Dino Bektesevic</a> is running into problems with <tt>Butler.makeRepo</tt> whereby the registry specified from his external config (which happens to be an in-memory sqlite) is being overwritten by a default value assuming a SQLite file on disk with butlerRoot.</p><p>I think it is reasonable to assume that if makeRepo is being called with a populated config and that that config has <tt>registry.root</tt> defined, that the caller of makeRepo does not want makeRepo to override the values. Should makeRepo attempt to create the tables in the provided root? What about <tt>datastore.root</tt>?</p><p>It\\'s a fairly small change to allow setConfigRoot to not override root if root is already present in config (we have to call it anyhow because it copies items over as well as updating the root). I think a flag to setConfigRoot (\"overrideRoot\"?) defaulting to False would work which would be True when called from makeRepo and would be forwarded to overrideParameters or else not even pass toUpdate to overrideParameters.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-9751\" title=\"Verify the performance of new matchPessimisticB code on selected test fields\" class=\"issue-link\" data-issue-key=\"DM-9751\"><del>DM-9751</del></a> created a new source selector that inherits from matcherSourceSelector called matcherPessimisticSourceSelector. This source selector is a stop gap measure to preserve the behavior of matcherSourceSelector for matchOptimisticB. If the new matchPessimisticB is adopted from a future RFC as the default matcher this ticket will merge the two source selectors and matcherSourceSelector with take on the behavior of matcherPessimisticSourceSelector.</p>\n",
            "<p>Per <a href=\"https://lsstc.slack.com/archives/C2JPMCF5X/p1557330175343800?thread_ts=1555439400.008300&amp;cid=C2JPMCF5X\" class=\"external-link\" rel=\"nofollow\">discussion on Slack</a>, <tt>ProcessCcdTask</tt> should set <tt>doWrite=False</tt> on it\\'s <tt>IsrTask</tt> subtask.</p><p>And please also make sure there aren\\'t unnecessary overrides in obs packages.</p>\n",
            "<p>In order to implement <a href=\"https://jira.lsstcorp.org/browse/DM-18739\" title=\"Work on obs_subaru\" class=\"issue-link\" data-issue-key=\"DM-18739\"><del>DM-18739</del></a>, we need a function that can tell if a particular dataset type is supposed to be standardized.  This is only necessary for image or exposure like types.  This will be a utility in obs_base.</p>\n",
            "<p>Currently the way salobj handles command acknowledgement and timeout is a bit odd. Basically, the command workflow is </p><p>1 - Remote sends command to a CSC and waits <br/>2 - CSC acknowledge with ack code SAL__CMD_ACK (300)<br/>3 - If long duration command, CSC sends ack SAL__CMD_INPROGRESS (301)<br/>4 - If fast command or when command is completed CSC sends ack code SAL__CMD_COMPLETE (303)</p><p>To get the acknowledgment salobj (or any sal subscriber), needs to pool. If no response is seeing the method returns SAL_<em>CMD_NOACK (-301). That behavior occurs regardless if the component is executing a command or not. For instance, once you send a command, and before the component sends the first SAL</em><em>CMD_ACK, the sender will receive SAL</em><em>CMD_NOACK. The same also happens between SAL</em><em>CMD_ACK and SAL</em><em>CMD_INPROGRESS and between SAL</em><em>CMD_INPROGRESS and SAL</em>_CMD_COMPLETE. </p><p>To clarify, assume you send a command to a component and poll the acknowledgment every <tt>X</tt> seconds, and the receiving component acknowledges every <tt>3*X</tt> seconds. You will basically get</p><p>t = 0 - Command send<br/>t = X - SAL__CMD_NOACK<br/>t = 2*X - SAL__CMD_NOACK<br/>t = 3*X - SAL__CMD_ACK<br/>t = 4*X - SAL__CMD_NOACK<br/>t = 5*X - SAL__CMD_NOACK<br/>t = 6*X - SAL__CMD_INPROGRESS<br/>t = 7*X - SAL__CMD_NOACK<br/>t = 8*X - SAL__CMD_NOACK<br/>t = 9*X - SAL__CMD_COMPLETE</p><p>On current version of SalObj, when a user sets the timeout it applies to the entire process, until the SAL__CMD_COMPLETE is received. </p><p>Nevertheless, most of the time, the user worry about the first acknowledgement (the SAL__CMD_ACK) and not the entire command execution time.</p><p>I think we need to improve the way SalObj handles command acknowledgments and timeouts to reflect this behavior. </p>\n",
            "<p>Run jointcal with HSC-RC2 and w_2019_18</p>\n",
            "<p>This will evaluate the performance of InfluxDB with the SAL influxwriter on SSD, NVME, and spinning disk.</p>\n",
            "<p>While processing DC2.1 data we found many instances of the astrometry matcher failing.  Here an example from a log file:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry INFO: Purged 2008 sources, leaving 164 good sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astromRefObjLoader INFO: Loading reference objects using center (70.054077, -44.428199) and radius 0.18204469504951715 deg</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astromRefObjLoader INFO: Loaded 1506 reference objects</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.referenceSelector INFO: Selected 33/1506 references</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd FATAL: Failed on dataId={\\'visit\\': 2188, \\'detector\\': 185, \\'run\\': \\'2188\\', \\'raftName\\': \\'R43\\', \\'detectorName\\': \\'S12\\', \\'snap\\': 0}: RuntimeError: Unable to match sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/17.0.1-2-g3e5d191+19/python/lsst/pipe/base/cmdLineTask.py\", line 388, in __call__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = self.runTask(task, dataRef, kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/17.0.1-2-g3e5d191+19/python/lsst/pipe/base/cmdLineTask.py\", line 447, in runTask</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return task.runDataRef(dataRef, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/17.0.1-2-g3e5d191+19/python/lsst/pipe/base/timer.py\", line 150, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/17.0.1-11-gf64fdeb0/python/lsst/pipe/tasks/processCcd.py\", line 198, in runDataRef</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    icSourceCat=charRes.sourceCat,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/17.0.1-2-g3e5d191+19/python/lsst/pipe/base/timer.py\", line 150, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/17.0.1-11-gf64fdeb0/python/lsst/pipe/tasks/calibrate.py\", line 540, in runDataRef</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    icSourceCat=icSourceCat,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/17.0.1-11-gf64fdeb0/python/lsst/pipe/tasks/calibrate.py\", line 670, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    sourceCat=sourceCat,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/17.0.1-2-g3e5d191+19/python/lsst/pipe/base/timer.py\", line 150, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/meas_astrom/17.0.1-8-g7a3d54a+6/python/lsst/meas/astrom/astrometry.py\", line 152, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = self.solve(exposure=exposure, sourceCat=sourceCat)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/17.0.1-2-g3e5d191+19/python/lsst/pipe/base/timer.py\", line 150, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/meas_astrom/17.0.1-8-g7a3d54a+6/python/lsst/meas/astrom/astrometry.py\", line 234, in solve</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    match_tolerance=match_tolerance,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/17.0.1-2-g3e5d191+19/python/lsst/pipe/base/timer.py\", line 150, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/meas_astrom/17.0.1-8-g7a3d54a+6/python/lsst/meas/astrom/astrometry.py\", line 330, in _matchAndFitWcs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    match_tolerance=match_tolerance,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/17.0.1-2-g3e5d191+19/python/lsst/pipe/base/timer.py\", line 150, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/cvmfs/sw.lsst.eu/linux-x86_64/lsst_distrib/w_2019_17/stack/miniconda3-4.5.12-1172c30/Linux64/meas_astrom/17.0.1-8-g7a3d54a+6/python/lsst/meas/astrom/matchPessimisticB.py\", line 272, in matchObjectsToSources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    raise RuntimeError(\"Unable to match sources\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">RuntimeError: Unable to match sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I tried to run with the optimsticB matcher and that seemed to succeed without any problems.  In previous data challenges, the pessimisticB matcher was more robust to failures, so this error is confusing.</p><p>I am in the process of copying a problematic visit over to lsst-dev at /scratch/rearmstr/Run2.1i/w_2019_17.  This visit had failures for detectors: 78, 81, 85, 89, 135, 139, 150, 181, 185.</p>\n",
            "\"<p>Use jointcal instead of meas_mosaic! </p><p>We've done sufficient QA, integration work and improvements to believe this is now working at least as well as meas_mosaic. This doesn't require an RFC because it just affects obs_subaru  (RC2 reprocessing and future HSC data releases).</p>\"\n",
            "<p>Write the March monthly report\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>Something seems to be going wrong in the application of NQUARTER in visualizeVisit.py (maybe it\\'s being applied twice, or maybe not at all).\\xc2\\xa0 <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=lauren\" class=\"user-hover\" rel=\"lauren\">Lauren MacArthur</a> suspects this was broken in <a href=\"https://jira.lsstcorp.org/browse/DM-19371\" title=\"cameraGeom.showCamera applies nQuarter to processed images\" class=\"issue-link\" data-issue-key=\"DM-19371\"><del>DM-19371</del></a>, and that the fix involves the new <tt>obeyNQuarter</tt> clause: <a href=\"https://github.com/lsst/afw/commit/f154d3474b433e269d65c697c02cd1738e918942\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/afw/commit/f154d3474b433e269d65c697c02cd1738e918942</a></p>\n",
            "<p>It has been observed that the PSF as measured on the coadd is narrower than the PSF model says it should be. This has found to be true on the warps as well, so we believe it\\'s an artifact of warping. <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rearmstr\" class=\"user-hover\" rel=\"rearmstr\">Bob Armstrong</a> is experimenting with higher-order Lanczos kernels.</p>\n",
            "<p>The gen3 butler storage class in IsrTask does not match what it is ingested as, fix this.</p>\n",
            "<p>Recent change of Jenkins build workers to Alpine broke Qserv container build scripts</p>\n",
            "<p>Add a configuration to sqrbot-jr so that Slack messages and other types of events are only retained for a small amount of time (such as 30 minutes).</p>\n",
            "\"<p>In a regular channel, Templatebot responds to <tt>app_mention</tt> Slack events. It doesn't seem to be currently receiving those. This ticket is to:</p><ul>\\t<li>Ensure that sqrbot-jr is sending Kafka messages for app_mention events</li>\\t<li>Ensure that templatebot is recieving those app_mention events.</li></ul>\"\n",
            "<p>GPFS direct mounts need a little more work to work in dask.</p>\n",
            "\"<p>Firefly doesn't work in the new regime.</p>\"\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a> noticed that the use of <tt>unsigned</tt> (== uint32, usually) as the index type for Eigen matrices in jointcal <em>might</em> be a problem:</p><ul>\\t<li>Eigen docs appear to want a signed integer;</li>\\t<li>our number of sources in some of our processing is approaching 2^31.</li></ul><p>There\\'s no hard evidence that this is what\\'s causing the segfault we\\'re seeing when processing the (larger, still-proprietary) HSC UltraDeep, and since <tt>unsigned</tt> should be able to handle 2^32, I\\'m personally skeptical that this is the problem.\\xc2\\xa0 But it should be easy to fix, and a good thing to do regardless, especially for the first reason.</p><p><tt>std::ptrdiff_t</tt> is probably the right choice to use instead - that will be a signed integer as large as the pointer type (i.e. int64, usually), and hence the largest unsigned type that\\'s actually usable as an index.</p><p>\\xc2\\xa0</p>\n",
            "<p>Write a initial version of the \"slew telescope script\". </p>\n",
            "<p>There have been some adjustments for the permissions on the file sets for Kubernetes. \\xc2\\xa0Update DMTN-084 to reflect that.</p>\n",
            "<p>read chiller docs, learn about how it likes its packets assembled. This is a duplicate of TSS-3457, which was accidentally created under the wrong project</p>\n",
            "\"<p>As requested by the camera team, some\\xc2\\xa0good runs of the old TS8 data are in the dev area so dev runs need to be ingested too. It'd be good if\\xc2\\xa0all the TS8 runs were in a single bulter repo.\\xc2\\xa0</p>\"\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Oracle works much better with lowercase field names, and case-sensitivity is in general inconsistent in SQL databases.</p><p>We should do this after unifying Dimension names and link names on <a href=\"https://jira.lsstcorp.org/browse/DM-17023\" title=\"Refactor to reduce code complexity in Dimensions system\" class=\"issue-link\" data-issue-key=\"DM-17023\">DM-17023</a>, since that will eliminate the only current use of differently-conventioned names to refer to (essentially) the same concepts, and make a good chunk of the Registry table names lowercase already.</p>\n",
            "<p>Help Andrew with TSSW documentation.</p><p>Met with Jonathan Sick and Andrew to discuss documentation tooling.</p><p>Wrote a barebones Java documentation example using Orchid.</p>\n",
            "<p>thorlabs flipper has a purpose as a potential part of a csc. Explore the potential communication protocols. Looking into pyusb as a possible library. Working on solving pyusb permission error. Probably need to write a udev rule to give the device the proper permissions.</p>\n",
            "<p>The FITS region files we are writing use LSST pixel 0,0 as origin.  This means that when the regions are loaded into DS9 the regions are shifted by a single pixel.  Adjust the output of the region to correct for this (and also adjust when reading back in).</p>\n",
            "<p>Running `matchedVisitMetrics`for <a href=\"https://jira.lsstcorp.org/browse/DM-17830\" title=\"Investigate color-dependent offsets from ref cat in jointcal vs. meas_mosaic\" class=\"issue-link\" data-issue-key=\"DM-17830\"><del>DM-17830</del></a> was yielding AM1 of 0 for HSC WIDE tracts 9615 and 9697 which have visits numbers in the single digits. AM1 is the median of the RMS of the distances between 2 stars in N visits. Closer inspection revealed that more than half of the RMSs were exactly zero, which is why the median was exactly zero.\\xc2\\xa0\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=wmwood-vasey\" class=\"user-hover\" rel=\"wmwood-vasey\">Michael Wood-Vasey</a> quickly found the problem which was that if a pair appeared in exactly one visit, the stdev(<span class=\"error\">&#91;one distance&#93;</span>) was exactly 0\\xc2\\xa0 and not NaN.</p><p>Require at least 2 distances before computing their stdev.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=wmwood-vasey\" class=\"user-hover\" rel=\"wmwood-vasey\">Michael Wood-Vasey</a> will investigate the potential bias is in the median RMS as a function of N.</p><p>This change will increase our reported AMx reported in squash.</p>\n",
            "<p>Find all uses of <tt>Err</tt> and <tt>Sigma</tt> in the version controlled DM documents (hopefully just LDMs?), determine if they are correct or not, and fix the ones that are incorrect.</p><p>How many LDMs are there (of order 20 on the page below), and where do they all live? This document is a good start at finding them:</p><p><a href=\"https://confluence.lsstcorp.org/display/DM/Requirements+and+Design+Hierarchy\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Requirements+and+Design+Hierarchy</a></p><p>This git repo should encompass all the important ones:</p><p><a href=\"https://github.com/lsst-dm/dm-docs.git\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/dm-docs.git</a></p>\n",
            "<p>Currently the output generated from the c++ single file programs are not descriptive enough. This makes it difficult to be parsed by the current automated test pipeline in place. This task is to modify the output to be more descriptive.\\xc2\\xa0</p><p>Example of the desired output is in the following link<br/><a href=\"https://docs.google.com/document/d/1M3ZDKKYpGXBDOgwese2kYT_cisGXg8y6JT040SHNxPU/edit\" class=\"external-link\" rel=\"nofollow\">https://docs.google.com/document/d/1M3ZDKKYpGXBDOgwese2kYT_cisGXg8y6JT040SHNxPU/edit</a></p>\n",
            "<p>Many region specifications (DS9, STC) define boxes in terms of center and width. Box2D has a <tt>getCenter()</tt> method but it would be useful if <tt>Box2I</tt> also had one to allow for more seamless usage.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-15862\" title=\"Reduce ISR code duplication between ip_isr, obs_subaru, and obs_decam\" class=\"issue-link\" data-issue-key=\"DM-15862\"><del>DM-15862</del></a> broke y-band stray-light calibration lookup in Gen2 (which has always been a hack) by hard-coding a path, then deferring a fix for that to <a href=\"https://jira.lsstcorp.org/browse/DM-16805\" title=\"Add PipelineTask support for optional input datasets\" class=\"issue-link\" data-issue-key=\"DM-16805\">DM-16805</a>.</p><p>That more complete fix will still have to wait for that ticket, but I\\'ll try to get a fix for Gen2 only done here.</p><p>\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>The notebooks on pontus need a reorganization. Things should be located by username.</p>\n",
            "<p>Configure MariaDB + efdwriters and Influx + efdwriters in La Serena and run MTM1M3 simulator for testing </p>\n",
            "<p>Testing of the software integration between DIMM CSC and vendor provided software. </p>\n",
            "<p>Since a count<img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/star_yellow.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/> apparently will hit all the worker nodes, seems like a good idea to add it to the queries the monkey runs.\\xc2\\xa0 Also we should fix the NN query to select \\'monkey\\' first to keep it separate from other queries.</p>\n",
            "<p>Add explanatory text to the exploratory dask notebooks so users can follow along.</p>\n",
            "<p>Specify the configuration and price the phase 2 EFD servers, then <br/>create a requisition for their purchase. Separately spec the add-ons<br/>(nVME, SSD, HD)</p>\n",
            "<p>The role of the DM Science Validation Scientist, as described in\\xc2\\xa0<a href=\"http://ls.st/LDM-294\" class=\"external-link\" rel=\"nofollow\">LDM-294</a>\\xc2\\xa0and <a href=\"http://ls.st/LDM-503\" class=\"external-link\" rel=\"nofollow\">LDM-503</a>\\xc2\\xa0will relocate to\\xc2\\xa0 LSST HQ in Tucson as a 100% role from mid 2019</p>\n",
            "<p>Please check that the v17.0.1.rc1 release candidate is good to go.</p><p>Patch release 17.0.1 will be created once this check is done.</p>\n",
            "<p>There is useful documentation in README files in obs_lsst that needs to be integrated into the sphinx documentation.</p>\n",
            "<p>When running the ci_lsst imsim tests they fail in the calibration construction phase with a bad key:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">root INFO: Running: .../stack/DarwinX86/pipe_drivers/16.0-10-g0ee56ad/bin/constructBias.py ./tmp/imsim --rerun timj/tmp --id visit=3010000..3010009:3 -j 4</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">LsstCamMapper WARN: Unable to find valid calib root directory</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CameraMapper INFO: Loading exposure registry from /Users/timj/work/lsstsw3/build/obs_lsst_new/tmp/imsim/registry.sqlite3</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">LsstCamMapper WARN: Unable to find valid calib root directory</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">bias FATAL: Failed: \\'ccd\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \".../stack/DarwinX86/pipe_drivers/16.0-10-g0ee56ad/python/lsst/pipe/drivers/constructCalibs.py\", line 365, in __call__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = task.runDataRef(**args)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \".../stack/DarwinX86/pipe_drivers/16.0-10-g0ee56ad/python/lsst/pipe/drivers/constructCalibs.py\", line 441, in runDataRef</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    expRefList, level=\"sensor\", ccdKeys=self.config.ccdKeys)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \".../stack/DarwinX86/pipe_drivers/16.0-10-g0ee56ad/python/lsst/pipe/drivers/constructCalibs.py\", line 230, in getCcdIdListFromExposures</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    name = dictToTuple(ccdId, ccdKeys)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \".../stack/DarwinX86/pipe_drivers/16.0-10-g0ee56ad/python/lsst/pipe/drivers/constructCalibs.py\", line 196, in dictToTuple</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return tuple(dict_[k] for k in keys)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \".../stack/DarwinX86/pipe_drivers/16.0-10-g0ee56ad/python/lsst/pipe/drivers/constructCalibs.py\", line 196, in &lt;genexpr&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return tuple(dict_[k] for k in keys)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \".../miniconda/envs/lsst-scipipe/lib/python3.7/collections/__init__.py\", line 1025, in __getitem__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    raise KeyError(key)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">KeyError: \\'ccd\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Failed to process imsim </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>It is likely a problem with the configurations for imsim in that the default keys are being used rather than the ccdKeys override.</p>\n",
            "<p>Shadowing can happen if you add en explicit translator method and forget to remove it from the constant or trivial mappings list. Check for this scenario and warn.  Also check that const/trivial methods are not being inherited from a parent and overriding the versions defined in the current class.</p>\n",
            "<p>There have been reports of some issues with ingest of BOT flat field data. <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=tjohnson\" class=\"user-hover\" rel=\"tjohnson\">Tony Johnson</a> has given me a file to use for the investigation.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-9873\" title=\"PropertySet does not support values of None\" class=\"issue-link\" data-issue-key=\"DM-9873\"><del>DM-9873</del></a> added support for <tt>None</tt> to be added to PropertyList. Update afw FITS reading to support undefined values.</p>\n",
            "<p>A <tt>Datastore.put</tt> should raise when the file already exists (perhaps adding an option to force it).</p>\n",
            "<p>As of 2019-04-08, <a href=\"https://ci.lsst.codes/job/sqre/job/infra/job/documenteer/436/display/redirect\" class=\"external-link\" rel=\"nofollow\">Jenkins is failing</a>. Error is:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/j/ws/sqre/infra/documenteer/doc_template/home/.local/lib/python3.7/site-packages/sphinx/environment/__init__.py\", line 785, in get_doctree</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    with open(doctree_filename, \\'rb\\') as f:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">FileNotFoundError: [Errno 2] No such file or directory: \\'/j/ws/sqre/infra/documenteer/doc_template/_build/doctree/py-api/lsst.meas.base.PhotoCalib.doctree\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Exception occurred:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/j/ws/sqre/infra/documenteer/doc_template/home/.local/lib/python3.7/site-packages/sphinx/environment/__init__.py\", line 785, in get_doctree</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    with open(doctree_filename, \\'rb\\') as f:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">FileNotFoundError: [Errno 2] No such file or directory: \\'/j/ws/sqre/infra/documenteer/doc_template/_build/doctree/py-api/lsst.meas.base.PhotoCalib.doctree\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>meas_algorithms contains several (e.g. <a href=\"https://github.com/lsst/meas_algorithms/blob/0bf8251ccb5c79be6e181817359729fdb2425311/python/lsst/meas/algorithms/objectSizeStarSelector.py#L43\" class=\"external-link\" rel=\"nofollow\">#1</a>, <a href=\"https://github.com/lsst/meas_algorithms/blob/d421edbfcf2fc993cbad9211c1498767479d069a/python/lsst/meas/algorithms/pcaPsfDeterminer.py#L35\" class=\"external-link\" rel=\"nofollow\">#2</a>, there are more) explicit uses of <tt>lsst.afw.display.ds9</tt>. These should be replaced by calls to the generic (backend-independent) <tt>lsst.afw.display</tt> system.</p>\n",
            "<p>There is a need to automatically update the SAL HTML definition pages on the LSST project page, <a href=\"https://project.lsst.org/ts/sal_objects/\" class=\"external-link\" rel=\"nofollow\">https://project.lsst.org/ts/sal_objects/</a>.\\xc2\\xa0 It would be good to have the Jenkins build publish these page, however there is an issue getting the data off the AWS hosted server.\\xc2\\xa0 This task covers the time it will take to investigate, propose and implement a solution.</p>\n",
            "<p>In the current version of <a href=\"https://jira.lsstcorp.org/browse/DM-15396\" title=\"Make DAX containers built off of stack containers\" class=\"issue-link\" data-issue-key=\"DM-15396\"><del>DM-15396</del></a>, I\\'m specifying a particular image in the dockerfile:</p><p>FROM lsstsqre/centos:7-stack-lsst_distrib-w_2018_33</p><p>This means use the 33rd week\\'s weekly build for lsst stack.\\xc2\\xa0 Really we want to follow the latest weekly build though, and build on top of whatever is the latest successful weekly stack build.</p><p>In docker, you can do this with a latest tag, which will follow the latest one.\\xc2\\xa0 I suggested we have a latest_weekly tag for the stack to help this out to Frossie and Josh, and they agreed they could help me out with that.</p><p>Once we have a good tag to follow, we should fix this ticket and change the FROM line to the new tag.\\xc2\\xa0 We should be fine with this particular weekly for a while anyway.\\xc2\\xa0 Right now we\\'re blocked until we get that.</p>\n",
            "<p>Use the yaml configuration file format phase 1. This task will use the yaml to manage the configuration files. This task is the phase 1.</p>\n",
            "<p>Using a bleed version of the conda environment, afw\\xc2\\xa0test case PhotoCalibTestCase fails with the following error:</p><p>\\xc2\\xa0</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># create with non-zero fluxMag0 and err </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">photoCalib = lsst.afw.image.makePhotoCalibFromCalibZeroPoint(fluxMag0, fluxMag0Err) </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">self.assertEqual(photoCalib.getInstFluxAtZeroMagnitude(), fluxMag0) </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt; self.assertEqual(photoCalib.getCalibrationErr(), calibrationErr) </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">E AssertionError: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1617423020.8062096</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> != </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1617423020.8062098</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Update the milestones repository with data extracted from PMCS <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update LDM-503, LDM-564, images repository <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update milestone dates loaded into Jira <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update skeleton Feb 2019 monthly report <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Circulate upcoming milestone list to dm-cams <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Audit and update <a href=\"https://confluence.lsstcorp.org/display/DM/DM+PMCS+Update+Requests\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/DM+PMCS+Update+Requests</a> <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li></ul>\n",
            "nan\n",
            "nan\n",
            "<p>Now that the shared stack has been rebuilt with the new conda environment, the minimum supported versions in the python, numpy, astropy, matplotlib, and scipy stub packages have to be changed to match the new environment.</p>\n",
            "<p>Run jointcal with HSC-RC2 and w_2019_14</p>\n",
            "<p>Run.py currently does not support timer option. Timer is used to add sleep timer between running commands.</p>\n",
            "<p>Once the new environment has been activated, the shared stack environment need to be updated accordingly.</p>\n",
            "<p>Make qa_explorer eups-installable.</p>\n",
            "<p>Add ts_sal unit tests to test <a href=\"https://jira.lsstcorp.org/browse/DM-18491\" title=\"getSample not reliably returning most recent data\" class=\"issue-link\" data-issue-key=\"DM-18491\"><del>DM-18491</del></a> current time issues and <a href=\"https://jira.lsstcorp.org/browse/DM-18637\" title=\"getCurrentTime is not reliably monotonic\" class=\"issue-link\" data-issue-key=\"DM-18637\"><del>DM-18637</del></a> get newest topic after get oldest does not always return the most recent value.</p>\n",
            "<p>SourceMeasurementTask is gone, but we still have code that refers to it, including:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/Users/rowen/LSST/lsstsw/build/meas_algorithms/python/lsst/meas/algorithms/debugger.py:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   21: from lsst.meas.algorithms.measurement import SourceMeasurementTask</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   26:     measurement = ConfigurableField(target=SourceMeasurementTask, doc=\"Measurements\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/Users/rowen/LSST/lsstsw/build/meas_algorithms/python/lsst/meas/algorithms/detection.py:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  209: The example also runs the SourceMeasurementTask; see \\\\ref meas_algorithms_measurement_Example for more explanation.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/Users/rowen/LSST/lsstsw/build/meas_deblender/examples/utils.py:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   15: class DebugSourceMeasTask(measAlg.SourceMeasurementTask):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   41:         measAlg.SourceMeasurementTask.preMeasureHook(self, exposure, sources)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   74:         measAlg.SourceMeasurementTask.postMeasureHook(self, exposure, sources)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   80:         measAlg.SourceMeasurementTask.preSingleMeasureHook(self, exposure, sources, i)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  102:         measAlg.SourceMeasurementTask.postSingleMeasureHook(self, exposure, sources, i)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/Users/rowen/LSST/lsstsw/build/meas_deblender/python/lsst/meas/deblender/deblendAndMeasure.py:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   31: from lsst.meas.algorithms import SourceMeasurementTask</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   50:         target = SourceMeasurementTask,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/Users/rowen/LSST/lsstsw/build/pipe_tasks/python/lsst/pipe/tasks/calibrate.py:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  180: &lt;DT&gt; initialMeasurement \\\\ref SourceMeasurementTask_ \"SourceMeasurementTask\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  189: &lt;DT&gt; measurement \\\\ref SourceMeasurementTask_ \"SourceMeasurementTask\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/Users/rowen/LSST/lsstsw/build/pipe_tasks/python/lsst/pipe/tasks/imageDifference.py:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   36: from lsst.meas.algorithms import SourceDetectionTask, SourceMeasurementTask, \\\\</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  104:         target=SourceMeasurementTask,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/Users/rowen/LSST/lsstsw/build/pipe_tasks/python/lsst/pipe/tasks/measurePsf.py:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  136: The example also runs SourceDetectionTask and SourceMeasurementTask; see \\\\ref meas_algorithms_measurement_Example for more explanation.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I will handle pipe_tasks calibrate.py as part of <a href=\"https://jira.lsstcorp.org/browse/DM-435\" title=\"add aperture-correction measurement code to the end of calibrate\" class=\"issue-link\" data-issue-key=\"DM-435\"><del>DM-435</del></a>.</p>\n",
            "<p>Document the Prompt Enclave software currently running on the Prompt Enclave (L1) test stand.</p><p>Document was copied from Jim\\'s location and is now being updated here:</p><p><a href=\"https://confluence.lsstcorp.org/display/DPES/L1+System+Test+Stand+Information\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DPES/L1+System+Test+Stand+Information</a></p>\n",
            "<p>See triggering ticket for discussion.</p>\n",
            "\"<p>I suspect from playing with LSST numbers that only differences in Z4 with focal plane height variations (chip gaps) are actually significant for HSC.  Check using batoid that this is the case.  If true, then we shouldn't model Z5+ chip-level dependencies in the full wavefront model.</p>\"\n",
            "<p>For some subset of the data (may be all) that was produced before rsync service deployment, manually initiate transfer process for the early data.</p>\n",
            "<p>In working on <a href=\"https://jira.lsstcorp.org/browse/DM-9873\" title=\"PropertySet does not support values of None\" class=\"issue-link\" data-issue-key=\"DM-9873\"><del>DM-9873</del></a> I was getting confusing test failures because sometimes a pex_exceptions C++ TypeError was turning up in Python as a RuntimeError.  It transpires that <a href=\"https://jira.lsstcorp.org/browse/DM-9435\" title=\"Document uses of pex::exceptions\" class=\"issue-link\" data-issue-key=\"DM-9435\"><del>DM-9435</del></a> changed the C++ side such that TypeError inherits from LogicError but did not change the Python interface wrapper.  This ticket will change the Python side to inherit from LogicError rather than RuntimeError.</p>\n",
            "<p>cmdLineFwk can read pre-built pipeline and quantum graph from pickle file, but it is not presently checking that object of correct type is read which can lead to exceptions in other places. Need to add simple check of the type of the object that was read.</p>\n",
            "nan\n",
            "<p>In the current LDM-151 <tt>draft</tt> branch,  <tt>DiffExp</tt> is used for difference images in the AP sections, but <tt>DIAExp</tt> is used in the DRP sections.</p>\n",
            "<p>The mojave builds are failing with the following error:</p><blockquote><p>+ pip install virtualenv<br/>/Users/square/j/ws/release/tarball/osx/10.9/clang-1000.10.44.4/miniconda3-4.5.12-1172c30_tmp/durable-67d1fe51/script.sh: line 3: pip: command not found<br/>script returned exit code 127</p></blockquote><p>An example failing build is <a href=\"https://ci.lsst.codes/blue/organizations/jenkins/release%2Ftarball/detail/tarball/4040/pipeline/\" class=\"external-link\" rel=\"nofollow\">here</a>.  Which is calling code <a href=\"https://github.com/lsst-sqre/jenkins-dm-jobs/blob/fd5ab2e1c2b73eb8ec08550bf7e9bcfa125154a3/pipelines/release/tarball.groovy#L610\" class=\"external-link\" rel=\"nofollow\">here</a></p>\n",
            "<p>The nightly failed because macOS mojave does not interact well with the JSON loading test of validate_drp.  Some of the plotting tests result in a segv with the TkAgg matplotlib backend (some strange interaction with tkinter and macOS).  The fix is to add <tt>~/matplotlib/matplotlibrc</tt> to the worker nodes and have a line in that file saying <tt>backend : Agg</tt>.</p>\n",
            "<p>We got updated information about the interface to the DIMM software. This task is to start integrating the software. </p>\n",
            "<p>The butlerRoot change missed a file in the Oracle registry, this fixes that.</p>\n",
            "<p>Finalize ATAOS and ATPointing integration test</p>\n",
            "<p>Schemas are slightly misaligned between ap_association and dax_ppdb. This causes a crash in running ap_pipe on round-tripped diaObjects. This ticket will add the nessacary columns (validityStart, validityEnd, lastNonForcedSource) to the default diaObject schema in ap_association</p>\n",
            "<p>Pending approval of <a href=\"https://jira.lsstcorp.org/browse/RFC-578\" title=\"Upgrade HSC bright star masks to Goulding S18A\" class=\"issue-link\" data-issue-key=\"RFC-578\"><del>RFC-578</del></a>, please install the Goulding S18A bright star masks on the LSST cluster.</p><p>I recommend the following strategy:</p><ul>\\t<li>Rename the current <tt>/datasets/hsc/deepCoadd/BrightObjectMasks</tt> --&gt; <tt>/datasets/hsc/deepCoadd/ArcturusMasks</tt>.</li>\\t<li>Install the Goulding S18A bright star masks in <tt>/datasets/hsc/deepCoadd/GouldingMasksS18A</tt>.</li>\\t<li>Create a soft link: <tt>/datasets/hsc/deepCoadd/BrightObjectMasks</tt> that points to <tt>/datasets/hsc/deepCoadd/GouldingMasksS18A</tt>.</li></ul><p>This keeps both versions available, defaulting to the new masks. Users can explicitly select the old masks by creating a link in their rerun named <tt>deepCoadd/BrightObjectMasks</tt> that points to <tt>/datasets/hsc/deepCoadd/ArcturusMasks</tt>.</p><p>I am currently downloading the Goulding S18A masks to <tt>/scratch/pprice/GouldingMasksS18A</tt>.</p>\n",
            "<p><a href=\"https://jenkins.io/security/advisory/2019-03-25/\" class=\"external-link\" rel=\"nofollow\">https://jenkins.io/security/advisory/2019-03-25/</a></p>\n",
            "<p>We need more detailed documentation for the GaussianCentroid algorithm, in terms of how it actually computes the centroid.  We (Jim and Perry) have done what we can, but we need help from whoever actually wrote it (RHL, we think) to provide the rest.  In particular:</p><ul class=\"alternate\" type=\"square\">\\t<li>Additional detail should be filled in in the class Doxygen for GaussianCentroidAlgorithm, in GaussianCentroid.h</li>\\t<li>The \"noPeak\" flag field description and name should be compared to what the algorithm actually does with it.  It looks to me like it\\'s a bit misnamed (and maybe shouldn\\'t be considered an error condition at all, if we want to run this on difference images), but I\\'m not sure.</li></ul>\n",
            "<p>Due to <a href=\"https://jira.lsstcorp.org/browse/DM-18637\" title=\"getCurrentTime is not reliably monotonic\" class=\"issue-link\" data-issue-key=\"DM-18637\"><del>DM-18637</del></a> the timestamps in the ScriptQueue script event are not reliable (and a unit test sometimes fails because of this). If that bug issue cannot be fixed quickly then get sign-off on a workaround and apply it using this ticket branch.</p>\n",
            "<p>Realize the OFC interface classes (in ts_ofc) to let the MTAOS to use. Chris and I discussed and defined the interface classes in the last sprint. I plan to realize them for Chris to be able to use with the real calculations instead of interface only. This is the phase 1 of task.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Add <tt>jointcal</tt> templates (<tt>jointcal_wcs</tt> and <tt>jointcal_photoCalib</tt>) to <tt>obs_lsst</tt> policy file so that <tt>jointcal</tt> can be run on <tt>imsim</tt> data (at least).</p>\n",
            "<p>It looks like &lt;exposure&gt;_wcs datasets are coming from the header (which may be an approximation) instead of the true WCS in the FITS binary tables.\\xc2\\xa0 Fix this, and add support for more components if it\\'s easy to do so.</p><p>Note that using the header was once thought to be necessary to do this efficiently, but in fact there\\'s always been a trick to get anything out of the binary tables efficiently (due originally to <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a>, I think): load a 1-pixel subimage of the exposure, and pull the component out of that.</p><p>However, since <a href=\"https://jira.lsstcorp.org/browse/DM-15500\" title=\"Add FITS image, catalog readers that infer types from file\" class=\"issue-link\" data-issue-key=\"DM-15500\"><del>DM-15500</del></a> we\\'ve had an\\xc2\\xa0<tt>ExposureFitsReader</tt> class that provides direct and efficient access to all of those components without that trick, and that\\'s what we should use here.</p>\n",
            "<p>write summary</p>\n",
            "<p>Victor has sent the JSR response template - fill in DM part</p>\n",
            "<p>Sometimes, when trying to debug SAL communication,  it is useful to have the test scripts generated by salgenerator. I think it would be helpful if make_salpy_lib has an option to keep those files. </p>\n",
            "<p>pyyaml 5.1 is out. Test it with the stack and use it if all tests pass. Includes some fixes that are needed for python3.7.</p>\n",
            "<p>Review the EFD related documents and attend the related meetings.</p>\n",
            "<p>Install Labvier on my machine. and try to get the ts_sal Labview program running. I will be needing to run this for development.\\xc2\\xa0</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Add a new function <tt>set_summary_state</tt> to <tt>ts_salobj</tt> that allows us to put a CSC into any valid summary state.</p><p>This will primarily be used to enable or disable CSCs but it may also be handy for changing configuration (by moving it to STANDBY, then the next desired state).</p>\n",
            "<p>Publish ascii errors as part of error code event in salobj. Handle serial timeout as fault state. Add simple retry to timeout to allow CSC to potentially continuing functioning.</p>\n",
            "<p>Right now, if the ADAM device is sending a voltage signal to the KiloArc, it will continue to send that signal until it receives a command to stop. The failure mode we are concerned about is, what happens if the CSC loses its connection to ADAM or crashes. Is there a way to detect that from the ADAM device, and stop sending the power signal as a result? This task is to investigate this. If there is not, then the higher level Illumination CSC will need the ability to cut power to the ADAM device, to ensure that the KiloArc can be gracefully powered down in the event of a CSC failure.</p>\n",
            "<p>Review the Hexapod/Rotator documentation received from MOOG.</p>\n",
            "<p>There has been a request to make a new release of EUPS so that it can be included as a dependency for the v17.0 pipelines release.  This ticket is to create the new EUPS release.  Further tickets are needed to change lsstsw/newinstall to use it and to enable to new shebangtron support.</p>\n",
            "<p>Work out details of CAP-9</p>\n",
            "<p>In TAP_SCHEMA.schemas table, \\'schema_index\\' is used to order schemas by importance.\\xc2\\xa0</p><p>Currently, gaiadr2 with non-existing table comes first, wise_00 comes last.</p><p>Please, set schema_index so that \"sdss_stripe82_01\", \"wise_00\", and \"tap_schema\" come first, followed (if they need to be kept) by non-existing or dev. datasets.\\xc2\\xa0</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2019_10 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-17940\" title=\"Reprocess RC2 with w_2019_10\" class=\"issue-link\" data-issue-key=\"DM-17940\"><del>DM-17940</del></a></p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2019_06 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-17400\" title=\"Reprocess RC2 with w_2019_06\" class=\"issue-link\" data-issue-key=\"DM-17400\"><del>DM-17400</del></a></p>\n",
            "<p>Run jointcal with HSC-RC2 and w_2019_10</p>\n",
            "<p>The latest version of lsstdesc/coord (v1.1), which is repackaged in lsst/coord (currently v1.0.5), has important bug-fixes including fixing a leaking file descriptor.  So it should be upgraded.<br/>This is only a secondary dependency, and does not require an RFC to update.</p>\n",
            "<p>This task is to create the subsystem \"Confluence Template\" that the T&amp;S team will use. This template is planned to be used by the team to contain an overview of a single CSC. For example, some of the items on the template will specify who the product owner is, what the release strategy is and where the links to the Jenkins automated test builds are if they exist.\\xc2\\xa0</p><p>This task will also go over the time spent working with James and getting his CSC into one of these templates so that we can go through a test run with the template as well an example for a future Tech talk when I go over the teams documentation.\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>The Qserv centos7-llvm builds have been failing for a long time now, in the ANTLR4 package, on an include of standard library header <tt>&lt;algorithm&gt;</tt>.  Track this down and fix.</p>\n",
            "<p>1. Milestone for Science Platfiorm</p><p>\\xc2\\xa0\\xc2\\xa0 Depends on DAX services for ADQL and Imgacutout\\xc2\\xa0</p><p>\\xc2\\xa0\\xc2\\xa0 decide if it test uses the new CAOM model\\xc2\\xa0 \\xc2\\xa0</p><p>\\xc2\\xa0</p><p>2. DAQ milestone - nominally April as thats when Huffer the new DAQ (full) would be delivered.\\xc2\\xa0</p>\n",
            "<p>The images in the drop down menu of the LSP spawner are currently sorted by date. This is ok, but it makes it a bit hard to find a specific image, especially if it is ancient (i.e., the preceding major release). It would be nice to instead sort by image name. I think this would mostly have the effect of being a sort by category and then a sort by date within category (at least if the naming conventions hold). I could see arguments for major release, weekly, daily (from least populated to most) or daily, weekly, major release (from most recent to least).</p><p>This will require changes to <a href=\"https://github.com/lsst-sqre/jupyterhubutils/blob/master/jupyterhubutils/scanrepo/scanrepo.py\" class=\"external-link\" rel=\"nofollow\">scanrepo.py</a></p>\n",
            "<p>Using a bleed version of the conda environment, afw\\xc2\\xa0test case PhotoCalibTestCase fails with the following error:</p><p>\\xc2\\xa0</p><p>&gt; self.assertEqual(photoCalib.getCalibrationErr(), calibrationErr)<br/> E AssertionError: 161742302.08062094 != 161742302.08062097</p><p>\\xc2\\xa0</p>\n",
            "<p>In order to make interactive QA plots such as <a href=\"https://jira.lsstcorp.org/browse/DM-11682\" title=\"Make a &quot;linked-sky-plots&quot; recipe that can be executed easily in a Jupyter notebook\" class=\"issue-link\" data-issue-key=\"DM-11682\"><del>DM-11682</del></a>, we need to persist parquet files containing the compiled data that are used to make the static matplotlib plots.  Admittedly, this should be a temporary step until all the source info is easily loadable from a column-store database, but for now it is necessary.  At the visit level it might be less so, but I\\'ll do it anyway.  This is probably technically part of <a href=\"https://jira.lsstcorp.org/browse/DM-10859\" title=\"Interface prototype Bokeh QA system with HSC data\" class=\"issue-link\" data-issue-key=\"DM-10859\"><del>DM-10859</del></a>, but I thought it might be useful to get it in its own ticket so it can be merged quickly.</p>\n",
            "nan\n",
            "<p>I\\'m fairly certain meas_modelfit is included in lsst_apps and hence in CI, but id doesn\\'t seem to be included in the LSST Doxygen build:</p><p><a href=\"http://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/search.php?query=modelfit\" class=\"external-link\" rel=\"nofollow\">http://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/search.php?query=modelfit</a></p>\n",
            "<p>Work on planning for future M1M3 support work</p>\n",
            "<p>Please reprocess the validation data sets so that their output data contains the VisitInfo metadata structure (see <a href=\"https://jira.lsstcorp.org/browse/DM-5503\" title=\"Implement single interface to sanitized exposure metadata\" class=\"issue-link\" data-issue-key=\"DM-5503\"><del>DM-5503</del></a>). I will provide a specific weekly to in the reprocessing in a comment.</p>\n",
            "<p>Improve the star/galaxy separation for validate_drp.</p><p>Many of the LSST SRD KPMs are defined for bright, isolated stars.  There is clear evidence that galaxies are being included in current runs (they have significantly higher photometric scatter at the same mag|SNR).  Improved star/galaxy separation will help generate better numbers</p><p>Stretch goal:  Include additional informative plots about how well the `extendedness` value in the catalogs is successfully separating stars and galaxies.</p>\n",
            "<p>As <a href=\"https://jira.lsstcorp.org/browse/DM-17669\" title=\"Reorganize how TS8 data are handled inside obs_lsst\" class=\"issue-link\" data-issue-key=\"DM-17669\"><del>DM-17669</del></a> has been merged, all TS8 butler repos need to be re-ingested. Otherwise the w_2019_06 stack and onward can\\'t read those repos. </p>\n",
            "<p>This task covers the time spent to support M1M3 Mirror Lab testing.</p>\n",
            "<p>Continue SAL++ mentoring</p>\n",
            "<p>Develop and support the active optics closed-loop simulation. This task will integrate the modules of ts_tcs_wep_phosim, ts_tcs_wep, and ts_tcs_ofcPython. This task will be a prototype of active optics closed-loop simulation. The prototype here will support the simulation of main telescope active optics system (MTAOS) in the final. This task is in the phase 2 of the development.</p>\n",
            "<p>Fight with dockerfiles in attempt to get a working environment with sal, salobj, AND pymodbus, while nominally learning a bit about how docker is supposed to work</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>This task covers the time spent to support M1M3 Mirror Lab testing.</p>\n",
            "<p>Make the mirror lab EFD instance accessible via a VPN connection using the second ethernet port</p>\n",
            "<p>When running\\xc2\\xa0</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">constructBias.py /datasets/ts8/repo-004 --calib /project/plazas/calibrations/ --output /project/plazas/test_output_dir --id imageType=\\'BIAS\\' run=9120 --batch-type none --config isr.doCrosstalk=False --clobber-config</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>the following error appears:\\xc2\\xa0</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">AttributeError: lsst.pipe.drivers.constructCalibs.BiasConfig has no attribute doLinearize</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>\\xc2\\xa0</p><p>Fix: change\\xc2\\xa0<tt>config.load</tt> to <tt>config.isr.load</tt> in\\xc2\\xa0bias.py, flat.py, dark.py (in obs_lsst/config/).\\xc2\\xa0</p>\n",
            "<ul>\\t<li>Follow up of focused DM-SAWG telecons (<a href=\"https://jira.lsstcorp.org/browse/DM-17903\" title=\"imsim ci_lsst tests fail with bad key ccd\" class=\"issue-link\" data-issue-key=\"DM-17903\"><del>DM-17903</del></a>, <a href=\"https://jira.lsstcorp.org/browse/DM-17837\" title=\"Fix incorrect detector serial in TS8 RTM-004\" class=\"issue-link\" data-issue-key=\"DM-17837\"><del>DM-17837</del></a>, <a href=\"https://jira.lsstcorp.org/browse/DM-17530\" title=\"obs_lsst no longer supports TS3 test data\" class=\"issue-link\" data-issue-key=\"DM-17530\"><del>DM-17530</del></a>)</li>\\t<li>People present: M. Fisher-Levine, A. Plazas, A. Nomerotski (first 15 minutes), P. Astier, P. Antilogus\\xc2\\xa0</li>\\t<li>Tentative points to discuss at DM-SAWG session in Berkeley (P. Antilogus will define the final agenda):\\xc2\\xa0\\t<ul>\\t\\t<li>DM presentation (by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=plazas\" class=\"user-hover\" rel=\"plazas\">Andr\\xc3\\xa9s Alejandro Plazas Malag\\xc3\\xb3n</a> with input from other DM people such as Robert Lupton, Merlin Fisher-Levine, and Chris Waters) with current state of ISR and CPP pipelines\\t\\t<ul>\\t\\t\\t<li>Order of ISR correction, precision of current corrections, tests</li>\\t\\t</ul>\\t\\t</li>\\t\\t<li>Provide examples of impacts on science (how well do we need to correct and why? Do we have enough information?):\\xc2\\xa0\\t\\t<ul>\\t\\t\\t<li>Impacts on WL, PSF\\xc2\\xa0</li>\\t\\t\\t<li>Impact of CTI</li>\\t\\t\\t<li>Leave detailed discussion on BF out; it will have a dedicated SAWG session during the\\xc2\\xa0\\xc2\\xa0</li>\\t\\t</ul>\\t\\t</li>\\t\\t<li>How to use data from AuxTel?\\xc2\\xa0</li>\\t</ul>\\t</li>\\t<li>For the discussion we want to identify places that need work, tasks (e.g., algorithm validation, precision of corrections validation), priorities, and volunteers.\\xc2\\xa0</li></ul>\n",
            "<p>Profiling on <a href=\"https://jira.lsstcorp.org/browse/DM-17496\" title=\"QuantumGraph generation hits SQLite join limit\" class=\"issue-link\" data-issue-key=\"DM-17496\"><del>DM-17496</del></a> revealed that the slow speed of preflight was not due to the big <tt>selectDimensions</tt> query, but rather follow-up data ID manipulations.</p><p>Improvements were also done and reviewed <a href=\"https://jira.lsstcorp.org/browse/DM-17496\" title=\"QuantumGraph generation hits SQLite join limit\" class=\"issue-link\" data-issue-key=\"DM-17496\"><del>DM-17496</del></a>, but I\\'m moving them here because they weren\\'t actually relevant for that ticket, and the work that is relevant isn\\'t done yet.</p>\n",
            "<p>When I try to run <tt>writeObjectTable.py</tt> on lsst-dev, it fails with a segfault &amp; long backtrace, starting like:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[tmorton@lsst-dev01 DM-14289]$ bash writeTables_test.sh</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Caught signal 11, backtrace follows:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/ssd/lsstsw/stack3_20171021/stack/miniconda3-4.3.21-10a4fa6/Linux64/utils/16.0-6-g3610b4f/lib/libutils.so(+0x15214) [0x7f078a865214]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/usr/lib64/libc.so.6(+0x362f0) [0x7f080a5892f0]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/ssd/lsstsw/stack3_20171021/python/miniconda3-4.3.21/bin/../lib/libstdc++.so.6(std::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::basic_string(std::string const&amp;)+0xb) [0x7f08032b640b]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/ssd/lsstsw/stack3_20171021/python/miniconda3-4.3.21/lib/python3.6/site-packages/pyarrow/../../../libparquet.so.1(+0x177ddc) [0x7f071bcb6ddc]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/ssd/lsstsw/stack3_20171021/python/miniconda3-4.3.21/lib/python3.6/site-packages/pyarrow/../../../libparquet.so.1(+0x1696c3) [0x7f071bca86c3]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/ssd/lsstsw/stack3_20171021/python/miniconda3-4.3.21/lib/python3.6/site-packages/pyarrow/../../../libparquet.so.1(+0x175e8b) [0x7f071bcb4e8b]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/ssd/lsstsw/stack3_20171021/python/miniconda3-4.3.21/lib/python3.6/site-packages/pyarrow/../../../libparquet.so.1(parquet::ApplicationVersion::ApplicationVersion(std::string const&amp;)+0x6d) [0x7f071bc4aa5d]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/ssd/lsstsw/stack3_20171021/python/miniconda3-4.3.21/lib/python3.6/site-packages/pyarrow/../../../libparquet.so.1(+0x83590) [0x7f071bbc2590]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/lib64/ld-linux-x86-64.so.2(+0xfb03) [0x7f080b964b03]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/lib64/ld-linux-x86-64.so.2(+0x146de) [0x7f080b9696de]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/lib64/ld-linux-x86-64.so.2(+0xf914) [0x7f080b964914]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/lib64/ld-linux-x86-64.so.2(+0x13ccb) [0x7f080b968ccb]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/usr/lib64/libdl.so.2(+0xfbb) [0x7f080b02dfbb]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">...etc</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The script I am running is the following:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">RERUN1=/datasets/hsc/repo/rerun/RC/w_2018_28/DM-14988/</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">OUTPUT1=/project/tmorton/DM-14289/w28</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">RERUN2=/datasets/hsc/repo/rerun/RC/w_2018_26/DM-14689/</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">OUTPUT2=/project/tmorton/DM-14289/w26</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">TRACT=9615</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">PATCH=4,4</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">FILTERS=HSC-G^HSC-R^HSC-I</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">writeObjectTable.py $RERUN1 --output $OUTPUT1 --id tract=$TRACT patch=$PATCH filter=$FILTERS --no-versions -j 20</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">writeObjectTable.py $RERUN2 --output $OUTPUT2 --id tract=$TRACT patch=$PATCH filter=$FILTERS --no-versions -j 20</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">writeQATable.py $OUTPUT1 --output $OUTPUT1 --id tract=$TRACT  patch=$PATCH --no-versions -j 20 --clobber-config</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">writeQATable.py $OUTPUT2 --output $OUTPUT2 --id tract=$TRACT  patch=$PATCH --no-versions -j 20 --clobber-config</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I can run the identical script in the jupyterlab environment container and everything is great.</p><p>I think this is related to the fact that I can run the qa_explorer tests on the JL env but not lsst-dev, where it hangs with a segfault as well (<a href=\"https://jira.lsstcorp.org/browse/DM-14224\" title=\"testParquet.py unit test hangs at &quot;collecting 0 items&quot;\" class=\"issue-link\" data-issue-key=\"DM-14224\">DM-14224</a>).  It is making testing of <a href=\"https://jira.lsstcorp.org/browse/DM-14289\" title=\"Update qa_explorer visualization code to use the new ParquetTable datasets\" class=\"issue-link\" data-issue-key=\"DM-14289\"><del>DM-14289</del></a> difficult, since I can\\'t do it on lsst-dev.</p>\n",
            "<p>Thereby including it as part of the lsst_distrib metapackage.</p>\n",
            "<p>Remove the <tt>Coadd</tt> class, any supporting code, and the <tt>makeBitMask</tt> function.</p>\n",
            "<p>Once <a href=\"https://jira.lsstcorp.org/browse/RFC-569\" title=\"Add obs_lsst to lsst_distrib\" class=\"issue-link\" data-issue-key=\"RFC-569\"><del>RFC-569</del></a> is adopted and obs_lsst is added to lsst_distrib, the sphinx build in pipelines.lsst.io has to be modified to include obs_lsst.</p>\n",
            "<p>When the next RC2 is generated, the release note need to be updated with the latest issues included</p>\n",
            "<p>DMTN-017 was written as a LaTeX doc before technotes existed. This story is to port DMTN-017 to a PDF viewer template (<a href=\"https://jira.lsstcorp.org/browse/DM-4602\" title=\"Support LaTeX/PDF documents with technote infrastructure\" class=\"issue-link\" data-issue-key=\"DM-4602\">DM-4602</a>) for PDF documents that can be published with LSST the Docs.</p>\n",
            "nan\n",
            "<p>In the baselined LDM-294 document, the \"DM documentalist\" position is listed as a member of SQuaRE (Jonathan Sick). In reality, this baseline hasn\\'t been implemented. Jonathan Sick doesn\\'t have DocuShare upload access and has never been tasked with any DM documentalist activities in SQuaRE\\'s epics. I think it\\'s fair to say that the management and systems engineering teams have actually been carrying out the role of documentalist. Besides this, \"DM Documentalist\" is not a defined role in LDM-294, beyond being included in Figure 5.</p><p>Prompted by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=swinbank\" class=\"user-hover\" rel=\"swinbank\">John Swinbank</a>\\'s comments in <a href=\"https://jira.lsstcorp.org/browse/RFC-401\" title=\"Revised DM change-controlled document release workflow\" class=\"issue-link\" data-issue-key=\"RFC-401\"><del>RFC-401</del></a>, this matter should be resolved and LDM-294 should be updated.</p><p>Key questions are:</p><ul class=\"alternate\" type=\"square\">\\t<li>What does the DM documentalist do?</li>\\t<li>Should DM Documentalist be part of the SQuaRE WBS (if Jonathan Sick is doing the work, as currently listed), or does the Documentalist role belong to a different team (such as DM Systems Engineering)? Or should Documentalist duties be shared by multiple people?</li></ul><p>If these questions can be resolved, the Change-controlled document workflow introduced by <a href=\"https://jira.lsstcorp.org/browse/RFC-401\" title=\"Revised DM change-controlled document release workflow\" class=\"issue-link\" data-issue-key=\"RFC-401\"><del>RFC-401</del></a> can be clarified.</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Update the milestones repository with data extracted from PMCS <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update LDM-503, LDM-564, images repository <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update milestone dates loaded into Jira <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Update skeleton Jan 2019 monthly report <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Circulate upcoming milestone list to dm-cams <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li>\\t<li>Audit and update <a href=\"https://confluence.lsstcorp.org/display/DM/DM+PMCS+Update+Requests\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/DM+PMCS+Update+Requests</a> <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></li></ul>\n",
            "<p>cmake-based dependents of the libcurl eups component fail under ubuntu with</p><p><tt>libcurl/7.53.1/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)</tt></p><p>It looks like an additional configure option is needed in the eupspkg.sh script to get the library built with the appropriate version information (cribbed from the debian package script for libcurl)</p>\n",
            "\"<p>These packages have doc/ directories that don't fit the current standards (mostly because they include package documention when they really only should have module documentation). This ticket is to fix these packages:</p><ul>\\t<li>afw</li>\\t<li>base</li>\\t<li>coadd_utils</li>\\t<li>daf_butler</li>\\t<li>display_ds9</li>\\t<li>ip_diffim</li>\\t<li>ip_isr</li>\\t<li>jointcal</li>\\t<li>log</li>\\t<li>meas_algorithms</li>\\t<li>meas_deblender</li>\\t<li>meas_extensions_photometryKron</li>\\t<li>meas_extensions_shapeHSM</li>\\t<li>meas_extensions_simpleShape</li>\\t<li>meas_modelfit</li>\\t<li>obs_base</li>\\t<li>obs_cfht</li>\\t<li>obs_lsstSim</li>\\t<li>obs_test</li>\\t<li>pex_exceptions</li>\\t<li>pipe_base</li>\\t<li>pipe_drivers</li>\\t<li>shapelet</li>\\t<li>utils</li>\\t<li>validate_drp</li>\\t<li>verify</li></ul><p>Also, there's a typo in the title of the <tt>lsst.meas.extensions.simpleShape</tt> module docs.</p>\"\n",
            "<p>This task is for reviewing the TMA FAT documents.\\xc2\\xa0 Andrew Serio is leading this effort and tasked me to review a couple of documents, so this task tracks the time necessary to do so.</p>\n",
            "<p>I removed a bug that I introduced to develop. It prevented scons from being able to run. I plan on meeting for a day with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rowen\" class=\"user-hover\" rel=\"rowen\">Russell Owen</a> to be able to hack out this feature.\\xc2\\xa0</p>\n",
            "<p>Continue SAL mentoring</p>\n",
            "<p>Instead of listening for the mount position from the ATMount, make ATAOS listen for the pointing component.\\xc2\\xa0</p>\n",
            "<p>Construct the\\xc2\\xa0OFC interface between the algorithm and control system.</p>\n",
            "<p>Improve the ATPneumatics XML as per disussion with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rcantarutti\" class=\"user-hover\" rel=\"rcantarutti\">Rolando Cantarutti</a></p><ul>\\t<li>Ditch the Position events because they are fully duplicated by the limit switch events.</li>\\t<li>Add Invalid mirror cover state to handle the case that both an open and a closed switch are active for the same cover.</li>\\t<li>Ditch the overlap of the \\xe2\\x80\\x9cstate\\xe2\\x80\\x9d enums with summary state and shorten the names to remove redundancy and stutter, so that the MirrorCoverState enums become:<p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&lt;Enumeration&gt;MirrorCovers_Closed,MirrorCovers_Opened,MirrorCovers_InMotionState, MirrorCovers_Invalid&lt;/Enumeration&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>and the mirror vents state enum becomes:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&lt;Enumeration&gt;CellVents_Opened,CellVents_Closed,CellVents_InMotion&lt;/Enumeration&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/></li>\\t<li>Delete the <tt>resetEStopTriggered</tt> event, rename the <tt>eStopTriggered</tt> event to <tt>eStopTrigger</tt> and set the <tt>triggered</tt> field appropriately.</li>\\t<li>Add two new events for reporting m1 and m2 commanded air pressure (each with a single field), unless folks have a very strong desire to add fields to the existing m1AirPressure and m2AirPressure telemetry instead.</li>\\t<li>Flesh out the Description and Units fields (including the units for pressure, which are Pa).</li></ul>\n",
            "<p>Inside of telemetry method, if a fault value is read in one of the registers, the laser will go into a fault state however, if the fault is not cleared before the next telemetry it will continue to go into a fault state which is not a valid transition.\\xc2\\xa0</p><p>The solution should check that the CSC is already in a fault state and not go into fault state.</p>\n",
            "<p>This task covers</p><ul>\\t<li>Time to research and learn about enabling SSH to Docker containers.</li>\\t<li>Update the salgenerator tests to work with the Docker image\\t<ul>\\t\\t<li>This may involve updating the tests to remove all SSH functionality.</li>\\t</ul>\\t</li></ul>\n",
            "<p>The task is to meet with Tiago (and Andy Clements) and provide Tiago with the information he needs to take over management of the pointing component contract.</p>\n",
            "<p>goal setting for FY 18</p>\n",
            "<ul>\\t<li>Implement setMaximumSpeeds in the ATHexapod, this will be used from the configuration files.</li>\\t<li>Update target position from the controller directly instead of following at a higher level\\xc2\\xa0</li></ul>\n",
            "<p>The LinearStage has logic that is tied to the now deprecated ts_statemachine and salpytools. The hardware api shall be cleaned up of this logic. The statemachine api will be removed because salobj inherently handles state functionality. The project structure will also change to a more traditional pythonic structure. The zaber library will be upgraded to the latest one released.</p><p>\\xc2\\xa0</p><p><a href=\"https://github.com/lsst-ts/ts_LinearStage/pull/6\" class=\"external-link\" rel=\"nofollow\">Github Pull Request</a></p>\n",
            "<p>This task will consist in making sure\\xc2\\xa0ATPointing and ATAOS run with the same version of SAL, write an OCS-Script to drive the test and run the test locally.\\xc2\\xa0</p><p>Final integration will happen when both systems can be deployed on the Test environment using our deployment strategy.\\xc2\\xa0</p><p>Artifacts:</p><ul>\\t<li>Docker container with ATPointing component</li>\\t<li>Docker container with ATAOS component</li>\\t<li>OCS-Script to drive the test</li></ul><p>Required CSC:</p><ul>\\t<li>ATPointing</li>\\t<li>ATAOS</li>\\t<li>ScriptQueue</li></ul><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p>Continue SAL mentoring, advise in building single task command/event test programs for faster Jenkins testing</p>\n",
            "<p>Meet with Orlando Castro from DatControl to test and review communication protocol between our software and their HVAC system. It seems that is can be done using a SQL data base to send commands to their system.</p><p>Also need to check if this also give us the telemetry of the system, so we can publish it through SAL later.</p><p>This task is to keep things moving forward while German is on vacation.</p>\n",
            "<p>For the most part I have the changes I have made here complete TSS-3276, this task is to go over with Dave on my computer and make sure indeed that this is the behavior that is desired. I also have questions.\\xc2\\xa0</p><p>Primarily which files are involved with the Python wrapping. I will also include these relevant files with the visuals I am creating to help understand the salgenerator pipeline.\\xc2\\xa0</p>\n",
            "<p>The automated tolerances computed in pessimistic B should never be smaller than the pixel scale. This ticket will resolve a bug discovered as part of looking into <a href=\"https://jira.lsstcorp.org/browse/DM-17843\" title=\"A new set of processCcd failure in HSC-RC2 reprocessing\" class=\"issue-link\" data-issue-key=\"DM-17843\"><del>DM-17843</del></a> that allows that to be the case.</p>\n",
            "\"<p>Darko Jevremovic reported he's had to switch off hyperthreading and manually override NCORES, MAKEFLAGS and SCONFLAGS because his 8-core machine had too little RAM to build afw with -j 8.</p><p>To fix this, eupspkg default build routines should take RAM into account when computing the level of build parallelism.</p><p>In the meantime, we should document the workaround (contact darko@aob.rs).</p>\"\n",
            "<p>Add plots similar to the visit-level <b>calibUsed</b>-only versions added in <a href=\"https://jira.lsstcorp.org/browse/DM-11322\" title=\"Add calibUsed-only qa plots for astrometry and photometry\" class=\"issue-link\" data-issue-key=\"DM-11322\"><del>DM-11322</del></a> but at the coadd level. This cannot be done until the flags are propagated to the coadd catalogs when <a href=\"https://jira.lsstcorp.org/browse/DM-11866\" title=\"Propagate astrometry and photometry visit calibration flags to coadds\" class=\"issue-link\" data-issue-key=\"DM-11866\"><del>DM-11866</del></a> lands.</p>\n",
            "<p>I used the sql scripts located here (<a href=\"https://github.com/lsst-dm/db_pdac_wise\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/db_pdac_wise</a>) for creating a mock-qserv.\\xc2\\xa0 This is a single container mysql deployment with the tables set up correctly but no data.\\xc2\\xa0 This is to help test things outside of NCSA without having to connect right to qserv.</p><p>For allsky_2band_p1bm_frm, it looks like it is missing the qs_fact column.\\xc2\\xa0 This is included in the wise_00 data generated by the felis tool, which I\\'m guessing was generated by looking at what is in qserv.\\xc2\\xa0 So it seems like there is a mismatch between what is contained in this repo, and what is in qserv.</p><p>Other missing columns are:</p><p>allsky_3band_p1bm_frm.icaldir</p><p>allsky_4band_p1bm_frm.icaldir</p><p>allsky_2band_p1bm_frm.qs_fact</p><p>The allwise_* tables seem to be fine.</p><p>This is just to track what might be missing.</p>\n",
            "<p>Following a discussion on community we have decided to adjust the calculation of detector_exposure_id and exposure_id to remove additional 0-padding between exposure ID and detector (3 digits for lsstCam rather than 4) and to have a maximum sequence number of 99,999 rather than 999,999. It would be good if we could get this done before v17.0.</p>\n",
            "<p>Review the SHWFS FAT (factory acceptance test) document and presentation by the vendor and feedback the problems to Jacques. This task will also review the document of LSE-150.</p>\n",
            "<p>Look at obs_lsst with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=tjenness\" class=\"user-hover\" rel=\"tjenness\">Tim Jenness</a> - perhaps after <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=krughoff\" class=\"user-hover\" rel=\"krughoff\">Simon Krughoff</a> adds some tests ...</p><p>1 point enough ??</p>\n",
            "<p>Per <a href=\"https://lsstc.slack.com/archives/C2B6DQBAL/p1540481139000100\" class=\"external-link\" rel=\"nofollow\">discussion on Slack of 2018-10-25</a>, there\\'s a certain amount of ambiguity in our developer documentation about formatting docstrings. Please propose some text to make this clearer.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=pmelchior\" class=\"user-hover\" rel=\"pmelchior\">Peter Melchior</a> and I have found that some of the default parameters in scarlet need to be modified to more useful values.</p><p> 1. Normalizing the morphology (S matrix) so that the peak value is set to unity is the most effective way to break the SED/morphology degeneracy, as opposed to the current method of normalizing the SED (A matrix). This provides a method to separate sources with similar colors but very different intensities and also converges more quickly than the current default normalization.</p><p>2. Turning off Nesterov acceleration. There appears to be an issue with combining our proximal gradient method with Nesterov acceleration, making the optimization algorithm asymptotic. It also appears to be even more unstable with the new normalization scheme, however using S matrix normalization <em>without</em> acceleration still runs faster than A matrix normalization <em>with</em> acceleration.</p><p>This ticket will also create a change log in scarlet to keep track of these and other modifications to keep users up to date with the changes. It will also make it easier to keep stack users up to date when updated versions of scarlet are imported into the stack.</p>\n",
            "\"<p>It's not a serverextension.  But I didn't used to get an error when trying to load it as one.</p>\"\n",
            "<p>Discuss and define the\\xc2\\xa0WEP interface between the algorithm and control system with Chris.</p>\n",
            "<p>With w_2019_04 lsst_distrib and master obs_lsst at the time, \"RangeError\" is seems in makeCoaddTempExp in several tracts of imsim DESC Run 1.2i data. An example to reproduce is:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeCoaddTempExp.py  /datasets/DC2/repo/ --rerun w_2019_04/sfm:private/username/yours -c doApplyUberCal=False --id tract=4432 patch=4,5 filter=g   --selectId visit=183892</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>which gives:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeCoaddTempExp INFO: Processing calexp 1 of 1 for this Warp: id=DataId(initialdata={\\'visit\\': 183892, \\'filter\\': \\'g\\', \\'raftName\\': \\'R34\\', \\'detectorName\\': \\'S12\\', \\'detector\\': 158, \\'tract\\': 4432}, tag=set())</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeCoaddTempExp.warpAndPsfMatch.psfMatch INFO: compute Psf-matching kernel</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeCoaddTempExp.warpAndPsfMatch INFO: Cannot PSF-Match: </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"src/WarpedPsf.cc\", line 72, in lsst::geom::Box2I lsst::meas::algorithms::{anonymous}::computeBBoxFromTransform(lsst::geom::Box2I, const lsst::geom::AffineTransform&amp;)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    Unexpectedly large transform passed to WarpedPsf {0}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">lsst::pex::exceptions::RangeError: \\'Unexpectedly large transform passed to WarpedPsf\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeCoaddTempExp INFO: directWarp has 349480 good pixels (2.0%)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeCoaddTempExp INFO: psfMatchedWarp has 0 good pixels (0.0%)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeCoaddTempExp INFO: Persisting deepCoadd_directWarp</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>FWIW, this wasn\\'t seen in last year\\'s processing using <tt>w_2018_49</tt>.</p>\n",
            "<p>Run jointcal with HSC-RC2 and w_2019_06</p>\n",
            "<p>Determine, on <tt>irsadev</tt> (which is why I can\\'t do this now, because I\\'m offsite), whether the current Firefly HiPS code displays the <a href=\"http://amiga.iaa.es/hipslist\" class=\"external-link\" rel=\"nofollow\">http://amiga.iaa.es/hipslist</a> maps in its index, and (whether or not they are in the index) whether it can display them.</p>\n",
            "<p>This ticket is to deploy <a href=\"https://astro-metadata-translator.lsst.io/\" class=\"external-link\" rel=\"nofollow\">https://astro-metadata-translator.lsst.io</a>\\xc2\\xa0to LSST the Docs. Since it\\'s a standalone Python package, the deployment will be done from Travis CI (following the pattern of SQuaRE\\'s Python packages).</p><p>As well, we\\'ll add <tt>astro_metadata_translator</tt> to the intersphinx configuration of pipelines.lsst.io so that links will be automatically resolved.</p>\n",
            "nan\n",
            "<ul>\\t<li>Limit write access to DM calendars to DMLT members only</li>\\t<li>Describe the DM calendars on the Developer Guide</li>\\t<li>Post a similar description on CLO.</li></ul>\n",
            "\"<p>A repository which does not use Git LFS is created and described in <tt>repos.yaml</tt>. It runs through CI, and is cloned onto a Jenkins build slave. Subsequently, the repository configuration in <tt>repos.yaml</tt> is updated to enable LFS. The build system should notice this change and update the cloned repository on disk appropriately. Currently, it doesn't.</p>\"\n",
            "<p>As developed in <a href=\"https://jira.lsstcorp.org/browse/DM-17549\" title=\"Add schema version to LSST alert schema\" class=\"issue-link\" data-issue-key=\"DM-17549\"><del>DM-17549</del></a>.</p>\n",
            "\"<p>ADQL BOX doesn't map to scisql box or qserv box.\\xc2\\xa0 So we're just going to get rid of it.</p>\"\n",
            "<p>If the activator is being used to run or list, it will not find, or hide results for modules for which there was an import error, and report to the user that that module does not exists. This should at least produce a warning that there was a problem importing a module by python so the user can track down why there was a problem importing.</p>\n",
            "<p>Spot check some epics marked done and make sure I can find deliverables.</p>\n",
            "<p>The release of pycodestyle 2.5.0 has caused flake8 to be unhappy with the current <tt>master</tt> of afw. Please fix it.</p><p>Unhappy flake8/Travis: <a href=\"https://travis-ci.org/lsst/afw/builds/488690857\" class=\"external-link\" rel=\"nofollow\">https://travis-ci.org/lsst/afw/builds/488690857</a><br/>pycodestyle release notes: <a href=\"https://pypi.org/project/pycodestyle/2.5.0/\" class=\"external-link\" rel=\"nofollow\">https://pypi.org/project/pycodestyle/2.5.0/</a><br/>Relevant Slack discussion: <a href=\"https://lsstc.slack.com/archives/C2JP8GGVC/p1549313396138300\" class=\"external-link\" rel=\"nofollow\">https://lsstc.slack.com/archives/C2JP8GGVC/p1549313396138300</a></p>\n",
            "<p>Restrict which nodes Hub and Firefly can start on.</p>\n",
            "<p>Write the self-evaluation in Ultipro for the 2018 performance evaluation.</p>\n",
            "<p>To deblend crowded fields it is useful to model stars as a single point convolved with the PSF. Through experimentation <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=pmelchior\" class=\"user-hover\" rel=\"pmelchior\">Peter Melchior</a> and I discovered that normalizing the A matrix (colors) causes too much variation in the S matrix (morphology) updates. Instead it appears that normalizing the S matrix (and fixing a single pixel) for point sources and allowing the A matrix to encode both SED and intensity information works better.</p><p>This ticket is to give users the option to use either A matrix or S matrix normalization for each source.</p>\n",
            "<p>Write the self-evaluation in Ultipro for the 2018 performance evaluation.</p>\n",
            "<p>Write the self-evaluation in Ultipro for the 2018 performance evaluation.</p>\n",
            "<p>Write the self-evaluation in Ultipro for the 2018 performance evaluation.</p>\n",
            "\"<p>Commit <tt>2d46b0cd620cc07b45baa191dcc280e9130dfeb9</tt> makes <tt>filter</tt> optional in the test <tt>Butler</tt> template for <tt>calexp</tt>. This is needed because <tt>fitler</tt> isn't handled properly.<br/>Filter is a special case because both <tt>abstract_filter</tt> and <tt>physical_filter</tt> exist but <tt>filter</tt> does not.</p>\"\n",
            "<p>Write the self-evaluation in Ultipro for the 2018 performance evaluation.</p>\n",
            "nan\n",
            "<p>Write the self-evaluation in Ultipro for the 2018 performance evaluation.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>TL;DR - Merlin messed up and merged early (there were reasons at the time), so this ticket is to apply the changes necessary here to deal with the changes to <tt>cp_pipe</tt> from review comments.</p>\n",
            "<p>As is in obs_lsstCam, the <tt>raw_visit</tt> table in registry.sqlite3 has the same per-file informarion as the <tt>raw</tt> table. But it should be\\xc2\\xa0just the visit information for optimization in obs_base. </p><p>I think this is to fix <tt>config.register.visit</tt>\\xc2\\xa0in obs_lsstCam config/ingest.py</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "\"<p>obs_lsst has some unnecessary overrides of obs_base datasets and some datasets that probably shouldn't exist at all.\\xc2\\xa0 For the latter we should try to track down where they were cargo-culted from as well.</p>\"\n",
            "<p>I have been asked to take a look at obs_lsstCam to do a mini review.</p>\n",
            "<p>Support BNL ts8 data and add raft data to the serial number dictionary</p>\n",
            "<p>Write the self-evaluation in Ultipro for the 2018 performance evaluation.</p>\n",
            "<p>Converting to pipeline tasks introduced a bug in runDataRef in MeasureCoaddSourcesTask, fix the bug.</p>\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/RFC-29\" title=\"Standardize logging and remove pex_logging\" class=\"issue-link\" data-issue-key=\"RFC-29\"><del>RFC-29</del></a> we allowed Python <tt>logging</tt> to be used in Python code so long as the log messages were forwarded to <tt>lsst.log</tt> whenever C++ logging is a possibility. A forwarder does exist as <tt>lsst.log.LogHandler</tt> and instructions for its use are available at <a href=\"https://github.com/lsst/log/blob/master/doc/mainpage.dox#L59\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/log/blob/master/doc/mainpage.dox#L59</a></p><p>To enable science pipelines to forward these Python log messages we need to setup this log handler in <tt>pipe_base</tt>.</p>\n",
            "\"<p>assembleCoadd wants to apply the bright object masks. They are inputs available to ci_hsc. gen2convert should convert them so they're available to the gen3 version when processing on ci_hsc</p>\"\n",
            "<p>If restrict lab/restrict dask are true, further filter node list in prepuller.</p>\n",
            "<p>Qserv czar is missing a length check at message table insertion; a too long error message can cause message insertion failure.  This may result in an empty message table, leading the czar to conclude that the query succeeded and subsequently attempt to access a non-existent result table.</p>\n",
            "\"<p>Got the following while butlerizing some Dev runs in the <tt>LCA-11021_RTM-006-Dev</tt> folder of the SLAC test stand data:<br/> <tt>ingest.parse WARN: translate_detector failed to translate detector: 'RTM-006'</tt></p><p>Is it valid to add to the\\xc2\\xa0raft serial dict?\\xc2\\xa0</p><p>One example file: <br/> <tt>/project/rgruendl/SLACmirror/SLACgpfs/jh_archive-test/LCA-11021_RTM/LCA-11021_RTM-006-Dev/5884D/xy_stage_acq/v0/38955/S22/E2V-CCD250-217-Dev_10.50_10.60_021_5884D_20180426174356.fits</tt></p>\"\n",
            "<p>write the Management summary</p>\n",
            "<p>Continuation from meeting on 1/16/19 (<a href=\"https://jira.lsstcorp.org/browse/DM-17229\" title=\"Telecon (1/16/19) with SAWG (LSST DESC) to discuss priority of sensor effects \" class=\"issue-link\" data-issue-key=\"DM-17229\"><del>DM-17229</del></a>).\\xc2\\xa0</p><p>See minutes in the comments\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0 \\xc2\\xa0\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p>The Gen3 formatter class for HSC raw data doesn\\'t call <tt>setFilter</tt> on the returned <tt>Exposure</tt>, which is a problem for downstream processing.\\xc2\\xa0 To fix that, we need to:</p><ul>\\t<li>add a <tt>makeFilter</tt> to <tt>FitsRawExposureFormatterBase</tt> in daf_butler, similar to the existing <tt>makeWcs</tt> and <tt>makeVisitInfo</tt> (including using it in the base class <tt>readInfoComponent</tt>.</li>\\t<li>implement <tt>makeFilter</tt> in obs_subaru appropriately.</li></ul><p>We\\'ll probably have to call the <tt>afw.image.Filter</tt> constructor with <tt>force=True</tt> to try to avoid mucking with the global variables (and hope no one else does); a better solution will have to wait for <a href=\"https://jira.lsstcorp.org/browse/RFC-541\" title=\"Design better (and Gen3-friendly) way of representing bandpass filters in code\" class=\"issue-link\" data-issue-key=\"RFC-541\"><del>RFC-541</del></a>.</p>\n",
            "<p>Write the self-evaluation in Ultipro for the 2018 performance evaluation.</p>\n",
            "<p>add logging mechanism</p>\n",
            "<p>Once <a href=\"https://jira.lsstcorp.org/browse/DM-8968\" title=\"Create deprecation decorator and doc update\" class=\"issue-link\" data-issue-key=\"DM-8968\"><del>DM-8968</del></a> is completed the developer guide needs to be updated with the new procedure for deprecating a feature. From <a href=\"https://jira.lsstcorp.org/browse/RFC-213\" title=\"Deprecation proceedure\" class=\"issue-link\" data-issue-key=\"RFC-213\"><del>RFC-213</del></a>, this should be a decorator that creates a deprecation warning in the next 6-month release and removal in the following release.</p>\n",
            "<p>PhotoCalTask passes a config object as the first argument to the DirectMatchTask constructor, however DirectMatchTask defines butler as its first argument, not config. This causes the config object to be assigned to the butler argument. If the referenceObjectLoader is passed to DirectMatchTask\\'s constructor then this has no impact. However if the referenceObjectLoader is None this will cause the task to fail.</p><p>See:<br/><a href=\"https://github.com/lsst/pipe_tasks/blob/master/python/lsst/pipe/tasks/photoCal.py#L256\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/pipe_tasks/blob/master/python/lsst/pipe/tasks/photoCal.py#L256</a><br/>and:<br/><a href=\"https://github.com/lsst/meas_astrom/blob/master/python/lsst/meas/astrom/directMatch.py#L42\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/meas_astrom/blob/master/python/lsst/meas/astrom/directMatch.py#L42</a></p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Update qserv and qserv_deploy container images an validate using CI</li>\\t<li>Put all openstack script in `obsolete/` directories, final goal is not to have kubernetes provisioning script inside qserv_deploy, but to delegate it to underlying infrastructure</li>\\t<li>update GKE procedure for creating k8s cluster</li></ul>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-17395\" title=\"Write all outputs from CharacterizeTask in ci_hsc\" class=\"issue-link\" data-issue-key=\"DM-17395\"><del>DM-17395</del></a> changed ci_hsc to write outputs for CharacterizeImageTask, but missed updating the SConsript for generating the pre-sfm run. This ticket fixes that.</p>\n",
            "<p>By default ProcessCcdTask does not write out all the outputs generated by CharacterizeImageTask. This ticket will set configs such that all outputs are written out when ci_hsc is run. This will aid in comparison checks and migration to gen3 middleware. This will not increase the run-time of ci_hsc, and will only minimally impact storage.</p>\n",
            "<p>Drop the dependency from pipe_tasks on coadd_chisquared.</p><p>Move the coadd_chisquared repository to lsst-dm/legacy-coadd_chisquared.</p><p>Update repos.yaml appropriately.</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2019_02 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-16110\" title=\"Reprocess RC2 with w_2019_02\" class=\"issue-link\" data-issue-key=\"DM-16110\"><del>DM-16110</del></a></p>\n",
            "<p>travissync job is both broken and no longer useful.</p>\n",
            "<p>A. Plazas, M. Fisher-Levine (DRP), P. Astier, P. Antilogus, A. Nomerotski (SAWG) will have a Zoom telecon on 01/16/19 regarding the status and priority of known sensor effects (e.g.,\\xc2\\xa0<a href=\"https://confluence.slac.stanford.edu/pages/viewpage.action?spaceKey=LSSTDESC&amp;title=Known+Sensor+Effects+and+Anomalies\" class=\"external-link\" rel=\"nofollow\">https://confluence.slac.stanford.edu/pages/viewpage.action?spaceKey=LSSTDESC&amp;title=Known+Sensor+Effects+and+Anomalies</a>). Some questions to guide the discussion:\\xc2\\xa0</p><ul class=\"alternate\" type=\"square\">\\t<li>What are the effects that we know or suspect will have an impact on LSST science (taking into account the science goals and requirements)?</li>\\t<li>For those effects, are there any algorithms to correct for them to acceptable levels or is this still a topic of investigation?</li>\\t<li>If there are, should they be implemented as part of the DM pipelines? What inputs would be needed?</li></ul><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p>Run jointcal with HSC-RC2 and w_2019_02</p>\n",
            "<p>JupyterLab can report the wrong stack info if the cache is considered fresh but in fact you have switched images within its lifetime.</p>\n",
            "<p>After running the test plan documented in DMTR-91 (LVV-P1), some test cases have been updated.</p><p>Therefore the LDM-533 need to be updated.</p>\n",
            "<p>Setup LDAP Groups to Support Generic JupyterHub Users</p><p>Update sssd.conf to show all_lsst Master Group</p><p>New LDAP Group for LSST2018 LSPdev Demos</p><p>Create a LSST Staff LDAP Group</p>\n",
            "<p>Create a summary analysis of the SmartDome commands, indicating which interrupt which others, etc.</p>\n",
            "<p>Initial version can probably just continue with the Gen2 of pretending these are FITS (they have readFits and writeFits for that reason).</p><p>Longer term (not this ticket), we should give them their own StorageClass and/or Formatter and maybe think about sharding them on SkyPix.</p>\n",
            "<p>Some of the columns names in dax_ppdb still has several columns that were not converted by myself from Sigma to Err. This ticket will convert the column names to the expected Err name.</p>\n",
            "<p>Fix commit error on last commit:\\xc2\\xa04fc891f69ed99fa223f464564b31d495e6902a8ba</p>\n",
            "<p>There seems to be a problem with propagating <tt>merge_footprint_XXX</tt> flags.</p><p>\\xc2\\xa0</p><p>E.g. in some DESC processing an object has</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> {</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_footprint_i\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_footprint_r\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_footprint_z\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_footprint_y\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_footprint_g\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_footprint_u\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_footprint_sky\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_peak_i\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_peak_r\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_peak_z\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_peak_y\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_peak_g\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_peak_u\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: True,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'merge_peak_sky\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: False}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>note that there is a <tt>merge_peak_sky</tt> but no <tt>merge_footprint_sky</tt>. When <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a> looked into this, it seemed as if the problem was generic rather than just for sky objects.</p>\n",
            "<p>Convert existing python docstrings to numpydoc format.</p>\n",
            "<p>To be prepared in conjunction with DRP manager / Science Lead and provided to Deputy Director (Zeljko).</p>\n",
            "<p>Lower some of the new logger INFO messages to DEBUG</p>\n",
            "<p>In the same way as we already have tickets for the creation of test plans.</p><p>We can then monitor the execution of milestones as part of the regular DMLT discussions.</p>\n",
            "<p>To be prepared in conjunction with DRP manager &amp; science lead and delivered to Deputy Director (Zeljko).</p>\n",
            "<p>Requested by Zeljko. To include an overview of capabilities as well as potential cost savings. Initial text provided by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ebellm\" class=\"user-hover\" rel=\"ebellm\">Eric Bellm</a>.</p>\n",
            "nan\n",
            "<p>Also, populate the December monthly report with milestone data, and send a summary of upcoming milestones to the <tt>dm-cams</tt> list.</p>\n",
            "<p>The adaptArgsAndRun api for PipelineTask needs to include a butler object.</p>\n",
            "<p>Options like <tt>-c label.option=True</tt> don\\'t seem to work.  If needed, I think <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=yusra\" class=\"user-hover\" rel=\"yusra\">Yusra AlSayyad</a> has a more complete how-to-reproduce.</p>\n",
            "<p>Some work did not get properly merged in pipe_supertasks on ticket-16797 before much of that content was refactored into different packages. This ticket will add that missing code to the right places.</p>\n",
            "<p>Convert <tt>lsst.afw.geom</tt>\\'s Python to Numpydoc, following the guidelines on <a href=\"https://community.lsst.org/t/2760\" class=\"external-link\" rel=\"nofollow\">community</a>.</p>\n",
            "<p>The photometric calibration output from fgcmcal is of the \"jointcal-photoCalib\" type even though a compatible \"fgcmcal-photoCalib\" dataset is defined in obs-base.\\xc2\\xa0 The primary difference between the two is the template, as \"fgcmcal-photoCalib\" does not require a tract.\\xc2\\xa0 This ticket will add the appropriate template to obs_subaru and update fgcmcal to output the new dataset type (without a fake tract).</p>\n",
            "<p>Dig out LSST Europe instructions and update for AAS - ask NCSA about account sign up page.</p>\n",
            "<p>The C++ documentation guide recommends providing package documentation using Doxygen groups, which are being phased out. The section on package documentation should be rewritten (possibly as a link) pointing developers to the new Sphinx-based system.</p>\n",
            "<p>While debugging coaddition, I have an alternate API for AssembleCoadd.run() that I use in my local copy of pipe_tasks so that I can quickly  coadd any list of tempExp DataRefs in a notebook without going through the long \"selectExposures\" task which converts a list of calexp data refs to a list of temp exp dataRefs. Would this be useful to anyone else?</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">     @pipeBase.timeMethod</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-    def run(self, dataRef, selectDataList=[]):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+    def run(self, dataRef, selectDataList=[], tempExpRefList=None):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">         \"\"\"!</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">         \\\\brief Assemble a coadd from a set of Warps</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">@@ -327,13 +327,14 @@ discussed in \\\\ref pipeTasks_multiBand (but note that normally, one would use the</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">                  - nImage: exposure count image</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">         \"\"\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">         skyInfo = self.getSkyInfo(dataRef)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-        calExpRefList = self.selectExposures(dataRef, skyInfo, selectDataList=selectDataList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-        if len(calExpRefList) == 0:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-            self.log.warn(\"No exposures to coadd\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-            return</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-        self.log.info(\"Coadding %d exposures\", len(calExpRefList))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-        tempExpRefList = self.getTempExpRefList(dataRef, calExpRefList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+        if tempExpRefList is None:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+            calExpRefList = self.selectExposures(dataRef, skyInfo, selectDataList=selectDataList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+            if len(calExpRefList) == 0:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+                self.log.warn(\"No exposures to coadd\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+                return</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+            self.log.info(\"Coadding %d exposures\", len(calExpRefList))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+            tempExpRefList = self.getTempExpRefList(dataRef, calExpRefList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Run jointcal with HSC-RC2 and w_2018_50</p>\n",
            "nan\n",
            "\"<p>Currently you can't change the config options that specify DatasetTypes to something new without explicitly registering them yourself first.\\xc2\\xa0 Make this something the command-line activator can (optionally) do for you.</p><p>\\xc2\\xa0</p>\"\n",
            "<p>DeblendAndMeasureTask has not been updated since 2014. It has bitrotted.\\xc2\\xa0\\xc2\\xa0</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_50 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-16109\" title=\"Reprocess RC2 with w_2018_50\" class=\"issue-link\" data-issue-key=\"DM-16109\"><del>DM-16109</del></a></p>\n",
            "<p>PipelineTask command line activator should be able to accept config overrides which are lists from the command line.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-15139\" title=\"Rename invert() and getInverse() to inverted()\" class=\"issue-link\" data-issue-key=\"DM-15139\"><del>DM-15139</del></a> standardized the method for returning an inverse transform to <tt>inverted</tt> but left the old <tt>getInverse</tt> and <tt>invert</tt> methods for backwards compatibility (even though all DM stack code was updated).</p><p>Please remove the deprecated methods after a suitable time period has elapsed, e.g. after the next major release.</p>\n",
            "<p>Format sql queries with query parameters for better debugging</p>\n",
            "<p>See if we can get the qa_explorer plots (including the ginga display) working in the JupyterLab environment. </p>\n",
            "<p>nopytest_test_coadds.py throws the following warnings in many places:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">lsst.afw.image WARN: Could not parse options; writing with defaults:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"src/PropertySet.cc\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line 189, in T lsst::daf::base::PropertySet::get(</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> string&amp;) </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> [with T = std::shared_ptr&lt;lsst::daf::base::PropertySet&gt;; std::string = std::basic_string&lt;</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">char</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    image not found {0}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">lsst::pex::exceptions::NotFoundError: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'image not found\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This seems to be coming from:<br/><a href=\"https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/posixStorage.py#L642\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/posixStorage.py#L642</a><br/>which calls and executes to:<br/><a href=\"https://github.com/lsst/afw/blob/a4679bc1e1d40d112e1484359a353fee477c1331/python/lsst/afw/image/image/fitsIoWithOptions.py#L97\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/afw/blob/a4679bc1e1d40d112e1484359a353fee477c1331/python/lsst/afw/image/image/fitsIoWithOptions.py#L97</a></p><p>Where it expects a property of the property set to be called `image`. However, the options that are passed through the call chain are:<br/>`<br/><span class=\"error\">&#91;&#39;visit&#39;, &#39;ccd&#39;&#93;</span><br/>`</p><p>This optional prameter is generated:<br/><a href=\"https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/posixStorage.py#L637\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/posixStorage.py#L637</a><br/>and that variable comes from:<br/><a href=\"https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/posixStorage.py#L249\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/posixStorage.py#L249</a><br/>which in turn comes from the butler here:<br/><a href=\"https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butler.py#L1421\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butler.py#L1421</a><br/>the location variable is created here:<br/><a href=\"https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butler.py#L1297\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butler.py#L1297</a><br/>That optional data ultimately is initialized here:<br/><a href=\"https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butlerLocation.py#L207\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butlerLocation.py#L207</a><br/>So whatever is creating butler locations (Some repository or mapper) is not adding the correct fields, or afw should be looking for different things to write.</p><p>These are just notes for what I have found so far, to help anyone who gets to this ticket. I am tagging <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a> because I think he was the last one to work with the additionalData code, and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a> because he may be familiar with this work, or how it impacts gen3 middleware and will know if this is even worth pursuing. Also tagging <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=yusra\" class=\"user-hover\" rel=\"yusra\">Yusra AlSayyad</a>, as I am not sure if I put this in the right epic.</p>\n",
            "<p>Following the departure of Bob Armstrong from the project, no further work is planned on shear measurement during the F18 cycle.</p>\n",
            "<p>Run jointcal with HSC-RC2 and w_2018_48</p>\n",
            "<p>Jointcal got caught during the <a href=\"https://jira.lsstcorp.org/browse/RFC-45\" title=\"Process for maintaining Copyright information in DM source code\" class=\"issue-link\" data-issue-key=\"RFC-45\"><del>RFC-45</del></a> copyright/license uncertainty and many of its files don\\'t follow any of the proposals there. We should get them cleaned up, following whatever standard was finalized in that RFC.</p>\n",
            "nan\n",
            "<p>Fix compiler warnings in meas model fit related to marking methods as overloads</p>\n",
            "<p>To include:</p><ul>\\t<li>Images repository</li>\\t<li>LDM-564</li>\\t<li>LDM-503</li></ul>\n",
            "<p>Rather than just populating the monthly report with milestones which are due that month, I should be able to generate and circulate a summary of all upcoming milestones through the duration of construction.</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_48 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-16101\" title=\"Reprocess RC2 with w_2018_48\" class=\"issue-link\" data-issue-key=\"DM-16101\"><del>DM-16101</del></a></p>\n",
            "<p>The LVV-T368 test case, step #2, has a typo (a missing <tt>~/</tt> prefix to the string <tt>notebooks</tt>). Please fix it.</p>\n",
            "<p>Started using this terminology informally on <a href=\"https://jira.lsstcorp.org/browse/DM-15424\" title=\"Revisit LimitedRegistry concept\" class=\"issue-link\" data-issue-key=\"DM-15424\"><del>DM-15424</del></a>, and it really clarified the docs.\\xc2\\xa0 Actually renaming the class would probably help even more, but belongs on another ticket (this one).</p><p>\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>In <a href=\"https://github.com/lsst-dm/dmtn-101\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/dmtn-101</a>, there are commands like {{\\\\inputData</p>{CBP}<p>}}. These are being detected by lsst-projectmeta-kit as <tt>\\\\input</tt> commands.</p>\n",
            "<p>This will create symmetry with teardown and, I hope, get rid of the problem where logout that is not followed by closing the window re-runs init() which then recreates the resources, leading to confusion on later logins.</p>\n",
            "<p>Per my mail to various luminaries of 2017-08-01, we have converged on having three requirements documents for the Science Pipelines: L1 (document ID TBD), L2 (TBD) and CPP (TBD), which will map through LDM-151 (Pipelines design) to three test specifications: L1 (TBD), L2 (LDM-534) and CPP (TBD).</p><p>Those requirements documents will capture all of the Pipelines requirements.</p><p>Update LDM-503 and the document tree figure to reflect this.</p>\n",
            "<p>Observation: When images loaded, the tab for images become active.</p><p>Most cases\\xc2\\xa0we want\\xc2\\xa0the tab to become active when images load.\\xc2\\xa0 This does not always look correct when many images load slowly as in LSST testing environment.</p><p>This ticket is to record the observation and add more use cases later so we can discuss and decide if the behavior needs to change.</p>\n",
            "<p>We can simplify configuration if we just expose the flag specifying authentication type (CILogon vs Github) and then choose the appropriate class based on that.</p>\n",
            "<p>See if we can get rid of that now.</p>\n",
            "\"<p>Per LPM-121, LSE-279, all LSST systems should be using KRB for authentication and LDAP for authorization. Currently using LDAP for both (proxies to KRB).\\xc2\\xa0The longer this remains undone, the greater the deviation from LSE-279. Machines need to support LSST' s Unified IAM project.</p>\"\n",
            "<p><font color=\"#000000\">Match what is already being done for NCSA 3003 systems, refactor code, make changes mandated by security vetting.</font></p>\n",
            "<p>Create the fy19 requisition for SLAC budgets</p>\n",
            "<p>Monthly review of LSST-MPC collaboration status, presentation of progress, review of issues.</p>\n",
            "nan\n",
            "<p>I made a number of cleanups of method names in <a href=\"https://jira.lsstcorp.org/browse/DM-9071\" title=\"Experiment with ProcessPoolExecutor for reading/writing jointcal results\" class=\"issue-link\" data-issue-key=\"DM-9071\">DM-9071</a>, in this commit:</p><p><a href=\"https://github.com/lsst/jointcal/commit/9efc5d23808b5e6f33d69e7ccd9bcf6c0bc844cb\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/jointcal/commit/9efc5d23808b5e6f33d69e7ccd9bcf6c0bc844cb</a></p><p>These should be picked out of that ticket and pushed to master.</p>\n",
            "<p>I think I\\'ve found a parsing bug in the ANTLR part of the czar, when parsing out the incoming SQL statement:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">mysql&gt; SELECT source_id, designation, ra, decl, w1mpro, w1sigmpro FROM `wise_00`.`allwise_p3as_psd` WHERE source_id = \\'2813m031_ac51-041856\\';</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ERROR 4110 (Proxy): Query processing error: QI=?: Failed to instantiate query: NoSuchTable:Table \\'`wise_00`.`allwise_p3as_psd`\\' does not exist.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> mysql&gt; SELECT source_id, designation, ra, decl, w1mpro, w1sigmpro FROM wise_00.allwise_p3as_psd WHERE source_id = \\'2813m031_ac51-041856\\';</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> +-----------------------+--------------------++-------------------------++-------------------+</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">|source_id|designation|ra|decl|w1mpro|w1sigmpro|</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+-----------------------+--------------------++-------------------------++-------------------+</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">|2813m031_ac51-041856|J184558.41-023707.0|281.4933836|-2.6186303|4.269|0.269|</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+-----------------------+--------------------++-------------------------++-------------------+</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> 1 row in set (0.10 sec)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>If you escape the schema or the table name with quotes, it doesn\\'t run, although it should. Probably just need to escape out somewhere in the parsing before we do whatever checking we\\'re doing (edited)<br/> I can also make a jira thing if someone wants me to for this</p><p>Andy Salnikov <span class=\"error\">&#91;12:15 PM&#93;</span><br/> I\\'d be surprised if quoting was that broken. It could also be case-sensitivity issue, can you try all-cap quoted names?</p><p>Christine Banek <span class=\"error\">&#91;12:17 PM&#93;</span></p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">mysql&gt; SELECT source_id, designation, ra, decl, w1mpro, w1sigmpro FROM `wise_00`.`ALLWISE_P3AS_PSD` WHERE source_id = \\'2813m031_ac51-041856\\';</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ERROR 4110 (Proxy): Query processing error: QI=?: Failed to instantiate query: NoSuchTable:Table \\'`wise_00`.`ALLWISE_P3AS_PSD`\\' does not exist.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> mysql&gt; SELECT source_id, designation, ra, decl, w1mpro, w1sigmpro FROM `WISE_00`.`ALLWISE_P3AS_PSD` WHERE source_id = \\'2813m031_ac51-041856\\';</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ERROR 4110 (Proxy): Query processing error: QI=?: Failed to instantiate query: NoSuchTable:Table \\'`WISE_00`.`ALLWISE_P3AS_PSD`\\' does not exist.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Andy Salnikov <span class=\"error\">&#91;12:17 PM&#93;</span><br/> And maybe `SHOW DATABASES` and `SHOW TABLES` to figure out correct table name case.</p><p>Christine Banek <span class=\"error\">&#91;12:17 PM&#93;</span><br/> it looks all lowercase in mysql client<br/> also, the quoting works like a charm for column names<br/> just not for schema / table names</p><p>Andy Salnikov <span class=\"error\">&#91;12:19 PM&#93;</span><br/> OK, then it is probably parser or qserv bug, JIRA is probably the best next step.</p>\n",
            "nan\n",
            "<p>Security vetting for the new hardware in the L1 Test Stand system.</p>\n",
            "<p>Run jointcal with HSC-RC2 and w_2018_46</p>\n",
            "<p>Implementation of <a href=\"https://jira.lsstcorp.org/browse/RFC-526\" title=\"Add FGCM as a 3rd party package to the stack and move fgcmcal from lsst-dm to lsst\" class=\"issue-link\" data-issue-key=\"RFC-526\"><del>RFC-526</del></a>:</p><p>The FGCM (pure python) third-party package (<a href=\"https://github.com/erykoff/fgcm\" class=\"external-link\" rel=\"nofollow\">https://github.com/erykoff/fgcm</a>) will be added to the stack (via a github fork to allow easy continued development), and the fgcmcal package currently hosted by lsst-dm (<a href=\"https://github.com/lsst-dm/fgcmcal\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/fgcmcal</a>) will be moved to lsst_distrib. There are no additional dependencies that will have to be added that are not already in lsst_distrib.</p><p>\\xc2\\xa0This ticket adds fgcm and fgcmcal to lsst_distrib</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_46 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-16100\" title=\"Reprocess RC2 with w_2018_46\" class=\"issue-link\" data-issue-key=\"DM-16100\"><del>DM-16100</del></a></p>\n",
            "<p>Implementation of <a href=\"https://jira.lsstcorp.org/browse/RFC-526\" title=\"Add FGCM as a 3rd party package to the stack and move fgcmcal from lsst-dm to lsst\" class=\"issue-link\" data-issue-key=\"RFC-526\"><del>RFC-526</del></a>:</p><p>The FGCM (pure python) third-party package (<a href=\"https://github.com/erykoff/fgcm\" class=\"external-link\" rel=\"nofollow\">https://github.com/erykoff/fgcm</a>) will be added to the stack (via a github fork to allow easy continued development), and the fgcmcal package currently hosted by lsst-dm (<a href=\"https://github.com/lsst-dm/fgcmcal\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/fgcmcal</a>) will be moved to lsst_distrib. There are no additional dependencies that will have to be added that are not already in lsst_distrib.</p><p>This ticket moves fgcmcal from lsst-dm to dm</p>\n",
            "nan\n",
            "nan\n",
            "<p>create Jira tickts for the test specs assigned to relevant people with reasonable dates on them\\xc2\\xa0 .. tagged so we can find them easily .. ?</p>\n",
            "<p>Update Gaia performance in overview paper - include new references.</p>\n",
            "<p>Run jointcal with HSC-RC2 and w_2018_44</p>\n",
            "nan\n",
            "<p>Bug encountered while trying to test the new astro metadata package that fixes obs_decam observatory longitude:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">dcrAssembleCoadd FATAL: Failed on dataId=DataId(initialdata={\\'filter\\': \\'g\\', \\'patch\\': \\'0,0\\', \\'tract\\': 0}, tag=set()): ValueError: operands could not be broadcast together with shapes (2003,2003) (2000,2000) (2003,2003) </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/sullivan/LSST/code/eups_distrib/stack/miniconda3-4.5.4-fcd27eb/DarwinX86/pipe_base/16.0-13-gb122224+4/python/lsst/pipe/base/cmdLineTask.py\", line 388, in __call__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = self.runTask(task, dataRef, kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/sullivan/LSST/code/eups_distrib/stack/miniconda3-4.5.4-fcd27eb/DarwinX86/pipe_base/16.0-13-gb122224+4/python/lsst/pipe/base/cmdLineTask.py\", line 447, in runTask</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return task.runDataRef(dataRef, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/sullivan/LSST/code/eups_distrib/stack/miniconda3-4.5.4-fcd27eb/DarwinX86/pipe_base/16.0-13-gb122224+4/python/lsst/pipe/base/timer.py\", line 149, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/sullivan/LSST/code/eups_distrib/build/pipe_tasks/python/lsst/pipe/tasks/dcrAssembleCoadd.py\", line 217, in runDataRef</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    results = AssembleCoaddTask.runDataRef(self, dataRef, selectDataList=selectDataList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/sullivan/LSST/code/eups_distrib/stack/miniconda3-4.5.4-fcd27eb/DarwinX86/pipe_base/16.0-13-gb122224+4/python/lsst/pipe/base/timer.py\", line 149, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/sullivan/LSST/code/eups_distrib/build/pipe_tasks/python/lsst/pipe/tasks/assembleCoadd.py\", line 361, in runDataRef</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    inputData.weightList, supplementaryData=supplementaryData)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/sullivan/LSST/code/eups_distrib/build/pipe_tasks/python/lsst/pipe/tasks/dcrAssembleCoadd.py\", line 378, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    modelWeights)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/sullivan/LSST/code/eups_distrib/build/pipe_tasks/python/lsst/pipe/tasks/dcrAssembleCoadd.py\", line 521, in dcrAssembleSubregion</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    maskedImage.image.array *= modelWeights</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ValueError: operands could not be broadcast together with shapes (2003,2003) (2000,2000) (2003,2003) </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>DRP accidentally let a print statement slip through to master. Remove it.</p><p>This is a first ticket Andres, and also includes familiarizing himself with our workflow.\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_44 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-16099\" title=\"Reprocess RC2 with w_2018_44\" class=\"issue-link\" data-issue-key=\"DM-16099\"><del>DM-16099</del></a></p>\n",
            "<p>Given that Sophie has done a lot of work on determining star v galaxy probabilities, work with here to determine an appropriate form for a Probability of an object being a star vs a galaxy given magnitude. This may involve discussions with Yusra as well, as she has some experience in this area as well.</p>\n",
            "<p>On Slack, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=krzys\" class=\"user-hover\" rel=\"krzys\">Krzysztof Findeisen</a> writes:</p><blockquote><p>suggested improvement for LDM-294: I don\\'t see any mention of `verify`, `ap_verify`, or `ap_pipe` in the Appendix A table of products (though `verify_metrics` is listed as part of Level 2 Quality Control). I know `verify`, at least, has a designated product owner...<br/>(it would also help if the table repeated its header on each page, I think most long-table LaTeX packages have an option for it)</p></blockquote><p>These all sound like good suggestions to me.</p>\n",
            "<p>From a customer:</p><p>On our Qserv install queries using NOT LIKE return the same as those using LIKE, we\\xe2\\x80\\x99re on a fairly recent build (a week or so old). Seems like an issue but I\\xe2\\x80\\x99m not sure if LIKE is supposed to be implemented or not.</p><p>\\xc2\\xa0</p><p>select shortName from Filter where shortName LIKE \\xe2\\x80\\x98Z\\xe2\\x80\\x99;</p><p>\\xc2\\xb1----------+</p><div class=\\'table-wrap\\'><table class=\\'confluenceTable\\'><tbody><tr><td class=\\'confluenceTd\\'> shortName </td></tr></tbody></table></div><p>\\xc2\\xb1----------+</p><div class=\\'table-wrap\\'><table class=\\'confluenceTable\\'><tbody><tr><td class=\\'confluenceTd\\'> Z </td></tr></tbody></table></div><p>\\xc2\\xb1----------+</p><p>select shortName from Filter where shortName NOT LIKE \\xe2\\x80\\x98Z\\xe2\\x80\\x99;<br/>\\xc2\\xb1----------+</p><div class=\\'table-wrap\\'><table class=\\'confluenceTable\\'><tbody><tr><td class=\\'confluenceTd\\'> shortName </td></tr></tbody></table></div><p>\\xc2\\xb1----------+</p><div class=\\'table-wrap\\'><table class=\\'confluenceTable\\'><tbody><tr><td class=\\'confluenceTd\\'> Z </td></tr></tbody></table></div><p>\\xc2\\xb1----------+</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>...we need to verify LIKE/NOT LIKE is getting handled correctly, and fix it if not.\\xc2\\xa0</p><p>Note, this kind of thing should not be falling through the cracks with antlr4 after <a href=\"https://jira.lsstcorp.org/browse/DM-16218\" title=\"verify QSMySQLListener adapters handle or throw grammar possibilities\" class=\"issue-link\" data-issue-key=\"DM-16218\"><del>DM-16218</del></a> is through review and checked in. (If the NOT in NOT LIKE is not handled then the parser code should throw a ParseException)</p>\n",
            "<p>Task is misnamed - should be called something like `runEotestTask.py`. Nobody uses this at the moment, so no RFC should be required.</p><p>Also, add Travis checking and reformat docstring for flake8.</p>\n",
            "<p><tt>lsst-dev01</tt> has access to all the GPFS filesystems available to the Verification Cluster (ie, as documented at <a href=\"https://developer.lsst.io/services/verification.html#verification-gpfs\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/services/verification.html#verification-gpfs</a>). However, if you didn\\'t already know that, you wouldn\\'t discover it by reading <a href=\"https://developer.lsst.io/services/lsst-dev.html\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/services/lsst-dev.html</a>. Please cross-link this documentation appropriately.</p>\n",
            "<p><a href=\"https://developer.lsst.io/processes/workflow.html#tickets\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/processes/workflow.html#tickets</a> makes various claims about the association of different types of issue (story/bug/improvement) with epics. In particular, it claims that \"bug\" and \"improvement\" type issues are not associated with epics.</p><p>This is simply incorrect: bugs and improvements should be associated with epics in just the same way as stories, and are treated identically for the purposes of earned value accounting.</p><p>(I think this bad documentation is based on a misunderstanding of the outcome of <a href=\"https://jira.lsstcorp.org/browse/RFC-43\" title=\"Semantics of JIRA issue types\" class=\"issue-link\" data-issue-key=\"RFC-43\"><del>RFC-43</del></a>.)</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=boutigny\" class=\"user-hover\" rel=\"boutigny\">Dominique Boutigny</a> reports that he\\'s found a reference catalog with fluxSigma errors that can no longer be read by our code in w_2018_39 and later.</p><p>How to reproduce:</p><p>\\xc2\\xa0</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> lsst.meas.algorithms</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">keys = lsst.meas.algorithms.getRefFluxKeys(ref.schema, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'lsst_u_smeared\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">assert</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> keys[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">] is not None\\xc2\\xa0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I suspect new backwards-compatibility code for flux to instFlux broke older backwards-compatiblity code for Sigma to Err.</p>\n",
            "<p>Write a prototype obs_metadata implementation that can translate FITS standard header cards for instrument, telescope and observation date.</p>\n",
            "<p>As the shared stack at /software has been updated to w_2018_41<br/>(<a href=\"https://community.lsst.org/t/shared-stack-updates/3328\" class=\"external-link\" rel=\"nofollow\">https://community.lsst.org/t/shared-stack-updates/3328</a> ) and the DESDM stack uses it, redo the minimum necessary steps and update <a href=\"https://jira.lsstcorp.org/browse/DM-16054\" title=\"Update to run hsc_test_hscmini.wcl with w_2018_36\" class=\"issue-link\" data-issue-key=\"DM-16054\"><del>DM-16054</del></a> to run hsc_test_hscmini.wcl \\xc2\\xa0with \\xc2\\xa0w_2018_41.</p>\n",
            "<p>Run jointcal with the HSC-RC2 dataset, the w_2018_41 stack</p>\n",
            "<p>Disk/optics were ordered in lieu of the entire system and parts were used from NCSA for this demo\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_42 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-16095\" title=\"Reprocess RC2 with w_2018_42\" class=\"issue-link\" data-issue-key=\"DM-16095\"><del>DM-16095</del></a></p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_41 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-16011\" title=\"Reprocess RC2 with w_2018_41\" class=\"issue-link\" data-issue-key=\"DM-16011\"><del>DM-16011</del></a></p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_38 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-15690\" title=\"Reprocess RC2 with w_2018_38\" class=\"issue-link\" data-issue-key=\"DM-15690\"><del>DM-15690</del></a></p>\n",
            "nan\n",
            "nan\n",
            "<p>This ticket covers work associated with reviewing tickets and advising with regards to numpydoc conversions. Primarily for <a href=\"https://jira.lsstcorp.org/browse/DM-15347\" title=\"meas_base to numpydoc format\" class=\"issue-link\" data-issue-key=\"DM-15347\"><del>DM-15347</del></a>.</p>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/DM-16286\" title=\"Update version checks in EUPS stub packages to match lsstsw minimums\" class=\"issue-link\" data-issue-key=\"DM-16286\"><del>DM-16286</del></a>, the shared stack build on Princeton systems is broken. We\\'ll need to bootstrap a new shared stack to revive it.</p>\n",
            "<p>It looks like PipelineTask.runQuantum (at least) uses iteration through the Config instance to find all of the input and output DatasetTypes.\\xc2\\xa0 This at least partially ignores the get*DatasetType methods, which should be permitted to add and modify the set of DatasetTypes processed.</p><p>Fixing this may involving changing the signatures of the get*DatasetType methods a bit - there is at least some information (e.g. \"scalar\") that is currently only available from the configs, and that probably needs to be forwarded through the get*DatasetType methods so they can be considered the final source of truth by PipelineTask and all activators.</p><p>\\xc2\\xa0</p>\n",
            "<p>Tiago would like TSS added to the types of tickets sqrbot knows about.</p>\n",
            "<p>Look at the java code in TSS</p>\n",
            "<p>At least one telecon and trying to sort out the invitee list</p>\n",
            "<p>I wrote a brief orientation guide to meas_base. Include it in the meas_base Sphinx documentation.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-15537\" title=\"Rename Sensor to Detector in Gen3 schema\" class=\"issue-link\" data-issue-key=\"DM-15537\"><del>DM-15537</del></a> renamed couple of things in gen3 registry, those names should also be changed in pipe_supertask.</p>\n",
            "<p>Old stack:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">source /software/lsstsw/stack3_20171023/loadLSST.bash</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">setup lsst_sims -t sims</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">echo $SIMS_CATUTILS_DIR</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># /software/lsstsw/stack3_20171023/stack/miniconda3-4.3.21-10a4fa6/Linux64/sims_catUtils/2.9.0.sims</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>New stack:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[yusra@lsst-dev01 ~]$ source /software/lsstsw/stack/loadLSST.bash</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Note: use devtoolset-6 in conjunction with this stack.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[yusra@lsst-dev01 ~]$ setup lsst_sims -t sims</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Ignoring unsupported tags in VRO: sims</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">setup: Unsupported tag(s): sims</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "nan\n",
            "nan\n",
            "<p>Check test.cilogon.org for regressions.</p>\n",
            "<p>There seems to have been a merge conflict on the notebook in</p><p><a href=\"https://github.com/womullan/watch\" class=\"external-link\" rel=\"nofollow\">https://github.com/womullan/watch</a></p><p>\\xc2\\xa0</p><p>I got Jeff to check out an old one which is fine for now,</p><p>There is also some code in the notebook which should just be in a python file.</p>\n",
            "<p>Run jointcal with the HSC-RC2 dataset, the w_2018_42 stack</p>\n",
            "\"<p>Something seems to not be quite right in the calculation of cross-correlations in <tt>MakeBrighterFatterKernelTask</tt>, as the sum of the cross-correlations are coming out much higher than they should be (I think, based on the code it was ported from at least).</p><p>Find out why, and once that's done, put the config value\\xc2\\xa0<tt>xcorrCheckRejectLevel</tt> back to the nominal value of 0.2 (or was it 0.1, check Will's code), if appropriate.</p>\"\n",
            "<p>The test <tt>testReadFitsWithOptions</tt> in <tt>test_maskedImageIO.py</tt> assumes that <tt>afwData is available, so it needs a</tt></p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">@unittest</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.skipIf(dataDir is None, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"afwdata not setup\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">) </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>decorator</p>\n",
            "nan\n",
            "<p>Thursday 18</p>\n",
            "<p>DO management seciton and summary.</p>\n",
            "<p>Added PST and PSTN to the texmf</p>\n",
            "<p>With <tt>w_2018_41</tt>, <tt>meas_mosaic</tt> fails with errors like</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">root WARN: Failed to read {\\'ccd\\': 24, \\'visit\\': 1324, \\'tract\\': 9615, \\'filter\\': \\'HSC-I\\'}: \"Field with name \\'i_instFlux\\' not found\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>and then Segmentation fault from zero matchList (<tt>Mosaic INFO: len(matchList) = 0 []</tt> ) </p><p>One (longer than necessary) command to reproduce is </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">mosaic.py /datasets/hsc/repo --calib /datasets/hsc/repo/CALIB --rerun RC/w_2018_41/DM-16011:private/usename/   --numCoresForReadSource=12 --id ccd=0..8^10..103 visit=26024^26028^26032^26036^26044^26046^26048^26050^26058^26060^26062^26070^26072^26074^26080^26084^26094 tract=9615 </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The same command (with the same input data) works using the <tt>w_2018_39</tt> stack. </p>\n",
            "<p>Implementation of <a href=\"https://jira.lsstcorp.org/browse/RFC-526\" title=\"Add FGCM as a 3rd party package to the stack and move fgcmcal from lsst-dm to lsst\" class=\"issue-link\" data-issue-key=\"RFC-526\"><del>RFC-526</del></a>:</p><p>The FGCM (pure python) third-party package (<a href=\"https://github.com/erykoff/fgcm\" class=\"external-link\" rel=\"nofollow\">https://github.com/erykoff/fgcm</a>) will be added to the stack (via a github fork to allow easy continued development), and the fgcmcal package currently hosted by lsst-dm (<a href=\"https://github.com/lsst-dm/fgcmcal\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/fgcmcal</a>) will be moved to lsst_distrib. There are no additional dependencies that will have to be added that are not already in lsst_distrib.</p><p>This ticket moves the third-party fgcm ticket to the stack.</p>\n",
            "nan\n",
            "<p>The old shared stack on lsst-dev01 contained a version of <tt>git_lfs</tt> that was easy to <tt>setup</tt> with eups.\\xc2\\xa0 This appears to be missing with the new shared stack from <a href=\"https://jira.lsstcorp.org/browse/DM-16129\" title=\"Refresh shared stack on lsst-dev\" class=\"issue-link\" data-issue-key=\"DM-16129\"><del>DM-16129</del></a></p>\n",
            "<p>Setup:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">source /software/lsstsw/stack/loadLSST.bash </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">setup lsst_distrib </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[yusra@lsst-dev01 notebooks]$ jupyter notebook --no-browser --port=8701</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20181012/python/miniconda3-4.5.4/envs/lsst-scipipe/bin/jupyter-notebook\", line 4, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    import notebook.notebookapp</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20181012/python/miniconda3-4.5.4/envs/lsst-scipipe/lib/python3.6/site-packages/notebook/notebookapp.py\", line 40, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    ioloop.install()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20181012/python/miniconda3-4.5.4/envs/lsst-scipipe/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 210, in install</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    assert (not ioloop.IOLoop.initialized()) or \\\\</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">AttributeError: type object \\'IOLoop\\' has no attribute \\'initialized\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Looks like the API change in <a href=\"https://jira.lsstcorp.org/browse/DM-15663\" title=\"Start pipeline conversion process for DetectCoaddSources\" class=\"issue-link\" data-issue-key=\"DM-15663\"><del>DM-15663</del></a> broken coaddDriver and gave the following error:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> Traceback:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20181012/stack/miniconda3-4.5.4-fcd27eb/Linux64/ctrl_pool/16.0-3-gbc759ec+15/python/lsst/ctrl/pool/parallel.py\", line 509, in logOperation</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    yield</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20181012/stack/miniconda3-4.5.4-fcd27eb/Linux64/pipe_drivers/16.0-6-gf9cb114+19/python/lsst/pipe/drivers/coaddDriver.py\", line 323, in coadd</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    self.detectCoaddSources.write(coadd, detResults, patchRef)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">TypeError: write() takes 3 positional arguments but 4 were given</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>One command to reproduce is:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">coaddDriver.py  /datasets/hsc/repo --calib /datasets/hsc/repo/CALIB/ --rerun RC/w_2018_41/DM-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">16011</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">private</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/user/name --batch-type=slurm --mpiexec=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'-bind-to socket\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> --job  bug --time </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">600</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> --cores </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">24</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  --id tract=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">9697</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> patch=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">4</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">,</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">8</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> filter=HSC-I --selectId ccd=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">..</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">8</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">^</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">10</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">..</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">103</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> visit=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">35892</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">^</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">36140</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">^</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">36144</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>I installed lsst_distrib 16.0 following the instructions at <a href=\"https://pipelines.lsst.io/v/16-0/install/newinstall.html\" class=\"external-link\" rel=\"nofollow\">https://pipelines.lsst.io/v/16-0/install/newinstall.html</a>. I then tried to run the demo following the instructions at <a href=\"https://pipelines.lsst.io/v/16-0/install/demo.html\" class=\"external-link\" rel=\"nofollow\">https://pipelines.lsst.io/v/16-0/install/demo.html</a>. The result:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[jds@magpie lsst_dm_stack_demo-16.0]$ ./bin/demo.sh </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Setting up: astrometry_net_data             Flavor: DarwinX86  Version: LOCAL:/Users/jds/Projects/LSST/src/lsst_dm_stack_demo-16.0/astrometry_net_data</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/jds/Projects/LSST/stack/stack/miniconda3-4.3.21-10a4fa6/DarwinX86/pipe_tasks/16.0+1/bin/processCcd.py\", line 23, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    from lsst.pipe.tasks.processCcd import ProcessCcdTask</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/jds/Projects/LSST/stack/stack/miniconda3-4.3.21-10a4fa6/DarwinX86/pipe_tasks/16.0+1/python/lsst/pipe/tasks/processCcd.py\", line 22, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    from lsst.ip.isr import IsrTask</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/jds/Projects/LSST/stack/stack/miniconda3-4.3.21-10a4fa6/DarwinX86/ip_isr/16.0+1/python/lsst/ip/isr/__init__.py\", line 27, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    from .isrFunctions import *</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/jds/Projects/LSST/stack/stack/miniconda3-4.3.21-10a4fa6/DarwinX86/ip_isr/16.0+1/python/lsst/ip/isr/isrFunctions.py\", line 26, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    import lsst.afw.geom as afwGeom</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/jds/Projects/LSST/stack/stack/miniconda3-4.3.21-10a4fa6/DarwinX86/afw/16.0+1/python/lsst/afw/__init__.py\", line 23, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    import lsst.utils</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/jds/Projects/LSST/stack/stack/miniconda3-4.3.21-10a4fa6/DarwinX86/utils/16.0/python/lsst/utils/__init__.py\", line 28, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    import lsst.pex.exceptions</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/jds/Projects/LSST/stack/stack/miniconda3-4.3.21-10a4fa6/DarwinX86/pex_exceptions/16.0/python/lsst/pex/exceptions/__init__.py\", line 26, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    from .wrappers import *</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/jds/Projects/LSST/stack/stack/miniconda3-4.3.21-10a4fa6/DarwinX86/pex_exceptions/16.0/python/lsst/pex/exceptions/wrappers.py\", line 33, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    from future.utils import with_metaclass</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ModuleNotFoundError: No module named \\'future\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>(The above is on a Mac, but I get the same on Linux)</p><p>The problem arises because of the following line in <tt>bin/demo.sh</tt>:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># Tell the stack where to find astrometric reference catalogs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">setup --nolocks -v -r ./astrometry_net_data astrometry_net_data</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Having <tt>setup</tt> lsst_distrib, I already have a version of astrometry_net_data configured. It, in turn, depends on a bunch of other packages:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ eups list -m astrometry_net_data  | xargs cat</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">if (type == exact) {</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(sconsUtils      -j 16.0)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(scons           -j 3.0.0.lsst1+3)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(python          -j 0.0.8)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(python_future   -j 0.16.0+3)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(pytest          -j 3.2.0.lsst4+1)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(pytest_flake8   -j 0.9.1+8)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(flake8          -j 3.5.0+8)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(python_mccabe   -j 0.6.1+9)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(pycodestyle     -j 2.3.1+3)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(pyflakes        -j 1.6.0+2)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(pep8_naming     -j 0.4.1+3)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(pytest_xdist    -j 1.20.1.lsst4+1)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(pytest_forked   -j 0.2.lsst4+1)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(python_execnet  -j 1.4.1.lsst4+1)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(pytest_session2file -j 0.1.9+9)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupOptional(doxygen         -j 1.8.13.lsst2)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">} else {</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   setupRequired(sconsUtils 16.0 [&gt;= 16.0])</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The lsst_dm_stack_demo version of astrometry_net_data has no dependencies:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ cat astrometry_net_data/ups/astrometry_net_data.table </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>When I set up this version, all the dependencies are removed from my configured stack, and it breaks.</p><p>An easy workaround is to change the line to read:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">setup --nolocks -v -j -r ./astrometry_net_data astrometry_net_data</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Which will not drop the dependencies of the old astrometry_net_data when setting up the new version.</p>\n",
            "<p>Run jointcal with the HSC-RC2 dataset, the w_2018_38 stack, with the following config overrides:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.astrometryRefObjLoader.ref_dataset_name=\\'ps1_pv3_3pi_20170110\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.photometryRefObjLoader.ref_dataset_name=\\'ps1_pv3_3pi_20170110\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.astrometryRefObjLoader.filterMap={\\'B\\': \\'g\\', \\'r2\\': \\'r\\', \\'N1010\\': \\'z\\', \\'N816\\': \\'i\\', \\'I\\': \\'i\\', \\'N387\\': \\'g\\', \\'i2\\': \\'i\\', \\'R\\': \\'r\\', \\'N921\\': \\'z\\', \\'N515\\': \\'g\\', \\'V\\': \\'r\\'}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.photometryRefObjLoader.filterMap={\\'B\\': \\'g\\', \\'r2\\': \\'r\\', \\'N1010\\': \\'z\\', \\'N816\\': \\'i\\', \\'I\\': \\'i\\', \\'N387\\': \\'g\\', \\'i2\\': \\'i\\', \\'R\\': \\'r\\', \\'N921\\': \\'z\\', \\'N515\\': \\'g\\', \\'V\\': \\'r\\'}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>In the future, the config overrides won\\'t be needed once <a href=\"https://jira.lsstcorp.org/browse/DM-15606\" title=\"Add jointcal config defaults to at least obs_subaru\" class=\"issue-link\" data-issue-key=\"DM-15606\"><del>DM-15606</del></a> is merged. </p>\n",
            "<p>Add a LongString data type into table data model to indicate a very long string.</p><p>This is a way to optimize storage and limit capability.</p>\n",
            "<p>This ticket will implement <a href=\"https://jira.lsstcorp.org/browse/RFC-107\" title=\"Wrap python docstring text after 79 characters\" class=\"issue-link\" data-issue-key=\"RFC-107\"><del>RFC-107</del></a>, which states that all Python docstrings and comments must have a maximum line length of 79 characters.</p>\n",
            "<p>Agree with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jsick\" class=\"user-hover\" rel=\"jsick\">Jonathan Sick</a> where to document local jupyter even if it is NOT SUPPORTED. We need a place for hacks and things people will do ..</p>\n",
            "<p>Some improvements are available for the Firefly parts of\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a>\\'s intro-with-globular notebook used in the Lyon 2018 hands-on session and later demos.</p><ul>\\t<li>Define the Display so the proper URL is available before the IFrame cell, so that `lsp-demo.lsst.codes` need not be hardcoded into the notebook</li>\\t<li>Dial down mask transparency via afw.display</li>\\t<li>Show how the <tt>firefly_client.plot</tt> convenience module can upload the catalog and overlay on the images.</li></ul>\n",
            "<p>With support for <tt>asinh_q_value</tt> and <tt>gamma_value</tt> added to <tt>firefly_client.FireflyClient.set_stretch</tt>, make these available in the <tt>display_firefly</tt> backend as <tt>Q</tt> and <tt>gamma</tt>.</p>\n",
            "<p>In C++, it\\'s natural to require an explicit template argument for templated functions whose template parameters only affect their return type.  That doesn\\'t work when wrapping normally with pybind11, which just sees a set of equivalent overloaded functions and blithely selects the first one defined.</p><p>The <span class=\"error\">&#91;Num-&#93;</span>Pythonic interface for functions like this would take a <tt>dtype</tt> argument to select the type returned, and this ticket will provide a helper class that makes that easy to implement.</p><p>This is a spin-off from <a href=\"https://jira.lsstcorp.org/browse/DM-15500\" title=\"Add FITS image, catalog readers that infer types from file\" class=\"issue-link\" data-issue-key=\"DM-15500\"><del>DM-15500</del></a>, where this helper code is now almost complete.</p><p>I\\'m calling this gen3-middleware because that\\'s why I\\'m doing <a href=\"https://jira.lsstcorp.org/browse/DM-15500\" title=\"Add FITS image, catalog readers that infer types from file\" class=\"issue-link\" data-issue-key=\"DM-15500\"><del>DM-15500</del></a>, even though this ticket is a few steps removed from the core gen3 work.  TCAMs are welcome to reclassify.</p>\n",
            "<p>During recent stress testing, it was found that if many exposures are taken very quickly one after the next, the Forwarder may get behind by 15 seconds or more. This will delay the acknowledgement that the readout is complete and the file has been processed and sent to archive. One solution is to extend the max time that the ATS CSC will wait for a response - which will allow even more delay to accumulate - then if the max time is exceeded, the system is put in Fault state as there is no response ACK.</p><p>Another solution is to NOT make the CSC dependent on the ACK arriving within a prescribed window of time, and simply address the result set information in the ACK when it arrives.<span class=\"error\">&#91;1&#93;</span> There is already an Forwarder health check every exposure, as well as a check that the transfer params were received by working Forwarders - both of which will send the system to FAULT state in no Forwarders are available to work...if a Forwarder dies during EndReadout, the AT CSC will know that an ACK was <ins>never</ins> received. Then the health state of the Forwarder will be checked on the next exposure.</p><p><span class=\"error\">&#91;1&#93;</span> If checksum verification of archived files is selected to be used, the \\'result set\\' is a struct that includes the path to the file on the Archive and the checksum calculated for the file before it was sent. When the file is verified as existing and its checksum is correct, the ArchiveController issues a receipt for that image file and the receipt is sent to the DMCS bookkeeping database.</p>\n",
            "nan\n",
            "nan\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=gpdf\" class=\"user-hover\" rel=\"gpdf\">Gregory Dubois-Felsmann</a> and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=pmelchior\" class=\"user-hover\" rel=\"pmelchior\">Peter Melchior</a> have both requested independently (the former quite a while ago) code that shows how to extract Footprints from SourceCatalogs without using afw code.</p>\n",
            "<p>Pipeline task init method should take kwargs that that in cases where a pipeline task is used as a subtask all arguments are appropriately forwarded to all constructors.</p>\n",
            "<p>EUPS binary/tarball builds on osx were disabled many weeks ago due to strange problems with eups https downloads from <tt>eups.lsst.codes</tt> hanging.\\xc2\\xa0 Since that time, the sqre osx environment has been \"white-listed\" with the NOAO traffic mangler \\xe2\\x80\\x93 it needs to be determined if this has resolved the problem and if not, the root cause needs to be identified.</p>\n",
            "<p>Currently the default Storage Classes are loaded whenever a Butler is created. Supertask needs to know about Storage Classes without an associated butler. To allow this to work change StorageClassFactory so that it always tries to load the definitions from the daf_butler/config directory.</p><p>PipelineTask may still need to provide a way for people to define non-standard StorageClasses but that is out of scope of this ticket.</p>\n",
            "<p>With <tt>w_2018_38</tt>, <tt>mosaic.py</tt> failed with many errors such as:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">root WARN: Failed to read {\\'ccd\\': 19, \\'visit\\': 1270, \\'tract\\': 9615, \\'filter\\': \\'HSC-I\\'}: \"Field with name \\'i_fluxErr\\' not found\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Then</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Mosaic INFO: frameIds : []</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Mosaic INFO: ccdIds : []</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Mosaic INFO: Creating kd-tree for matched catalog ...</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Mosaic INFO: len(matchList) = 0 []</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Caught signal 11, backtrace follows:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&lt;....&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Segmentation fault</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>It looks related to the changes of <a href=\"https://jira.lsstcorp.org/browse/DM-10302\" title=\"Rename &quot;*_flux&quot; fields to &quot;*_instFlux&quot; in SourceCatalogs\" class=\"issue-link\" data-issue-key=\"DM-10302\"><del>DM-10302</del></a>? </p>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/RFC-528\" title=\"Remove RA/Dec angle handling from utils package\" class=\"issue-link\" data-issue-key=\"RFC-528\"><del>RFC-528</del></a>, remove the unused sexagesimal angle routines from utils and afw. obs_ctio0m9 needs fixing since it is the only package that uses the utils routines. Replace that with astropy usage.</p>\n",
            "\"<p>To see whether it improves the outlier rejection fraction, I'm going to increase the visit polynomial order by 2 (from 5 to 7) and see if that helps. It's just CPU time: don't have to make any real modifications to the execution scripts.</p>\"\n",
            "<p>This is the DM version of\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/TSEIA-83\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/TSEIA-83</a></p><p>Dates in header service headers are illegal</p><p>Headers in files written with the OCS/CCS bridge such as</p><p><tt>DATE-OBS</tt>\\xc2\\xa0\\xc2\\xa0<tt>2018-08-20T20:51:59.393(UTC)</tt></p><p>which are illegal (with the trailing\\xc2\\xa0<tt>UTC</tt>). \\xc2\\xa0This is with\\xc2\\xa0<tt>dayObs=2018-08-20 seqnum=3</tt></p><p>\\xc2\\xa0</p><div class=\\'table-wrap\\'><table class=\\'confluenceTable\\'><tbody><tr><td class=\\'confluenceTd\\'>KEYWORD: DATE-OBS</td></tr><tr><td class=\\'confluenceTd\\'>REFERENCE: FITS Standard</td></tr><tr><td class=\\'confluenceTd\\'>STATUS: reserved</td></tr><tr><td class=\\'confluenceTd\\'>HDU: any</td></tr><tr><td class=\\'confluenceTd\\'>VALUE: string</td></tr><tr><td class=\\'confluenceTd\\'>COMMENT: date of the observation</td></tr><tr><td class=\\'confluenceTd\\'>DEFINITION: The date of the observation, in the format specified in the</td></tr><tr><td class=\\'confluenceTd\\'>FITS Standard. The old date format was \\'yy/mm/dd\\' and may be used only</td></tr><tr><td class=\\'confluenceTd\\'>for dates from 1900 through 1999. The new Y2K compliant date format is</td></tr><tr><td class=\\'confluenceTd\\'>\\'yyyy-mm-dd\\' or \\'yyyy-mm-ddTHH:MM:SS<span class=\"error\">&#91;.sss&#93;</span>\\'.</td></tr></tbody></table></div>\n",
            "\"<p>Remove remnants of pex_policy, which was long ago shifted to used <tt>pex_config</tt>.</p><p>The main things being gotten rid of are:</p><p>Commands:</p><p>killcondor.py - used the old style pex_policy job description to identify and kill jobs.<br/>writeNodeList.py - this was required in an early version of ctrl_orca to enumerate the nodes used (in pbs jobs, I believe).<br/>ProvenanceRecorder.py - This was used to make database records for policy files used in a run.  This was in addition to the provenance information that used to be recorded via the provenance package, which is also obsolete, since it also used pex_policy.  I don't think a replacement was ever made for that package.</p><p>lsst/ctrl/orca:</p><p>PolicyUtils.py - used to get all file names listed in a policy</p><p>The ups/ctrl_orca.table needs to have pex_policy removed as a required setup.</p>\"\n",
            "<p>Per <a href=\"https://jira.lsstcorp.org/browse/RFC-385\" title=\"Changes to teams within the JIRA DM project\" class=\"issue-link\" data-issue-key=\"RFC-385\"><del>RFC-385</del></a>, please create the following new JIRA teams:</p><ul class=\"alternate\" type=\"square\">\\t<li>System Management</li>\\t<li>DM Science</li>\\t<li>Data Facility</li></ul>\n",
            "<p>Please verify that there are no tickets currently assigned to the following teams (this should be the case after <a href=\"https://jira.lsstcorp.org/browse/DM-11943\" title=\"Map tickets from old teams to new teams\" class=\"issue-link\" data-issue-key=\"DM-11943\"><del>DM-11943</del></a> is completed), then delete them:</p><ul class=\"alternate\" type=\"square\">\\t<li>DMLT / Management</li>\\t<li>T/CAMs</li>\\t<li>Project Science</li>\\t<li>Process Middleware</li>\\t<li>Site Infrastructure</li></ul>\n",
            "<p>Implement the consensus decision on <a href=\"https://jira.lsstcorp.org/browse/RFC-326\" title=\"Require https: as default for all public Web services\" class=\"issue-link\" data-issue-key=\"RFC-326\"><del>RFC-326</del></a> to state, as a DM policy, that all services facing the public Internet will use secure protocols (https:, in particular, for Web services), unless a specific technical justification for not doing so is accepted by the DM-CCB and the project ISO.</p>\n",
            "<p>It looks like in current implementation of graph builder it is possible to make graphs containing loops. Simplest example that was observed already is when pipeline of a single task reads and writes into the same dataset type. We are already supposed to have loop detection when we build Pipeline, maybe logic there is not robust enough and needs a small fix.</p>\n",
            "nan\n",
            "<p>Timing the match scoring and matching methods would be useful in the context routing out slow downs in the association step of ap_pipe.</p>\n",
            "<p>The change in variable names from Sigma to Err where not caught in ap_association as it not currently part of lsst_distrib. This ticket makes that change in package.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-10302\" title=\"Rename &quot;*_flux&quot; fields to &quot;*_instFlux&quot; in SourceCatalogs\" class=\"issue-link\" data-issue-key=\"DM-10302\"><del>DM-10302</del></a> changed the names of `flux` columns to instFlux. As ap_association isn\\'t currently in distrib the change was missed on the package. This ticket will modify the names of the columns ap_association expects from flux to instFlux</p>\n",
            "<p>Two suggestions (only!) for the footprint menu in Firefly:</p><ol>\\t<li>Make it hierarchical, so that, e.g., all the HST instrument footprints appear in a submenu.  (I would like to have at least three footprints for LSST, for instance.)</li>\\t<li>Make its content part of the application configuration, e.g., controlled via the <tt>suit</tt> package for LSST or the <tt>ife</tt> package for IRSA.  The Firefly repo could still contain a standard set of footprint files, but more could be added in the application, and even some of the standard ones suppressed, perhaps?</li></ol>\n",
            "<p>\\xc2\\xa0</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">4</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/ndarray/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1.5</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.lsst1+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/include/ndarray/pybind11.h:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">83</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">8</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: warning: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'ndarray::Pybind11Helper&lt;double, 2, 2&gt;\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> declared with greater visibility than the type of its field </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'ndarray::Pybind11Helper&lt;double, 2, 2&gt;::wrapper\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> [-Wattributes]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/home/jbosch/LSST/lsstsw/stack/Linux64/ndarray/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1.5</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.lsst1+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/include/ndarray/pybind11.h: In instantiation of </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'struct ndarray::Pybind11Helper&lt;double, 1, 0&gt;\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/usr/include/c++/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">7</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/tuple:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">185</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">12</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:   recursively required from </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'struct std::_Tuple_impl&lt;1, pybind11::detail::type_caster&lt;ndarray::Array&lt;double, 1, 0&gt;, void&gt;, pybind11::detail::type_caster&lt;ndarray::Array&lt;double, 2, 0&gt;, void&gt;, pybind11::detail::type_caster&lt;lsst::geom::Point&lt;int, 2&gt;, void&gt; &gt;\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I had thought these would go away with <a href=\"https://jira.lsstcorp.org/browse/DM-15151\" title=\"Set symbol visibility to hidden in pybind11 wrappers\" class=\"issue-link\" data-issue-key=\"DM-15151\"><del>DM-15151</del></a>, but I guess not, and it\\'s probably better for us to fix them in the code anyway.</p>\n",
            "<p>The move of the implementation of FitsStorage on <a href=\"https://jira.lsstcorp.org/browse/DM-15599\" title=\"Stop using boost persistence in afw\" class=\"issue-link\" data-issue-key=\"DM-15599\"><del>DM-15599</del></a> neglected to include support for reading PropertyLists directly from FITS.\\xc2\\xa0 This is somewhat understandable; we had no test coverage for that functionality and it was used in only one place (obs_lsstCam) that\\'s not yet in CI.\\xc2\\xa0 Should be easy to add it back in.</p>\n",
            "<p>The sims team would like an automatically built weekly sims version that is built on the weekly build of <tt>lsst_distrib</tt>.  They would like the result to be a binary distribution that would allow end users to install a full stack of sims plus DM dependencies that are all consistent with the weekly build.  I.e.</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$&gt; eups distrib install lsst_sims -t w_2018_13</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This is currently possible to do by hand, but it would be useful to them to have it automatically build.  They are very clear that a failing <tt>lsst_sims</tt> weekly build should not imply a failing <tt>lsst_distrib</tt> build.</p>\n",
            "<p>Write summary for Monthly report</p>\n",
            "<p>Config inherits from UserDict and hence gets a lot of dict-like methods.\\xc2\\xa0 \\xc2\\xa0They don\\'t all seem to work; <tt>get</tt> didn\\'t until <a href=\"https://jira.lsstcorp.org/browse/DM-15424\" title=\"Revisit LimitedRegistry concept\" class=\"issue-link\" data-issue-key=\"DM-15424\"><del>DM-15424</del></a>, and <tt>del</tt> doesn\\'t seem to work either, at least when nested below the top level.</p><p>We should probably add tests for all dict-like operations.</p><p>As an alternative, I\\'ve been working around these issues by just working directly with the <tt>data</tt> attribute, which really is a nested dictionary (with some lists).\\xc2\\xa0 I\\'m finding that much more pleasant.\\xc2\\xa0 Perhaps we should expose that more directly, and remove more of Config\\'s implementation, i.e. make it so the children of a Config are not themselves expected to be Configs.</p>\n",
            "<p>Update LDM-503 to include approriate tests for handling data from Camera Calibration Optical Bench (CCOB). This may only be possible after the Feb meeting which sets the CCOB schedule. </p>\n",
            "<p>Version being pulled in by ipykernel is old.</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_36 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-15603\" title=\"Reprocess RC2 with w_2018_36\" class=\"issue-link\" data-issue-key=\"DM-15603\"><del>DM-15603</del></a></p>\n",
            "nan\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/DM-14503\" title=\"Finish implementing YAML storage for PropertyList/PropertySet\" class=\"issue-link\" data-issue-key=\"DM-14503\"><del>DM-14503</del></a> support for YAML serialization of PropertySet and PropertyList was added to daf_persistence.  To allow gen3 butler to serialize these using YAML it makes sense to move the YAML support directly into daf_base.  This would require a pyyaml dependency on daf_base but we already use yaml in many places and it\\'s in the core python dependency list. YAML support could be optional in the sense that it is only enabled if yaml can be found.</p>\n",
            "<p>Some of the butler/datastore tests use a fixed name for the datastore root. Now that we are regularly building daf_butler on Jenkins we are getting test failures due to race conditions since now test methods using the same root are running in parallel. Modify the tests to use a different root in <tt>setUp</tt>.</p>\n",
            "<p>Run jointcal with the HSC-RC2 dataset, the w_2018_36 stack, with the following config overrides:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.astrometryRefObjLoader.ref_dataset_name=\\'ps1_pv3_3pi_20170110\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.photometryRefObjLoader.ref_dataset_name=\\'ps1_pv3_3pi_20170110\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.astrometryRefObjLoader.filterMap={\\'B\\': \\'g\\', \\'r2\\': \\'r\\', \\'N1010\\': \\'z\\', \\'N816\\': \\'i\\', \\'I\\': \\'i\\', \\'N387\\': \\'g\\', \\'i2\\': \\'i\\', \\'R\\': \\'r\\', \\'N921\\': \\'z\\', \\'N515\\': \\'g\\', \\'V\\': \\'r\\'}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.photometryRefObjLoader.filterMap={\\'B\\': \\'g\\', \\'r2\\': \\'r\\', \\'N1010\\': \\'z\\', \\'N816\\': \\'i\\', \\'I\\': \\'i\\', \\'N387\\': \\'g\\', \\'i2\\': \\'i\\', \\'R\\': \\'r\\', \\'N921\\': \\'z\\', \\'N515\\': \\'g\\', \\'V\\': \\'r\\'}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>In the future, the config overrides won\\'t be needed once <a href=\"https://jira.lsstcorp.org/browse/DM-15606\" title=\"Add jointcal config defaults to at least obs_subaru\" class=\"issue-link\" data-issue-key=\"DM-15606\"><del>DM-15606</del></a> is merged. </p>\n",
            "<p>Recent changes to l1dbproto\\'s DiaObjectLast table have caused issues within ap_association. Since ap_pipe does not not currently utilize the full features of l1dbproto it seems safer to switch this default to \"baseline\" instead.</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_32 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-15184\" title=\"Reprocess RC2 with w_2018_32\" class=\"issue-link\" data-issue-key=\"DM-15184\"><del>DM-15184</del></a></p>\n",
            "<p>When testing Boost 1.68 in <a href=\"https://jira.lsstcorp.org/browse/DM-15385\" title=\"Update boost to v1.68\" class=\"issue-link\" data-issue-key=\"DM-15385\"><del>DM-15385</del></a>, afw fails to build almost immediately because of failures in <tt>lsstGil.h</tt>.</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">include/lsst/afw/image/lsstGil.h:119:34: error: macro \"GIL_DEFINE_BASE_TYPEDEFS\" requires 3 arguments, but only 2 given</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>In v1.68 <tt>GIL_DEFINE_BASE_TYPEDEFS</tt> gains a new argument in the middle:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">// B - bits size/signedness, CM - channel model, CS - colour space, LAYOUT - pixel layout</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">// Example: B = \\'8\\', CM = \\'uint8_t\\', CS = \\'bgr,  LAYOUT=\\'bgr_layout_t\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">...</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">#define GIL_DEFINE_BASE_TYPEDEFS(B, CM, CS)</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This is not documented as a breaking change so I wonder if we are using internal APIs here. The immediate fix would be to add the channel model definition to our header file, but it would be preferable to use a public API if one exists since that might also work for boost 1.66 (that we are currently using).</p>\n",
            "<p>If astropy.units fails to import and a raises an exception (eg if warnings are converted to errors) when being imported via Schema.cc during import of <tt>lsst.afw.image</tt> an abort signal is received:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">terminating with uncaught exception of type pybind11::error_already_set: SystemError: &lt;built-in method __contains__ of dict object at 0x10049b900&gt; returned a result with an error set</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Stepping through schema.cc the line triggering this is:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">* thread #1, queue = \\'com.apple.main-thread\\', stop reason = breakpoint 2.1</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    frame #0: 0x0000000116e3d53d schema.so`void lsst::afw::table::(anonymous namespace)::declareSchemaType&lt;unsigned char&gt;(mod=0x00007ffeefbf33c0) at schema.cc:187 [opt]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   184 \\t    std::string suffix = FieldBase&lt;T&gt;::getTypeString();</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   185 \\t    py::str pySuffix(suffix);</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   186 \\t</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-&gt; 187 \\t    py::object astropyUnit = py::module::import(\"astropy.units\").attr(\"Unit\");</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   188 \\t</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   189 \\t    // FieldBase</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   190 \\t    PyFieldBase&lt;T&gt; clsFieldBase(mod, (\"FieldBase\" + suffix).c_str());</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  * frame #0: 0x0000000116e3d53d schema.so`void lsst::afw::table::(anonymous namespace)::declareSchemaType&lt;unsigned char&gt;(mod=0x00007ffeefbf33c0) at schema.cc:187 [opt]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    frame #1: 0x0000000116e3d143 schema.so`lsst::afw::table::(anonymous namespace)::pybind11_init_schema(mod=0x00007ffeefbf33c0) at schema.cc:398 [opt]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    frame #2: 0x0000000116e3cf5d schema.so`::PyInit_schema() at schema.cc:390 [opt]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Something in the pybind11 layer is failing to catch the python exception and forward it on.</p><p>Depending on your system this can be reproduced with:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> warnings</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">warnings.simplefilter(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"error\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> lsst.afw.image</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Given the reference to schema.cc and <tt>_<em>contains</em>_</tt> I initially thought this was related to <a href=\"https://jira.lsstcorp.org/browse/DM-15406\" title=\"mosaic.py timeout error in readCatalog\" class=\"issue-link\" data-issue-key=\"DM-15406\"><del>DM-15406</del></a> and there is some commentary there.</p>\n",
            "\"<p>The MOC display doesn't show correctly when 'Galactic' is selected from the image viewer.\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>Implemented:</p><p>this development fixed the MOC display bugs in Galactic coordinate system by converting the world point with the same coordinate system as that of the project center while finding some pixel alongside the great circle passing the given projection center and a world point.</p><p>test:<br/>do hips image search and get moc display in galactic coordinate system.</p>\"\n",
            "<p>As per the discussion in <a href=\"https://jira.lsstcorp.org/browse/RFC-315\" title=\"Change the definitions of e.g. overscan in cameraGeom to describe the detector\" class=\"issue-link\" data-issue-key=\"RFC-315\">RFC-315</a>, two config parameters need to be added to overscanCorrection() to allow excluding the first and last n rows.</p><p>Both parameters should default to 0, so that the default configuration reproduces current functionality. </p>\n",
            "<p>To reproduce, run:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.py /datasets/hsc/repo/  --rerun </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">private</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/user/name --id visit=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">36234</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ccd=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">24</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>It finished successfully using <tt>w_2018_26</tt>, but failed using <tt>w_2018_27</tt> or <tt>w_2018_28</tt> with the following:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd FATAL: Failed on dataId={</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'visit\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">36234</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'ccd\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">24</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'field\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'SSP_WIDE\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'dateObs\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'2015-07-21\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'pointing\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1297</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'filter\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'HSC-I\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'taiObs\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'2015-07-21\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'expTime\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">200.0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}: RuntimeError: Unable to measure aperture correction </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> required algorithm </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'modelfit_CModel_exp\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: only </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> sources, but require at least </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/ssd/lsstsw/stack3_20171021/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_base/16.0-2-g852da13+6/python/lsst/pipe/base/cmdLineTask.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">392</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in __call__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = task.run(dataRef, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/ssd/lsstsw/stack3_20171021/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_base/16.0-2-g852da13+6/python/lsst/pipe/base/timer.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">150</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/ssd/lsstsw/stack3_20171021/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_tasks/16.0-4-g08dccf71+3/python/lsst/pipe/tasks/processCcd.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">188</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    doUnpersist=False,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/ssd/lsstsw/stack3_20171021/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_base/16.0-2-g852da13+6/python/lsst/pipe/base/timer.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">150</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/ssd/lsstsw/stack3_20171021/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_tasks/16.0-4-g08dccf71+3/python/lsst/pipe/tasks/characterizeImage.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">349</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    background=background,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/ssd/lsstsw/stack3_20171021/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_base/16.0-2-g852da13+6/python/lsst/pipe/base/timer.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">150</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/ssd/lsstsw/stack3_20171021/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_tasks/16.0-4-g08dccf71+3/python/lsst/pipe/tasks/characterizeImage.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">428</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in characterize</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    apCorrMap = self.measureApCorr.run(exposure=dmeRes.exposure, catalog=dmeRes.sourceCat).apCorrMap</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/ssd/lsstsw/stack3_20171021/stack/miniconda3-4.3.21-10a4fa6/Linux64/meas_algorithms/16.0-6-g2dd73041+3/python/lsst/meas/algorithms/measureApCorr.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">245</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    (name, len(subset2), self.config.minDegreesOfFreedom+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">RuntimeError: Unable to measure aperture correction </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> required algorithm </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'modelfit_CModel_exp\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: only </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> sources, but require at least </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>processCcd passed in w_2018_31 but failed in w_2018_32 for HSC RC2 data <br/><tt>visit=36118 ccd=21</tt> and <tt>visit=36240 ccd=70</tt>, with </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">RuntimeError: No matches to use for photocal</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>For <tt>--id visit=36118 ccd=21</tt>, it changed from </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match.sourceSelection INFO: Selected 1332/1582 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match.referenceSelection INFO: Selected 257/2570 references</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match INFO: Matched 1 from 1332/1582 input and 257/2570 reference sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>to </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match.sourceSelection INFO: Selected 201/1582 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match.referenceSelection INFO: Selected 257/2570 references</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match INFO: Matched 0 from 201/1582 input and 257/2570 reference sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>For <tt>--id visit=36240 ccd=70</tt>, it changed from </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match.sourceSelection INFO: Selected 2714/3727 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match.referenceSelection INFO: Selected 330/2294 references</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match INFO: Matched 1 from 2714/3727 input and 330/2294 reference sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>to </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match.sourceSelection INFO: Selected 339/3727 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match.referenceSelection INFO: Selected 330/2294 references</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.photoCal.match INFO: Matched 0 from 339/3727 input and 330/2294 reference sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ktl\" class=\"user-hover\" rel=\"ktl\">Kian-Tat Lim</a> drafted DMTN-092 following discussions on AP-PPDP interfaces at LSST2018. Read it, see how happy you are with it, and flag any potential issues.</p>\n",
            "<p>Run jointcal with the HSC-RC2 dataset, the w_2018_34 stack, and the default jointcal config.</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_30 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14988\" title=\"Reprocess RC2 with w_2018_28\" class=\"issue-link\" data-issue-key=\"DM-14988\"><del>DM-14988</del></a></p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>Upload the validate_drp metrics (json files) to SQuaSH:</p><ol>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_34 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-15517\" title=\"Reprocess RC2 with w_2018_34\" class=\"issue-link\" data-issue-key=\"DM-15517\"><del>DM-15517</del></a></p>\n",
            "<p>Allow preselection of default Hub container size via environment variable (e.g. so \"medium\" rather than \"small\" can be the default).</p>\n",
            "<p>See if we can get RISE running in Lab environment well enough to allow it to be used for JupyterCon presentation.</p>\n",
            "<p>During the test of the newly deployed lsst-pdac/portal/suit, I stumbled on something that is obviously wrong. A position search on\\xc2\\xa0\"NEOWISE-R Year 1 Single Exposure (L1b) Source Table\" at\\xc2\\xa0\\xc2\\xa0(0.014937 -0.008658) with radius 10\" returned data with w1flux and w1sigflux empty while w1mpro and w1sigmpro both have data.\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>Upon further study, the w1flux and w1sigflux columns seem to have \"char\" as data type, while the meta data showed that they should be \"float\". We need further investigation into this.\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>The downloaded data is attached.\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>7/25/2018</p><p>Further investigation revealed that those two fields had datatype \"UNKNOWN\" when returned from DAX API dbserv V1. Ticket <a href=\"https://jira.lsstcorp.org/browse/DM-15206\" title=\"dbserv_v1 mapping float to Uknown for DS_wise table\" class=\"issue-link\" data-issue-key=\"DM-15206\"><del>DM-15206</del></a> has been created for this.\\xc2\\xa0\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>8/28/2018</p><p>An unknown datatype\\'s value could not be passed properly and displayed. Firefly does not need to be modified.\\xc2\\xa0</p>\n",
            "\"<p>Some headers seem to be missing, set defaults where it's safe, and do whatever else is necessary within reason.</p>\"\n",
            "<p>Cleaning up the Forwarder directory before moving it.</p>\n",
            "<p>The antlr4 generator inserts 2 semi colons at the end of lines in some cases. This makes our compiler mad with warnings.\\xc2\\xa0</p><p>Scons does not like to modify files in place and there is no elegant way to run sed on files being built. Instead, we make the build step 2 parts (the antlr4 step followed by the sed step inline separated by a semi colon).</p><p>\\xc2\\xa0</p>\n",
            "<p>This ticket is concerned with merging changes to the code made to improve performance. There was a large drop in performance between KPM20 and KPM30 in the cluster at in2p3. Performance was restored to previous level for the LSST dataset, but only in the case where join queries were not included in the batches of test queries. Single join queries run quickly, but when run with a group of queries the entire system slows down significantly. This is thought to be caused by MariaDB not having sufficient resources and is still being sorted out. MariaDB optimizations should improve the situation. The number of computers in the cluster at in2p3 may simple not have enough resources to meet the KPM30 requirements.</p><p>Code was modified to add instrumentation for diagnosis and other changes were made to improve performance. Most of the changes were in qdisp (where the threading model was changed significantly between KPM20 and KPM30), wsched (as testing showed some significant problems), and memman (used by wsched and its mlock calls took significant time).</p><p>Part of the performance issue was configuration values appropriate for the PDAC were applied to the in2p3 cluster. Configuration files are part of the container. Kubernetes has tools for writing the appropriate configuration files to individual systems and they should be used as soon as practical.</p>\n",
            "\"<p>For expediency we (mostly me) haven't been as diligent in making sure our <tt>Registry</tt> ABC stayed up to date with changes to <tt>SqlRegistry</tt>.<br/>Update it.</p>\"\n",
            "<p>After merging <a href=\"https://jira.lsstcorp.org/browse/DM-15098\" title=\"Add Registry.getRegion(DataId)\" class=\"issue-link\" data-issue-key=\"DM-15098\"><del>DM-15098</del></a> it was found that <tt>sphgeom::HtmPixelization::pixel</tt> causes a segfault when called on Linux.<br/>Some investigation has shown that this bug was prexisting (and not unit tested) and caused by an upstream pybind11 bug (<a href=\"https://github.com/pybind/pybind11/issues/1132\" class=\"external-link\" rel=\"nofollow\">https://github.com/pybind/pybind11/issues/1132</a>).<br/>Until that is fixed, work around it by changing the holder type of all <tt>sphgeom::Pixelization</tt> subclasses to <tt>std::unique_ptr&lt;T&gt;</tt>.</p>\n",
            "<p>Create a template in <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/templates</a>\\xc2\\xa0for nbreport projects (see <a href=\"https://nbreport.lsst.io)./\" class=\"external-link\" rel=\"nofollow\">https://nbreport.lsst.io).</a></p><p>This is an LSST2018 hack project</p>\n",
            "<p>Or rather, in the validation datasets used by lsst_ci.</p><p>Should use PS1 or Gaia stored rather than SDSS stored in a_d_n format.</p><p>Write an RFC to explain the change and see if anybody objects.</p>\n",
            "<p>Using sconsUtils with Python 3.7:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/sconsUtils/16.0-1-gd93e90d/python/lsst/sconsUtils/builders.py:202: FutureWarning: Possible nested set at position 11</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  files_expr += \"-name %s -prune\" % re.sub(r\"(^|[^\\\\\\\\])([[*])\", r\"\\\\1\\\\\\\\\\\\2\", file)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Rebase and merge these branches after making sure they work.\\xc2\\xa0 Will require daf_butler to be added as a dependency of at least some of these packages.</p><p>\\xc2\\xa0</p>\n",
            "<p>Describe the process for getting an LSP account at the LDF by the self registration mechanism.</p>\n",
            "<p>Add features to LTD Keeper that are needed by the notebook-based report system\\'s API server (as developed in <a href=\"https://jira.lsstcorp.org/browse/DM-15199\" title=\"Create uservice_nbreport project for publishing notebook-based reports\" class=\"issue-link\" data-issue-key=\"DM-15199\"><del>DM-15199</del></a>):</p><ul>\\t<li><tt>autoincrememnt</tt> feature for edition slugs so that LTD Keeper can create editions with monotonically increasing integer edition numbers that serve as notebook report instance IDs.</li>\\t<li><tt>manual</tt> tracking mode for editions so that the nbreport server can manage the updates of new editions with builds.</li></ul>\n",
            "<p>There are mentions of <tt>IcrsCoord</tt> in <tt>qa_explorer</tt>.  These need to be updated to the new coord objects.</p>\n",
            "<p>The <tt>display_ginga</tt> package has configuration issues that prevent it being built.</p><p>Specifically, there is a missing import and a missing package setup.</p>\n",
            "<p>I communicated with Alex Drlica-Walker about best practices for interacting with Emacs in the JupyterLab terminal emulator.  See <a href=\"https://github.com/LSSTScienceCollaborations/DMStackClub/issues/56\" class=\"external-link\" rel=\"nofollow\">here</a> for conversation.</p><p>Relatedly, I made my first attempt at using the new lspdev on-boarding procedure.  Procedure emailed to <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=frossie\" class=\"user-hover\" rel=\"frossie\">Frossie Economou</a>.</p><p>I also set up my duo account.</p>\n",
            "<p>Install and test Helm on kubernetes cluster</p>\n",
            "<p>On <a href=\"https://github.com/lsst/display_matplotlib/issues/1\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/display_matplotlib/issues/1</a>, the request is:</p><blockquote><p>Would it be possible to give the user control over the colormap used to display images? I see that this is currently set to cmap=pyplot.cm.gray.</p></blockquote>\n",
            "<p>From <a href=\"https://github.com/lsst/display_matplotlib/issues/2:\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/display_matplotlib/issues/2:</a></p><blockquote><p>I\\'ve tried to plot source catalog objects as ellipses using the display.dot function and passing source.getShape as the first argument:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">#Display the cutout and sources with afw display</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">image = cutout.image</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">#image = calexp.image</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">plt.figure()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">afw_display = afwDisplay.Display()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">afw_display.scale(\\'asinh\\', \\'zscale\\')</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">afw_display.mtv(image)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">plt.gca().axis(\\'off\\')</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># We use display buffering to avoid re-drawing the image after each source is plotted</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">with afw_display.Buffering():</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    for s in sources:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        afw_display.dot(\\'+\\', s.getX(), s.getY(), ctype=afwDisplay.RED)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        afw_display.dot(\\'o\\', s.getX(), s.getY(), size=20, ctype=\\'orange\\')   </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        #ADW: This should work, but doesn\\'t?</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        afw_display.dot(s.getShape(), s.getX(), s.getY(), size=35, ctype=\\'orange\\')</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    # Our \"ultra-faint galaxy\" (e.g. smudge)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    afw_display.dot(\\'o\\', x_target, y_target, size=35, ctype=\\'cyan\\')</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>However I get the following error:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/opt/lsst/software/stack/stack/miniconda3-4.5.4-10a4fa6/Linux64/afw/16.0-19-g2da375352/python/lsst/afw/display/interface.py in dot(self, symb, c, r, size, ctype, origin, *args, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    526             symb = afwGeom.ellipses.Axes(symb)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    527 </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--&gt; 528         self._impl._dot(symb, c, r, size, ctype, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    529 </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    530     def line(self, points, origin=afwImage.PARENT, symbs=False, ctype=None, size=0.5):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/opt/lsst/software/stack/stack/miniconda3-4.5.4-10a4fa6/Linux64/display_matplotlib/16.0+11/python/lsst/display/matplotlib/matplotlib.py in _dot(self, symb, c, r, size, ctype, fontFamily, textAngle)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    371 </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    372             axis.add_artist(Ellipse((c + x0, r + y0), xradius=symb.getA(), yradius=symb.getB(),</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--&gt; 373                                           rot_deg=math.degrees(symb.getTheta()), color=ctype))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    374         elif symb == \\'o\\':</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    375             from matplotlib.patches import CirclePolygon as Circle</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">TypeError: __init__() missing 2 required positional arguments: \\'width\\' and \\'height\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I\\'ve confirmed that <tt>matplotlib.patches.Ellipse</tt> does expect the width and height arguments (at least in recent versions).</p></blockquote>\n",
            "<p>daf_butler currently uses intermediate module paths (i.e. modules that should be considered implementation details, because their symbols are lifted into a parent package) when specifying formatters in config files (and possibly other things).  This currently makes the gen3-middleware stack incompatible with weekly builds w_2018_29 and later, because some of those intermediate modules changed in afw.  We should fix this by removing the source of fragility.</p>\n",
            "<p>When actually, it was 2014. This is important for correctly assigning copyright (as well as for enabling greater pedantry, etc).</p>\n",
            "<p>Seeing a future warning emanating from meas_deblender when running\\xc2\\xa0SourceDeblendTask:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/opt/lsst/software/stack/stack/miniconda3-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">4.3</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">21</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-10a4fa6/Linux64/meas_deblender/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">14.0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-g8b7e855+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">32</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/python/lsst/meas/deblender/plugins.py:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">455</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: FutureWarning: `rcond` parameter will change to the </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">default</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">To use the future </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">default</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> and silence </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">this</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">`.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xc2\\xa0X1, r1, rank1, s1 = np.linalg.lstsq(Aw[:, :NT1], bw)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>\\xc2\\xa0</p><p>Harmless for now, however our demo/tutorials trip it numerous times so it would be great if we could fix it.\\xc2\\xa0</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=fred3m\" class=\"user-hover\" rel=\"fred3m\">Fred Moolekamp</a>\\xc2\\xa0Jim told me to assign it to you, don\\'t hate me.</p><p>\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>qserv does not support subqueries; rewrite the query in a non-subquery form.</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_28 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14988\" title=\"Reprocess RC2 with w_2018_28\" class=\"issue-link\" data-issue-key=\"DM-14988\"><del>DM-14988</del></a></p>\n",
            "\"<p>In pybind11 2.2.0 a bug was introduced in the STL vector caster line 162 in <tt>stl.h</tt> needs to be <tt>auto const &amp;</tt> instead of <tt>auto &amp;</tt> because otherwise it doesn't work with bit references (which are temporaries).</p><p>Report this issue and PR upstream.</p>\"\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_26 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14689\" title=\"Reprocess RC2 with w_2018_26\" class=\"issue-link\" data-issue-key=\"DM-14689\"><del>DM-14689</del></a></p>\n",
            "<p><tt>hammer5</tt> no longer exists</p><p><a href=\"https://developer.lsst.io/team/drp.html#connecting-from-outside-princeton\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/team/drp.html#connecting-from-outside-princeton</a></p>\n",
            "\"<p>The exposure time for warps is well-defined, but it's not being set.</p>\"\n",
            "<p>Until we go to Java 10 we need a way to control the number of\\xc2\\xa0 cores the firefly docker container uses.</p><p>\\xc2\\xa0</p><p>The docker container will name allow for a environment variable JVM_CORES</p>\n",
            "<p>For some reasons <tt>ctrl_orca</tt> is missing the <tt>bin</tt> folder, at least in recent releases (e.g. docker images v15, w_2018_23, ...).  Usually a <tt>bin</tt> folder is created for packages with a <tt>bin.src</tt> folder during the build process. But the <tt>bin</tt> folder is not made in <tt>ctrl_orca</tt>; <tt>rewrite_shebang</tt> is not run in the build process.   This is also true in <tt>lsstsw</tt> build and the shared stack in <tt>/software</tt> on LSST machines.  Manually <tt>scons</tt>-ing it works. </p>\n",
            "<p>Review LDM-522</p>\n",
            "<p>Add the ability to exclude named packages and modules from the piplines.lsst.io documentation through a \"skip\" field in the package-toctree and module-toctree directives.</p><p>The \"skip\" field takes a comma-delimited list of names.</p><p>This field is useful for temporarily removing packages that break the documentation build.</p>\n",
            "<p>16.0 is out, so I can remove all of the Python 2 accommodation from the JL environment.</p>\n",
            "<p>Schema naming conventions changed from \".\"-separated with no case consistency to \"_\" and camelCase with the introduction of meas_base.\\xc2\\xa0 I remember writing the new conventions down somewhere, but the first two places I looked:</p><p>\\xc2\\xa0- afw::table::Schema class docs</p><p>\\xc2\\xa0- afw::table overview page in Doxygen</p><p>...document the old convention.</p><p>\\xc2\\xa0</p><p>Fix those, ideally by locating the original text (maybe Confluence somewhere?) and transferring it to those locations.</p><p>\\xc2\\xa0</p>\n",
            "<p>Thereby implementing <a href=\"https://jira.lsstcorp.org/browse/RFC-489\" title=\"Remove {{lsst-dev01:/ssd/lsstsw/stack2}}\" class=\"issue-link\" data-issue-key=\"RFC-489\"><del>RFC-489</del></a>.</p>\n",
            "<p>Working on a document that describes the requirements for a production kubernetes cluster</p>\n",
            "<p>A significant fraction of sources in HSC-R tract 9813 patch 3,4 have failed initial cModel fits (2.3% nan flux/objective, 10.2% negative flux), while 5.1% of dev/exp fits have nan flux/objective. After learning how to use the butler to display in ds9, I found that these failures come from a combination of sources near the edge of a patch, in/near the halos/diffraction spikes of bright stars, or from difficult/failed deblends, in roughly that order. I did not find any surprising failures - all of the failures also set a seemingly sensible failure flag.</p><p>The attached plot can be generated by the notebook created in <a href=\"https://jira.lsstcorp.org/browse/DM-14118\" title=\"Create Jupyter notebook summarizing cModel config results\" class=\"issue-link\" data-issue-key=\"DM-14118\"><del>DM-14118</del></a> (lsst-dev:/home/dtaranu/src/mine/taranu_lsst/cModelConfigs.ipynb).</p>\n",
            "<p>Allow configuration of a container-startup parameter so that we can pass URLs to be cloned by user notebooks down from the spawner.</p>\n",
            "<p>Datashader API changed; figure out how we need to adapt our examples and re-adopt master branch.</p>\n",
            "<p>update DMTN-025 with:</p><ul class=\"alternate\" type=\"square\">\\t<li>parsl</li>\\t<li>desdm framework</li>\\t<li>current status</li></ul>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_24 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14688\" title=\"Reprocess RC2 with w_2018_24\" class=\"issue-link\" data-issue-key=\"DM-14688\"><del>DM-14688</del></a></p>\n",
            "<p>Mount /scratch to Firefly and point workdir to that shared dir.</p>\n",
            "<p>Here is the striking slide from S. Dagoret presentation last week.</p><p>What is going on in the blue? This should be zero here, as there are no telluric features\\xc2\\xa0<img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/help_16.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/><img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/sad.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/><img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/thumbs_down.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></p><p><a href=\"https://indico.in2p3.fr/event/17361/contributions/62542/attachments/48385/61105/2018-05-25-atmspectra-final.pdf\" class=\"external-link\" rel=\"nofollow\">https://indico.in2p3.fr/event/17361/contributions/62542/attachments/48385/61105/2018-05-25-atmspectra-final.pdf</a></p><p><span class=\"image-wrap\" style=\"\"><img src=\"https://jira.lsstcorp.org/secure/attachment/32965/32965_Capture+d%E2%80%99e%CC%81cran+2018-05-31+a%CC%80+09.51.51.png\" style=\"border: 0px solid black\" /></span></p>\n",
            "<p>Things are breaking with 0.9.0 of JupyterHub; get_pod_manifest() no longer works like it did.  This needs investigation and fixing.</p>\n",
            "<p>testQueryAnaGeneral.cc causes a warning:</p><p>Comparison between signed and unsigned integer expressions\\xc2\\xa0return left == right.</p><p>Probably in `BOOST_REQUIRE_EQUAL(first-&gt;subChunkIds.size(), 3);` ought to be\\xc2\\xa03u.</p>\n",
            "<p>After the merge of <a href=\"https://jira.lsstcorp.org/browse/DM-11300\" title=\"Fix kwargs passing (outputPrefix is None error) in validate_drp\" class=\"issue-link\" data-issue-key=\"DM-11300\"><del>DM-11300</del></a>, validate_drp has dropped the repo from the output filename.  Thus, <tt>&lt;repo&gt;<em>&lt;filter&gt;.json</tt> has become <tt></em>&lt;filter&gt;.json</tt>.</p>\n",
            "\"<p>I'd like to run <tt>validate_drp</tt> on output data products from <tt>obs_lsstSim</tt>.  To do this I need to be able to store a full visitId descriptor as something that <tt>multiMatch</tt> can index on.  Currently, that's just integers.  </p><p>Is it possible to adapt (or replace) <tt>multiMatch</tt> to accept more general indexing keys to support <tt>obs_lsstSim</tt>?</p>\"\n",
            "<p>Currently, <span class=\"error\">&#91;with some difficulty&#93;</span> it is possible to discover the <tt>user_id</tt> that created an instance (might be possible for other resources as well) but it is not possible to map this back to a username / person.  This can make it difficult to \\'self police\\' instances.</p><p>The administrative API endpoints are not publicly accessible and I doubt any end user has the appropriate permission. </p>\n",
            "<p>The new antlr4 package requires gcc 5.0 or greater, but Debian Jessie, on which the Qserv base containers are based, only supports gcc 4.9.  Upgrading the base containers to Centos7 + Devtoolset6 seems the best option.</p><p>This should also address currently busted Travis CI runs, and buildability of containers off latest master (sphgeom pybind11 compiler compatibility issue).</p>\n",
            "<p>Test WISE metadata and update\\xc2\\xa0the references to WISE tables to use logical db.</p>\n",
            "<p>Add README files for everything going into <tt>/datasets/hsc/</tt> to specify at least the relevant RFC. </p><p><tt>cosmos</tt> \\xe2\\x86\\x92 <a href=\"https://jira.lsstcorp.org/browse/RFC-266\" title=\"Incorporate HSC Cosmos data into /datasets\" class=\"issue-link\" data-issue-key=\"RFC-266\"><del>RFC-266</del></a>. <br/><tt>ssp_extra</tt> \\xe2\\x86\\x92 <a href=\"https://jira.lsstcorp.org/browse/RFC-323\" title=\"Add more HSC SSP data in /datasets/hsc to have a complete RC dataset\" class=\"issue-link\" data-issue-key=\"RFC-323\"><del>RFC-323</del></a><br/><tt>ssp_pdr1</tt> \\xe2\\x86\\x92 <a href=\"https://jira.lsstcorp.org/browse/RFC-297\" title=\"Put HSC Survey PDR1 data in /datasets\" class=\"issue-link\" data-issue-key=\"RFC-297\"><del>RFC-297</del></a>.  <br/><tt>commissioning</tt> or <tt>newhorizons</tt>  predate the policy and arrived via <a href=\"https://jira.lsstcorp.org/browse/DM-7985\" title=\"Migration of scientific datasets\" class=\"issue-link\" data-issue-key=\"DM-7985\"><del>DM-7985</del></a>,</p>\n",
            "<p>Update READMEs and cleanup examples</p>\n",
            "<p>Refactor TF setup for ease of use and edge cases</p>\n",
            "nan\n",
            "<p>the following region text sample has no text display:\\xc2\\xa0</p><p>text 2101 2131 \"my label\"</p>\n",
            "\"<p>Update the <br/>1. [ ] validation_data_cfht<br/>2. [ ] validation-data_decam<br/>3. [ ] validation_data_hsc</p><p>repositories with output from release 13.0 processing.</p><p>4. [ ] Tag each repo with '13.0'</p>\"\n",
            "<p>Add a <tt>ConnectedSet</tt> helper (name optional) that allows for insertion of elements and connections and iteration over them in topologically sorted order.</p>\n",
            "<p>Foreign key support is disabled by default on Sqlite3. Enable it and see what breaks.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-3705\" title=\"Update ndarray to use current numpy API\" class=\"issue-link\" data-issue-key=\"DM-3705\"><del>DM-3705</del></a> brings the ndarray NumPy API up to level 1.7. This allows us to suppress the warnings about it by forcing that API level to be used. Unfortunately, that requires sticking <tt>#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION</tt> at the top of every module that uses ndarray.</p><p>Find some way to do this and do it.</p>\n",
            "nan\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li>\\t<li>dispatch_verify.py</li></ol><p>with the w_2018_22 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14547\" title=\"Reprocess RC2 with w_2018_22\" class=\"issue-link\" data-issue-key=\"DM-14547\"><del>DM-14547</del></a></p>\n",
            "<p>We no longer recommend the use of versions in the <tt>setupRequired</tt> or <tt>setupOptional</tt> statements in hand-written table files.\\xc2\\xa0 Those table files are automatically expanded to include exact versions when products are installed, which provides much more rigorous dependency version handling.\\xc2\\xa0 The version inequalities we used to include manually never provided much rigor, and provide none now that stack packages are versioned together.</p>\n",
            "<p>We use names like \"forcedPhotCcd.py\" for bin scripts but \"ProcessCcdForcedTask\" for class names; these need to be made consistent, and it\\'s the former convention that was selected in an old (non-JIRA) RFC.</p>\n",
            "<p>To respond to LIT-390, produce a chart showing how our progress through milestones corresponds to the schedule.</p>\n",
            "<p>Please add the following utilities to Firefly docker container:</p><ul class=\"alternate\" type=\"square\">\\t<li>procps (<a href=\"http://procps.sourceforge.net/\" class=\"external-link\" rel=\"nofollow\">http://procps.sourceforge.net/</a>)</li>\\t<li>wget</li>\\t<li>emacs</li></ul><p>These utilities will be helpful when debugging a dockerized Firefly deployment using kubectl.</p>\n",
            "<p><tt>astrometryNetDataConfig.py</tt> gained a <tt>from past.builtins import execfile</tt> during the python3 conversion. We should replace this with a more modern syntax.</p>\n",
            "nan\n",
            "<p>PDF export fails for complex notebooks.  </p><p>Fixing it will require newer (non-Centos-packaged) pandoc and LaTex installations.</p>\n",
            "\"<p>When upload a ds9 region file to be overlaid on an image, the keyword is required to be lower-case characters. Lets make it case insensitive .</p><p>test:</p><ul>\\t<li>do image search on firefly on target (0,0, j2000) and upload footprint file from 'Load DS9 Region File' popup.</li>\\t<li>go to firefly/demo/ffapi-footprint-test.html, and add footprint layer from the footprint tool page.</li></ul>\"\n",
            "<p>Main ingress point and welcome page with links and information</p>\n",
            "<p>Summarize low-level processing details for the operations team and add it to <br/><a href=\"https://confluence.lsstcorp.org/display/DM/S18+HSC+PDR1+reprocessing\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/S18+HSC+PDR1+reprocessing</a> </p>\n",
            "<p>skyCorrection.py of the entire HSC PDR1 dataset with w_2018_15</p>\n",
            "<p>Run pipe_analysis scripts</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>and validate_drp</p><ol>\\t<li>matchedVisitMetrics.py</li>\\t<li>validateDrp.py</li>\\t<li>reportPerformance.py</li></ol><p>with the w_2018_20 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14339\" title=\"Reprocess RC2 with w_2018_20\" class=\"issue-link\" data-issue-key=\"DM-14339\"><del>DM-14339</del></a></p>\n",
            "<p>Geom was removed from the dependency tree in a previous ticket.  ci_hsc still expects in its test that setup packages are recorded, causing a failure.</p>\n",
            "nan\n",
            "<p>Dataset\\'s foreign keys to DataUnit have been commented-out in the schema file.</p><p>Uncomment them and get things working (actually, we\\'ll need to update their representation in the schema in order to make them compound keys).</p><p>I\\'ve already started this in trying to get the schema on <a href=\"https://jira.lsstcorp.org/browse/DM-12620\" title=\"Write Initial Butler Metadata Schema Proposal\" class=\"issue-link\" data-issue-key=\"DM-12620\"><del>DM-12620</del></a> synced with master, and I think I\\'m pretty close, but it makes sense to split this off from that ticket.</p>\n",
            "<p>There is a incorrect reference to <tt>display_ds9</tt> in the sConstruct file in display ginga.  Change this to <tt>display_ginga</tt>.</p>\n",
            "<p>On Slack, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=tmorton\" class=\"user-hover\" rel=\"tmorton\">Tim Morton</a> writes:</p><blockquote><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">conda install dask distributed datashader</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">conda install bokeh=0.12.14</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">conda install -c conda-forge holoviews</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">conda install -c ioam parambokeh</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Oh, and fastparquet</p></blockquote><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=hchiang2\" class=\"user-hover\" rel=\"hchiang2\">Hsin-Fang Chiang</a> says:</p><blockquote><p>Is it possible to install fastparquent in the shared stack at <tt>/software</tt>? It\\'s used in <tt>pipe_analysis</tt>.</p></blockquote>\n",
            "<p>Enables Sphinx support by uncommenting `automodapi` and fixing the errors and warnings.</p>\n",
            "<p>Idle culler is still not working.</p>\n",
            "<p>Update LDM-503 with the test specification for LDM-503-1.</p>\n",
            "\"<p>If the prepuller gets stuck, it's possible for pods to hang around in ErrImagePull or ImagePullBackOff and clog up the system.</p><p>So we should kill the pods when the timer goes off to shut down the prepuller.</p>\"\n",
            "<p>Run matchedVisitMetrics.py validateDrp.py and reportPerformance.py with the HSC RC2 w_2018_18 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14243\" title=\"Reprocess RC2 with w_2018_18\" class=\"issue-link\" data-issue-key=\"DM-14243\"><del>DM-14243</del></a>.</p>\n",
            "<p>Support pytest.</p>\n",
            "\"<p>The idle culler broke at some point because it's using a mixture of tz-naive and tz-aware dates.  Fix that.</p>\"\n",
            "<p>Run matchedVisitMetrics.py validateDrp.py and reportPerformance.py with the HSC RC2 w_2018_17 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14055\" title=\"Reprocess RC2 with w_2018_17\" class=\"issue-link\" data-issue-key=\"DM-14055\"><del>DM-14055</del></a>.</p>\n",
            "<p>Now that Python 2 is not supported, we can remove all the items in the Python style guide talking about Python 2 and <tt>_<em>future</em>_</tt>/<tt>futurize</tt>.</p>\n",
            "<p>Support pytest.</p>\n",
            "<p>Run</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>with the w_2018_17 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14055\" title=\"Reprocess RC2 with w_2018_17\" class=\"issue-link\" data-issue-key=\"DM-14055\"><del>DM-14055</del></a></p><p>Use the tickets/<a href=\"https://jira.lsstcorp.org/browse/DM-13154\" title=\"Refine limits and labeling for color analysis plots\" class=\"issue-link\" data-issue-key=\"DM-13154\"><del>DM-13154</del></a> branch </p>\n",
            "<p>Change the \"JupyterHub\" page title to something more like \"LSST Science Platform Interactive Environment\"</p>\n",
            "<p>Remove py2 support from:</p><ul class=\"alternate\" type=\"square\">\\t<li>jenkins (<tt>stack-os-matrix</tt> + assorted publishing/release related jobs)</li>\\t<li><tt>newinstall.sh</tt></li>\\t<li><tt>lsstsw</tt></li></ul>\n",
            "<p>`dispatch_verify` is not finding the <tt>dataset</tt> env variable in Jenkins. </p><p>From `dispatch_verify` help:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">**Metadata and environment**</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">dispatch_verify.py can enrich Verification Job metadata with information</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">from the environment. In a Jenkins CI execution environment (``--env=ci``) the</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">following environment variables are consumed:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">- ``BUILD_ID`` : ID in the ci system</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">- ``BUILD_URL``: ci page with information about the build</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">- ``PRODUCT``: the name of the product built, in this case \\'validate_drp\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">- ``dataset``: the name of the dataset processed by validate_drp</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">- ``label`` : the name of the platform where it runs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>and here is the current result sent to SQuaSH is:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"env\": {</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      \"date\": \"2018-04-21T03:18:28.473897+00:00\",</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      \"ci_id\": \"1267\",</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      \"ci_url\": \"https://ci.lsst.codes/job/sqre/job/validate_drp/1267/\",</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      \"status\": 0,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      \"ci_name\": \"unknown\",</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      \"ci_label\": \"unknown\",</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      \"env_name\": \"jenkins\",</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      \"ci_dataset\": \"unknown\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    }</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>From that  `BUILD_ID`, `BUILD_URL`, and `PRODUCT` are set in the Jenkins environment, however it looks like `dataset` is not. <b>Note that this env variable is lower case.</b></p><p>More info at <a href=\"https://ci.lsst.codes/job/sqre/job/validate_drp/1267/\" class=\"external-link\" rel=\"nofollow\">https://ci.lsst.codes/job/sqre/job/validate_drp/1267/</a></p>\n",
            "<p>Decide and document the stack version, task steps, and configs to be used in the S18 reprocessing of the HSC PDR1 data on the Verification Cluster (<a href=\"https://jira.lsstcorp.org/browse/DM-13666\" title=\"S18 reprocessing of the HSC SSP PDR1 dataset\" class=\"issue-link\" data-issue-key=\"DM-13666\">DM-13666</a>).</p>\n",
            "<p>Divide usage.py into modules (putting like functions into the same module).</p>\n",
            "<p>Modify the README.rst file to refect new changes in the code, and modify usage.py so that key_len will be calculated from the input dictionary automatically.</p>\n",
            "<p>Fix usage.py so that it will include data for failed jobs.\\xc2\\xa0 \\xc2\\xa0Add a special command-line option so that the user can specify which jobIDs have failed that they would still like to include in the data.\\xc2\\xa0</p>\n",
            "<p>Create a new confluence page and summarize the node utilization for the HSC-RC2 reprocessing jobs from w_2018_04 to w_2018_14.  The slurm job IDs are: </p><p>w_2018_04: <br/>108261, 108352, 108354, 108356, 108353, 108357, 108355, 108347, 108349, 108348, 108351, 108350, 108343, 108345, 108344, 108363, 108346, 108406, 108401, 108403, 108255, 108257, 108260, 108256, 108259, 108258, 108250, 108252, 108251, 108254, 108253, 108245, 108247, 108246, 108331, 108249, 108248, 108268, 108270, 108269, 108272, 108271, 108279, 108281, 108280, 108332, 108282, 108273, 108275, 108274, 108277, 108276, 108278,</p><p>w_2018_06:<br/>109095, 109169, 109170, 109171, 109310, 109168, 109311, 109150, 109152, 109151, 109154, 109153, 109145, 109147, 109146, 109149, 109148, 109337, 109233, 109202, 109088, 109090, 109093, 109089, 109092, 109091, 109083, 109085, 109084, 109087, 109086, 109078, 109080, 109079, 109082, 109081, 109155, 109157, 109159, 109308, 109160, 109309, 109135, 109137, 109136, 109139, 109138, 109113, 109132, 109131, 109134, 109133, 109106, 109108, 109107, 109110, 109109, 109101, 109103, 109102, 109105, 109104, 109115, 109117, 109116, 109119, 109118, 109120,</p><p>w_2018_08:<br/>110555, 110635, 110637, 110639, 110636, 110640, 110638, 110625, 110627, 110626, 110629, 110628, 110620, 110622, 110621, 110624, 110623, 110846, 111407, 110773, 110838, 110549, 110551, 110554, 110550, 110553, 110552, 110544, 110546, 110545, 110548, 110547, 110539, 110541, 110540, 110543, 110542, 110614, 110616, 110618, 110615, 110619, 110617, 110587, 110589, 110607, 110591, 110608, 110582, 110584, 110583, 110586, 110606, 110571, 110573, 110572, 110575, 110574, 110566, 110568, 110567, 110570, 110569, 110576, 110602, 110577, 110604, 110603, 110605, </p><p>w_2018_10:<br/>118122, 118272, 118274, 118276, 118273, 118277, 118275, 118234, 118236, 118235, 118238, 118237, 118229, 118231, 118230, 118233, 118232, 118406, 118438, 118369, 118342, 118093, 118095, 118098, 118094, 118097, 118096, 118086, 118089, 118087, 118092, 118090, 118080, 118083, 118082, 118085, 118084, 118203, 118215, 118217, 118204, 118218, 118216, 118198, 118200, 118199, 118202, 118201, 118193, 118195, 118194, 118197, 118196, 118146, 118148, 118147, 118150, 118149, 118141, 118143, 118142, 118145, 118144, 118151, 118153, 118152, 118155, 118154, 118156,</p><p>w_2018_12:<br/>125046, 125138, 125140, 125142, 125139, 125143, 125141, 125133, 125135, 125134, 125137, 125136, 125128, 125130, 125129, 125132, 125131, 125217, 125243, 125188, 125190, 125040, 125042, 125045, 125041, 125044, 125043, 125035, 125037, 125036, 125039, 125038, 125030, 125032, 125031, 125034, 125033, 125117, 125119, 125121, 125118, 125122, 125120, 125112, 125114, 125113, 125116, 125115, 125107, 125109, 125108, 125111, 125110, 125081, 125083, 125082, 125085, 125084, 125076, 125078, 125077, 125080, 125079, 125086, 125088, 125087, 125090, 125089, 125091</p><p>w_2018_14:<br/>125522, 125588, 125590, 125592, 125589, 125593, 125591, 125578, 125580, 125579, 125582, 125581, 125573, 125575, 125574, 125577, 125576, 125653, 125654, 125677, 125602, 125601, 125510, 125512, 125515, 125511, 125514, 125513, 125505, 125507, 125506, 125509, 125508, 125500, 125502, 125501, 125504, 125503, 125559, 125561, 125563, 125560, 125564, 125562, 125554, 125556, 125555, 125558, 125557, 125549, 125551, 125550, 125553, 125552, 125528, 125530, 125529, 125532, 125531, 125523, 125525, 125524, 125527, 125526, 125533, 125535, 125534, 125537, 125536, 125538</p><p>These do not include the QA/QC jobs. </p>\n",
            "<p>SSIA.</p>\n",
            "<p>The utility apps (such as catalog listing, image triggering, etc.) must be rebuilt as well as the DAQ Forwarder code.</p>\n",
            "nan\n",
            "<p>Find a way to not have to redo the JupyterLab build on each startup.</p>\n",
            "<p>In order to optimize the search of HiPS list and properties, create a method to cache the search result. The search result will be re-used repeatedly for any coming query and only be updated when the server have made any modification.\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p>meas_algorithms has several \"naked\" matplotlib imports that happen at the top level, and thus prevent anything that imports meas_algorithms from subsequently setting the backend. A simple fix is to move those imports into the functions where matplotlib is used, so they only occur if matplotlib is run, and preferably wrap them in try:except and log.warn on any errors.</p><p>This is a stop-gap until 5790 is properly dealt with.</p>\n",
            "<p>Run</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>with the w_2018_15 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-14123\" title=\"Reprocess RC2 with w_2018_15\" class=\"issue-link\" data-issue-key=\"DM-14123\"><del>DM-14123</del></a></p><p>Use the tickets/<a href=\"https://jira.lsstcorp.org/browse/DM-13154\" title=\"Refine limits and labeling for color analysis plots\" class=\"issue-link\" data-issue-key=\"DM-13154\"><del>DM-13154</del></a> branch </p>\n",
            "\"<p>When starting a new instance, occasionally something strange seems to happen with the  network setup.  The instance will come up but is inaccessible (icmp, ssh). When this happens, the console log shows that a DHCP address was obtained and cloud-init injected ssh-keys, so it isn't a total network setup failure.</p><p>I have seen this happen a few times in the last couple of weeks but I can't reliably reproduce it.  I'm wondering if neutron is logging anything interesting when this happens.</p><p>This failure mode happened  again a few minutes ago with 7adffa82-7221-454c-acfe-5f21cdd34ea8.  Which I killed and recreated as instance b6f64981-099b-46e5-a27e-e3694372f447 with the same private IP address.   The new instance is accessible as expected.</p>\"\n",
            "<p>It appears that at some point in the last few months the horizon console interface has stopped working.  I am still able to access the console log output via the API/CLI.</p>\n",
            "<p>The downtime announcement email for <tt>Nebula unavailable Feb 9-10</tt> mentioned a \"roadmap\" for swift.  I have checked and post maintenance, there is not a swift endpoint available in the catalog.  Is there a time line for availability?</p>\n",
            "<p>Evaluate the plan for porting HSC documentation to LSST.</p>\n",
            "<p>Implementation ticket for <a href=\"https://jira.lsstcorp.org/browse/RFC-461\" title=\"Remove lsst.utils.multithreading\" class=\"issue-link\" data-issue-key=\"RFC-461\"><del>RFC-461</del></a>.</p><p>Remove <tt>python/lsst/utils/multithreading/</tt> and the associated unittests, <tt>test_sharedData.py</tt> and <tt>test_lockProtection.py</tt>. </p>\n",
            "<p>This ticket is to implement the final change from <a href=\"https://jira.lsstcorp.org/browse/RFC-397\" title=\"Allow python&#39;s super() in light of our planned py3 switch\" class=\"issue-link\" data-issue-key=\"RFC-397\"><del>RFC-397</del></a>. I\\'ve tweaked the wording slightly here to clarify the single/multiple inheritance point.</p><p>This is the replacement version of the section of the python style guide about <tt>super()</tt>:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">`super` MAY be used with care to call inherited methods</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Python provides `super()` so that each base class\\xe2\\x80\\x99s method is only called once. Using `super()` ensures a consistent Method Resolution Order, and prevents inherited methods from being called multiple times.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">In Python 3, `super()` does not require naming the class that it is part of, making its use simpler and removing a maintenance issue.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">The trickiest issue with the use of `super()` is that, in the presence of multiple inheritance, there is no way for a class to know for certain which inherited method will be called.  In particular, this means that the calling signature (arguments) for all versions of a method must be compatible.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">As a result, there are a few argument-related caveats about the use of `super()` in multiple inheritance hierarchies:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">* Only pass `super()` the exact arguments you received.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">* When you use it on methods whose acceptable arguments can be altered on a subclass via addition of more optional arguments, always accept `*args`, `**kw`, and call `super()` like `super().currentmethod(alltheargsideclared, *args, **kwargs)`. If you don\\xe2\\x80\\x99t do this, forbid addition of optional arguments in subclasses.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">* Never use positional arguments in `__init__` or `__new__`.  Always use keyword args, and always call them as keywords, and always pass all keywords on to `super()`.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">To use `super()` with multiple inheritance, all base classes in Python\\'s Method Resolution Order need to use `super()`; otherwise the calling chain gets interrupted.  If your class may be used in multiple inheritance, ensure that all relevant classes use `super()`, including documenting requirements for subclasses.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Following these guidelines for single inheritance hierarchies, will let them be extended to multiple inheritance with minimal difficulty.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "nan\n",
            "<p>Using the SLURM JobIDs detailed here (<a href=\"https://confluence.lsstcorp.org/display/DM/S17B+HSC+PDR1+reprocessing),\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/S17B+HSC+PDR1+reprocessing),</a>\\xc2\\xa0create a color-coded node-usage plot, like those created with <a href=\"https://jira.lsstcorp.org/browse/DM-13699\" title=\"Modify usage.py and usageplot.py to allow for color-coded plots\" class=\"issue-link\" data-issue-key=\"DM-13699\"><del>DM-13699</del></a>, and also find the total node-hours of the entire run. Put the plot here, as well as in the confluence page above.</p>\n",
            "<p>+underlined text+When completing <a href=\"https://jira.lsstcorp.org/browse/DM-13578\" title=\"Plot the node utilization for RC1 Reprocessed Jobs\" class=\"issue-link\" data-issue-key=\"DM-13578\"><del>DM-13578</del></a>, it was recognized that some of the SLURM IDs gave the following error when finding their information via sacct due to the GPSF outage on 24 Oct. 2017:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">JobID JobName NNodes Elapsed State ExitCode</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">------------ ---------- -------- ---------- ---------- --------</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Conflicting JOB_STEP record </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> jobstep </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95210.0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> at line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">263284</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> -- ignoring it</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Conflicting JOB_STEP record </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> jobstep </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95211.0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> at line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">263288</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> -- ignoring it</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Conflicting JOB_TERMINATED record (COMPLETED) </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> job </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95210</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> at line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">263355</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> -- ignoring it</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Conflicting JOB_TERMINATED record (COMPLETED) </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> job </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95211</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> at line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">263359</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> -- ignoring it</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95210</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> mtWide </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">3</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">00</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">04</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">28</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> NODE_FAIL </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">127</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95210.0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> hydra_pmi+ </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">3</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">00</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">04</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">27</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> FAILED </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">7</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95210.1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> hydra_pmi+ </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">3</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">07</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">44</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">48</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> COMPLETED </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95211</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> mtCosmos </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">4</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">00</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">04</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">04</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> NODE_FAIL </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">127</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95211.0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> hydra_pmi+ </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">4</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">00</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">04</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">04</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> FAILED </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">7</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">95211.1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> hydra_pmi+ </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">4</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">10</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">10</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">13</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> COMPLETED </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>So while the job initially failed, it was later run successfully with the same JobID.\\xc2\\xa0 Modify usage.py to allow for the inclusion of such jobs.</p>\n",
            "<p>Presently L1db configures itself from INI-style file using Python <tt>ConfigParser</tt>. For better integration with pipeline tools <tt>pex.config</tt> should be used instead.</p>\n",
            "<p>As per <a href=\"https://jira.lsstcorp.org/browse/RFC-308\" title=\"Remove /repo from paths to datasets\" class=\"issue-link\" data-issue-key=\"RFC-308\">RFC-308</a>, we will remove the trailing repo from butler root /datasets/decam/repo</p>\n",
            "\"<p>Symptom: Artifact candidates are being clipped when there not sufficient epochs remaining to do so. </p><p>Cause:  A crude N-Image is passed to filterArtifacts to compute the maximum number of epochs a candidate can appear in and be clipped. If there are &lt; 3 epochs it's zero. (i.e nothing should be clipped). This N-Image is too crude.</p><p>The actual N-Image can be lower due to recorded chip defects (everything in the bad mask plane).</p><p>NOTE: This only affects coadds with small numbers of epochs</p>\"\n",
            "<p>Per <a href=\"https://jira.lsstcorp.org/browse/DM-14060\" title=\"Update igprof\" class=\"issue-link\" data-issue-key=\"DM-14060\"><del>DM-14060</del></a>, please install the new version of igprof on:</p><ul class=\"alternate\" type=\"square\">\\t<li>All four lsst-dev stacks;</li>\\t<li>Both Princeton Tiger stacks;</li>\\t<li>Both Princeton Perseus stacks.</li></ul>\n",
            "<p>Update <tt>lsst-dm/milestones</tt>, and flow the changes to LDM-503, LDM-564 and <tt>lsst-dm/images</tt>.</p>\n",
            "<p>Run</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>with the w_2018_14 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-13890\" title=\"Reprocess RC2 with w_2018_14\" class=\"issue-link\" data-issue-key=\"DM-13890\"><del>DM-13890</del></a></p>\n",
            "nan\n",
            "<p>Understand options for tracking resource consumption of individual processes on batch compute system</p>\n",
            "<p>The branch protection+travisCI+flake8 system will soon be made available for activation on LSST repositories. I\\'ve volunteered be a non-SQuaRE person to test the process, using the jointcal repo (which has a very small list of commit users right now).</p><p>Once the \"final draft\" instructions are available, I\\'ll follow them for jointcal and provide feedback to SQuaRE.</p>\n",
            "<p>NED\\'s UI displays VO Table FIELD descriptions as tooltips.   Can Firefly table display do this too?   See b.ned.ipac.caltech.edu/byname.   Select the Photometry &amp; SEDs tab and hover over a column header.</p><p>Firefly developers have indicated that tooltips should work for this purpose, but this feature is not well documented and a JIRA ticket will request assistance.</p><p>{{&lt;FIELD ID=\"main_col4\" name=\"DEC(deg)\" NEDname=\"DEC(deg)\" ucd=\"pos.eq.dec;meta.main\" datatype=\"double\" unit=\"degrees\" width=\"10\"&gt;<br/>&lt;DESCRIPTION&gt;Declination in degrees (Equatorial J2000.0)&lt;/DESCRIPTION&gt;<br/>&lt;/FIELD&gt;}}</p><p>CogE: Jeff</p>\n",
            "<p>Non-standard configuration; needs to be set up to test locally but transitioned for installation in Tucson before shipping.</p>\n",
            "<p>On some installations, ip forwarding has to be explicitly set. \\xc2\\xa0Adding that to the documentation.</p>\n",
            "<p>Running the visit-level scripts using the current master of <tt>pipe_analysis</tt> (<tt>6b5727d</tt>)  with the <tt>w_2018_10</tt> stack gave errors in getting the <tt>wcs</tt> dataset. </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_base/14.0-6-ge2c9487+51/python/lsst/pipe/base/cmdLineTask.py\", line 408, in __call__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = task.run(dataRef, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/hchiang2/stack/pipe_analysis/python/lsst/pipe/analysis/visitAnalysis.py\", line 215, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    raise RuntimeError(\"No datasets found for datasetType = {:s}\".format(repoInfo.dataset))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">RuntimeError: No datasets found for datasetType = wcs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>It needs updates for the dataset name changes of <a href=\"https://jira.lsstcorp.org/browse/DM-11138\" title=\"Convert meas_mosaic wcs output to a format directly readable by the butler\" class=\"issue-link\" data-issue-key=\"DM-11138\"><del>DM-11138</del></a>. </p>\n",
            "<p>Run <tt>matchedVisitMetrics.py</tt> <tt>validateDrp.py</tt> and <tt>reportPerformance.py</tt>  with the HSC RC2 w_2018_12 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-13795\" title=\"Reprocess RC2 with w_2018_12\" class=\"issue-link\" data-issue-key=\"DM-13795\"><del>DM-13795</del></a>.</p>\n",
            "<p>While processing some cosmos data on lsst-dev it became necessary to run data sequentially using the multibandDriver to diagnose a problem. This can be done by using the --batch-type=None option. </p><p>Most of the processing preceded fine, however I noticed that openMP was not being disabled. This was most evident when the deblender was using several hundred percent cpu. Occasionally a processing job would seed to get stuck (not get past the deblending stage, yet still using 100% cpu) even when left for 24 hours. I attached to the process using gdb and found that some numpy routine was making some openblas calls. These calls would get into a state where libopenblas ,which is compiled into numpy, was issuing calls to sleep a tread, which would then turn over control to the kernel. The kernel would complete the sleep and immediately turn control back to openblas, which would then issue a thread sleep call. This kept the cpu using 100% cpu, but no work ever got done, and the loop could not exit.</p><p>Killing the process and restarting could get the processing past the particular patch/tract that was getting stuck, but sometimes a different tract/patch would get stuck. It was not deterministic but happened several times when processing all the patches in a tract.</p><p>Some relevant lines from the traceback when the program was in the sleep loop are below:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">#0  0x00007fa6496d0e47 in sched_yield ()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    at ../sysdeps/unix/syscall-template.S:81</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">#1  0x00007fa63ddbf365 in exec_blas_async_wait ()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   from /software/lsstsw/stack/Linux64/miniconda2/3.19.0.lsst4/bin/../lib/libopenblas.so</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">#2  0x00007fa63ddbfa02 in exec_blas ()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   from /software/lsstsw/stack/Linux64/miniconda2/3.19.0.lsst4/bin/../lib/libopenblas.so</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">#3  0x00007fa63ddbfd9d in blas_level1_thread ()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   from /software/lsstsw/stack/Linux64/miniconda2/3.19.0.lsst4/bin/../lib/libopenblas.so</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "nan\n",
            "<p>Run</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>with the w_2018_12 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-13795\" title=\"Reprocess RC2 with w_2018_12\" class=\"issue-link\" data-issue-key=\"DM-13795\"><del>DM-13795</del></a></p>\n",
            "<p>We are getting warnings from Slack about rate limits on our ghslacker app.\\xc2\\xa0 Also the cache does not appear to be working.</p>\n",
            "<p>Implement <a href=\"https://jira.lsstcorp.org/browse/RFC-462\" title=\"Temporarily include meas_mosaic in lsst_distrib\" class=\"issue-link\" data-issue-key=\"RFC-462\"><del>RFC-462</del></a>.</p><p>Also update meas_mosaic to optionally depend on\\xc2\\xa0obs_subaru.</p>\n",
            "<p>Coord and Wcs will soon switch to using SpherePoint and SkyWcs (<a href=\"https://jira.lsstcorp.org/browse/DM-11162\" title=\"Replace all use of Coord and subclasses with SpherePoint\" class=\"issue-link\" data-issue-key=\"DM-11162\"><del>DM-11162</del></a>). Since ap_association is not currently part of the stack this will require updating the code after the ticket mentioned perviously is implemented.</p>\n",
            "\"<p>If all goes well, this should allow us to start removing our dependence on the NumPy C API (left for another ticket).</p><p>This will probably require modifying our pybind11 build to install its CMake\\xc2\\xa0config files (unless we're doing that already, which I doubt), since ndarray now uses those to find pybind11.</p>\"\n",
            "<p>Liase with SQuaRE to determine the most effective way to transfer HSC docs to LSST. Organize a hackathon session for DRP developers at which we get this done. Bring doughnuts.</p>\n",
            "<p>I have installed my stack using the eups distrib binaries. Today I went to rebuild the meas_extensions_hsm package which links to the galsim package, and the build failed. It complained about not being able to find libgalsim.dylib in the galsim package. Upon looking in the directory for galsim I see:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">_-rwxr-xr-x\\xc2\\xa0 1 nate\\xc2\\xa0 staff\\xc2\\xa0 3289320 Dec 13 10:12_ _libgalsim.1.5.dylib_</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">_lrwxr-xr-x\\xc2\\xa0 1 nate\\xc2\\xa0 staff\\xc2\\xa0 \\xc2\\xa0 \\xc2\\xa0 190 Dec 13 10:12_ _libgalsim.dylib_ _-&gt; /Users/square/jenkins/workspace/release/tarball/osx/10.9/clang-800.0.42.1/miniconda3-4.3.21-10a4fa6/build/stack/miniconda3-4.3.21-10a4fa6/DarwinX86/galsim/1.5.1.lsst1/lib/libgalsim.1.5.dylib_</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Which shows the simlink for the dylib is still pointing to the a directory on the build system. I propose that if this cant be fixed on the packaging side that we need a program like the shebangtron that will rewrite all the simlinks</p>\n",
            "<p>Decide whether we want to spend more resources on CModel, or do something new.</p>\n",
            "<p>Per e-mail with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=klong\" class=\"user-hover\" rel=\"klong\">Kevin Long</a> of 2017-09-25 (and around then), he prefers that epics which have been scheduled in PMCS not be marked as \"won\\'t fix\", but rather:</p><ul class=\"alternate\" type=\"square\">\\t<li>That they must contain a single story;</li>\\t<li>That story may be marked as \"won\\'t fix\";</li>\\t<li>The epic should then be marked as \"done\".</li></ul><p>This process is documented: he is going to check exactly where. At that point, we should make sure that DMTN-020 is consistent with his documentation.</p>\n",
            "<p>Current L1DB implementation assumes HTM-20 indexing for DiaObject/DiaSource tables. There is code in L1db class that depends on that when doing region-based selection. It would be better to make this more flexible and client-controlled so that other indexing models could be tested/employed.</p>\n",
            "<p>1 graf on sqrbot, 2 on Jupyterlab</p>\n",
            "<p>The <a href=\"https://github.com/lsst-dm/milestones\" class=\"external-link\" rel=\"nofollow\">lsst-dm/milestones</a> system was created to enable automatic generation of LDM-564 from a single PMCS export. Apply it to LDM-503 as well.</p>\n",
            "<p>Run <tt>matchedVisitMetrics.py</tt> and <tt>validateDrp.py</tt> with the HSC RC2 w_2018_10 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-13647\" title=\"Reprocess RC2 with w_2018_10\" class=\"issue-link\" data-issue-key=\"DM-13647\"><del>DM-13647</del></a>.</p><p>Follow <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=wmwood-vasey\" class=\"user-hover\" rel=\"wmwood-vasey\">Michael Wood-Vasey</a>\\'s example:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># Need to specify tract, otherwise one will get a meas_base failure.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">matchedVisitMetrics.py </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"${REPO}\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> --output </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"${OUTREPO}\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> --config useJointCal=True --id visit=${VISITIDS} tract=${TRACT}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># Capture the output</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">validateDrp.py </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"${OUTREPO}\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/matchedVisit_${FILTER}.json --noplot &gt; ${OUTREPO}/metrics.log</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Use the ticket branch of <a href=\"https://jira.lsstcorp.org/browse/DM-13742\" title=\"Fix plot names to include filter. Add outputPrefix option to validateDrp.\" class=\"issue-link\" data-issue-key=\"DM-13742\"><del>DM-13742</del></a>.</p>\n",
            "<p>Run</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>with the w_2018_10 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-13647\" title=\"Reprocess RC2 with w_2018_10\" class=\"issue-link\" data-issue-key=\"DM-13647\"><del>DM-13647</del></a></p>\n",
            "<p>Right now these test data use sqlite directly. Change this to sqlalchemy (core). This serves both to familiarize myself with the data and will enable testing on different databases later.</p>\n",
            "<p>Run</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>with the w_2018_08 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-13532\" title=\"Reprocess RC with w_2018_08\" class=\"issue-link\" data-issue-key=\"DM-13532\"><del>DM-13532</del></a></p>\n",
            "<p>We discovered that <tt>pexConfig</tt> objects create <tt>_<em>doc</em>_</tt> (docstring) attributes automatically based on information passed to configuration constructors. This means that configuration fields are documented in the attributes of configuration classes inside the regular API documentation.</p><p>This is great, but can also fail if the automatically-generated config field docstring is not reStructuredText/Numpydoc compatible.</p><p>This ticket is to change the <tt>_<em>doc</em>_</tt> generators of <tt>pexConfig</tt> fields so that they output Numpydoc/reStructuredText docstrings.</p>\n",
            "<p>Working on <a href=\"https://jira.lsstcorp.org/browse/DM-13781\" title=\"L1DB interface for reading/writing afw.table data\" class=\"issue-link\" data-issue-key=\"DM-13781\"><del>DM-13781</del></a> I tried to convert baseline schem to YAML and noticed some minor issues in that schema file:</p><ul>\\t<li>in some comments it uses <tt>&lt;/desc&gt;</tt> instead of <tt>&lt;/descr&gt;</tt></li>\\t<li>DiaSource index has a name IDX_DiaObject_htmId20</li>\\t<li>DiaSource index IDX_DiaSource_filterName refers to non-existing field name</li></ul><p>Also I need to verify that type of <tt>flags</tt> field in DiaForcedSource is correct (TINYINT)</p>\n",
            "<p>For the deblender to be useful in the long term, which includes possibly deblending entire images as a single blend, we need to be able to define a bounding box for each source that is a small fraction of the total image size (see the issue created by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=pmelchior\" class=\"user-hover\" rel=\"pmelchior\">Peter Melchior</a> <br/> at <a href=\"https://github.com/fred3m/deblender/issues/14\" class=\"external-link\" rel=\"nofollow\">https://github.com/fred3m/deblender/issues/14</a>).</p><p>This ticket will attempt to identify the best algorithm to create an initial bounding box large enough to fit all of the flux for <em>most</em>  individual objects, with the possibility of growing the box during optimization if the source appears to need a larger area.</p>\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/RFC-121\" title=\"Prevent force pushing to master\" class=\"issue-link\" data-issue-key=\"RFC-121\"><del>RFC-121</del></a> we adopted a policy of protecting master. This ticket is to add that documentation to the developer guide and include the settings needed to ensure that the pull requests are up to date with the base branch (which is our policy).</p>\n",
            "nan\n",
            "<p>Individual groups submitted responses to provide material/ideas for the all-DM DMTN-074.\\xc2\\xa0</p><p>DRP contribution here:</p><p><a href=\"https://paper.dropbox.com/doc/Existing-QA-Tools-and-Use-Cases-QXhgTyKhmKVMvJI93D39U\" class=\"external-link\" rel=\"nofollow\">https://paper.dropbox.com/doc/Existing-QA-Tools-and-Use-Cases-QXhgTyKhmKVMvJI93D39U</a></p>\n",
            "<p>Prepare slides for presentation at the <b>Systems Engineering/Data Management Joint Subsystem Meeting,\\xc2\\xa0March 5 - 9, 2018 | Pasadena, CA</b> during the\\xc2\\xa0\\xe2\\x80\\x9cCurrent status of QA tooling and dataset\\xe2\\x80\\x9d session on Mar 7.</p>\n",
            "<p>Use the latest weekly to match to the HST data to get a larger dataset for classification/training use.</p>\n",
            "<p>These nice before and after plots shown in <a href=\"https://jira.lsstcorp.org/browse/DM-13410\" title=\"Shrink input bboxes in inputRecorder per psfMatched Warp in WarpCompare\" class=\"issue-link\" data-issue-key=\"DM-13410\"><del>DM-13410</del></a> were from a the pre-review test run. The version that got merged doesn\\'t set SENSOR_EDGE (and consequently INEXACT_PSF) of the new EDGE pixels.\\xc2\\xa0</p><p>This has the effect that fewer sources measured on the coadd will have the inexactPsf_flag set. However, most (80-98%) of the EDGE pixels are\\xc2\\xa0also BAD or INTRP which are then\\xc2\\xa0 \"REJECTED\" which then propagates to INEXACT_PSF:</p><p><span class=\"image-wrap\" style=\"\"><a id=\"32162_thumb\" href=\"https://jira.lsstcorp.org/secure/attachment/32162/32162_DM-13410_vs_08_SENSOR_EDGE.png\" title=\"DM-13410_vs_08_SENSOR_EDGE.png\" file-preview-type=\"image\" file-preview-id=\"32162\" file-preview-title=\"DM-13410_vs_08_SENSOR_EDGE.png\"><img src=\"https://jira.lsstcorp.org/secure/thumbnail/32162/_thumb_32162.png\" style=\"border: 0px solid black\" /></a></span></p><p><span class=\"image-wrap\" style=\"\"><a id=\"32164_thumb\" href=\"https://jira.lsstcorp.org/secure/attachment/32164/32164_DM-13410_vs_08_REJECTED.png\" title=\"DM-13410_vs_08_REJECTED.png\" file-preview-type=\"image\" file-preview-id=\"32164\" file-preview-title=\"DM-13410_vs_08_REJECTED.png\"><img src=\"https://jira.lsstcorp.org/secure/thumbnail/32164/_thumb_32164.png\" style=\"border: 0px solid black\" /></a></span></p><p><span class=\"image-wrap\" style=\"\"><a id=\"32161_thumb\" href=\"https://jira.lsstcorp.org/secure/attachment/32161/32161_DM-13410_vs_08_INEXACT.png\" title=\"DM-13410_vs_08_INEXACT.png\" file-preview-type=\"image\" file-preview-id=\"32161\" file-preview-title=\"DM-13410_vs_08_INEXACT.png\"><img src=\"https://jira.lsstcorp.org/secure/thumbnail/32161/_thumb_32161.png\" style=\"border: 0px solid black\" /></a></span></p>\n",
            "<p>Add monitoring for the new Kubernetes cluster.</p>\n",
            "<p>Run through Butler composites with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a> and discuss results with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=tjenness\" class=\"user-hover\" rel=\"tjenness\">Tim Jenness</a> and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mgower\" class=\"user-hover\" rel=\"mgower\">Michelle Gower</a>.</p>\n",
            "<p>Run </p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>with the w_2018_04 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-13256\" title=\"Reprocess RC with w_2018_04\" class=\"issue-link\" data-issue-key=\"DM-13256\"><del>DM-13256</del></a></p>\n",
            "<p>Run</p><ol>\\t<li>visitAnalysis</li>\\t<li>coaddAnalysis</li>\\t<li>colorAnalysis</li>\\t<li>compareVisitAnalysis</li>\\t<li>compareCoaddAnalysis</li></ol><p>with the w_2018_06 RC2 outputs from <a href=\"https://jira.lsstcorp.org/browse/DM-13435\" title=\"Reprocess RC with w_2018_06\" class=\"issue-link\" data-issue-key=\"DM-13435\"><del>DM-13435</del></a></p>\n",
            "<p>Process WIDE_VVDS (tract=9697) and WIDE_GAMA15H (tract=9615) data with w_2018_03<br/> and add the output products to the repo of <a href=\"https://jira.lsstcorp.org/browse/DM-13463\" title=\"Reprocess RC1 with w_2018_03\" class=\"issue-link\" data-issue-key=\"DM-13463\"><del>DM-13463</del></a>.  Pipeline steps and configs are the same as <a href=\"https://jira.lsstcorp.org/browse/DM-13463\" title=\"Reprocess RC1 with w_2018_03\" class=\"issue-link\" data-issue-key=\"DM-13463\"><del>DM-13463</del></a>. </p><p>The visit IDs are as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a> <a href=\"https://jira.lsstcorp.org/browse/DM-11345?focusedCommentId=90372&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-90372\" class=\"external-link\" rel=\"nofollow\">this comment</a></p>\n",
            "<p>SDSS PDAC Metadata needs a bit more cleaning and normalization in lsst/cat and lsst-dm/db_pdac_stripe82.</p>\n",
            "<p>As is imageREST_v0 API (URL pattern/style) is already supported on top of v1 code base.</p><p>Once we transition over to imageREST_v1, which can be seen as v0++ from functionality standpoint,  there is really no need for the old v0 code (isolated to a few files) to remain in the code base.</p>\n",
            "<p>When I visit <a href=\"http://doxygen.lsst.codes/stack/doxygen/x_masterDoxyDoc/index.html\" class=\"external-link\" rel=\"nofollow\">http://doxygen.lsst.codes/stack/doxygen/x_masterDoxyDoc/index.html</a>, type something into the search box, and hit enter, I get a <tt>search.php</tt> file to download in response.</p><p>Obviously, I should get search results.</p><p>This was discussed on <a href=\"https://jira.lsstcorp.org/browse/DM-10544\" title=\"https://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/ 404s\" class=\"issue-link\" data-issue-key=\"DM-10544\"><del>DM-10544</del></a>, but doesn\\'t seem to have actually been fixed there (or, if it was, it has subsequently broken again).</p>\n",
            "nan\n",
            "<p>Update for February 2018</p>\n",
            "<p>Implement <a href=\"https://jira.lsstcorp.org/browse/RFC-452\" title=\"Remove old lsst-dev01 shared stacks\" class=\"issue-link\" data-issue-key=\"RFC-452\"><del>RFC-452</del></a> by removing old shared stacks from lsst-dev01.</p>\n",
            "nan\n",
            "<p>In order for FGCM to persist files via the butler, new datasets need to be added to obs_base.\\xc2\\xa0 Until now this has been done on my own branch.\\xc2\\xa0 This will be a clean update on this ticket, with comments which are now (finally) expected.</p>\n",
            "<p>Add a YAML formatter to daf_butler.</p>\n",
            "<p><tt>scaleVariance</tt> fails for small images. Make coaddition algorithms more robust either by changing scaleVariance() or wrapping uses of it in a try block. I\\'ve also considered requiring a configurable number of pixels to cover a patch before its written out as a warp. </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">compareWarpAssembleCoadd FATAL: Failed on dataId=DataId(initialdata={\\'tract\\': 9813, \\'filter\\': \\'HSC-Y\\', \\'patch\\': \\'8,1\\'}, tag=set()): IndexError: cannot do a non-empty take from an empty axes.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_base/14.0-6-ge2c9487+39/python/lsst/pipe/base/cmdLineTask.py\", line 408, in __call__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = task.run(dataRef, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_base/14.0-6-ge2c9487+39/python/lsst/pipe/base/timer.py\", line 150, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/yusra/lsst_devel/LSST/DMS/pipe_tasks_DM-13410/python/lsst/pipe/tasks/assembleCoadd.py\", line 363, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    inputData.weightList, supplementaryData=supplementaryData)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/yusra/lsst_devel/LSST/DMS/pipe_tasks_DM-13410/python/lsst/pipe/tasks/assembleCoadd.py\", line 1605, in assemble</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    spanSetMaskList = self.findArtifacts(templateCoadd, tempExpRefList, imageScalerList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/yusra/lsst_devel/LSST/DMS/pipe_tasks_DM-13410/python/lsst/pipe/tasks/assembleCoadd.py\", line 1646, in findArtifacts</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    warpDiffExp = self._readAndComputeWarpDiff(warpRef, imageScaler, templateCoadd)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/yusra/lsst_devel/LSST/DMS/pipe_tasks_DM-13410/python/lsst/pipe/tasks/assembleCoadd.py\", line 1767, in _readAndComputeWarpDiff</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    log=self.log)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/yusra/lsst_devel/LSST/DMS/pipe_tasks_DM-13410/python/lsst/pipe/tasks/coaddBase.py\", line 306, in scaleVariance</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    q1, q3 = numpy.percentile(sigNoise[good], (25, 75))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/lib/function_base.py\", line 4269, in percentile</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    interpolation=interpolation)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/lib/function_base.py\", line 4011, in _ureduce</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    r = func(a, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/lib/function_base.py\", line 4386, in _percentile</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    x1 = take(ap, indices_below, axis=axis) * weights_below</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 134, in take</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return _wrapfunc(a, \\'take\\', indices, axis=axis, out=out, mode=mode)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 57, in _wrapfunc</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return getattr(obj, method)(*args, **kwds)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">IndexError: cannot do a non-empty take from an empty axes.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Should improve the Python interface and reduce copying.</p>\n",
            "\"<p>there's a dependency nightmare that we need to sort out. Removing antlr4 from the qserv build allows us to continue working on qserv while we get the dependency problems RFC'd and integrated into the build.</p>\"\n",
            "<p>Currently, <tt>ap_pipe</tt> requires a single input repository with two directories, <tt>ingested</tt> and <tt>calibingested</tt>, each a repository in its own right. This will be a problem for <a href=\"https://jira.lsstcorp.org/browse/DM-13163\" title=\"Refactor ap_pipe to use CmdLineTask primitives\" class=\"issue-link\" data-issue-key=\"DM-13163\"><del>DM-13163</del></a> because most command-line tasks allow the URIs of the data and calib repositories to be independent, and in any case the Stack convention is different from our current usage.</p><p>This ticket will change the command line to accept a separate calib repository (the argument should behave the same as <tt>processCcd.py --calib</tt>?). The API to <tt>ap_verify</tt> will not be changed, as it will almost certainly change when <a href=\"https://jira.lsstcorp.org/browse/DM-13163\" title=\"Refactor ap_pipe to use CmdLineTask primitives\" class=\"issue-link\" data-issue-key=\"DM-13163\"><del>DM-13163</del></a> is implemented.</p>\n",
            "<p>We often store Box2Is and Box2Ds in tables.  We should have a FunctorKey to do this to reduce code duplication.</p><p>Unfortunately we may not be able to use this actually reduce existing code duplication when code has used a different convention for naming fields (as we\\'d need to maintain backwards compatibility with already-persisted objects), but this should at least reduce duplication going forward.</p><p>I\\'m planning to do this now for <a href=\"https://jira.lsstcorp.org/browse/DM-12370\" title=\"Add a coadded transmission curve implementation\" class=\"issue-link\" data-issue-key=\"DM-12370\"><del>DM-12370</del></a> so I can use it there.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-10729\" title=\"Near-term jointcal acceptance: make validate_drp use meas_mosaic outputs\" class=\"issue-link\" data-issue-key=\"DM-10729\"><del>DM-10729</del></a> implemented one way of writing back out to a catalog prior to <a href=\"https://jira.lsstcorp.org/browse/RFC-322\" title=\"Rename &quot;*_flux&quot; fields to &quot;*_instFlux&quot; in SourceCatalogs\" class=\"issue-link\" data-issue-key=\"RFC-322\"><del>RFC-322</del></a> being implemented, that introduced a <tt>_calFlux</tt> field for the <tt>outField</tt>. <tt>_calFlux</tt> isn\\'t used elsewhere in the stack, and is inconsistent with the documentation.</p><p>This ticket is to change it to write to <tt>outField+\"_flux\"</tt>, which allows writing the calibrated fluxes back to the same field (by having <tt>inField==outField</tt>), which is consistent with what meas_mosaic is currently doing.</p>\n",
            "<p>Docker does not behave very well inside Openstack in our Nebula implementation, we have adapted a Daemon Set from kubernetes to run on every node to pull big images</p>\n",
            "<p>A recent merge has broken docker image build scripts used by developers and Travis and Jenkins CI (undefined variable $DOCKER_RUN_DIR in several Dockerfiles)</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Change the unit test logging for qserv to record debug level messages so it is easier to debug intermittent failures.\\xc2\\xa0</p>\n",
            "<p>Send appropriate list of users to team/site representatives for verification.</p>\n",
            "nan\n",
            "<p>Add a use case and requirement that describes the need for the <tt>Butler</tt> to have the ability to persist the data blobs associated with a <tt>Job</tt> and the JSON file that describes the <tt>Job</tt> in different datastores.\\xc2\\xa0 For example the blobs may be placed in an object store with the <tt>Job</tt> could be ingested in a JSON aware SQL database.</p>\n",
            "<p>Discuss porting of BF measurement code with Will Coulton and Bob Armstrong to better understand the code, and requirements for porting, and better plan and time-estimate the upcoming work</p>\n",
            "<p>When the deblender was updated to use different size boxes for all objects, the <tt>recenter_sources</tt> method was modified to fit each sources position separately. This might be the reason behind some faint sources that we see drifting during the fit, so this ticket will update the <tt>recenter_sources</tt> method to project each source onto the full model so that the positions can be updated simultaneously again.</p>\n",
            "\"<p>Create a new folder <tt>/datasets/hsc/calib/20171219/STRAY_LIGHT</tt> and copy the data from Paul's folder /scratch/pprice/strayLight </p><p>Create a link in <tt>/datasets/hsc/calib/20170105/STRAY_LIGHT</tt> </p><p>Check <tt>yBackground</tt> are available via Butler. </p>\"\n",
            "<p>The current implementation of the <tt>Butler</tt> prototype hardcodes the the path hint for storage.<br/>Fix this by implementing <tt>makePath</tt>.</p>\n",
            "<p>The stack release v14.0 just came out. It would be useful if v14.0 is available in the shared stack on lsst-dev. </p>\n",
            "<p>The shared stacks on lsst-dev01 (and Tiger &amp; Perseus, for the Princeton crowd) should be updated to install 2018-vintage weeklies. This should just be a matter of tweaking the regexp.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/RFC-25\" title=\"Increase MaskPixel size from 16 to 32 bits\" class=\"issue-link\" data-issue-key=\"RFC-25\"><del>RFC-25</del></a> triggered <a href=\"https://jira.lsstcorp.org/browse/DM-7477\" title=\"Increase mask plane size to 32 bits\" class=\"issue-link\" data-issue-key=\"DM-7477\"><del>DM-7477</del></a> to increase the mask plane from 16 bits to 32 bits. Firefly has the function to display mask plane when it is part of teh extension. We need to double check to make sure the display still works. </p>\n",
            "\"<p>Jointcal is still getting NaNs in some of the HSC PDR1 data. It appears that finite errors are not guaranteed by the centroid_flag, so we have to reject non-finite Sigmas during source selection. For now, we'll add it to astrometrySourceSelector, but we'll have to think of a better solution since this will affect all source selectors.</p>\"\n",
            "<p>In LCR-1024 requirements language was added to LSE-30 to connect it to LSE-163. This ticket is for adding the derived requirements relationships from the relevant DM requirements back to LSE-30.</p>\n",
            "<p>Update the running kernel on all jenkins related linux nodes as a partial mitigation of the</p><p><a href=\"https://spectreattack.com/\" class=\"external-link\" rel=\"nofollow\">https://spectreattack.com/</a></p><p>Centos 7/EL7 related links:</p><p><a href=\"https://access.redhat.com/security/vulnerabilities/speculativeexecution\" class=\"external-link\" rel=\"nofollow\">https://access.redhat.com/security/vulnerabilities/speculativeexecution</a><br/><a href=\"https://lwn.net/Articles/742919/\" class=\"external-link\" rel=\"nofollow\">https://lwn.net/Articles/742919/</a><br/><a href=\"https://access.redhat.com/errata/RHSA-2018:0007\" class=\"external-link\" rel=\"nofollow\">https://access.redhat.com/errata/RHSA-2018:0007</a></p><p>EC2 instances may need to be restarted regardless due to AWS patching hypervisors, so it makes sense to update the kernel at the same time.</p><p>Presumably, the jenkins OSX nodes will also need to be updated but this may be split into a separate ticket.</p>\n",
            "<p>If I try to create a histogram chart with x axis set to be \\'log\\' from the tri-view viewer,  no histogram chart is rendered. <br/>This issue is found by doing the following, <br/>step 1: Do catalog search, such as m31 and cone size is 200 arcsec. <br/>step 2: add a histogram chart  to the tri-view viewer: </p><ul class=\"alternate\" type=\"square\">\\t<li>click \\'Charts\\' from the menu to get chart selection dropdown window.</li>\\t<li>select \\'histogram\\' and column \\'dec\\'</li>\\t<li>set x axis to be \\'log\\',</li>\\t<li>click OK button.</li></ul><p>Some numbers are filled into the fields of \\'Min\\', \\'Max\\', and \\'Bin width\\' when \\'histogram\\' and a single column name are selected from the \\'Charts\\' dropdown window. However those numbers are only applicable to the case when x is linear scaled and they are not suitable when x is selected to be \\'log\\'. </p>\n",
            "<p>How to repeat the problem:</p><p>LSST image search, DeepCoadd. </p><p>Query One: RA = 0, Dec = -1, images enclosed by 36 arcsec box. This query should fail and no data and images are back.</p><p>Query Two: keep the same target, change the box size from 36 to 3600 arcsec. This query should have many rows in and five images are shown.</p><p>In the triview table panel, switch back to the Query One tab, the table is switched, but the image panel still shows the 5 images from the Query Two.</p>\n",
            "nan\n",
            "<p>Sqrbot is getting a null response when inquiring about a Jira link.</p>\n",
            "<p>Currently the clusters at Princeton only have the python 2 version of the stack updated every week. It would be convenient to have the Python 3 version as well.</p>\n",
            "<p>I think we agreed at the 2018-12-11 Monday Meeting that it\\'s better to included interpolated CR pixels in the coadd (since the interpolation is pretty good) rather than leave them out and get lots more pixels masked with INEXACT_PSF.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a>, if you\\'re in a position to do this quickly before the next HSC release, please steal it.  Otherwise I\\'ll try to get to it later.</p>\n",
            "<p>Following IHS-612, there will be multiple slurm queues on LSSTVC.   It would be great to be able to tell <tt>allocateNodes.py</tt> which queue to send jobs to. </p>\n",
            "<p>sqr-018 needs some maintenance</p>\n",
            "<p>Minor improvements to UX</p>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/RFC-415\" title=\"Add cp_pipe to lsst_distrib\" class=\"issue-link\" data-issue-key=\"RFC-415\"><del>RFC-415</del></a>, rename ip_cpp to cp_pipe and add to lsst_distrib</p>\n",
            "<p>confirm  that the newly loaded NEOWISE data table is accessible through current DAX service</p>\n",
            "<p>Specifically:</p><ul class=\"alternate\" type=\"square\">\\t<li>Make sure the overhead rate is correct (mail from David Kittelson, 2017-09-19);</li>\\t<li>Account for Vanderbei &amp; Naghib work on the scheduler, if applicable.</li></ul>\n",
            "<p>Update the color mapping of the visit outlines such that each visit gets a unique color.  Also add a legend with the visit numbers such that they can be identified in the plot.  Additionally, allow for multiple tracts to be specified and have their outlines drawn on the plot with unique gray-scaling and added to the legend.</p>\n",
            "<p>This ticket implements <a href=\"https://jira.lsstcorp.org/browse/RFC-421\" title=\"Add display_firefly to lsst_distrib\" class=\"issue-link\" data-issue-key=\"RFC-421\"><del>RFC-421</del></a>.</p><p><tt>display_firefly</tt> will be added as <tt>setupRequired</tt> to the table file in <tt>lsst_distrib</tt>.</p>\n",
            "<p><tt>validate_drp</tt> has been failing since the 22nd. This is suspiciously coincidental with the merger of <a href=\"https://github.com/lsst-sqre/jenkins-dm-jobs/pull/58\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/jenkins-dm-jobs/pull/58</a> .  The first build failure appears to be shell script related but the most recent failures for both the <tt>cfht</tt> and <tt>hsc</tt> data set look like they may be the result of a change in the stack.</p><p><b>HSC</b></p><p><a href=\"https://ci.lsst.codes/job/validate_drp/835/dataset=hsc,label=centos-7,python=py2/console\" class=\"external-link\" rel=\"nofollow\">https://ci.lsst.codes/job/validate_drp/835/dataset=hsc,label=centos-7,python=py2/console</a></p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/bin/validateDrp.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">97</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    validate.run(args.repo, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/python/lsst/validate/drp/validate.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">104</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/python/lsst/validate/drp/validate.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">217</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in runOneFilter</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    job=job, linkedBlobs=linkedBlobs, verbose=verbose)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/python/lsst/validate/drp/calcsrd/amx.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">159</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in __init__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    verbose=verbose)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/python/lsst/validate/drp/calcsrd/amx.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">242</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in calcRmsDistances</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    visit[obj2], ra[obj2], dec[obj2])</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/python/lsst/validate/drp/calcsrd/amx.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">326</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in matchVisitComputeDistance</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    j = visit_obj2_idx[j_raw]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">IndexError: index </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">3</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> is out of bounds </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> axis </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> with size </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">3</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Build step </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'Execute shell\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> marked build as failure</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[PostBuildScript] - Execution post build scripts.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p><b>CFHT</b></p><p><a href=\"https://ci.lsst.codes/job/validate_drp/835/dataset=cfht,label=centos-7,python=py2/console\" class=\"external-link\" rel=\"nofollow\">https://ci.lsst.codes/job/validate_drp/835/dataset=cfht,label=centos-7,python=py2/console</a></p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/bin/validateDrp.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">97</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    validate.run(args.repo, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/python/lsst/validate/drp/validate.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">104</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/python/lsst/validate/drp/validate.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">204</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in runOneFilter</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    verbose=verbose)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/python/lsst/validate/drp/matchreduce.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">147</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in __init__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    repo, dataIds, matchRadius)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-g3511a1277e+1/python/lsst/validate/drp/matchreduce.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">229</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in _loadAndMatchCatalogs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    oldSrc = butler.get(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'src\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, vId, immediate=True, flags=SOURCE_IO_NO_FOOTPRINTS)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/daf_persistence/12.1-19-gd507bfc/python/lsst/daf/persistence/butler.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">845</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in get</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    location = self._locate(datasetType, dataId, write=False)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/daf_persistence/12.1-19-gd507bfc/python/lsst/daf/persistence/butler.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">795</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in _locate</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    location = repoData.repo.map(datasetType, dataId, write=write)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/daf_persistence/12.1-19-gd507bfc/python/lsst/daf/persistence/repository.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">198</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in map</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    loc = self._mapper.map(*args, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/daf_persistence/12.1-19-gd507bfc/python/lsst/daf/persistence/mapper.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">144</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in map</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> func(self.validate(dataId), write)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/obs_base/12.1-21-gbdb6c2a+2/python/lsst/obs/base/cameraMapper.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">379</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in mapClosure</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> mapping.map(mapper, dataId, write)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/obs_base/12.1-21-gbdb6c2a+2/python/lsst/obs/base/mapping.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">124</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in map</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    actualId = self.need(iter(self.keyDict.keys()), dataId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/obs_base/12.1-21-gbdb6c2a+2/python/lsst/obs/base/mapping.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">257</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in need</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    lookups = self.lookup(newProps, newId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/obs_base/12.1-21-gbdb6c2a+2/python/lsst/obs/base/mapping.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">221</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in lookup</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = self.registry.lookup(properties, self.tables, lookupDataId, template=self.template)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/cfht/label/centos-7/python/py2/lsstsw/stack/Linux64/daf_persistence/12.1-19-gd507bfc/python/lsst/daf/persistence/registries.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">330</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in lookup</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    c = self.conn.execute(cmd, valueList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">sqlite3.OperationalError: no such column: flags</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Container builds no longer work; need to scl enable devtoolset-6</p>\n",
            "<p>Add ext_shapeHSM_HsmShapeRegauss_e1, ext_shapeHSM_HsmShapeRegauss_e2, ext_shapeHSM_HsmShapeRegauss_resolution to the coadd comparison script to aid with assessing changes relevant to shear measurements.</p>\n",
            "<p>We need a larger minimum memory footprint.</p>\n",
            "nan\n",
            "<p>Attend a class offered at Princeton university which covers galaxy morphology and properties to prepare for upcoming work in galaxy modeling.</p>\n",
            "\"<p>There should be minimal effort for the DRP mid-cycle replan, but I need to spend an hour or two to figure out what's on track and what isn't.</p>\"\n",
            "nan\n",
            "nan\n",
            "<p><tt>despyDMdb</tt> is one of the packages DESDM framework consist of. The goal is to port it to Python 3.</p>\n",
            "<p><tt>despfitsutils</tt> is one of the packages DESDM framework consist of. The goal is to port it to Python 3.</p>\n",
            "<p><tt>QCFramework</tt> is one of the packages DESDM framework consist of. The goal is to port it to Python 3.</p>\n",
            "<p><tt>despyServiceAccess</tt> is one of the packages DESDM framework consist of. The goal is to port it to Python 3.</p>\n",
            "<p>This is the most minimal version of <a href=\"https://jira.lsstcorp.org/browse/DM-12366\" title=\"Add spatially varying transmissions curves and coadd them\" class=\"issue-link\" data-issue-key=\"DM-12366\"><del>DM-12366</del></a>, requested by NAOJ.  It makes sense to do it on a separate ticket.</p><p>This will mostly be highly HSC-specific code, as it\\'s a lot harder to come up with a way to report fractions of different filters used when you can have more than two filters and arbitrary names for them; for HSC we know exactly which pairs of filters we need to take ratios of.</p>\n",
            "nan\n",
            "<p>It is believed that the problems with bad colors in HSC-Z and Y that we observed in <a href=\"https://jira.lsstcorp.org/browse/DM-12776\" title=\"Fix problem in deblender interface with the stack\" class=\"issue-link\" data-issue-key=\"DM-12776\"><del>DM-12776</del></a> are due to the way we are using inverse variance maps to weight gradient steps in the deblender. When two bands have substantially different mean variance, certain colors converge more quickly than other colors, and at all times are capable of taking larger steps toward the minimum, which we believe results in poor colors in the bands with higher variance. Similarly, images with widely varying pixel variances could also see some pixels reaching convergence more quickly than others (although we have not observed this directly).</p><p>To combat this <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=pmelchior\" class=\"user-hover\" rel=\"pmelchior\">Peter Melchior</a> and I propose to normalize the weights for SED updates along each band, so that only pixel by pixel variations are weighted for each SED update, and normalize the weights for morphologies along each single band image. This should give us more uniform convergence and hopefully solve <a href=\"https://jira.lsstcorp.org/browse/DM-12776\" title=\"Fix problem in deblender interface with the stack\" class=\"issue-link\" data-issue-key=\"DM-12776\"><del>DM-12776</del></a> as well.</p>\n",
            "<p>To reproduce, the first one with --cores=1 works, but second with --cores=2 does not:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">source /software/lsstsw/stack/loadLSST.bash</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">setup lsst_distrib</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">export wideVisitsG=9852^9856^9860^9864^9868^9870^9888^9890^9898^9900^9904^9906^9912^11568^11572^11576^11582^11588^11590^11596^11598</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">coaddDriver.py  /datasets/hsc/repo --rerun RC/w_2017_46/DM-12545:private/yusra/psfMatching/newStack --time 500 --cores=1  --id tract=8766  patch=5,5 filter=HSC-G --selectId ccd=0..8^10..103 visit=$wideVisitsG </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">coaddDriver.py  /datasets/hsc/repo --rerun RC/w_2017_46/DM-12545:private/yusra/psfMatching/newStack --time 500 --cores=2  --id tract=8766  patch=5,5 filter=HSC-G --selectId ccd=0..8^10..103 visit=$wideVisitsG</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Note to get any useful output you\\'d need to either switch:<br/>makeCoaddTempExp.doApplyUbercal=False<br/>AssembleCoadd.doApplyUbercal=False</p><p>OR </p><p>setup meas_mosaic (which I currently can\\'t build with the python3 stack)</p>\n",
            "<p>Using daf_persistence 13.0-5-g87674b4 (w_2017_12) in Princeton I get an error; I cannot test this at lsst-dev as w_2017_11 doesn\\'t seem to be installed.  The paths are correct for lsst-dev, however, so you should be able to repeat this there.</p><p>The error is:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import lsst.daf.persistence as dafPersist</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">butler = dafPersist.Butler(\"/datasets/comCam/repo\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">r = butler.get(\\'raw\\', run=\\'4672D\\', ccd=\\'S00\\', visit=261576101)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">---------------------------------------------------------------------------</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">NoResults</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">                                 Traceback (most recent call last)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&lt;ipython-input-9-ac5a11c0f585&gt; in &lt;module&gt;()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      1 butler = dafPersist.Butler(\"/tigress/HSC/LSST/comCam\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">----&gt; 2 r = butler.get(\\'raw\\', run=\\'4672D\\', ccd=\\'S00\\', visit=261576101)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/tigress/HSC/LSST/stack/Linux64/daf_persistence/13.0-5-g87674b4/python/lsst/daf/persistence/butler.pyc in get(self, datasetType, dataId, immediate, **rest)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    943         location = self._locate(datasetType, dataId, write=False)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    944         if location is None:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--&gt; 945             raise NoResults(\"No locations for get:\", datasetType, dataId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    946         self.log.debug(\"Get type=%s keys=%s from %s\", datasetType, dataId, str(location))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    947 </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">NoResults</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: No locations for get: datasetType:raw dataId:DataId(initialdata={\\'ccd\\': \\'S00\\', \\'run\\': \\'4672D\\', \\'visit\\': 261576101}, tag=set([]))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>But if I query the registry directly I see my data; using dat_persistence 13.0-3-gc00b09a also seems to work.</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ sqlite3 /tigress/HSC/LSST/comCam/registry.sqlite3 </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SQLite version 3.9.2 2015-11-02 18:31:45</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Enter \".help\" for usage hints.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">sqlite&gt; select visit from raw where ccd=\\'S01\\' and run = \\'4672D\\' and visit = 261576101;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">261576101</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>The recent upgrade of the python3 baseline after stack release 14.0 seems to have busted the Qserv container builds (and thus Travis CI for Qserv)</p>\n",
            "nan\n",
            "nan\n",
            "<p>Copy TS3 data from SLAC/BNL to lsst-dev for use with obs_auxTel. Should be put in <tt>/datasets</tt>.</p><p>Sensor is 098.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=FabioHernandez\" class=\"user-hover\" rel=\"FabioHernandez\">Fabio Hernandez</a> <a href=\"https://github.com/lsst/pipelines_lsst_io/issues/66\" class=\"external-link\" rel=\"nofollow\">writes</a>:</p><blockquote><p>There is a colon missing in <a href=\"https://github.com/lsst/pipelines_lsst_io/blob/master/install/demo.rst\" class=\"external-link\" rel=\"nofollow\">this file</a> so the note in <a href=\"https://pipelines.lsst.io/install/demo.html#download-the-demo-project\" class=\"external-link\" rel=\"nofollow\">https://pipelines.lsst.io/install/demo.html#download-the-demo-project</a> does not render correctly.</p></blockquote>\n",
            "<p>This message means that no psfMatched warps were found, and a static sky model could not be built but a user might not deduce that from:</p><p>```Traceback (most recent call last):<br/>  File \"/software/lsstsw/stack/Linux64/ctrl_pool/13.0-6-gf96f8ec+54/python/lsst/ctrl/pool/parallel.py\", line 496, in logOperation<br/>    yield<br/>  File \"/software/lsstsw/stack/Linux64/pipe_drivers/13.0-21-g61c0bd4+9/python/lsst/pipe/drivers/coaddDriver.py\", line 261, in coadd<br/>    coaddResults = self.assembleCoadd.run(patchRef, selectDataList)<br/>  File \"/software/lsstsw/stack/Linux64/pipe_base/13.0-14-g8b3bf66+40/python/lsst/pipe/base/timer.py\", line 150, in wrapper<br/>    res = func(self, *args, **keyArgs)<br/>  File \"/home/yusra/lsst_devel/LSST/DMS/pipe_tasks/python/lsst/pipe/tasks/assembleCoadd.py\", line 388, in run<br/>    supplementaryData = self.makeSupplementaryData(dataRef, selectDataList)<br/>  File \"/home/yusra/lsst_devel/LSST/DMS/pipe_tasks/python/lsst/pipe/tasks/assembleCoadd.py\", line 1629, in makeSupplementaryData<br/>    templateCoadd = self.assembleStaticSkyModel.run(dataRef, selectDataList).coaddExposure<br/>AttributeError: \\'NoneType\\' object has no attribute \\'coaddExposure\\'```</p>\n",
            "<p>Create a single patch of a cosmos coadd that has HSM, SDSS Shape, and simple shape all run.</p>\n",
            "<p>If a user has been idle longer than some threshold, terminate the container.</p>\n",
            "<p>When creating fake object catalogs using makeSourceList.py or makeSourListGrid.py, it is currently necessary to specify a filter in the dataId. As this task only uses a skyMap, this should not be necessary. Change the behavior of these scripts so that specifying a filter in the dataId is not a requirement.</p>\n",
            "<p>Need to look for local Docker registry as a place for private images in the context of Kubernetes</p>\n",
            "<p><a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\" class=\"external-link\" rel=\"nofollow\">https://ipywidgets.readthedocs.io/en/stable/user_install.html</a></p>\n",
            "<p>Create a visit tag for all HSC RC data using DESDM. This includes visit/ccd that would fail processCcd.</p>\n",
            "<p>Implements <a href=\"https://jira.lsstcorp.org/browse/RFC-409\" title=\"Only check configuration/schemas/versions in output repositories\" class=\"issue-link\" data-issue-key=\"RFC-409\"><del>RFC-409</del></a>.</p><p>If this is as easy as I\\'m guessing, I should be able to get this done before the RFC is adopted, and then merge it at the same time as <a href=\"https://jira.lsstcorp.org/browse/DM-12450\" title=\"Implement RFC-407: improve interface for clobbering vs. reusing outputs\" class=\"issue-link\" data-issue-key=\"DM-12450\"><del>DM-12450</del></a> to allow me to group the announcements about these changes in behavior.</p>\n",
            "<p>Add the catalog that contains fake galaxy parameters generated from COSMOS to synpipe and update the config file for the fake object catalog generator to point to this file.</p>\n",
            "<p>Now that TE1 is calculated on the master branch of <tt>validate_drp</tt> but not included in the release metrics.  This causes a <tt>KeyError</tt> when I run <tt>reportPerformance.py</tt> on JSON files produced with a master version.</p>\n",
            "<p>The current Avro schemas in lsst-dm/sample-avro-alert (and also in ZTF\\'s schemas) can give a warning when decoded in Spark using that says (e.g., shows up I think for all nullable fields):</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[WARNING] Avro: Invalid default for field cutoutScience: null not a [{\"type\":\"record\",\"name\":\"cutout\",\"namespace\":\"ztf.alert\",\"fields\":[{\"name\":\"fileName\",\"type\":\"string\"},{\"name\":\"stampData\",\"type\":\"bytes\",\"doc\":\"jpeg\"}]},\"null\"]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[WARNING] Avro: Invalid default for field cutoutTemplate: null not a [{\"type\":\"record\",\"name\":\"cutout\",\"namespace\":\"ztf.alert\",\"fields\":[{\"name\":\"fileName\",\"type\":\"string\"},{\"name\":\"stampData\",\"type\":\"bytes\",\"doc\":\"jpeg\"}]},\"null\"]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This happens when I use Spark package com.databricks:spark-avro_2.11:3.2.0, create a SparkSession, and read data this way:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">data = (sparkSession</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        .read</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        .format(\"com.databricks.spark.avro\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        .load(\"ztf/with-schema/ztf_avro_packets\"))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This might be because null needs to be in quotes and it isn\\'t?  I don\\'t know.  </p><p>This story is try quotes around \"null\" type in default type field and see if </p><p>1) the Spark warning goes away<br/>2) data still serializes/deserializes with plain Python modules and nullable fields </p>\n",
            "nan\n",
            "nan\n",
            "<p>Implementation ticket for <a href=\"https://jira.lsstcorp.org/browse/RFC-400\" title=\"Temporarily disable link time optimization on GCC\" class=\"issue-link\" data-issue-key=\"RFC-400\"><del>RFC-400</del></a>.</p>\n",
            "<p>External package treecorr fails to build on Linux gcc python3 due to its <tt>setup.py</tt> not encoding the \"determine C++ compiler\" test code before writing it.</p><p>We can fix this with a patch ourselves and then push it upstream later. Who would be responsible for pushing the fix upstream?</p>\n",
            "\"<p>Update both shared stacks on <tt>lsst-dev01</tt> to build against devtoolset-6.</p><p>Since this won't be ABI compatible with the earlier (no-devtoolset) stacks, we'll need to create entirely new stacks, which should probably build over a weekend.</p>\"\n",
            "\"<p>In the current processing model, tract is the processing unit, each tract is processed independently, and we don't assume there is disk space to save all products of one tract for other tracts to use. SFM of one visit/ccd would be done once for each overlapping tract; therefore tract ID is needed in filename patterns to ensure a unique filename.  </p><p>In DESDM wcl, add tract ID and camera symbol to the filenames of the SFM products. </p>\"\n",
            "<p>Break different sections into subconfigs.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Make bokeh part of default set of packages.</p>\n",
            "<p>See if it breaks anything to take out our chowns.</p>\n",
            "<p>Let <tt>ap_verify</tt> call the association step in <tt>ap_pipe</tt> and verify that the code runs to completion on the standard <tt>ap_pipe</tt> dataset (<tt>verify_ap_hits2015</tt>, <tt>visit=410985 ccdnum=25</tt>).</p>\n",
            "<p>hack_volume is no longer needed</p>\n",
            "<p>At present, the docker containers that are published as part of the weekly pipelines/apps tag/release process are using python 2.7.  In addition, they are from scratch builds which should no longer be necessary as weekly binary \"tarball\" builds are being published.</p>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<p>The prototype QA dashboard (<a href=\"https://jira.lsstcorp.org/browse/DM-10619\" title=\"Build a prototype bokeh server implementation to demonstrate desired interactive QA plots\" class=\"issue-link\" data-issue-key=\"DM-10619\"><del>DM-10619</del></a>) was only implemented using one patch-worth of HSC data.  With a factor of ~100 more data (e.g., a whole tract), performance may suffer to the point where qualitatively different solutions for some things may be required, such as perhaps density (or partial-density) plots for the scatter image, which may require different solutions for selection, etc.  This will require re-running <tt>coaddAnalysis.py</tt> again on an HSC tract, saving the data table, and plugging that in as the data in the prototype dashboard.  This ticket should spawn new tickets to solve whatever issues arise from using this larger data set.</p>\n",
            "<p>At least some of the implementation was in</p><p>$OBS_SUBARU_DIR/python/lsst/obs/subaru/ingest.py</p><p>on the old HSC fork.</p>\n",
            "<p>Starting this morning, (2017-07-31 ~ 03:00am EDT), <tt>pipe_tasks</tt> on master fails <tt>tests/testPhotoCal.py</tt>.  See first attached file (<tt>consoleText.txt</tt> for full log from Jenkins job.  second attached file <tt>pipe_tasks_failure_build.log</tt> for the same error with a local build on my desktop.</p>\n",
            "<p>The existing simulation data used for testing the DCR template building code is missing some important metadata. Those simulations should be brought up to date, and re-created with all the required metadata.</p>\n",
            "nan\n",
            "<p>Is Galsim a viable option for propagating uncertainty, or do we need to write something bespoke for this purpose?</p><p>If the latter, file a new ticket to do that work.</p>\n",
            "<p>Need SQL API for:</p><ul>\\t<li>submitting async query, note that we should be able to specify where the results are going / what is the format of the results</li>\\t<li>retrieving status of async query</li>\\t<li>retrieving results of async query</li>\\t<li>retrieving partial results of async query while it is running</li></ul>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=sthrush\" class=\"user-hover\" rel=\"sthrush\">Samantha Thrush</a> noticed that tasks fail if the output is a non-empty non-repo folder.  To reproduce with <tt>w_2017_26</tt>: </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ mkdir out</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ echo </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1234</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> &gt; out/a</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ processCcd.py /datasets/hsc/repo --id visit=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">444</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ccd=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">4</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  --output out</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This gives errors: </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/software/lsstsw/stack/Linux64/pipe_tasks/13.0-38-gf73ba12/bin/processCcd.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">25</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    ProcessCcdTask.parseAndRun()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/software/lsstsw/stack/Linux64/pipe_base/13.0-9-g1c7d9c5+5/python/lsst/pipe/base/cmdLineTask.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">509</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in parseAndRun</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    parsedCmd = argumentParser.parse_args(config=config, args=args, log=log, override=cls.applyOverrides)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/software/lsstsw/stack/Linux64/pipe_base/13.0-9-g1c7d9c5+5/python/lsst/pipe/base/argumentParser.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">512</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in parse_args</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    namespace.butler = dafPersist.Butler(inputs=inputs, outputs=outputs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/software/lsstsw/stack/Linux64/daf_persistence/13.0-20-g8cd6840/python/lsst/daf/persistence/butler.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">531</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in __init__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    self._setAndVerifyParentsLists(repoDataList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/software/lsstsw/stack/Linux64/daf_persistence/13.0-20-g8cd6840/python/lsst/daf/persistence/butler.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">905</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in _setAndVerifyParentsLists</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    repoData.cfg.extendParents(parents)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/software/lsstsw/stack/Linux64/daf_persistence/13.0-20-g8cd6840/python/lsst/daf/persistence/repositoryCfg.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">167</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in extendParents</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">if</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> all(x == y </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> (x, y) in zip(self._parents, newParents)):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">TypeError: zip argument #</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> must support iteration</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>If the folder is empty (i.e. skipping <tt>$ echo 1234 &gt; out/a</tt> in the example) then the task runs just fine.</p>\n",
            "<p>When DAX has problem as today (6/22/17), select the table \"Forced photometry based on i-band coadds\" table from \"SDSS Stripe82\" in <a href=\"http://localhost:8080/firefly/lsst-pdac-triview.html;a=layout.showDropDown\" class=\"external-link\" rel=\"nofollow\">http://localhost:8080/firefly/lsst-pdac-triview.html;a=layout.showDropDown</a>, in the metadata table area SUIT throws out this error message:</p><p>\"Catalog Fetch Error: edu.caltech.ipac.firefly.server.query.DataAccessException: DataAccessException:ERROR:DAX Error: OperationalError from:unknown\"</p><p>We need to improve the error message, following exception convention implemented by Trey in ticket <a href=\"https://jira.lsstcorp.org/browse/DM-10560\" title=\"Clean up image failure Error messages\" class=\"issue-link\" data-issue-key=\"DM-10560\"><del>DM-10560</del></a>, for our users.</p>\n",
            "<p>Remove all astrometry.net wrapper code from <tt>meas_astrom</tt> and put it in a new package named <tt>meas_extensions_astrometryNet</tt>.</p>\n",
            "<p>Generate a list of the tests that we want to prioritise with DM code on the test stand data.</p><p>This will include:</p><ul class=\"alternate\" type=\"square\">\\t<li>DM Staff (ie, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mfisherlevine\" class=\"user-hover\" rel=\"mfisherlevine\">Merlin Fisher-Levine</a>, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rhl\" class=\"user-hover\" rel=\"rhl\">Robert Lupton</a>) reading the existing list of tests and deciding which they reckon are important.</li>\\t<li>Consulting with the camera team to understand what their priorities are.</li></ul>\n",
            "<p>Linearization was implemented in <a href=\"https://jira.lsstcorp.org/browse/DM-6356\" title=\"Add linearity correction to obs_decam\" class=\"issue-link\" data-issue-key=\"DM-6356\"><del>DM-6356</del></a>. Make sure that linearity is still applied given the full decam ISR task.</p>\n",
            "<p>Update all git-lfs repositories to be compliant with current git-lfs best practices.</p><p>1. Remove <tt>batch = false</tt> configurations.<br/>2. Ensure <tt>.lfsconfig</tt> files exist.</p>\n",
            "<p><tt>pex_config</tt> is able to report where a config parameter is set.  Please add a command line option <tt>--show history=config.parameter.name</tt> to the cmdLineTask parser.</p><p>The implementation will probably want to use something like:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> lsst.pex.config.history as pch</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">pch.Color.colorize(</span><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">False</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">print</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> pch.</span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">format</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">(config.calibrate.astrometry.solver, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"matchingRadius\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Get list of what resources we need for k8s/jupyterlab together.</p>\n",
            "<p>composite objects should get passed to the std_&lt;datasetType&gt; function of the mapper, if there is one.</p>\n",
            "<p>Currently data points in the QA dashboard prototype can only be selected using the bokeh mouse tools (rectangle select, free-drag select, etc.) on two dimensions at a time (either in the x-y plane or in ra-dec space).  The dashboard should allow an additional more flexible query option that can filter the points that get displayed in the first place.  This should be relatively straightforward to implement using the pandas <tt>DataFrame.query</tt> method, which already accepts and parses a string to implement queries.</p>\n",
            "\"<p>We're writing the <tt>icExp</tt> files in <tt>CharacterizeImageTask</tt>, which we don't use, but greatly increases our disk usage. </p><p>We want the denormalized match catalogs from <tt>CalibrateTask</tt> and from multiband processing.</p>\"\n",
            "nan\n",
            "<p>as described on this wiki page <a href=\"https://confluence.lsstcorp.org/pages/editpage.action?pageId=58950873\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/pages/editpage.action?pageId=58950873</a><br/>update daf_persistence according to  <a href=\"https://jira.lsstcorp.org/browse/RFC-215\" title=\"Disallow executable tests due to &quot;#!/usr/bin/env python&quot; problems on OSX\" class=\"issue-link\" data-issue-key=\"RFC-215\"><del>RFC-215</del></a> and <a href=\"https://jira.lsstcorp.org/browse/RFC-229\" title=\"Python tests should be named test_*.py for pytest support\" class=\"issue-link\" data-issue-key=\"RFC-229\"><del>RFC-229</del></a></p>\n",
            "<p>Many clients of <tt>XYTransform</tt> use its methods <tt>linearizeForwardTransform</tt> and <tt>linearizeReverseTransform</tt>. We do not yet have analogous code for <tt>Transform</tt>. This functionality can be implemented as either a method on <tt>Transform</tt> or a separate function; the latter would provide better encapsulation.</p>\n",
            "<p>We need to be able to pass information from user about query type (sync/async). This may require tweaking the parser.</p>\n",
            "<p>Prepare an outline for Science Platform design document</p>\n",
            "<p>Rewrite more of imgserv according to PEP8 and Python 3 improvements</p>\n",
            "<p>Add pandoc so we can get PDF exports.</p>\n",
            "<p>Make kernel list look like we want it to when we do this for real.</p>\n",
            "<p>After <a href=\"https://jira.lsstcorp.org/browse/DM-10253\" title=\"Construct master calibs for obs_ctio0m9\" class=\"issue-link\" data-issue-key=\"DM-10253\"><del>DM-10253</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-10565\" title=\"Get source detection and astrometry &quot;working&quot; in obs_ctio0m9\" class=\"issue-link\" data-issue-key=\"DM-10565\"><del>DM-10565</del></a> things were working well with obs_ctio0m9, but changes to some defaults in meas_astrom meant that the <tt>processCcd.py</tt> config merged there is no longer correct. This ticket exists to make those changes.</p>\n",
            "\"<p>Metaserv's database information will be based on the model in VOResource so that we can implement RegTAP. Our implementation of RegTAP will be based on views, as our underlying tables may need additional columns that should not be exposed through the RegTAP interface,</p>\"\n",
            "<p>In Firefly  chart column expression, we use log() as 10-based logarithm, ln() as natural logarithm. </p><p>I checked Python, Perl, C, C++, Java, the convention is to use log() as natural logarithm, and log10() as the 10-based logarithm. </p><p>We need to make the change and document it. </p>\n",
            "<p>At the DMLT telecon of 2017-06-26, we agreed to:</p><ul class=\"alternate\" type=\"square\">\\t<li>Not provide LDM-472 to reviewers;</li>\\t<li>Remove mention of LDM-472 from DMTN-020 (which will go to reviewers);</li>\\t<li>Transfer all useful information from LDM-472 to LDM-294 (which will go to reviewers).</li></ul>\n",
            "<p>Change logging setup to use shovel-based RMQ transport for logstash.</p>\n",
            "<p>Update DMTN-044 to reflect the acceptance of the SQuaRE provided binary release system, and that decisions about long-term release maintenance will be deferred until the release manager position has been filled, and place it in Docushare.</p>\n",
            "<p><tt>newinstall.sh</tt> should be updated to use eups 2.1.3 to reduce the time required to install binary tarballs.  <tt>lsstsw</tt> should be updated at the same time to keep our build envs in sync.</p>\n",
            "<p>Building on the work started by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=womullan\" class=\"user-hover\" rel=\"womullan\">Wil O\\'Mullane</a> in <a href=\"https://jira.lsstcorp.org/browse/DM-10801\" title=\"Update DMTN-020 \" class=\"issue-link\" data-issue-key=\"DM-10801\"><del>DM-10801</del></a>.</p>\n",
            "<p>Take nightly GH snapshots / expire snapshots according to retention policy.</p>\n",
            "<p>Currently standard procedure to deal with segfaults is to run a debugger. While this works for developers it is inconvenient for end users and potentially impossible for intermittent bugs on large clusters.<br/>Hence automatically printing a backtrace on segfault can be useful to quickly diagnose problems.<br/>A quick trial implementation suggests that relatively easy, this ticket aims to add this functionally to the stack.</p>\n",
            "<p>Ensure that the reducer subtask correctly sets the mask to invalid for pixels where the reduced exposure is infinite or NaN.</p>\n",
            "<p>This will make it much easier to change the runtime behavior without having to spin a new container.</p>\n",
            "<p>Work related to porting <tt>dax_imgserv</tt> to Python 3.</p>\n",
            "\"<p>In contrast to the regular pybind11 type casters the ndarray ones don't work well with <tt>nullptr</tt>.<br/>E.g. the function <tt>void testOptionalArray(ndarray::Array&lt;double, 1, 1&gt; * arr = nullptr)</tt> should accept <tt>None</tt> as a default argument, but it does not.</p>\"\n",
            "\"<p>Make things-that-should-be-configurable Kube deployment variables/secrets; be consistent about using secrets for secret things and env vars otherwise.  Generally make the deployment more useful for people-who-aren't-SQuaRE.</p>\"\n",
            "<p>Test the corrections made in <tt>meas_mosaic</tt> in <a href=\"https://jira.lsstcorp.org/browse/DM-10688\" title=\"return update ccdSet in solveMosaic_CCD\" class=\"issue-link\" data-issue-key=\"DM-10688\"><del>DM-10688</del></a> by running a full HSC-RC run with the current stack to see if the ellipticity residuals are better.</p>\n",
            "\"<p>I have some unusual data (HSC pinhole filter images) for which I'd like to run only very basic Isr tasks (overscan subtraction and bias subtraction), which is tricky to manage with processCcd.py.  This ticket is to create a subaruIsr.py command line executable to accomplish this.</p>\"\n",
            "nan\n",
            "nan\n",
            "<p>Whilst looking at an individual spot from the CBP on DECam I noticed a weird feature, and upon further investigation, several more, though these were very hard to see.</p><p>This ticket is to investigate what image processing techniques will make these hard-to-see features pop out so that they can be examined more closely.</p>\n",
            "<p>Jointcal produces a number of compile-time warnings (which one can miss without the scons fix described in <a href=\"https://jira.lsstcorp.org/browse/RFC-246\" title=\"Suppress warnings for external packages\" class=\"issue-link\" data-issue-key=\"RFC-246\"><del>RFC-246</del></a>). We should clean these up, which might be helped by compiling with both gcc and clang, and comparing their messages. It may be best to do this after we\\'ve dealt with other problems (like the boost pointer memory management), as that may take care of some of the warnings along the way. On the other hand, there\\'s quite a bit of low-hanging fruit in the form of variables that are defined but never used.</p>\n",
            "<p>Statistics were generated at IN2P3 for correcting <tt>JOIN</tt> queries. The general process needs to be documented so we can optimize it in the future (see <a href=\"https://jira.lsstcorp.org/browse/DM-9757\" title=\"Add stat table usage options to mysql config file\" class=\"issue-link\" data-issue-key=\"DM-9757\"><del>DM-9757</del></a> for reference).</p>\n",
            "<p>When comparing the effectiveness of the deblender it useful to have the true light distribution of an isolated galaxy to compare the output of the deblender.  The blending simulation script in <a href=\"https://jira.lsstcorp.org/browse/DM-8624\" title=\"Evaluate the deblender using simulations\" class=\"issue-link\" data-issue-key=\"DM-8624\"><del>DM-8624</del></a> currently stores the true total flux of each object, but nothing else.  This ticket is to add true spatial information to the script in <a href=\"https://jira.lsstcorp.org/browse/DM-8624\" title=\"Evaluate the deblender using simulations\" class=\"issue-link\" data-issue-key=\"DM-8624\"><del>DM-8624</del></a> for each object.</p>\n",
            "<p>Like the <tt>Mappings</tt> they adapt, a <tt>Transform</tt> may or may not have a forward transformation, and may or may not have an inverse transformation. Test methods should be added to <tt>Transform</tt> to let clients defend against calling a missing transformation.</p>\n",
            "<p>ci_hsc is now taking over an hour to run, when it used to take around half an hour. Why?</p>\n",
            "<p>go through the stack &amp; find all the paf Butler Policies. load them as daf.persistence.Policy and write them out to yaml. in git, remove the paf file, add the yaml file. </p>\n",
            "<p>The details of the WISE catalogs loading into PDAC need to documented at:</p><ul>\\t<li><a href=\"https://confluence.lsstcorp.org/display/DM/Loading+catalogs+into+PDAC\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Loading+catalogs+into+PDAC</a></li></ul>\n",
            "<p>Implement changes to display_firefly to enable it to work with more servers, and fix some issues found in testing.</p><ul>\\t<li>Add a <tt>basedir</tt> parameter, to make use of the capability added in <a href=\"https://jira.lsstcorp.org/browse/DM-9843\" title=\"Update firefly_client to handle variations in base URL\" class=\"issue-link\" data-issue-key=\"DM-9843\"><del>DM-9843</del></a>, to allow the firefly backend to be used with the PDAC server and the public IRSA server.</li>\\t<li>Pass keyword arguments to the FireflyClient constructor.</li>\\t<li>Update the image and mask handling, in part for changes due to the pybind11 conversion, and to restore mask labeling.</li></ul><p>In afw.display:</p><ul>\\t<li>Fix the &#95;&#95;getattr&#95;&#95; method of the display interface</li>\\t<li>Reorder tests so that displays are not closed prematurely</li></ul>\n",
            "<p><a href=\"https://github.com/esheldon/meds\" class=\"external-link\" rel=\"nofollow\">MEDS</a> is a file-based interface for multi-epoch fitting developed for use in the Dark Energy Survey.  At the 2017/02/17 DESC hack day, Erin Sheldon, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=boutigny\" class=\"user-hover\" rel=\"boutigny\">Dominique Boutigny</a>, and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a> started a project to build MEDS files from DM stack outputs at <a href=\"https://github.com/esheldon/medsdm\" class=\"external-link\" rel=\"nofollow\">https://github.com/esheldon/medsdm</a>.</p><p>With a small amount of additional work on the DM side, and a bit more on Erin\\'s, this will allow us to run the multi-epoch shear measurement codes developed for DES, giving us an early prototype we can use to test various multifit vs. coadd science and algorithmic performance questions.</p><p>This issue is intended to capture the small amount of remaining work necessary to get the DM inputs to MEDS generation up to approximately the level of quality of the DES inputs.  A to-do list can be found in the medsdm git repo.</p>\n",
            "<h4><a name=\"Shortversion%3A\"></a>Short version:</h4><p>Clarify what existing community practices, notably including VO interfaces, appear to rely on the availability of unauthenticated access to information in astronomical archives.</p><h4><a name=\"Details%3A\"></a>Details:</h4><p>At the February DM All Hands, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=frossie\" class=\"user-hover\" rel=\"frossie\">Frossie Economou</a> raised an objection when it was mentioned that there is a presumption that all user access to LSST data through the DM interfaces (as opposed to through EPO) will be authenticated.</p><p>We don\\'t appear to have ever documented an explicit requirement that all access be authenticated.  The basic controlling requirement is OSS-REQ-0176, \"The LSST Data Management System shall provide open access to all LSST Level 1 and Level 2 Data Products, as defined in the LSST System Requirements and herein, in accordance with LSSTC Board approved policies. ...\", which was a carefully crafted indirection at a time when the policy for non-US/Chile access was still being developed.</p><p>However, this presumption has been around for a long time.  It is inherent to the project policy that access to the non-Alert data will be limited to individuals who are entitled to it.  No matter what we think the final policy might be, we do have to design a system that can be consistent with this policy.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=frossie\" class=\"user-hover\" rel=\"frossie\">Frossie Economou</a> stated that the astronomical community relies on certain types of data and metadata - she mentioned coverage maps, among others - being available through unauthenticated interfaces.</p><p>This ticket is to ask her (and others) to collect documentation of those existing practices, so that we can figure out what the expectations may be and how to respond to them in our design.</p>\n",
            "<p>SUI/T design document outline.  </p>\n",
            "nan\n",
            "<p>Calexp and coadd image directory trees from NCSA and IN2P3 sides of the strip82 processing need to be merged, so imgserv can serve images for the entirety of stripe82.  We anticipate doing this with some scripts to build the merged directory trees as link farms.</p><p>The datasets will be put into this folders:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/datasets/sdss/preprocessed/dr7/sdss_stripe82_00</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/datasets/sdss/preprocessed/dr7/sdss_stripe82_00/calexp</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/datasets/sdss/preprocessed/dr7/sdss_stripe82_00/coadd</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The name of the bade folder matches the name of the corresponding catalog within the PDAQ Qserv.</p>\n",
            "\"<p>Now that we switched Qserv to mariadb, it'd be good to switch the rest of the stack. This story involves trying out if things still work if we switch mysqlclient to mariadbclient.</p>\"\n",
            "<p>Includes need cleanup: group into standard lib, boots and local, sort as appropriate etc. Also, unify forward declarations.</p>\n",
            "<p>Design how to redesign CSS, we currently take a snapshot when char starts. It is too static. </p>\n",
            "<p>DDL information is embedded as comments in the master version of the schema (in \"cat\" repo). Currently we are only using it for schema browser. This story involves designing the procedure involving loading DDL information into MetaServ. We need to be ready to support a variety of scenarios:</p><ul>\\t<li>we are getting already preloaded database, need to just load metadata about it to metaserv (we might have the original ascii file with extra information, or not)</li>\\t<li>we are starting from scratch, need to initialize database (including loading schema), and need to load the information to the metaserv</li>\\t<li>we already have the database and metadata in metaserv, but we want to change something (eg. alter table, or delete table, or delete database).</li></ul>\n",
            "<p>As discussed at <a href=\"https://confluence.lsstcorp.org/display/DM/Data+Access+Hangout+2015-02-23\" class=\"external-link\" rel=\"nofollow\">Data Access Hangout 2015-02-23</a>, we should support json format. This includes defining the exact format, and implementing it. This story covers defining the format.</p>\n",
            "<p>This story captures issues/topics that we want to bring up with mysql team.</p>\n",
            "<p>We need to setup a service (eg on lsst-dev) that can be used by the IPAC team to play with our webserv/metaserv/dbserv/imgserv.</p><p>The server runs on lsst-dev machine, port 5000. To ssh-tunnel, try:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ssh -L 5000:localhost:5000 lsst-dev.ncsa.illinois.edu</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>An example usage:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  curl \\'http://localhost:5000/db/v0/query?sql=SHOW+DATABASES+LIKE+\"%Stripe%\"\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  curl \\'http://localhost:5000/db/v0/query?sql=SHOW+TABLES+IN+DC_W13_Stripe82\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  curl \\'http://localhost:5000/db/v0/query?sql=DESCRIBE+DC_W13_Stripe82.DeepForcedSource\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  curl \\'http://localhost:5000/db/v0/query?sql=DESCRIBE+DC_W13_Stripe82.Science_Ccd_Exposure\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  curl \\'http://localhost:5000/db/v0/query?sql=SELECT+deepForcedSourceId,scienceCcdExposureId+FROM+DC_W13_Stripe82.DeepForcedSource+LIMIT+10\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  curl \\'http://localhost:5000/db/v0/query?sql=SELECT+ra,decl,filterName+FROM+DC_W13_Stripe82.Science_Ccd_Exposure+WHERE+scienceCcdExposureId=125230127\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  curl \\'http://localhost:5000/image/v0/raw/cutout?ra=7.90481567257&amp;dec=-0.299951669961&amp;filter=r&amp;width=30.0&amp;height=45.0\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Setup Qserv and configure webserv to talk to Qserv. Verify all works, and fix discovered problems.</p>\n",
            "<p>SUI which rely on JDBC fail because they internally issue some queries that are not yet supported by Qserv. Need to patch it (in the short term), and add proper support (in the long term). This story covers the patching only. The queries that upset Qserv are listed below. </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SHOW VARIABLES WHERE Variable_name =\\'language\\' OR Variable_name = \\'net_write_timeout\\' OR Variable_name = \\'interactive_timeout\\' OR Variable_name = \\'wait_timeout\\' OR Variable_name = \\'character_set_client\\' OR Variable_name = \\'character_set_connection\\' OR Variable_name = \\'character_set\\' OR Variable_name = \\'character_set_server\\' OR Variable_name = \\'tx_isolation\\' OR Variable_name = \\'transaction_isolation\\' OR Variable_name = \\'character_set_results\\' OR Variable_name = \\'timezone\\' OR Variable_name = \\'time_zone\\' OR Variable_name = \\'system_time_zone\\' OR Variable_name = \\'lower_case_table_names\\' OR Variable_name = \\'max_allowed_packet\\' OR Variable_name = \\'net_buffer_length\\' OR Variable_name = \\'sql_mode\\' OR Variable_name = \\'query_cache_type\\' OR Variable_name = \\'query_cache_size\\' OR Variable_name = \\'license\\' OR Variable_name = \\'init_connect\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SELECT @@session.auto_increment_increment</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SET NAMES latin1</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SET character_set_results = NULL</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SET autocommit=1</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SET sql_mode=\\'STRICT_TRANS_TABLES\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>rename DATABASE_PARTITIONING to PARTITIONING</p><p>rename DATABASES to DBS</p>\n",
            "<p>Transferring knowledge from K-T to the DB team.</p>\n",
            "<p>The SUI team is using JDBC connector and queries like</p><p>\"SET @@session.autocommit = </p>{0}<p>\".format(switch)</p><p>are derailing everything. We should add support for these queries. </p>\n",
            "<p>We are mixing boost and std shared_ptrs. This should be cleaned up - use std:shared_ptr consistently everywhere. In a few places we have other types of pointers, (e.g weak_ptr). Migrate these too.</p>\n",
            "<p>The zookeeper client in C++ that the czar uses doesn\\'t auto-reconnect. This is a capability provided in the kazoo library that qserv\\'s python layer provides, but isn\\'t provided in the c++ client. <br/>The zookeeper client disconnects pretty easily: if you step through your code in gdb, the zk client will probably disconnect because its threads expect to keep running. zk sessions may expire too. Our layer should reconnect unless there is really no way to recover without assistance from the calling code (e.g. configuration is wrong, etc.).</p><p>This ticket includes only basic reconnection attempting, throwing an exception only when some \"reconnection-is-impossible\" condition is met.</p>\n",
            "<p>5 tests fail in the testCppParser.</p>\n",
            "<p>It looks like DISTINCT aggregate is not supported yet in qserv. Daniel told me that this should be relatively straightforward to add. Adding this ticket so that we do not forget it.</p>\n",
            "<p>There seem to be confusion about driving table and secondary index. At the moment in zookeeper structure we have</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/DATABASES/&lt;dbName&gt;/objIdIndex</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/DATABASES/&lt;dbName&gt;/TABLES/&lt;tableName&gt;/partitioning/secIndexColName</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/DATABASES/&lt;dbName&gt;/TABLES/&lt;tableName&gt;/partitioning/drivingTable</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/DATABASES/&lt;dbName&gt;/TABLES/&lt;tableName&gt;/partitioning/latColName</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/DATABASES/&lt;dbName&gt;/TABLES/&lt;tableName&gt;/partitioning/lonColName</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/DATABASES/&lt;dbName&gt;/TABLES/&lt;tableName&gt;/partitioning/keyColName</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Issues to think about:</p><ul>\\t<li>we can\\'t call it objIdIndex, it is too lsst-specific.</li>\\t<li>drivingTable and keyColName - perhaps these should be at database level, which means we would only allow one drivingTable and one secondary index per database?</li>\\t<li>or, maybe instead of database level, it is a partitioning parameter? Note that two databases might use different name for secondary index or driving table, yet they might be joinable. That argues for introducing a new group, something like /DATABASE/partitioning in addition to /DATABASE_PARTITIONING.</li>\\t<li>consider renaming drivingTable to keyTable</li>\\t<li>do we really need secIndexColName and keyColName? Can\\'t we get rid of one, and rename to keyColName?</li></ul>\n",
            "\"<p>It'd be very useful to have fully functioning Qserv release with the latest set of changes (build, packaging, CSS, Daniel's fixes etc) during the Hackathon week.</p>\"\n",
            "<p>Need to better document what is supported / accepted by schemaToMeta.py. We are currently relying on cat/sql/baselineSchema.sql as the guide.</p>\n",
            "<p>The mess of thread.cc and dispatcher.cc need to be<br/>re-thought and re-designed so that the interface is smaller and more obvious.</p>\n",
            "<p>Web alpha version of the form (using django or Fermi Java webservices code) that collects input from users about data repositories. Authentication not covered in this version.</p>\n",
            "<p>Current provenance schema in baseline (cat/sql) is very old and no longer reflect latest thinking. This story involves bringing cat/sql up to data and replacing existing prv_* tables with tables we came up with in the epic.</p>\n",
            "<p>Clean up the way modules are imported in qserv master, use relative import when appropriate instead of lsst.qserv.master.&lt;package&gt; </p><p>(migrated from Trac #2369)</p>\n",
            "<p>Reported by Serge:</p><p>In CssException.h you\\xe2\\x80\\x99ve got:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class CssRunTimeException: public std::runtime_error { \\xe2\\x80\\xa6 };</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class CssException_XXXX : public CssRunTimeException { \\xe2\\x80\\xa6 };</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This is inconsistent (shouldn\\xe2\\x80\\x99t it be CssRunTimeException_XXX, or maybe even CssRunTimeError?), lengthy, violates the LSST C++ naming conventions, and doesn\\xe2\\x80\\x99t match the KvInterface docs, which all still talk about a CssException class that does not exist. Can we consider changing this to something more like:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class CssError : public std::runtime_error</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class KeyError : public CssError</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class NoSuchTable : public KeyError</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class NoSuchDb : public KeyError</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class AuthError : public CssError</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class ConnError : public CssError</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>? Then we can succinctly throw and catch css::NoSuchTable, css::AuthError etc\\xe2\\x80\\xa6</p>\n",
            "<p>Need to come up with KPIs for Qserv</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-2417\" title=\"Data loader script crashes trying to create chunk table\" class=\"issue-link\" data-issue-key=\"DM-2417\"><del>DM-2417</del></a> revealed that the current implementation of createTable in db module behaves differently that mysql: mysql will issue a warning if table exists, and db module will fail with an error. We should make the db behave similarly to how mysql behaves. </p>\n",
            "<p>Transferring knowledge from K-T to the DB team.</p>\n",
            "<p>When we run with 110 simultaneous queries, czar fails with \"uncaught exception\"</p>\n",
            "<p>Fabrice, can you package log4cxx? I should have asked you earlier, sorry I waited so long, not it becoming urgent! Bill is almost done with his logging prototype and will be turning it into a real package, and we need to have log4cxx packages. Many thanks.</p><p>log4cxx version 0.10.0, which was released in 4/3/2008 but is still undergoing \"incubation\" at Apache. </p>\n",
            "<p>Setup Qserv on lsst-db2 with and load some reasonable data set (perhaps PT 1.2). One potential caveat: we need to setup access for some accounts that are ideally other than our internal qsmaster.</p>\n",
            "<p>Transferring knowledge from K-T to the DB team.</p>\n",
            "<p>I wonder if we could catch more exceptions in czar to simplify debugging. For example, if I change:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--- a/core/modules/czar/lsst/qserv/master/app.py</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+++ b/core/modules/czar/lsst/qserv/master/app.py</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">@@ -418,7 +418,7 @@ class InbandQueryAction:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">                    self.constraints.size())</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">         dominantDb = getDominantDb(self.sessionId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">         dbStriping = getDbStriping(self.sessionId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-        if (dbStriping.stripes &lt; 1) or (dbStriping.subStripes &lt; 1):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+        if (dbStriping.x &lt; 1) or (dbStriping.y &lt; 1):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>It will return to client a very cryptic error:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Qserv error: Unexpected error: (&lt;type \\'exceptions.AttributeError\\'&gt;, AttributeError(\\'x\\',), &lt;traceback object at 0x969a02c&gt;)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>with no other clues, traceback or information in the log.</p>\n",
            "<p>Track versions of data inside zookeeper, and detect from Qserv code if Qserv code is compatible with given format of data.</p>\n",
            "<p>Need to implement deleting databases. Deliverable: a design of the system that will be capable of deleting a distributed database including all copies of that database on all workers, all replicas of all chunks are deleted. It should be possible to \"create database x\" at any time later.</p>\n",
            "<p>Qserv has code to support:</p><ul>\\t<li>qserv_areaspec_box</li>\\t<li>qserv_areaspec_circle</li>\\t<li>qserv_areaspec_ellipse</li>\\t<li>qserv_areaspec_poly</li></ul><p>but only the first one (box) is exercised in our integration tests. This story involves adding queries to test the other 3.</p>\n",
            "<p>While we aren\\'t using any of the new features of Kazoo\\'s 2.x series, the removal of zope.interface as a dependency is a worthwhile feature.</p><p>The 2.0b1 release seems at least as stable as our own code, so I don\\'t think we\\'ll see any negative effects.</p><p>This ticket covers:</p><ul class=\"alternate\" type=\"square\">\\t<li>Upgrade of the packaged kazoo from 1.3.1 to 2.0b1 (or later).</li>\\t<li>(optionally) patches for kazoo\\'s setup.py so that it doesn\\'t search for and try to download any dependencies. This can be done in a later ticket, though.</li></ul><p>I note that kazoo can be run without installation: you can untar it, cd into the directory, and if you run python from there, you can immediately \"import kazoo\" and use it. Hence we could avoid setup.py completely and just copy the \"kazoo\" subdirectory into some directory in the PYTHONPATH.</p>\n",
            "nan\n",
            "<p>try running </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">find core css admin client tests site_scons | xargs grep -i qms</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>There is a lot of old unused qms related code.</p>\n",
            "<p>Design watcher, including its interactions with other components (mysql, css, etc). In the near term, the watcher will handle deleting tables and databases.</p>\n",
            "<p>Checkout mysql cluster ndb from the perspective of data distribution - could it be potentially useful to store data related to data distribution?</p>\n",
            "<p>Transferring knowledge from K-T to the DB team.</p>\n",
            "<p>The config file for the qserv czar has some items that are no longer relevant, and in this issue, we focus on the ones that are clearly the responsibility of our qserv css.</p><p>This ticket includes:<br/>&#8211; removing these items from the installation/configuration templates<br/>&#8211; removing these items from sample configuration files<br/>&#8211; removing these items from the code that reads in the configuration file and sets defaults for these items<br/>&#8211; fixing things that seem to break as a result of this cleanup.</p><p>danielw volunteers to assist on the last item, as needed.</p>\n",
            "\"<p>Per discussion at data access meeting Aug 10, it'd be good to send column names with the query results.</p>\"\n",
            "<p>Transferring knowledge from K-T to the DB team.</p>\n",
            "<p>We need to add a query (or more?) to the qserv_testdata that involve blobs. Blobs are interesting because they might break some parts of the qserv if we failed to escape things properly etc. </p>\n",
            "<p>Remove remaining dependencies on mysqldb in qserv.:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">./core/modules/tests/MySqlUdf.py</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">./core/modules/wmgr/python/config.py</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>and use the sqlalchemy from db module instead.</p>\n",
            "<p>Describe (my) perception of the current state of the SuperTask interface from the Science Pipelines perspective to gather feedback from other Science Pipelines stakeholders and clarify any problems to the rest of the SuperTask working group.</p>\n",
            "<p>The current DCR template generation code requires the user to supply the name of the telescope, and has telescope-specific code that interfaces with the butler. This code should be re-written to be less fragile and to remove the lines that depend on the telescope.</p>\n",
            "<p>Update the developer guide to indicate that Python 3 must be supported and that code must run on Python 2.7 and 3.</p><p>This ticket will reference the tech note delivered as part of <a href=\"https://jira.lsstcorp.org/browse/DM-6315\" title=\"Write Python 3 porting guide (SQR-014)\" class=\"issue-link\" data-issue-key=\"DM-6315\"><del>DM-6315</del></a>. Writing extensive user documentation on the <tt>future</tt> package is beyond the scope of this ticket.</p>\n",
            "<p>Before starting work on <a href=\"https://jira.lsstcorp.org/browse/DM-9678\" title=\"Assess the current PSF system\" class=\"issue-link\" data-issue-key=\"DM-9678\"><del>DM-9678</del></a> in earnest, I need to familiarize myself with the existing framework. A quick look at the stack documentation suggests PSF code is scattered across multiple packages (e.g., <tt>afw::detection::Psf</tt>, <tt>meas::algorithms::ImagePsf</tt>, <tt>meas::algorithms::PsfCandidate</tt>, <tt>pipe.tasks.measurePsf</tt>), so untangling things may not be trivial.</p>\n",
            "<p>Current behavior:<br/>When there are more than one images displayed,  turning \"WCS match\" checkbox on will zoom and rotate all the images to the same pixel size and direction as the active image (selected, with orange color highlight), turning the checkbox off does nothing. </p><p>Improvement:<br/>Turning off the \"WCS match\" should reset the images to a zero rotation.</p><p>Also include two bug fixes:</p><ul class=\"alternate\" type=\"square\">\\t<li>A rotation issue: clicking rotate north on north up images fliped them south</li>\\t<li>When north is up, clicking north up makes the image rotate south.</li></ul>\n",
            "<p>An examples subdirectory can be added to the firefly_client repository at the top level. It can contain sample Jupyter notebooks. The starting point can be notebooks for the Python API from the firefly repository, where the API was first developed.</p>\n",
            "\"<p>To use existing code in the stack for multi-band photometry, forced photometry, etc.. on the models generated with the DCR algorithm, many data types need to be added to obs_base. These will be added using the current name 'dcrModel' throughout, though it is expected that name might change following the eventual RFC to add the data type.</p>\"\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-6248\" title=\"DRP Top-Level Diagram and Descriptions, Draft 1\" class=\"issue-link\" data-issue-key=\"DM-6248\"><del>DM-6248</del></a> adds a large, complex diagram that will need to be cleaned up and converted to use the same conventions and colors as other diagrams in LDM-151.</p>\n",
            "<p>Summarize the plans for processing data from the Calibration Telescope and any open questions that remain about the approach to be taken in bullet-point form. Provide them to <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mfisherlevine\" class=\"user-hover\" rel=\"mfisherlevine\">Merlin Fisher-Levine</a> for incorporation into LDM-151.</p>\n",
            "<p>Based on the input provided by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=aguyonnet\" class=\"user-hover\" rel=\"aguyonnet\">Augustin Guyonnet</a> in <a href=\"https://jira.lsstcorp.org/browse/DM-9356\" title=\"Summarize plans &amp; questions for Calib Telescope work\" class=\"issue-link\" data-issue-key=\"DM-9356\"><del>DM-9356</del></a>, update LDM-151 to provide a complete description of the plans for processing data from the Calibration Telescope.</p>\n",
            "<p>A method of mangling the shebangs on OSX to a valid path is needed.</p>\n",
            "nan\n",
            "\"<p>The range of phase value should be [0, 2)</p><p>plotly based phase folding chart doesn't react properly while an invalid period value is selected from the periodogram table. The phase folded chart should show empty content when an invalid period value is selected. </p>\"\n",
            "<p>Update firefly_widgets to account for some changes in external dependencies:</p><ul>\\t<li>Generalize the connection parameter, for working with Firefly servers now being deployed with <tt>suit</tt> or <tt>irsaviewer</tt> in the URL, as was done for firefly_client in <a href=\"https://jira.lsstcorp.org/browse/DM-9843\" title=\"Update firefly_client to handle variations in base URL\" class=\"issue-link\" data-issue-key=\"DM-9843\"><del>DM-9843</del></a></li>\\t<li>Make some minor syntax changes to work with ipywidgets 6.0</li>\\t<li>Update example notebooks accordingly</li></ul>\n",
            "<p>Per meeting of 2017-03-29, review the SpanSet &amp; Footprint APIs before <a href=\"https://jira.lsstcorp.org/browse/DM-8108\" title=\"Update stack code to use new Footprint API\" class=\"issue-link\" data-issue-key=\"DM-8108\"><del>DM-8108</del></a> goes for review.</p>\n",
            "<p>Add unit test asserts to lsst.afw.geom.utils:</p><ul class=\"alternate\" type=\"square\">\\t<li>assertSpherePointsAlmosttEqual</li>\\t<li>assertSpherePointListsAlmostEqual</li>\\t<li>assertPointListsAlmostEqual</li></ul><p>and unit tests for them. This work is needed (or at least very useful) for the new WCS classes.</p>\n",
            "nan\n",
            "<p>Audience is the PST-SC Chairs telecon scheduled for April 18th.</p><p>Should be able to mostly reuse slides from last P&amp;CW, with some updates from LDM-151.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=swinbank\" class=\"user-hover\" rel=\"swinbank\">John Swinbank</a> reports that the header of latex documents using the <tt>lsstdoc</tt> class file is inconsistent leading to the document information sometimes crushing into the blue horizontal rule.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rearmstr\" class=\"user-hover\" rel=\"rearmstr\">Bob Armstrong</a> has fixed some critical problems in meas_mosaic and coaddition, so it\\'s time for a new release.  I\\'m also hoping to include a blendedness bugfix that should be trivial.</p><p>I do not think we\\'ll get PostgreSQL registry support into this minor release (I don\\'t know how much work it will be, so I don\\'t want to assume it\\'s trivial).</p><p>We should also need to add <tt>display_ds9</tt> to hscPipe on this release.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a>, I\\'m planning to work on this today unless I hear from you that you\\'re back in town and available to work on it.  If you do work on it, we should make sure we sync our versiondbs first so we don\\'t make anyone install anything unnecessary due to spurious version changes.</p>\n",
            "<p>As stated in <a href=\"https://jira.lsstcorp.org/browse/DM-9862\" title=\"Update meas_mosaic&#39;s wcs/fcr output files to reflect LSST coordinate system\" class=\"issue-link\" data-issue-key=\"DM-9862\"><del>DM-9862</del></a>, meas_mosaic assumes the 0,0 for each CCD to be the lower left hand corner.  LSST uses a different coordinate system so meas_mosaic rotates the wcs into the LSST frame when writing to disk.  However the photometric correction is still in the HSC frame, so when applying the meas_mosaic correction we need to rotate the wcs back to the HSC frame.  We can then create the photometric correction, rotate it into the LSST frame and apply it to the image.  We then rotate the wcs back to the LSST frame.</p>\n",
            "<p>The current unit tests for the DCR template generation prototype uses `numpy.save()` and `numpy.load()` to persist and depersist test data. This format is fragile and has already been broken once with the conversion from swig to pybind11, so a more robust test data format should be used.</p>\n",
            "<p>Currently, I maintain a shared stack on <tt>lsst-dev01</tt> by simply <tt>eups distrib</tt> installing recent releases from a cron job using <a href=\"https://github.com/lsst-dm/shared-stack\" class=\"external-link\" rel=\"nofollow\">this script</a>. This situation arose following discussions at the February 2016 JTM, with the understanding being that this was a temporary arrangement because SQuaRE\\'s other commitments left them short-handed in terms of shared stack maintenance.</p><p>A year later, we should revisit this discussion and figure out how to address underlying maintenance problems with the <tt>lsst-dev01</tt> shared stack, most notably how &amp; whether to update underlying \"system\" dependencies which are provided by Conda (e.g. AstroPy).</p>\n",
            "<p>People are starting to use lsst-texmf for document writing but there is some confusion. This ticket is to write a document explaining how to use the lsst latex classes.</p><p>The consensus is that this document should match the LSST \"software guide\" standard and be written using sphinx in a subdirectory of lsst-texmf (rather than writing it in Latex). The documentation will be published to <a href=\"https://lsst-texmf.lsst.io\" class=\"external-link\" rel=\"nofollow\">https://lsst-texmf.lsst.io</a> and will include links to the rendered example PDFs.</p><p>This ticket covers the writing of the guide. Publishing will be handled separately.</p>\n",
            "<p>A test run for the <tt>decam</tt> dataset succeed yesterday morning but the periodic evening build failed with the stack trace below.  Perhaps this is related to the <tt>daf_persistence</tt> changes yesterday?</p><p><a href=\"https://ci.lsst.codes/job/validate_drp/dataset=decam,label=centos-7,python=py2/863/\" class=\"external-link\" rel=\"nofollow\">https://ci.lsst.codes/job/validate_drp/dataset=decam,label=centos-7,python=py2/863/</a></p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/decam/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-gb01c0af08e/bin/validateDrp.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">97</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    validate.run(args.repo, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/decam/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-gb01c0af08e/python/lsst/validate/drp/validate.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">104</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/decam/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-gb01c0af08e/python/lsst/validate/drp/validate.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">204</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in runOneFilter</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    verbose=verbose)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/decam/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-gb01c0af08e/python/lsst/validate/drp/matchreduce.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">148</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in __init__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    repo, dataIds, matchRadius)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/decam/label/centos-7/python/py2/lsstsw/stack/Linux64/validate_drp/master-gb01c0af08e/python/lsst/validate/drp/matchreduce.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">208</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in _loadAndMatchCatalogs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    calexpMetadata = butler.get(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"calexp_md\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, vId, immediate=True)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/validate_drp/dataset/decam/label/centos-7/python/py2/lsstsw/stack/Linux64/daf_persistence/13.0-4-g886c4ba/python/lsst/daf/persistence/butler.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">945</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in get</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    raise NoResults(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"No locations for get:\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, datasetType, dataId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">lsst.daf.persistence.butlerExceptions.NoResults: No locations </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> get: datasetType:calexp_md dataId:DataId(initialdata={</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'filter\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'z\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'visit\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">176837</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'ccdnum\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">14</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}, tag=set([]))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">cp: cannot stat \\xe2\\x80\\x98/home/jenkins-slave/workspace/validate_drp/dataset/decam/label/centos-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">7</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/python/py2/validate_drp/Decam_output_z.json\\xe2\\x80\\x99: No such file or directory</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/home/jenkins-slave/workspace/validate_drp/dataset/decam/label/centos-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">7</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/python/py2/archive/decam/processCcd.log: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">5</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">,</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">072</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> B / </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">93.7</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> KiB = </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0.053</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Produce slides or a short, informal document showing examples from DRP where we need to change data units and/or parallelization axis at a scale we expect to be handled by SuperTask.</p>\n",
            "<p>Currently the PSF convolution operator is a collection of 2D sparse arrays, which are different for each band, that converted are into full arrays in order to use <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=pmelchior\" class=\"user-hover\" rel=\"pmelchior\">Peter Melchior</a>\\'s proximal operator algorithm. Since the current simulated data is PSF matched, the processing time can be significantly reduced (by several orders of magnitude) by using the PSF operator as a sparse matrix in each band.</p><p>This fix is temporary so that we can profile and test PSF convolution and other features of the new deblender but  it is expected that this section of the code will be re-written in C++ in the final deblender before it is merged into the stack in a future sprint.</p>\n",
            "<p>Few random thoughts on quanta to keep record of my misunderstanding.</p>\n",
            "<p>This is for the implementation of <a href=\"https://jira.lsstcorp.org/browse/RFC-262\" title=\"Add ref_cats_htm to /datasets\" class=\"issue-link\" data-issue-key=\"RFC-262\"><del>RFC-262</del></a>: the re-organization of the <tt>/datasets</tt> directory to facilitate closing of <a href=\"https://jira.lsstcorp.org/browse/RFC-257\" title=\"Support multiple reference catalogs\" class=\"issue-link\" data-issue-key=\"RFC-257\"><del>RFC-257</del></a>.</p>\n",
            "<p>The majority of the <tt>daf_persistence</tt> tests fail when attempting to build a conda package via <tt>conda-lsst</tt> on el5 with gcc 5.2.</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"tests/reposInButler.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">36</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> lsst.daf.persistence as dp</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jhoblitt/conda-lsst/miniconda/conda-bld/work/python/lsst/daf/persistence/__init__.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">28</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    from .persistenceLib </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> *</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jhoblitt/conda-lsst/miniconda/conda-bld/work/python/lsst/daf/persistence/persistenceLib.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">27</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    _persistenceLib = swig_import_helper()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jhoblitt/conda-lsst/miniconda/conda-bld/work/python/lsst/daf/persistence/persistenceLib.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">26</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in swig_import_helper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> importlib.import_module(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'_persistenceLib\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jhoblitt/conda-lsst/miniconda/envs/_build/lib/python2.7/importlib/__init__.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">37</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in import_module</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    __import__(name)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ImportError: No module named _persistenceLib</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">tests/butlerSubset.py</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I\\'m at a loss as why the tests are failing in this environment.   The library is being successfully built.</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ ls -la /home/jhoblitt/conda-lsst/miniconda/conda-bld/work/python/lsst/daf/persistence/_persistenceLib.so </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-rwxrwxr-x </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> jhoblitt jhoblitt </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">9716560</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> Oct </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">19</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">14</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">47</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> /home/jhoblitt/conda-lsst/miniconda/conda-bld/work/python/lsst/daf/persistence/_persistenceLib.so</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">$ swig -copyright</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SWIG Version </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">3.0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">10</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Copyright (c) </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1995</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1998</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">University of Utah and the Regents of the University of California</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Copyright (c) </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1998</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2005</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">University of Chicago</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Copyright (c) </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2005</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2006</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Arizona Board of Regents (University of Arizona)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Jenkins return status is not captured correctly and this information should be displayed at the dashboard as well (right now a missing measurement means the jenkins job failed)</p>\n",
            "<p>Highlighting objects based on a \"third\" parameter, e.g. a flag setting, (other than spatial, for which we are already producing diagnostic figures) can be very useful in diagnosing pathologies (see, e.g. <a href=\"https://jira.lsstcorp.org/browse/DM-9252\" title=\"Investigate bimodal distribution of footprint sizes for &quot;stars&quot;\" class=\"issue-link\" data-issue-key=\"DM-9252\"><del>DM-9252</del></a>).  This ticket is to add this ability to the analysis plotting scripts.</p>\n",
            "<p>Per <a href=\"https://docushare.lsstcorp.org/docushare/dsweb/Get/Version-37829/LCR-581CalibrationHardwareRequirementsUpdateApproved.pdf\" class=\"external-link\" rel=\"nofollow\">LCR-581</a>:</p><blockquote><p>To be added to LSE-30 (OSS):</p><p>Beam Projector Coordinate Relationship</p><p>Specification: Coordinate system transformations shall be measured<br/>and/or computed relating the collimated beam projector position and<br/>telescope pupil position to the illumination position on the telescope<br/>optical elements and focal plane, and a software interface shall be<br/>developed to represent these relationships, including their possible<br/>evolution in time.</p><p>Justification:</p><p>This is necessary to facilitate the data acquisition and reduction. The<br/>user shall be able to specify an LSST pupil and focal plane position for<br/>a given spot, then have the CBP and telescope offset accordingly.<br/>Similarily, the spot positions should be predictable based on the CBP<br/>and telescope position.</p><p>This requirement will need to be flowed down appropriately to the Data<br/>Management and Observatory Control System requirements documents. It is<br/>assumed that Data Management will develop a Python interface that<br/>represents the relationships, and that the Observatory Control System<br/>will use those in the construction of the control system functions<br/>relating to the collimated beam projector.</p></blockquote><p>Note the requirements on DM above. These should be reflected in LDM-151.</p>\n",
            "<p><tt>afw.display.setDefaultBackend(\"firefly\")</tt> will attempt to connect to a Firefly server running on localhost:8080. If no connection is possible, the command fails. For cases when a remote server or alternate port are desired, <tt>setDefaultBackend</tt> will be modified to accept optional arguments.</p><p>Meanwhile, the workaround is to use <tt>afwDisplay.Display(frame=n, host=xxx, port=yyyy)</tt> to connect to a remote Firefly server.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-8088\" title=\"When making PSF-matched coadds, warp first then PSF-match\" class=\"issue-link\" data-issue-key=\"DM-8088\"><del>DM-8088</del></a> changed makeCoaddTempExp so that the user no longer has to specify the pixel dimensions of the model PSF to match to. The model Psf dimensions are updated at runtime to match those of the warped calexp PSFs (which have dimensions impossible for a user to know ahead of time). </p><p>AssembleCoadd currently attaches the PSF corresponding to the <b>user-specified model PSF</b> dimensions rather than the updated PSF-dimensions.  This is bad because the user-specified dimensions could be way off and it\\'s incongruous to tell users that they don\\'t have to pay attention to this in makeCoaddTempExp, but they do in assembleCoadd. </p><p>This ticket will ensure that the modelPsf dimension information flows down from the coaddTempExps to the assembled deeepCoadd in a sensible way. Most likely using the maximum dimensions of the input coaddTempExps. </p>\n",
            "\"<p>While validating on HSC data, we encountered a use case for rectangular bin sizes in <tt>SubtractBackgroundTask</tt>.  We propose two new config fields:</p><ul>\\t<li>binSizeX</li>\\t<li>binSizeY</li></ul><p>By default they will be None and populated with the value in binSize. This change will be 100% backwards compatible. Everyone's config files will produce the same results. </p>\"\n",
            "<p>Write down and get the DMLT to agree to a description of what reprocessing of the HSC PDR will be performed on the LSST VC over the timescale of the S17 cycle, and some indication of what happens thereafter.</p>\n",
            "nan\n",
            "<p>Publish dochub-prototype HTML to <tt>www.lsst.io</tt> via LSST the Docs.</p>\n",
            "<p>Update the PDAC sample queries and test cases page <a href=\"https://confluence.lsstcorp.org/display/DM/PDAC+sample+queries+and+test+cases\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/PDAC+sample+queries+and+test+cases</a> to include WISE data</p>\n",
            "\"<p>Respond to Kevin Long's e-mail of 2017-03-07, reconciling DLP milestones against the new replan milestones.</p>\"\n",
            "\"<p>ltdstatus (and, when kubified, probably the indexer) hang on GKE.  I think it's a memory condition, because they're doing a lot of threads in parallel.</p><p>Two things I want to try: 1) increase the size of the cluster instances a notch, 2) put a limiter on number of simultaneous threads spawned in our scatter/gather.</p>\"\n",
            "\"<p>Take account of muon tracks' angle of incidence on the sensor. This will improve spectral resolution.</p>\"\n",
            "nan\n",
            "<p>Fit the spectra presented in <a href=\"https://jira.lsstcorp.org/browse/DM-6030\" title=\"Investigate possibilty of cosmic ray muons (etc) for precision gain calibration\" class=\"issue-link\" data-issue-key=\"DM-6030\"><del>DM-6030</del></a> (or some variation thereof) with Landau-Gauss convolutions.</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>The raw data table should be updated and a light curve calculation restarted (the existing phase folded table is removed) if the time column name in TS viewer changes because the table is sorted on the new column &#8211; currently nothing happens when user changes the input value for the time column name field to be another valid one.</li>\\t<li>add time column name field for LSST</li></ul>\n",
            "<p>The base kafka image in the docker-compose file for the current alert_stream repo is deprecated already.  <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/sad.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/>  Need to swap this image out with the current stable version of kafka, go through new release docs to update deprecated environment variables, swap out the zookeeper image, and upgrade the python base image of the main Dockerfile.  We want to do this before testing because the currently used version of kafka and also the python base image lack features/performance we will want later, so we should test the versions we want to use.</p>\n",
            "<p>astshim fails to build on linux using Jenkins. Here is a build log<br/><a href=\"https://ci.lsst.codes/job/stack-os-matrix/22127/label=centos-7,python=py2/console\" class=\"external-link\" rel=\"nofollow\">https://ci.lsst.codes/job/stack-os-matrix/22127/label=centos-7,python=py2/console</a></p><p>Also fix build warnings</p>\n",
            "<p>The v13 release <a href=\"https://sw.lsstcorp.org/eupspkg/tags/v13_0.list\" class=\"external-link\" rel=\"nofollow\">has been tagged</a>, but the <a href=\"https://confluence.lsstcorp.org/display/DM/Data+Release+Production+WIP+F16+Release+Notes\" class=\"external-link\" rel=\"nofollow\">DRP release notes</a> are a couple of months out of date. Update them and provide them to SQuaRE to accompany the release.</p>\n",
            "<p>HSC would like to base its next release on a stable version of the LSST codebase. How could this work in a way that benefits both projects? Draft some ideas and discuss with stakeholders.</p>\n",
            "\"<p>jointcal currently has a couple of trapfpe() functions that wrap feenableexcept, which doesn't exist on OSX. Were these an important part of error handling in meas_simastrom, or can I just remove them?</p>\"\n",
            "\"<p>pybind11 usually casts base-class references or pointers to the most-derived wrapped type, using RTTI and dynamic casts.  This does not seem to work for Table and Record objects, where we instead have to wrap derived-class accessors that return the appropriate type.</p><p>I suspect this is because the true types are defined in anonymous namespaces in C++ files, so the most-derived types are not actually accessible to pybind11, and it's doing some sort of dict lookup on <tt>std::type_info</tt> rather than a tree of <tt>dynamic_casts</tt> (what Boost.Python did).  If that's the case, a invisible change to how these classes are implemented could clean up our pybind11 wrappers.  I imagine we wouldn't want to try to fix this upstream, as pybind11's approach is almost certainly faster than Boost.Python's and works as well in the vast majority of cases.</p>\"\n",
            "<p>We need to provide option to display the image cutout, using DAX API.</p>\n",
            "\"<p>Pybind11 version 2, with it's latest bugfix update (2.0.1), is out.<br/>This is a big release with some API incompatibilities (most of which we already depend on). But we have been using pybind11 <tt>master</tt> so far so we won't have to change much.<br/>Nevertheless this is slightly more work than normal (normally about 0.1 SP) because <tt>py::metaclass()</tt> is now a required attribute for all classes that use <tt>.def_static</tt> which requires a lot of (trivial) changes. And of course there may be other hidden problems.</p><p>Now that a major fraction of the porting work is done, and we have the upstream features we need merged into the release version, the intention is to stick to fixed releases from now on if possible (instead of tracking master).</p>\"\n",
            "<p>Intended to be the final big rebase before merge.</p>\n",
            "<p>meas_modelfit contains a lot of code that was used for FDR-era prototyping of modelfitting and has not been used since.  Some of this is worth keeping and reviving, because it\\'s hard-won algorithmic code we may want to use in the future, while some of it should be removed.  In many cases, the unwanted code is being kept around because it\\'s the only way the code we want is still tested; in other cases a small, easy-to-replace fraction of it is used by the bitrotted code we want to keep or code in active use (i.e. CModel).</p><p>This ticket is for cleaning up that mess.  Roughly, that means:</p><ul class=\"alternate\" type=\"square\">\\t<li>Remove the custom table/record/catalog classes.</li>\\t<li>Remove the custom CmdLineTasks.</li>\\t<li>Remove the Sampler and Interpreter classes.</li></ul><p>Some of this work may be best spawned done on other tickets, which should be linked here.</p>\n",
            "<p>Porting code from HSC to LSST brought over a unit test into meas_algorithms for functionality that exists in meas_base in LSST. This is due to the refactoring of code into meas_base on the LSST some while ago. This unit test currently runs with code from meas_algorithms, which means it can not simply be moved, as meas_base comes before meas_algorithms in the build order. This work may involve rewriting the unit test to use different code, or evaluating if it is worth bringing that functionality to meas_base along with the test. The code in question is the detection task.</p>\n",
            "<p>Implement <a href=\"https://jira.lsstcorp.org/browse/RFC-223\" title=\"Remove Shapelet code from meas_algorithms\" class=\"issue-link\" data-issue-key=\"RFC-223\"><del>RFC-223</del></a>.</p>\n",
            "<p>Create detailed RFC and implement move of interface and utility code from multiple existing packages to new package.</p><p>See also <a href=\"https://confluence.lsstcorp.org/display/DM/Summer2015+Package+Reorganization+Planning\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Summer2015+Package+Reorganization+Planning</a></p>\n",
            "<p>Create detailed RFC and implement move for these packages.</p><p>See also <a href=\"https://confluence.lsstcorp.org/display/DM/Summer2015+Package+Reorganization+Planning\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Summer2015+Package+Reorganization+Planning</a></p>\n",
            "<p>Create detailed RFCs and implement splitting measurement plugins into separate package.  May want one package for extremely basic plugins, always-used plugins (PixelFlags, TransformedCentroid, etc).</p><p>See also <a href=\"https://confluence.lsstcorp.org/display/DM/Summer2015+Package+Reorganization+Planning\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Summer2015+Package+Reorganization+Planning</a></p>\n",
            "<p>This should split all content in pipe_tasks into two packages (aside from what may have been removed in previous issues).</p>\n",
            "<p>Create detailed RFC and implement merge of base, utils, and daf_base.</p><p>See also <a href=\"https://confluence.lsstcorp.org/display/DM/Summer2015+Package+Reorganization+Planning\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Summer2015+Package+Reorganization+Planning</a></p>\n",
            "<p>Increase the loading and processing speed of <tt>validate_drp</tt> following suggestions by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a></p><p>1. Don\\'t read in footprints<br/>Pass <tt>flags=lsst.afw.table.SOURCE_IO_NO_FOOTPRINTS</tt> to <tt>butler.get</tt></p><p>2. Work on speed of calculation of RMS and other expensive quantities.  Current suggestions:<br/>a. <tt>calcRmsDistances</tt><br/>b. <tt>multiMatch</tt><br/>c. <tt>matchVisitComputeDistance</tt><br/>d. Consider boolean indexing in <tt>afw</tt>\\'s <tt>multiMatch.py</tt></p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   objById = {record.get(self.objectKey): record for record in self.reference}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">to:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   objById = dict(zip(self.reference[self.objectKey], self.reference))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Note that while this ticket will involve work to reduce the memory footprint of the processing, it will not cover work to re-architect things to enable efficient processing beyond the memory on one node.</p>\n",
            "nan\n",
            "nan\n",
            "<p>In sfm.py on line 271, a comment indicates that some code is a temporary work around until the switch from meas_algorithms to meas_base is complete. This work is complete, so this temporary workaround should be removed, or if it is decided it should be kept, the comment should be removed. See <a href=\"https://github.com/lsst/meas_base/blob/tickets/DM-2915/python/lsst/meas/base/sfm.py#L271\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/meas_base/blob/tickets/DM-2915/python/lsst/meas/base/sfm.py#L271</a></p>\n",
            "<p>Migrate Firefly\\'s onlinehelp system so that it can be used by SUIT.</p><ul class=\"alternate\" type=\"square\">\\t<li>created github repository: <a href=\"https://github.com/lsst/suit-onlinehelp/\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/suit-onlinehelp/</a></li>\\t<li>copy content from existing irsaviewer online help.</li>\\t<li>change build/config script for SUIT.</li>\\t<li>setup build/install environment for pdac</li></ul><p>To build and install online help on pdac:</p><ul class=\"alternate\" type=\"square\">\\t<li>log into sui-tomcat01</li>\\t<li>switch to suiadmin</li>\\t<li>source /hydra/cm/env/env.sh</li>\\t<li>cd /hydra/cm/suit-onlinehelp</li>\\t<li>git pull</li>\\t<li>gradle install</li></ul>\n",
            "<p>Need a Time Series viewer app for IRSA, under IFE repository.</p><p>Please, create app with no logo (for now - for later probably we will need a new icon).</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=npease\" class=\"user-hover\" rel=\"npease\">Nate Pease</a> points out that the lsst_py3 Jenkins build is currently failing and has been since <a href=\"https://ci.lsst.codes/job/stack-os-matrix/label=centos-7,python=py3/21317/console\" class=\"external-link\" rel=\"nofollow\">build #454</a> (regardless of the misleading red circles on Jenkins). Reported error is:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">======================================================================</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">FAIL: testLeaks (__main__.TestMemory)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">!Check for memory leaks in the preceding tests</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">----------------------------------------------------------------------</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/jenkins-slave/workspace/stack-os-matrix/label/centos-7/python/py3/lsstsw/stack/Linux64/utils/12.1-5-g648ee80+2/python/lsst/utils/tests.py\", line 161, in testLeaks</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    self.fail(\"Leaked %d block%s\" % (nleak, plural))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">AssertionError: Leaked 13 blocks</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">----------------------------------------------------------------------</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Ran 10 tests in 0.688s</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">FAILED (failures=1, skipped=2)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">     Number of calls to function has reached maxfev = 10.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">     Number of calls to function has reached maxfev = 10.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">     Number of calls to function has reached maxfev = 10.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">     Number of calls to function has reached maxfev = 10.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "nan\n",
            "<p>This one is made to include some issues report in <a href=\"https://jira.lsstcorp.org/browse/DM-7027\" title=\"Region issues\" class=\"issue-link\" data-issue-key=\"DM-7027\"><del>DM-7027</del></a> (issues 4, 5, 6):</p><p>4. When a region is selected, yellow dashed line appears around it. On zoom the line does not change color.<br/>5. Can not add empty region. Line 124 of the test script.<br/>6. Can not add or delete regions after the first one. (Load test script, click Show Regions, then Add Region, line 121 of the test script) When there is one region in the layer and you are adding another region with a different position but everything else the same, the added region is perceived to be the same.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>May not have any work associated with it, but is an <tt>lsst_distrib</tt> dependency. Investigate and update SP.</p>\n",
            "<p>Split off from <a href=\"https://jira.lsstcorp.org/browse/DM-6302\" title=\"Wrap pex_exceptions with pybind11\" class=\"issue-link\" data-issue-key=\"DM-6302\"><del>DM-6302</del></a>.</p>\n",
            "nan\n",
            "<p>Split off from <a href=\"https://jira.lsstcorp.org/browse/DM-6302\" title=\"Wrap pex_exceptions with pybind11\" class=\"issue-link\" data-issue-key=\"DM-6302\"><del>DM-6302</del></a>.</p>\n",
            "<p>The <tt>log</tt> package was recently added as a future replacement for <tt>pex_logging</tt>.<br/>Wrap this package with pybind11 instead of swig.</p>\n",
            "<p>fix Phase folded table created  for time series viewer (<a href=\"https://jira.lsstcorp.org/browse/DM-8670\" title=\"Revamp LC results area\" class=\"issue-link\" data-issue-key=\"DM-8670\"><del>DM-8670</del></a>) </p><ul class=\"alternate\" type=\"square\">\\t<li>fix the time column value (mjd) on the expanded cycle part. (the phase folded table is made to contain the data rows for two phase cycles): the value of \\'mjd\\' column in the expanded part is duplicated from the original raw table.</li>\\t<li>make the creation of phase folded to be derived from full set of raw table, not just partial raw table shown on the page.</li></ul>\n",
            "<p>In Swig `MatchList` objects are (un)pickled by creating a `Catalog` of the contained `Record` type and the (un)pickling that.<br/>With pybind11 this is not possible because `MatchList` is just a Python `list` of `Match` objects. Pickling them individually (via the same route) does not make much sense.<br/>It is unclear if this pickling support is actually needed anywhere outside of <tt>testSourceMatch.py</tt> where it is currently disabled (as of <a href=\"https://jira.lsstcorp.org/browse/DM-8415\" title=\"Finish wrapping of pickling with pybind11 in afw\" class=\"issue-link\" data-issue-key=\"DM-8415\"><del>DM-8415</del></a>).<br/>This ticket aims to either fix or permanently remove this functionality when the need for it becomes clear.</p>\n",
            "<p>Now that there is a working astrometrySourceSelector (just merged in meas_algorithms from <a href=\"https://jira.lsstcorp.org/browse/DM-5933\" title=\"Replace jointcal.StarSelector with meas_algorithms.starSelector\" class=\"issue-link\" data-issue-key=\"DM-5933\"><del>DM-5933</del></a>), we should get matchOptimisticB working with it. This would entail replacing matchOptimisticB.SourceInfo with AstrometrySourceSelectorTask and tweaking the latter to do whatever matchOptimisticB needs, and removing SourceInfo.</p>\n",
            "<p>astrometrySourceSelector can not be used alone in matchOptimisticB as it tests for two different criteria depending on if it\\'s matching objects(needs good centroid, is a parent object, has a minimum S/N, valid flux) or returning those objects to astrometry.py(all the previous plus is not saturated, is not interpolated, and is not edge). The new source selector matcherSourceSelector will make former selection, astrometrySourceSelector will make the second test. This ticket extends the work of <a href=\"https://jira.lsstcorp.org/browse/DM-6824\" title=\"Use meas.algorithms.astrometrySourceSelector in measOptimisticB\" class=\"issue-link\" data-issue-key=\"DM-6824\"><del>DM-6824</del></a>.</p>\n",
            "<p>The following change will be in Firefly:</p><ul>\\t<li>histogram  Y axis label: Number</li>\\t<li>Charts scatter/histogram option dialog, \"search\" button:  \"OK\"</li>\\t<li>Choose columns dialog \"Set column or expression\" button:  \"OK\"</li></ul><p>The following changes will be in IRSA Viewer:</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=shupe\" class=\"user-hover\" rel=\"shupe\">David Shupe</a> has provided me with some code he\\'s been experimenting with to explore interfaces to the Science Pipelines and has asked for feedback. Provide it to him (or find somebody else who can).</p><p>He writes:</p><blockquote><p>Thanks, this would be very helpful! I\\xe2\\x80\\x99ve pushed the current working version to <a href=\"https://github.com/stargaser/forced_phot\" class=\"external-link\" rel=\"nofollow\">https://github.com/stargaser/forced_phot</a> . The goal is return a table of photometry at a specified location on a specified<br/>set of single-epoch exposures.</p><p>The README has some information. The main script is \\xe2\\x80\\x9cget_forcedphot.py\\xe2\\x80\\x9d and the arguments are:<br/>------------------<br/>usage: get_forcedphot.py <span class=\"error\">&#91;-h&#93;</span><br/>                         input_repo output_repo json_input coord_str<br/>                         filter_name output_table</p><p>Run forced photometry on specified images and output a time-series table</p><p>positional arguments:<br/>  input_repo    input repository directory path for images<br/>  output_repo   dummy repository directory for schema<br/>  json_input    json file as returned by imgserv<br/>  coord_str     coordinates string as name,ra,dec<br/>  filter_name   name of filter to subset input table <span class=\"error\">&#91;ugriz&#93;</span><br/>  output_table  output table path in FITS format</p><p>optional arguments:<br/>  -h, --help    show this help message and exit<br/>\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94</p><p>To interface with Firefly, this will be modified to take a JSON input from Firefly and to return a JSON file specifying the output table location.</p><p>Some problems I had include:</p><ul>\\t<li>couldn\\xe2\\x80\\x99t get the schema right to add PSF magnitudes</li>\\t<li>couldn\\xe2\\x80\\x99t use the writeOutput method for each catalog because of schema problem</li>\\t<li>calib.getMagnitudes couldn\\xe2\\x80\\x99t convert the ndarrays for psfFlux to C++ (non-aligned arrays?)</li>\\t<li>multiple exposures can be specified with multiple \\xe2\\x80\\x98\\xe2\\x80\\x94id \\xe2\\x80\\x98 arguments \\xe2\\x80\\x94 very cool! Is there a way to gather up all the individual results into one table in the same pipeline task?</li></ul><p>To get something working, I have fallen back to Astropy to manipulate the catalog table files.</p><p>For now, I\\xe2\\x80\\x99ve been running this on lsst-dev since the data are available there, in /home/shupe/projects/forced_phot.</p></blockquote>\n",
            "<p>For all the stories describing comparisons between HSC and LSST results (notably <a href=\"https://jira.lsstcorp.org/browse/DM-5301\" title=\"Compare LSST and HSC pipelines through through single-frame processing\" class=\"issue-link\" data-issue-key=\"DM-5301\"><del>DM-5301</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-5827\" title=\"Compare LSST and HSC pipelines through through multi-band coadd processing\" class=\"issue-link\" data-issue-key=\"DM-5827\"><del>DM-5827</del></a>), please provide instructions describing the steps to reproduce the comparison. In particular, include:</p><ul>\\t<li>A list of any tweaks that had to be applied to the code;</li>\\t<li>Non-default configuration options;</li>\\t<li>Exactly which comparisons were made.</li></ul>\n",
            "<p>My ELK system has had instances have their root file systems become read-only.</p><p>This needs to be reported to NCSA and work arounds need to be found.</p>\n",
            "<p>Boot from USB, repartition and reinstall ESXi. Reconfigure ssh server and client. Copy backed up VM directories and thin vmdks.</p>\n",
            "<p>See <a href=\"https://jira.lsstcorp.org/browse/RFC-246\" title=\"Suppress warnings for external packages\" class=\"issue-link\" data-issue-key=\"RFC-246\"><del>RFC-246</del></a> for the reasoning and for an example implementation.</p>\n",
            "<p>The LC viewer need an extra download button to get all the cutout from the light-curve table.<br/>The output can be a tar/zip file, or it can be also the wget (curl) scripts to download them if too many images.</p>\n",
            "<p>Do the following: </p><ul>\\t<li>Add hooks so the time series tool to be able to be launched externally</li>\\t<li>Gator or the triview (or something else) should be able to launch the LC with search parameters (see my comment below about initial values for IRSA)</li></ul>\n",
            "\"<p>In catalog or image search, if the query takes a long time to get the result, the table tab is not shown until the result comes,  user still sees the previous search result during waiting.</p><p>It would be nice to show the current table tab immediately, so user can see that the search is going on.<br/>How to repeat the case:<br/>Make the first query: target (1,1), cone, 10 arcsec.<br/>Then make the second query: same target, cone 1000 arcsec.<br/>The second table won't show until the result comes out.</p>\"\n",
            "<p>To inform planning for processing runs of HSC public data, we need to estimate the following:</p><ul class=\"alternate\" type=\"square\">\\t<li>The likely size of the raw data which will be released;</li>\\t<li>The likely size of the processed image data and other ancillary products which will be stored to disk;</li>\\t<li>The number of rows of catalogue data which will be persisted (either as afw::table cataloges or database tables);</li>\\t<li>The number of core hours required to process the data; and</li>\\t<li>The minimum RAM per core required.</li></ul>\n",
            "<p>The background model pixel values differ by 0.00011 \\xc2\\xb1 0.00035 on average in python2 versus python3. The cause of this discrepancy needs to be tracked down and fixed.</p>\n",
            "<p>Use Docker compose or something similar to easily scale up from one Kafka alert consumer to N consumers.</p>\n",
            "nan\n",
            "<p>This is a bug introduced by in <a href=\"https://jira.lsstcorp.org/browse/DM-8367\" title=\"provide line chart\" class=\"issue-link\" data-issue-key=\"DM-8367\"><del>DM-8367</del></a> line chart. The precision of the expression columns is not set when the values are saved to an IPAC table. When the table is read back and the first row happens to be 0.0, all values will be passed to the client with 1 decimal digit.</p><p>Test: load sample table, change y column to -count/time. Notice that all values in the point tooltip have 1 digit after decimal point and that highlighted points do not match the points on the line. (Highlighted values are calculated on client from the values of the table, plot points - on the server.)</p><p><a href=\"https://github.com/Caltech-IPAC/firefly/pull/279\" class=\"external-link\" rel=\"nofollow\">https://github.com/Caltech-IPAC/firefly/pull/279</a></p>\n",
            "<p>The story is about to branch off \\'dev\\' a version of IRSAViewer to have the latest version of Firefly and enable:</p><ul class=\"alternate\" type=\"square\">\\t<li>histogram feature (simple UI, no binning method options, only column/expression input)</li></ul><p>Test version should be ready by beginning January. </p><p>Release plan for end of January.</p>\n",
            "<p>Insert the content from the DRP Data Flow diagram on Confluence into LDM-151, adjusting it to the outline developed on <a href=\"https://jira.lsstcorp.org/browse/DM-6247\" title=\"DRP Outline for LDM-151\" class=\"issue-link\" data-issue-key=\"DM-6247\"><del>DM-6247</del></a>.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Correctly handling wavelength-dependent photometric and PSF effects is one of the biggest qualitative differences between the current state-of-the-art and what we have in mind for LSST, and that makes it easy to get wrong.  We need to make sure all steps that produce high-quality fluxes or rely on high-quality PSFs have access to object colors and a reasonable approach to using them.</p>\n",
            "<p>Fixes to LDM-151 DRP section in response to <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=zivezic\" class=\"user-hover\" rel=\"zivezic\">Zeljko Ivezic</a>\\'s comments.</p>\n",
            "<p>Write outline for Data Release Production section of LDM-151, using the DRP Data Flow diagram as the organizing principle.</p>\n",
            "<p>Adding text to LDM-151 where appropriate, working around the structure defined by Jim et al.</p>\n",
            "nan\n",
            "<p>Finish wrapping <tt>KeyMap</tt>, use it to implement <tt>Channel.warnings</tt> and add a unit test.</p><p>Also fix an obscure bug in <tt>Mapping._decompose</tt> which can result in a returned mapping having the <tt>Invert</tt> flag set wrong if the mapping is created by software other than astshim.</p>\n",
            "<p>Expand the flatten and unflatten methods of SpanSets such that they can operate on multi-dimensional ndarrays. This work involves making the template parameters for these functions, and the getter classes more generic.</p>\n",
            "nan\n",
            "\"<p>Update the periodogram panel option so is only reflect LS algorithm and keep as single option for now. <br/>Others doesn't make sense with the current API and there won;t be time to make progress on that until March release.</p>\"\n",
            "<p>On cc-in2p3 cluster (ccqserv123) next message appears in xrootd-console.log:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[2016-12-10T23:37:28.298+0100] [LWP:275] INFO  xrdssi.msgs (cmsd:0) - Meter: Insufficient space;  7GB available &lt; 11GB high watermark</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Maybe next lst.cf directive should be moved to global:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    # Specify that no significant free space is required on servers</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    # Indeed current configuration doesn\\'t expect to be dynamically</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    # written to, but export the space in R/W mode</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    cms.space 1k 2k</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>As part of his PhD thesis work on HSC, Jos\\xc3\\xa9 Garmilla produced a star-galaxy classifier and associated supporting code. He has now left the field: we should ensure that his code is not abandoned.</p><p>On this ticket, please:</p><ul class=\"alternate\" type=\"square\">\\t<li>Track down Jos\\xc3\\xa9\\'s code and any associated documentation;</li>\\t<li>Make it available in a repository in the lsst-dm organization.</li></ul><p>No changes to the code are required.</p>\n",
            "nan\n",
            "<p>Igor is complaining that data loading takes much longer time for ForcedSources data than for Sources even though their total size is compatible. This can be related to the number of records (ForcedSources is narrower and should have more records than Sources), though there is nothing in data loader which should depend on this. Opening this ticket to investigate.</p>\n",
            "<p>Move the free function nearestFootprint to a free function in SpanSets, rename it to nearestSpanSet, and update functionality.</p>\n",
            "<p>Add a method to SpanSets which returns a new SpanSet that contains the pixels at the boarder of the original SpanSet</p>\n",
            "<p>This requires new hardware, which has been ordered; delivery expected in December 2016.</p>\n",
            "<p>To make headway on aperture corrections, we are bringing the HSC implementation of BoundedField over.</p>\n",
            "<p>Service feature requests and bugfixes from JK, T/CAMs including format changes on sqre-jirakit.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=boutigny\" class=\"user-hover\" rel=\"boutigny\">Dominique Boutigny</a> noticed that jointcal is now very slow to write its output. This is at least in part due to the way I rewrote the output code to work with decam, which does not have \"ccd\" in its dataRefs. I think new slowdown is coming from the repeated calls to <tt>get(\"calexp\").getDetector().getId()</tt>.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a> suggested making a dictionary to map visit and ccd name to each dataRef:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">visit_ccd_to_dataRef = {(dataRef.dataId[\\'visit\\'], dataRef.get(\\'calexp\\').getDetector.getId()): dataRef for dataRef in dataRefs}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>and then replacing the for loop and if statement with a lookup in the dict.</p><p>Note to Butler people: this problem is related to the problem of having no standard set identifiers in the dataIds: if we can guarantee that \"visit\" and \"ccd\" are always there (and, I\\'d argue, some other things), this code would be quite a bit simpler.</p>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/DM-1598\" title=\"Design of calibration and ingest system\" class=\"issue-link\" data-issue-key=\"DM-1598\"><del>DM-1598</del></a> there will be a detailed design and prototype implementation for the calibration &amp; ingest system. This issue covers cleaning up that code, documenting it, having it reviewed, and merging to master.</p>\n",
            "<p>During deployment of SQuaSH we realized that JSONField() as implemented in <a href=\"https://jira.lsstcorp.org/browse/DM-8414\" title=\"Investigate alternatives to ingest JSON blobs into the SQUASH database\" class=\"issue-link\" data-issue-key=\"DM-8414\"><del>DM-8414</del></a> works only with MySQL and that the corresponding field type for MariaDB is the DynamicField()</p><p>This ticket is to make sure we can use MariaDB features and stick with it in production.</p>\n",
            "<p>May not require any wrapping, if so then this ticket is just for tracking. Otherwise, adjust SP.</p>\n",
            "<p>There is one skipped test in <tt>testSourceTable.py</tt>: <tt>testPickle</tt>. This segfaults, likely when a source catalog is pickled. Fix this. </p><p>Should all kinds of catalog be pickleable? If so, make sure all are being tested.</p>\n",
            "<p>This ticket captures work done to publish the display_firefly backend for afw.display to eups, including researching and learning the steps to do it.</p><ul>\\t<li>tag the ws4py and firefly_client dependencies appropriately</li>\\t<li>rebuild display_firefly using Jenkins</li>\\t<li>publish display_firefly using Jenkins</li></ul><p>enabling:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">export EUPS_PKGROOT=https://sw.lsstcorp.org/eupspkg</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">eups distrib list display_firefly # returns version to use in next line</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">eups distrib install display_firefly master-g0a33da8b30+2</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Switch from using <tt>pex_logging</tt> to <tt>log</tt> in <tt>meas_mosaic</tt>. </p>\n",
            "<p>Switch from using <tt>pex_logging</tt> to <tt>log</tt> in <tt>ci_hsc</tt>. </p>\n",
            "<p>Attend the Camera visualization weekly meeting, act as the point of contact the UIUC team, bring back the requests and bug reports to Firefly team. </p>\n",
            "<p>It\\'s (fairly) well known that DM has a policy of making materials deriving from talks given, papers published, etc by DM members available on <a href=\"https://zenodo.org/communities/lsst-dm\" class=\"external-link\" rel=\"nofollow\">Zenodo</a>. But we need some documentation specifying at least:</p><ul class=\"alternate\" type=\"square\">\\t<li>The details of the policy (what should be made available, who is responsible, etc);</li>\\t<li>The mechanism (how does one upload to Zenodo, what collections should the upload be added to, etc);</li>\\t<li>Requirements regarding licensing.</li></ul>\n",
            "\"<p>qserv/qserv:dev image is based on qserv/qserv:latest and may become huge if former one isn't update on a regular basis.</p><p>This ticket will allow to create qserv/qserv:dev from scratch to reduce its size.</p>\"\n",
            "<p>Remove <tt>pex_logging</tt> dependency in <tt>ctrl_pool</tt>. </p>\n",
            "<p>Implement <a href=\"https://jira.lsstcorp.org/browse/RFC-224\" title=\"Remove GPU code from afw\" class=\"issue-link\" data-issue-key=\"RFC-224\"><del>RFC-224</del></a>.</p>\n",
            "<p>Implementation of `db.utils.loadSqlScript()` runs mysql command and passes  password as command line argument which is not very secure. We want better way to pass credentials to mysql, special protected defaults file is probably the best choice.</p>\n",
            "<p>To support the afwDisplay backend for Firefly, firefly_client is being added to the stack as a third-party package. To more easily incorporate changes as firefly_client is developed, firefly_client has been forked to the LSST Github org from the Caltech-IPAC org. A branch will be created and the eups tables will be added to it.</p>\n",
            "nan\n",
            "<p>Summary of our first discussion with Gregory and K-T which covered few simplest use cases.</p>\n",
            "<p>Switch from using <tt>pex_logging</tt> to <tt>log</tt> in <tt>meas_modelfit</tt>. </p>\n",
            "<p>Following the developer instructions for third-party packages, add the <tt>ws4py</tt> package as a third-party package that is installable by eups.</p>\n",
            "nan\n",
            "<p>Please, add the same feature to the raw-table highlight as the phase folded table.</p><p>When the raw-table LC is loaded and a row is highlighted, display the image single exposure.</p>\n",
            "<p>Fix travis PR build are broken for unknown reason since a few month</p>\n",
            "<p>Resulted in two new jenkins jobs:</p><ul>\\t<li><tt>backup/nightly-sqre-github-snapshot</tt> - a \"cron\" job that runs nightly, executing the snapshot process from inside a container</li>\\t<li><tt>backup/build-sqre-github-snapshot</tt> - builds the docker container used by <tt>backup/nightly-sqre-github-snapshot</tt>.</li></ul><p>Containers are pushed to <a href=\"https://hub.docker.com/r/lsstsqre/sqre-github-snapshot/\" class=\"external-link\" rel=\"nofollow\">https://hub.docker.com/r/lsstsqre/sqre-github-snapshot/</a></p>\n",
            "<p>Tests in <tt>DateTime</tt> depend on specific behaviour of <tt>enum</tt> that pybind11 does not support. These tests are hence (temporarily) disabled in <tt><a href=\"https://jira.lsstcorp.org/browse/DM-6168\" title=\"Wrap afw using pybind11\" class=\"issue-link\" data-issue-key=\"DM-6168\"><del>DM-6168</del></a></tt>.<br/>Deficiencies (or features) of the current upstream enum support are:</p><ul>\\t<li>enums are unordered (they have no less-than operator)</li>\\t<li>enums (even unscoped ones) are not implicitly convertible to their underlying type</li></ul><p>The latter property is sometimes desirable because it automatically prevents enums of different types to be interchanged in a call.<br/>However, we do seem to have some code that depends on implicit convertibility (I would argue that we should use scoped enums more in general, but that is a separate matter).</p><p>This ticket aims to bring pybind11 enum support more in-line with the expected behaviour from C++.</p>\n",
            "<p>The DCR template generation code has been developed and tested using simulated data. It would be informative to try running it on real data to identify new issues and see if it works.</p>\n",
            "<p>Currently SpanSets can intersect, intersectNot, and union between a themselves and another SpanSet. This ticket will add the ability to use these methods with masks as \"other\". This work will replace the intersectMask and footprintAndMask methods from the old footprint implementation.</p>\n",
            "<p>Andy H. provided the solution:</p><blockquote><p>Hi Fabrice,</p><p>Yes, this is common for configurations that don\\'t expect to be dynamically<br/>written to but yet export the space in R/W mode (which we do). All the<br/>message is saying is you don\\'t have enough space for impromptu writes (which<br/>is true but then you don\\'t expect any). So, there is a configuration<br/>directive to resolve this problem:</p><p>cms.space 1k 2k</p><p>The directive is documented here:<br/><a href=\"http://xrootd.org/doc/dev45/cms_config.htm#_Toc454223038\" class=\"external-link\" rel=\"nofollow\">http://xrootd.org/doc/dev45/cms_config.htm#_Toc454223038</a></p><p>I would add this directive to the config file as soon as you can and restart<br/>he cmsd.</p><p>Andy</p></blockquote>\n",
            "<p>version should be \\'dev\\' here, but \\'dev\\' need to be updated to contains <a href=\"https://jira.lsstcorp.org/browse/DM-7139\" title=\"Move to Docker/Swarm 1.12\" class=\"issue-link\" data-issue-key=\"DM-7139\"><del>DM-7139</del></a> code:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">admin/tools/docker/deployment/swarm/manager/env-docker.sh</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">@@ -2,8 +2,8 @@</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> # Allow to customize Docker container execution</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> # VERSION can be a git ticket branch but with _ instead of /</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-# example: u_fjammes_DM-4295</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-VERSION=dev</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+# example: tickets_DM-7139, or dev</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+VERSION=tickets_DM-7139</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>The flask internal web server is single-threaded, which will cause web services to be blocked e.g. during long running queries.  We will need to place some sort of multithreaded/pooling web server (e.g. nginx + wsgi) ahead of the flask service for acceptable behavior until implementing/adopting disconnected queries. </p>\n",
            "\"<p>butler can take a URI or relative path for it's inputs and outputs arguments, provided that it has a way to figure out what the details of the repo are, e.g. mapper, and provided the default mode (inputs 'r', outputs 'w') is acceptable.<br/>this needs to be documented in the butler init function. and a formal test written.</p>\"\n",
            "<p>Using SQuaSH after the last deployment <a href=\"https://jira.lsstcorp.org/browse/DM-8195\" title=\"deploy squash code changes feature\" class=\"issue-link\" data-issue-key=\"DM-8195\"><del>DM-8195</del></a> two improvements were suggested by users. One is to include the Date in the code change table, so that it becomes evident when a given package changed. The other improvrment fixes the git url linking the package name right to the git commit of the respective change.</p>\n",
            "<p>make a list of the original SUIT requirement from EE<br/>Help with the requirement flowdown</p>\n",
            "<p>Implement the following SpanSet operations:</p><ul class=\"alternate\" type=\"square\">\\t<li>Construct from an ellipse - note geom::ellipses::PixelRegion; this should do most of the work.</li>\\t<li>Compute centroid - see old Footprint implementation</li>\\t<li>Compute shape (quadrupole moments) - see old Footprint implementation</li></ul><p>One complication here is that this will introduce a circular dependency between afw::geom and afw::geom::ellipses.  That\\'s easy to address at the C++ level, but it\\'s tricky in Python (which package imports the other?)  I\\'ll be emailing dm-devel shortly to start a discussion on how to address this problem.</p>\n",
            "<p>Update codekit to use current github3</p><p><a href=\"https://jira.lsstcorp.org/browse/DM-8340\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/DM-8340</a></p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rhl\" class=\"user-hover\" rel=\"rhl\">Robert Lupton</a> requested:<br/>I think it\\'d be really helpful to have a relatively short document describing (or at least mentioning) the features that are in the butler that the `classic\\' butler didn\\'t have.</p><p>I think we can put a section in LDM-463 for this.</p>\n",
            "<p>A new email notification should be sent for every successfully completed background jobs when a new email is entered.</p>\n",
            "nan\n",
            "<p>Two tables are added in the LSSTCatalog\\'s UI.  Thus, the search processors in the server side need to be updated to reflect the changes in the UI.  </p><p>The following work will be done:</p><ul>\\t<li>Find out the ra and dec columns based on the table name passed from the UI</li>\\t<li>Process the constraints passed from the UI and add to the SQL\\'s \"where\" clause</li>\\t<li>Re-arrange the codes</li>\\t<li>Test all four tables to make sure they work for each of the search method except mutli-object.</li>\\t<li>Add error handling when the search method is not supported</li>\\t<li>Add error handling when the data type defined in the metadata of the DAX\\'s JSON file is not the same as in the actual datatype in the same JSON file.</li></ul>\n",
            "<p>SUIT vision document work, review, revision, and submission for approval by TCT. </p>\n",
            "<p>After a discussion between <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=gpdf\" class=\"user-hover\" rel=\"gpdf\">Gregory Dubois-Felsmann</a>, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=xiuqin\" class=\"user-hover\" rel=\"xiuqin\">Xiuqin Wu</a> and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=shupe\" class=\"user-hover\" rel=\"shupe\">David Shupe</a>, there is a strong rationale for separating the FireflyClient API into its own repository (not combined with widgets):</p><ul>\\t<li>FireflyClient has very few dependencies, while <tt>firefly_widgets</tt> already depends on Astropy and more dependencies may be added.</li>\\t<li>FireflyClient is pure Python, while <tt>firefly_widgets</tt> includes both Javascript and Python.</li></ul><p>The proposal is to move FireflyClient out of the <tt>firefly</tt> repository and into its own repository <tt>firefly_client</tt>. <del>Within this repository, FireflyClient needs to be packaged to be pip-installable via <tt>pip install firefly_client</tt>.</del></p><p><del>To conform to Python module naming conventions, the module needs to be all lower-case, so that the users will import the class with something like <tt>from firefly_client import FireflyClient</tt> after it has been installed.</del></p><p>Examples of using the Python API could be included in an <tt>examples</tt> subdirectory in this repository.</p>\n",
            "nan\n",
            "<p>Remove obsolete files and directories and update documentation.<br/>See:</p><ul class=\"alternate\" type=\"square\">\\t<li>admin/tools/cluster/</li>\\t<li>admin/tools/*</li></ul>\n",
            "<p>from pull request <a href=\"https://jira.lsstcorp.org/browse/DM-6500\" title=\"convert irsaviewer to react.js\" class=\"issue-link\" data-issue-key=\"DM-6500\"><del>DM-6500</del></a>:  <a href=\"https://github.com/Caltech-IPAC/firefly/pull/102\" class=\"external-link\" rel=\"nofollow\">https://github.com/Caltech-IPAC/firefly/pull/102</a></p><ul>\\t<li>2MASS All-Sky \\'Read Me!\\' link in Catalog Search panel points to <a href=\"http://localhost:8080/irsaviewer/Q&#39;http://hades.ipac.caltech.edu/applications/Gator/GatorAid/irsa/scan.html&#39;E\" class=\"external-link\" rel=\"nofollow\">http://localhost:8080/irsaviewer/Q\\'http://hades.ipac.caltech.edu/applications/Gator/GatorAid/irsa/scan.html\\'E</a></li>\\t<li><del>If you search m31 2MASS scan info catalog (4th catalog in the list), then bring back catalog panel, the first catalog is highlighted, but if you search, you\\'ll notice that you are still searching 2MASS scan info.</del></li></ul>\n",
            "<p>It can be desirable to run ctrl_pool enabled commands (such as constructBias.py from pipe_drivers) without any batch system.</p><p>Please add an option</p><blockquote><p>--batch-type None</p></blockquote><p>that simply runs the job in the current process.</p>\n",
            "<p>meas_extensions_ngmix has no useful documentation, not even a <tt>doc</tt> directory. Add some.</p><p>This should include at least an overview of the package contents, a description of its capabilities, and instructions on enabling it within the meas_base framework. The package should have a README.</p>\n",
            "\"<p>There is already an external ndarray project on GitHub (we've been using a fork of that).  We should merge the forks and switch to using the external package. </p>\"\n",
            "<p>ci_hsc has a test that verifies that extendedness as measured on coadds broadly agrees with the star selection done for PSF estimation on individual frames.  This tests a bunch of stuff, including aperture corrections on the coadds and propagation of flags from visits to coadds.</p><p>It doesn\\'t test that aperture correction vs. extendedness logic is correct in processCcd.py, but just copying this test to the appropriate validation function in ci_hsc should do the trick.  This is currently broken, but should be fixed in <a href=\"https://jira.lsstcorp.org/browse/DM-5877\" title=\"Use Afterburners to clean up aperture correction logic\" class=\"issue-link\" data-issue-key=\"DM-5877\"><del>DM-5877</del></a>.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a> <a href=\"https://community.lsst.org/t/centrally-defined-butler-datasets/841\" class=\"external-link\" rel=\"nofollow\">recommends</a> a new way to define datasets common to all cameras in daf_butlerUtils, but modifying these yaml files require explicit lists of datasets to be modified in tests/cameraMapper.py.</p><p>If these tests are still useful, they need to depend on a minimal set of dataset definitions instead of the real ones.</p>\n",
            "<p>Take another pass through the plan developed in <a href=\"https://jira.lsstcorp.org/browse/DM-7846\" title=\"Redraft and revise straw-man DRP plan\" class=\"issue-link\" data-issue-key=\"DM-7846\"><del>DM-7846</del></a>, checking for sanity/correctness/missing information/etc.</p>\n",
            "<p>This ticket will handle the first part of <a href=\"https://jira.lsstcorp.org/browse/DM-8180\" title=\"Histogram display and expression improvements\" class=\"issue-link\" data-issue-key=\"DM-8180\"><del>DM-8180</del></a>, which will result in correct histogram display for the long values that can be converted into doubles without loosing precision.<br/>(ex. LSST htm index)</p>\n",
            "<p>Ensure that <tt>base</tt> works with Python 3.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Ensure that the <tt>utils</tt> package will work with Python 3.</p>\n",
            "<p>The current release of astrometry.net does not support Python 3. Upstream needs to be fixed.</p>\n",
            "<p>1. In the color stretch dialog:  (in chrome Version 50.0.2661.102 (64-bit) on my Mac OSX 10.9.5)</p><ul>\\t<li>the asinh beta and powerLaw Gamma input field do not  look like part of the input fields group. Too much white space in between.</li>\\t<li>When clicked on the Z scale option when the asinh and powerLaw types selected, the min and max values overlapped with the option choice.</li></ul>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-6521\" title=\"Enhance lsst.log by having a Log object and Python interface \" class=\"issue-link\" data-issue-key=\"DM-6521\"><del>DM-6521</del></a> improved Log class interface by replacing some static methods with non-static. Qserv is currently using couple of static methods which were retained in Log class for the duration of this migration. Once updated log package is released update qserv code to use new non-static methods and remove static methods from Log class after that.</p>\n",
            "<p>At the moment, when an error occurs, the panel does not update leaving the loading masks visible indefinitely.  This panel should instead update itself with error message(s) from the fetch.</p><p>TODO:</p><ul class=\"alternate\" type=\"square\">\\t<li>Fix CatalogConstraintsPanel</li>\\t<li>add generic error display into BasicTableView</li>\\t<li>move createErrorTbl from TablesCntlr to TableUtil</li></ul>\n",
            "<p>This is a problem with uploads, large image loads, and Atlas.   When a big image is loading the user does  not get feedback.  The problem is the the UI is not creating the ImageViewer soon enough.</p>\n",
            "<p>The eimage dataset type is special to obs_lsstSim so was not updated in the process of implementing the VisitInfo ticket.</p>\n",
            "<p>Assign first thoughts responsibilities to all software primitives and algorithmic components.  This is my take.  John will have his own take.</p>\n",
            "<p>in 2015 iPlant was rebranded to CyVerse  (<a href=\"http://www.cyverse.org/\" class=\"external-link\" rel=\"nofollow\">http://www.cyverse.org/</a>) with a revised mandate to serve all life sciences.<br/>CyVerse\\'s  Data Store is based on technology iRODS (<a href=\"http://irods.org/\" class=\"external-link\" rel=\"nofollow\">http://irods.org/</a>). <br/>CYVerse\\'s Atmosphere provides a managing portal for users\\'s VM instances and data spaces called volume. The instance and volume is tied under a project. </p><p>There are other tools and UIs under CyVerse. Data Store and Atmosphere are very close to what we wanted  for LSST workspace.  It provides many VM instance images preconfigured for life sciences domain-specific tasks. We could definitely learn from this if LSST provides the VM for its users.  LSST could supply instance images with specific astronomical tools preconfigured.  </p><p>Deciding if the CyVerse could be used as LSST workspace implementation will need much more study and discussion with other teams involved in workspace design and implementation. </p><p>The direction we are going with Jupyter Notebook and JupyterHub most likely preclude us from using CyVerse directly. </p>\n",
            "nan\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-5988\" title=\"Support Monocam reduction\" class=\"issue-link\" data-issue-key=\"DM-5988\"><del>DM-5988</del></a> introduced a hack in reading the raw files: we use a database to cache metadata from the shutter files and update the camera files at read time.  The camera files have now been \"sanitised\" (updated with the appropriate metadata), and it\\'s time to remove the hack.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mfisherlevine\" class=\"user-hover\" rel=\"mfisherlevine\">Merlin Fisher-Levine</a> writes:</p><blockquote><p>Data is on lsst-dev in:</p><p>/nfs/lsst2/photocalData/data/monocam/sanitised9/1m3/1m3</p><p>Raw calibs are in:</p><p>/nfs/lsst2/photocalData/data/monocam/sanitised9/1m3/calibs</p><p>Regarding what I want: everything to be the same, but with a normal ingest, i.e. no splicing, just taking everything that is needed from one set of files. Some points to note:</p><ul>\\t<li>should be able to ingest all the raws and calibs files, and register their OBJECT types to allow processing with these as ids (inc. pipe_drivers scripts)</li>\\t<li>pipe_drivers master calib scripts should still run (and their outputs still be ingestable)</li>\\t<li>processCcd should run</li></ul></blockquote>\n",
            "<p>Develop a new WBS describing work to be undertaken in 02C.04.</p>\n",
            "<p>The new VisitInfo interface to exposure metadata has broken some minor functionality of the DCR modeling code, but promises to greatly simplify the task of reading real data. This ticket is to update the reading and writing of metadata to use VisitInfo.</p>\n",
            "<p>Qserv master on PDAC has been re-install from scratch for security reasons:<br/><a href=\"https://jira.ncsa.illinois.edu/browse/LSST-801\" class=\"external-link\" rel=\"nofollow\">https://jira.ncsa.illinois.edu/browse/LSST-801</a></p><p>Qserv needs to be re-installed and re-tested here once master node will be available.</p>\n",
            "<p>Having collected data in <a href=\"https://jira.lsstcorp.org/browse/DM-6039\" title=\"Download temporally relevant raw calibs for CTIO DECam data\" class=\"issue-link\" data-issue-key=\"DM-6039\"><del>DM-6039</del></a>, push all this through the master calib creation scripts and ingest master calibs into registry.</p><p>This is a necessary but not-necessarily-sufficient ingredient for making progress on <a href=\"https://jira.lsstcorp.org/browse/DM-5465\" title=\"Finish getting obs_decam ISR working with CBP data\" class=\"issue-link\" data-issue-key=\"DM-5465\"><del>DM-5465</del></a>.</p>\n",
            "<p>Use the construct*.py scripts added to pipe_drivers to produce temporally relevant master biases, darks, flats (and fringe frames?) for the recent USNO observing with monocam.</p><p>A small amount of hacking will be required due to the fact that the current ingestion model assumes that each CCD frame has a USNO counterpart which tells about the telescope pointing etc, but the bias frames do not have these.</p><p>Once the master calibs are produced, get them ingested.</p>\n",
            "<p>There is a requirement for composite datasets that components of composites be cached and shareable, and we expect to use an object cache for this. <br/>We have identified that we need to be able to cache C++ weak_ptr and python weakref in the same cache in an opaque way. This needs some prototype R&amp;D.</p>\n",
            "<p>A utility class is needed to upload the unit testing data file in firefly_test_data tree.</p>\n",
            "<p>Please add at least a README file providing a short summary of its functionality and some bare-bones documentation on how to enable and use it.</p>\n",
            "<p> fix circles connecting &amp; add way to reorder image tabs.<br/>Most of this ticket has the code to reorder the images tabs in the image select panel</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-2674\" title=\"Get meas_mosaic working on HSC data with LSST stack\" class=\"issue-link\" data-issue-key=\"DM-2674\"><del>DM-2674</del></a> involves getting HSC\\'s <tt>meas_mosaic</tt> working with the LSST stack.  This issue consists of adapting the analysis.py script of <a href=\"https://jira.lsstcorp.org/browse/DM-4393\" title=\"Get analysis script working for HSC/LSST stack comparisons\" class=\"issue-link\" data-issue-key=\"DM-4393\"><del>DM-4393</del></a> &amp; <a href=\"https://jira.lsstcorp.org/browse/DM-4730\" title=\"Adapt qa analysis script for LSST vs. HSC single visit processing comparison\" class=\"issue-link\" data-issue-key=\"DM-4730\"><del>DM-4730</del></a> to (optionally) apply the astrometric and photometric solutions derived running <tt>meas_mosaic</tt> to the individual visits before comparison.  This is useful in general and is specifically useful in comparing the <tt>meas_mosaic</tt> results between the HSC and LSST stacks.</p>\n",
            "<p>Three things need to happen:</p><ul class=\"alternate\" type=\"square\">\\t<li>I want to change plotId the data structure to itemId</li>\\t<li>there are a couple of utilities function that are specific to images but I don\\xe2\\x80\\x99t think that matters</li>\\t<li>I want to add a type for each viewer</li></ul>\n",
            "<p>An empty column seems to be visible on the right-hand side of a table when no description is available in option panel of the XY-plot column setting, table option and fits header table.</p>\n",
            "<p>The region text defined with  region object (not text region) is not shown on PNG. </p>\n",
            "<p>Begin the visualization documentation process.  This is the first step of probably much more documentation.  However, some needs to be put into jsdocs soon so this ticket should be that documentation.</p>\n",
            "<p>A few components and functions of the StarFast simulator have fallen behind the needs of <a href=\"https://jira.lsstcorp.org/browse/DM-6245\" title=\"Compare competing algorithms for correcting DCR in template images\" class=\"issue-link\" data-issue-key=\"DM-6245\"><del>DM-6245</del></a>. In particular, the exposures created by the simulator are missing needed metadata. This ticket is to clean up the interface to better support the current uses, and to supply the missing metadata.</p>\n",
            "\"<p>MAJOR: imposing filters on the catalog makes the plot go away. <br/>(1) Gator. Search in WISE. All WISE. M16. 30 arcmin<br/>(2) In the data table, enable filters. Type \\xe2\\x80\\x9c&gt;10\\xe2\\x80\\x9d in each of the w1snr, w2snr, w3snr, w4snr column filter boxes. do NOT tab across to get them; it messes up the column headings.<br/>(3) the plot never comes back, the overlays never update on the image, and the \\xe2\\x80\\x9ccircular cyclical dots\\xe2\\x80\\x9d indicating \\xe2\\x80\\x9cI\\xe2\\x80\\x99m thinking\\xe2\\x80\\x9d never stops. As in, I did this, reproduced this, typed this up, got distracted by a text, checked email in different accounts, came back to this, and still no updates. <br/>Reproducibility:<br/>restarted tool both platforms. WISE/AllWISE/M16/30 arcmin cone.<br/>both come back with 17,816 sources.<br/>impose filters.<br/>plot vanishes as soon as first filter imposed. never returns from all four filters being imposed. Firefox is tilling me 695 sources are left (with the \\xe2\\x80\\x9ccircular cyclical dots\\xe2\\x80\\x9d still spinning) and Chrome is telling me 979 sources are left  (with the \\xe2\\x80\\x9ccircular cyclical dots\\xe2\\x80\\x9d still spinning).<br/>another test: <br/>restarted tool both platforms. WISE/AllWISE/M16/30 arcmin cone.<br/>both come back with 17,816 sources.<br/>impose JUST filter on w1snr. &gt;10<br/>Firefox: 3823 sources, plot vanishes, overlay doesn\\xe2\\x80\\x99t update, \\xe2\\x80\\x9ccircular cyclical dots\\xe2\\x80\\x9d still spinning<br/>Chrome: 3609 sources, plot vanishes, overlay doesn\\xe2\\x80\\x99t update, \\xe2\\x80\\x9ccircular cyclical dots\\xe2\\x80\\x9d still spinning<br/>So, this problem exists for one filter AND more than one filter.</p><p><b>Copied from the pull request by Loi (9/30/2016)</b><br/>We were using cookies to pass websocket connection info to the server. This approach does not work in and embedded mode, ie. Gator.  I've converted to use custom http headers instead. This also affects python api. I've modified the code to reflect the changes.</p><p>This change fixed the above problem and should not have any regression issue</p>\"\n",
            "<p>Chat with stakeholders in the deblender (at least RHL, Jim Bosch) to get a better feeling for their vision of how it should be developed in the future. Understand the architectural requirements for multi-band deblending.</p>\n",
            "<p>When exposing Histogram React Component to API and writing the demo, I found the following bugs:</p><ul class=\"alternate\" type=\"square\">\\t<li>log scale for y axis fails</li>\\t<li>tooltip might be misaligned with bin boundaries</li></ul>\n",
            "<p>participate discussion of WBS restructuring,  review and edit</p>\n",
            "<p>Participate in the 2-day discussion of 2D plotting package design,  functions supported, and strategy for introducing new 3rd party software packages,</p>\n",
            "<p>Allow null values to display as \"null\", currently a value of null is left blank. </p>\n",
            "nan\n",
            "<p>Create a services layer with methods to access the API - this will make the metrics bokeh app easier to read and all methods to access the API can be organized in the same file (services.py) shared by the bokeh apps.</p>\n",
            "<p>The stack is being adapted to work with Python 3 as well as Python 2. Following the guide from LSST2016 for porting packages to Python 3, adapt the FireflyClient API. This will allow afw.display to work with Firefly in a Python 3 stack.</p>\n",
            "<p>Locate and evaluate a dataset of SDSS Stripe82 which is going to be used for testing the prototype DAC.</p>\n",
            "<p>Start trying to think through the replan using OmniPlan. Is it useful? If not, are there alternative technologies that would be better?</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-5695\" title=\"Implement simple 1D DCR correction on simulated data\" class=\"issue-link\" data-issue-key=\"DM-5695\"><del>DM-5695</del></a> will create transfer matrices stored as numpy arrays. This ticket extends that work to determine a useful format and write functionality to persist those arrays.</p>\n",
            "<p>Catalog search panel in IrsaViewer, the target panel label, feedback, and input box are jumping as input is being typed.  Their position should be fixed.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-7271\" title=\"Change default format for float and double to %g\" class=\"issue-link\" data-issue-key=\"DM-7271\"><del>DM-7271</del></a>: table enhancements</p><ul>\\t<li>do not apply default data format</li>\\t<li>introduce optional display format</li>\\t<li>add \"AUTO\" and \"NONE\" as format keywords.</li>\\t<li>for fits table, set display format to \"%.9g\" for double type.</li>\\t<li>add support for TDISPn fits table header</li>\\t<li>remove condition so temp files will not get written into source directory</li></ul><p>When reading fits table, set display format to \"%.9g\" for double if TDISPn is not given.</p>\n",
            "<p>The current logic to set detection.thresholdValue to 5.0 if doDecorrelation == True is set in setDefaults(), and so never runs. This block needs to be moved elsewhere (doValidate, perhaps?) so that it runs correctly.</p>\n",
            "<p>We need to add JSDoc generation in Jekins build and bundle it in the firefly.war file when we make Firefly release.</p>\n",
            "<p>SQR-012 provides details of how the new unittests should be written, but it only gives an example of the old testing boilerplate in the introduction. It would be very helpful to have the first thing a reader sees be the new, correct, boilerplate, so they can immediately drop it into a new testing file.</p>\n",
            "<p>Review the composite dataset description document with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a> and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=Parejkoj\" class=\"user-hover\" rel=\"Parejkoj\">John Parejko</a>, and any others who may be interested (e.g. post on community or do an RFD)</p>\n",
            "<p>Current version of my prototype script does not read (forced)sources from database. These will be needed in AP for calculation of the DiaObject parameters. This is probably one of the most interesting features because it is time-based queries and it will potentially have a big impact on database design and may require changes to schema.</p>\n",
            "nan\n",
            "<p>Bug fixes for using the new <tt>LoadIndexedReferenceObjectTask</tt> and its associated components.</p>\n",
            "<p>Support a means of ingesting index reference catalogs from FITS tables (e.g. SDSS catalogs).</p>\n",
            "<p>Prepare materials for and participate in the meeting.</p>\n",
            "<p>Prepare materials for and participate in the meeting.</p>\n",
            "<p>Prepare materials for and participate in the meeting.</p>\n",
            "<p>Prepare materials for and participate in the meeting.</p>\n",
            "<p>Write a description of composite datasets as I understand them based on the email KT sent on May 20 (attached), and on conversation I had with KT and Fritz on July 20.</p>\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/DM-3368\" title=\"Port HSC MPI driver for single-visit processing\" class=\"issue-link\" data-issue-key=\"DM-3368\"><del>DM-3368</del></a>, we stripped out the focus calculation since it\\'s not camera-generic, and the scatter/gather isn\\'t necessary for general processing.  We need to reinstate the focus calculation in its own scatter/gather script.</p>\n",
            "<p>obs_subaru enables bright object masks by default, as that\\'s desirable for HSC production runs.  </p><p>However, when HSC data is processed without bright object masks available (as will happen in most GO observations and development use), multiBandDriver.py will fail because the BRIGHT_OBJECT mask plane is not present but the base_PixelFlags algorithm is configured to make use of it. This is confusing, and it also requires the definition of a configuration file to fix the problem because base_PixelFlags cannot be configured directly on the command-line.</p><p>Some possibilities for fixing this:</p><ul class=\"alternate\" type=\"square\">\\t<li>Add the BRIGHT_OBJECT mask plane in AssembleCoadd if doMaskBrightObjects is True but the external catalog is not found.  This will make the PixelFlags operation a silent no-op.</li>\\t<li>Allow configuration options to allow PixelFlags algorithm to silently skip some flags if the appropriate masks are not available.</li></ul><p>I am sure there are other options as well.</p>\n",
            "<p>Install, configure and snapshot Mac OS X El Capitan. This requires configuring the vmx file then installing Mac OS X Mountain Lion and upgrading.</p>\n",
            "<p>Install, configure and snapshot Mac OS X Yosemite. This requires configuring the vmx file then installing Mac OS X Mountain Lion and upgrading.</p>\n",
            "<p>SWIG 3.0.5 is now out and has several useful fixes w.r.t. 3.0.2 (which we are presently using) including:</p><ul class=\"alternate\" type=\"square\">\\t<li>A bug we\\'ve had to work around involving templated methods of classes</li>\\t<li>improved handling of new-style enums (they are no longer hoisted into the global namespace, which was a serious misfeature of SWIG 3.0.2)</li></ul><p>I propose we try it out using buildbot (when we have some time), and if it works, we adopt it. Adopting it will help us relax the restrictions on what C+<ins>11 features can be used in C</ins>+ header files.</p>\n",
            "<p>We need to support regular Firefly distribution builds (with bundled tomcat server),<br/>similar to the builds we did in lsst firefly repository before the conversion.</p><p>This is to get Camera team started with new API.</p>\n",
            "\"<p>Figure out and configure the firewall, ssh server and ssh client for ESXi.</p><p>This isn't especially well documented since it's part of VMWare vSphere.</p><p>This part specifically was time consuming since most users by vSphere.</p>\"\n",
            "<p>The visualization system is not update the memory accounting for the caching system.</p>\n",
            "<p>In preparation for linking Jupyter notebooks with Firefly and other SUIT components, read Jupyter documentation. Learn how to build a sample widget or interactive dashboard in the Jupyter framework</p>\n",
            "<p>When a table is filtered from the expanded mode, the layout is changed back to unexpanded.</p><p>It looks like the issue is more general: table actions trigger layout changes, which are not always right. For example, TABLE_REMOVE action while in a dropdown makes the  dropdown to get closed. I\\'ve traced it to FireflyLayoutManager.js:layoutManager generator function.</p><p>Test sequence in firefly: </p><ul class=\"alternate\" type=\"square\">\\t<li>When a table is loaded, open \"Charts\" dropdown, select Col link for X, then select Col link for Y. (At this point the previous table is removed).</li>\\t<li>TABLE_REMOVE action on the second click triggers dropdown to go away.</li></ul>\n",
            "nan\n",
            "<p>jointcal has its own custom star selector. This should be removed and replaced with a star selector based on meas_algorithms.starSelector. A good choice might be meas_algorithms.objectSizeStarSelector.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-6382\" title=\"Generate template DCR images\" class=\"issue-link\" data-issue-key=\"DM-6382\"><del>DM-6382</del></a> creates template images of a field at arbitrary airmasses, which can be used to match the template airmass to the science image precisely to mitigate Differential Chromatic Refraction in image differencing. This ticket is to determine the best method to supply the new templates to image differencing, which may be simply to create a new exposure and ingest/process the template as though it were a real observation.</p>\n",
            "<p>Write the presentation for the SPIE conference. Date of presentation: 26th June.</p>\n",
            "nan\n",
            "<p>This is a backport issue to capture subsequent HSC-side work on features already backported to afw.  It includes (so far) the following HSC issues:</p><ul class=\"alternate\" type=\"square\">\\t<li><a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1135\" class=\"external-link\" rel=\"nofollow\">HSC-1135</a></li>\\t<li><a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1129\" class=\"external-link\" rel=\"nofollow\">HSC-1129</a></li>\\t<li><a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1215\" class=\"external-link\" rel=\"nofollow\">HSC-1215</a></li></ul>\n",
            "<p>We need to create a persistable, map-like container class to hold aperture corrections, with each element of the container being an instance of the class to be added in <a href=\"https://jira.lsstcorp.org/browse/DM-740\" title=\"Implement abstract base class for approximated or interpolated fields\" class=\"issue-link\" data-issue-key=\"DM-740\">DM-740</a>.</p><p>A prototype has been developed on DM-797 on the HSC side:<br/><a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-797\" class=\"external-link\" rel=\"nofollow\">https://hsc-jira.astro.princeton.edu/jira/browse/HSC-797</a><br/>and the corresponding code can be found on these changesets:<br/><a href=\"https://github.com/HyperSuprime-Cam/afw/compare/32d7a8e7b75da6f5327fee65515ee59a5b09f6c7...tickets/DM-797\" class=\"external-link\" rel=\"nofollow\">https://github.com/HyperSuprime-Cam/afw/compare/32d7a8e7b75da6f5327fee65515ee59a5b09f6c7...tickets/DM-797</a></p>\n",
            "<p>It would be useful to have a parameter that indicates how much any given galaxy is blended. This will be useful for testing how photometry or shears are affected by blending effects.</p><p>Ports code from HSC-1260.</p>\n",
            "\"<p>This improves handling of several edge case failure modes, tweaks the configuration to improve performance, and adds some introspection useful for Jose Garmilla's tests.</p><p>Includes HSC-1288, HSC-1284, HSC-1228, HSC-1250, HSC-1264, HSC-1273, HSC-1240, HSC-1249, HSC-1238, HSC-990, HSC-1155, HSC-1191</p>\"\n",
            "<p>This is a code transfer from HSC-1247.</p>\n",
            "<p>Add a new mask plane for regions with no data - fully vignetted, edge patches in coadd.</p><p>This is a port of <a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-669\" class=\"external-link\" rel=\"nofollow\">HSC-669</a>.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-4009\" title=\"Allow FlagHandler to be used from Python\" class=\"issue-link\" data-issue-key=\"DM-4009\"><del>DM-4009</del></a> added the C++ and swig changes needed to allow the FlagHandler to be used from Python.  During review, Nate suggested that a decorator class could be used to improve the use of this code in Python.  This ticket will be to review Nate\\'s decorator and confirm that it is the correct model for Python-only plugins.</p><p>We will also modify the unit test in <a href=\"https://jira.lsstcorp.org/browse/DM-4009\" title=\"Allow FlagHandler to be used from Python\" class=\"issue-link\" data-issue-key=\"DM-4009\"><del>DM-4009</del></a> and the EmPsfApprox plugin in <a href=\"https://jira.lsstcorp.org/browse/DM-6123\" title=\"Build SFM housing for PSF approximation using ngmix code\" class=\"issue-link\" data-issue-key=\"DM-6123\"><del>DM-6123</del></a> to use the decorator.</p>\n",
            "<p>Restore the registry for star selectors that was lost in <a href=\"https://jira.lsstcorp.org/browse/DM-5532\" title=\"Change star selectors to return stars instead of PSF candidates\" class=\"issue-link\" data-issue-key=\"DM-5532\"><del>DM-5532</del></a>, now that tasks in registries can be used as subtasks.</p><p>Also use the registry where appropriate.</p>\n",
            "<p>The algorithm to calculate the label position does not work well for the Ecliptic coordinate system.  The algorithm needs to be modified to work for all the coordinates.</p>\n",
            "<p>It would be beneficial to have in the TABLE_NEW_LOADED payload a<br/>trigger field, which would differentiate actions triggered by sort (where<br/>data do not change, only their order) or filter from other loads. We don\\'t<br/>need to reload table statistics or histogram on sort. But we do need to to<br/>reload them on filter.</p><p>created TABLE_SORT action to distinguish sorting from filtering.  sorting should not reload xyplot nor catalog overlay.</p><p>Also:</p><ul class=\"alternate\" type=\"square\">\\t<li>disable history when in api mode.</li>\\t<li>ensure tableMeta.source reflects the file on the server.</li>\\t<li>fix TablePanelOptions not resetting columns selection.</li>\\t<li>remove \\'Fits Data\\' tab when no images available.</li>\\t<li>fix \\'Coverage\\' appearing when it should.</li></ul>\n",
            "<p>Create a new project in JIRA (DM Baseline Plan), spec provided here: <a href=\"https://confluence.lsstcorp.org/display/DM/ProjMgmtWG%3A+The+New+DLP\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/ProjMgmtWG%3A+The+New+DLP</a><br/>I am sure we will fine tune it, but it is a (hopefully good) start.</p>\n",
            "<p>Prepare a draft schedule, with some detail for 2016-2017, for deployments of the SUIT into (test) production, including the datasets that will be served.</p>\n",
            "<p>When neither <tt>&#45;-output</tt> or <tt>&#45;-rerun</tt> is specified as an argument to a <tt>CmdLineTask</tt>, any output from that task appears to be written back to the input repository. Note the use of the term \"appears\": from a preliminary inspection of the code and documentation, it\\'s not clear if this behaviour can be overridden e.g. by environment variables.</p><p>The HSC stack behaves differently, using <tt>$INPUT/rerun/$USER</tt> as a default output location. A <a href=\"https://community.lsst.org/t/new-argument-parser-behavior-rerun-flag-introduction-discussion/345\" class=\"external-link\" rel=\"nofollow\">brief discussion</a> suggests that this is the preferred behaviour.</p><p>Please update the LSST stack to match the HSC behaviour.</p>\n",
            "<p>On some systems, we are asked to request a total number of tasks, rather than specify a combination of nodes and processors per node.</p><p>It also makes sense to use the SMP option this way.</p><p>This is a port of <a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1369\" class=\"external-link\" rel=\"nofollow\">HSC-1369</a>.</p>\n",
            "<p>SingleFrameVariancePlugin can produce the following numpy warning, with no hint as to where the problem is coming from:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/Users/rowen/UW/LSST/lsstsw/miniconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I tracked it down by adding the following code to the calling code:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import warnings</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">with warnings.catch_warnings():</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    warnings.filterwarnings(\\'error\\')</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>It would be nice if the measurement plugin handled this situation more gracefully, such as turning the warning into an exception or testing for it and handling it.</p><p>One way to reproduce this problem is to run <tt>tests/testProcessCcd.py</tt> in <tt>pipe_tasks</tt>. However, it is commonly seen when running <tt>processCcd</tt> on other data, as well.</p>\n",
            "<p><a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1295\" class=\"external-link\" rel=\"nofollow\">HSC-1295</a> introduces <tt>flux.scaled</tt>, which measures the flux within a circular aperture that is set from the size of the PSF, scaled by some factor.  Stephen Gwyn recommends using this as our fiducial calibration flux.</p>\n",
            "<p>The reference object loader in <tt>meas_algorithm</tt>\\'s <b>loadReferenceObjects.py</b> grows the bbox by the config parameter pixelMargin:  doc = \"Padding to add to 4 all edges of the bounding box (pixels)\" . This is set to 50 by default but is not reflected by the radius parameter set in the metadata, so some matches may reside outside the circle searched within this radius. This increase needs to be reflected in the radius set in the metadata fed into <tt>joinMatchListWithCatalog()</tt>.</p>\n",
            "<p>Update <tt>ProcessCcdTask</tt> so that it can be used with different datasete types as appropriate for the ISR task. This will allow us to get rid of obs-specific variants <tt>ProcessCcdSdssTask</tt> and <tt>ProcessCcdDecamTask</tt></p><p>The plan is to change <tt>ProcessCcdTask</tt> as follows:</p><ul class=\"alternate\" type=\"square\">\\t<li>set <tt>doMakeDataRefList=False</tt> in the call to <tt>add_id_argument</tt></li>\\t<li>get the dataset type from the ISR task (default to \"raw\") and set it in data container</li>\\t<li>make the dataRef list by calling <tt>makeDataRefList</tt> on the data container</li></ul><p>Question for DECam folks: do you want two executable scripts for DECam (one that processes data from the community pipeline and one that performs ISR)? Or do you prefer one exectutable (in which case you switch between performing ISR and reading the output of the community pipeline output by retargeting the ISR task)? If you prefer one binary, then which should be the default: perform ISR or read the output of the community pipeline?</p>\n",
            "<p>It\\'s confusing to have to use an extra <tt><span class=\"error\">&#91;:&#93;</span></tt> to set a column in afw.table, and we can make that unnecessary if we override <tt>&#95;&#95;setitem&#95;&#95;</tt> as well as <tt>&#95;&#95;getitem&#95;&#95;</tt>.</p>\n",
            "<p>Currently all of the logic that goes into using bright object masks falls into obs_subaru and pipe_tasks. This ticket should move parts (such as the bright object mask class) out of obs_subaru, into a camera agnostic location. The work should also duplicate relevant camera configurations and parameter overrides in the other camera packages. Bright object masks were originally introduced in <a href=\"https://jira.lsstcorp.org/browse/DM-4831\" title=\"Add bright object masks to pipeline outputs\" class=\"issue-link\" data-issue-key=\"DM-4831\"><del>DM-4831</del></a></p>\n",
            "<p>We need to ensure that the latest version of the application(javascript) is loaded.<br/>Conditions:<br/>1. once loaded, it should be cached by the browser.<br/>2. name of the script has to be a static, so it can be referenced by api user.<br/>3. it also has to load dependencies(gwt scripts) after the main script is loaded.</p><p>To do this, we created a tiny firefly_loader.js script whose role is to load the main script and then its dependencies.<br/>firefly_loader.js is configured to never cache so that the latest main script is always picked up.<br/>The main script is appended with a unique hash on every build.  This ensures that the browser will pick up the new script the very first time, and then cache it for future use.</p>\n",
            "<p>This tracks SPs spent on JIRA requests. </p>\n",
            "<p>Create CentOS5 conda binary builds using docker then push them to the S3 static website.</p>\n",
            "<p>In order to lock memory, the memory locking limit within the container for the qserv worker needs to be raised. My understanding is the container uses whatever is the host setting so the limit has to be set for the container user and whatever the user is inside the container. The particular limits is:</p><p>memorylocked 64 kbytes</p><p>notice that by default it\\'s 64K. That needs to be raised to say 75% of the real machine size. I wouldn\\'t make it unlimited as a memlock mistake may crash the whole machine. The limits are specified in \"/etc/security/limits.conf\". You will know that you are successul when you ssh into the container as the qserv worker user and the \"limit\" command tell you have can lock lots of memory.</p><p>We would also set the CAP_IPC_LOCK privilege but setting the soft/hard limit above should be good enough. So, let\\'s start with that. </p>\n",
            "<p>Currently, validation is performed only if a field has changed. We need to be able to validate all fields on form submit.</p><p>The issue is not limited to initial (ex. empty) value being invalid. The invalid message is lost when a field is unmounted/re-mounted.</p><p>You can test the following way:</p><ul class=\"alternate\" type=\"square\">\\t<li><a href=\"http://localhost:8080/firefly/;a=layout.showDropDown?view=AnyDataSetSearch\" class=\"external-link\" rel=\"nofollow\">http://localhost:8080/firefly/;a=layout.showDropDown?view=AnyDataSetSearch</a></li>\\t<li>Open chart settings, enter 1000 into X/Y ratio - the field is shown as invalid</li>\\t<li>Switch to histogram and back, the invalid message is gone, the field appears to be valid</li></ul><p>Another test case is Example Dialog tab \\'X 3\\', \\'X 3\\'  tab test field initial value 88 is invalid (it should be between 22 and 23), but it appears valid. </p>\n",
            "<p>The fields group can be out of sync with actions if they are trying to use store data when that actual value is changes.  This is a classic side-effect issue.  It can be solved with sagas.</p><p>Our current example.  The color panels updating from the plot when the activePlotId changes.</p><p>More to do:</p><ul>\\t<li>field groups need a sega to more effective respond to out side actions</li>\\t<li>the dispatchChangeFieldGroup needs better, more documented parameters</li>\\t<li>update multiple fields at the same time.</li>\\t<li>should we have the field group support reset to init state? probably not, but look into it.</li>\\t<li>change init values?</li>\\t<li>Check example dialog and see if the large/smaller example is validating correctly.</li></ul>\n",
            "<p>Jon is trying to run tests with large result which kills proxy/czar because it runs out of virtual memory. Would be nice to reduce memory use and find a way not to keep query result in memory.</p>\n",
            "<p>Per <a href=\"https://jira.lsstcorp.org/browse/RFC-117\" title=\"Add sphgeom as an LSST package\" class=\"issue-link\" data-issue-key=\"RFC-117\"><del>RFC-117</del></a>, the sphgeom package needs decent overview documentation, linked from the top-level README.md. The doxygen output should also be reviewed.</p>\n",
            "\"<p>Write some snippets to aide in the processing and visualisation of the CBP data/analysis.</p><p>Essentially, write some helper functions that you can throw sections of images at to help look at the shape of the CBP spots, as ds9 isn't great ideal this.</p><p>Some nice features would be:</p><p>A function that takes a list of images or arrays, and plots them side-by-side, which provides some intelligent options for the stretches, and optionally stretches each image as is best for it, or ties them all to be the same. This would be as 2D colour plots.</p><p>A function that takes part of an image and displays it as a colour-graded surface.</p><p>A function that takes part of an image and displays it as a 3D bar-chart (as in ROOT, but without using ROOT because there is already enough evil in the world)</p>\"\n",
            "<p>We need a plan for  all the Firefly APIs development in the new React/Redux based JS framework, including JS API and Python API.</p><ul class=\"alternate\" type=\"square\">\\t<li>Backward compatibility</li>\\t<li>Syntax format for JS API</li>\\t<li>Syntax format for Python API</li>\\t<li>Schedule</li>\\t<li>convert the existing API first</li>\\t<li>list of new ones to be added, when</li></ul>\n",
            "<p>Please provide a minimal level of documentation for <tt>pipe_drivers</tt>, to include:</p><ul>\\t<li>A <tt>doc</tt> directory with the usual content so that docstrings get generated by Doxygen;</li>\\t<li>A package overview;</li>\\t<li>All docstrings should be appropriate for parsing by Doxygen (ie, should start with <tt>\"\"\"!</tt> where necessary).</li></ul>\n",
            "<p>Tatiana will attend the weekly meeting. Xiuqin and Gregory also attends when needed. </p>\n",
            "<p>Ginga and Glue (glueviz) are community visualization tools in Python. Become familiar with the capabilities of both, thinking from the point of view of using Firefly for the display but using Python for many other things.</p>\n",
            "<p>The server hard to make a hard copy now takes a StaticDrawInfo object.  We want to use only a region array.  Change the server side to support this.</p>\n",
            "nan\n",
            "<p>We need to avoid duplicate requests which result from minor differences in TableRequest parameters, which are not used to get data.<br/>For example, loading catalog table, which triggers table statistics, and then getting an XY plot, results in 3 requests, returning identical data.</p><p>1. RequestClass=ServerRequest; <b>tbl_id=tbl_id-1;</b> UserTargetWorldPt=10.68479;41.26906;EQ_J2000;m31;ned; SearchMethod=Cone; catalog=wise_allwise_p3as_psd; RequestedDataSet=wise_allwise_p3as_psd; radius=200; use=catalog_overlay; catalogProject=WISE</p><p>2. RequestClass=ServerRequest;RequestedDataSet=wise_allwise_p3as_psd; catalog=wise_allwise_p3as_psd; use=catalog_overlay; UserTargetWorldPt=10.68479;41.26906;EQ_J2000;m31;ned; catalogProject=WISE; radius=200; SearchMethod=Cone</p><p>3. RequestClass=ServerRequest; <b>tbl_id=xyplot-tbl_id-1;</b> catalog=wise_allwise_p3as_psd; use=catalog_overlay; UserTargetWorldPt=10.68479;41.26906;EQ_J2000;m31;ned; SearchMethod=Cone; RequestedDataSet=wise_allwise_p3as_psd; catalogProject=WISE; radius=200; <b>decimate=decimate=ra,dec,10000,1,,,,</b></p><p>The difference between 1 and 2 is tbl_id parameter. The difference between 2 and 3 is tbl_id and decimate parameters. As well as the order of the parameters. None of which change the catalog search result.</p><p>Test Case: Test Searches, Test catalog, AllWISE Source, radius=200</p>\n",
            "<p>Determine the metadata and dependencies needed to fully process two images simulated with StarFast through diffim. </p>\n",
            "<p>Dockerfile are generated using templates and sed, this should be strengthened.</p>\n",
            "<p>Currently, if a region of sky is simulated in StarFast the stars must always have the same x,y coordinates (before DCR effects). This ticket is to support arbitrary rotations and offsets of the simulated stars to mimic realistic repeated observations of the same field.</p>\n",
            "<p><a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1355\" class=\"external-link\" rel=\"nofollow\">HSC-1355</a>: \"with this fix, we get much  better fringe subtraction\".</p>\n",
            "<p>See also <a href=\"https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=LDMDG&amp;title=NCSA+Nebula+OpenStack+Issues\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=LDMDG&amp;title=NCSA+Nebula+OpenStack+Issues</a></p>\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/DM-3368\" title=\"Port HSC MPI driver for single-visit processing\" class=\"issue-link\" data-issue-key=\"DM-3368\"><del>DM-3368</del></a>, we provided a means of running multiple processCcd tasks across an exposure, but without performing global calibration etc as provided by HSC\\'s ProcessExposureTask.</p><p>Please augment this with whatever additional capability is required to enable HSC data release processing.</p>\n",
            "<p>While Tatiana is the assignee of this ticket, Xiuqin and Gregory participate this weekly telecon semi-regularly to lend support. </p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Added arrow up/down to move between rows.</li>\\t<li>Added page up/down to move between pages.</li></ul><ul class=\"alternate\" type=\"square\">\\t<li>Fixed table loading mask not showing</li>\\t<li>Fixed PagingBar rendering more than it should</li>\\t<li>Fixed annoying StandardView missing unique key warning</li></ul>\n",
            "nan\n",
            "<p>DM-46921 and <a href=\"https://jira.lsstcorp.org/browse/DM-5348\" title=\"Get rid of ProcessCcdSdssTask and ProcessCcdDecamTask\" class=\"issue-link\" data-issue-key=\"DM-5348\"><del>DM-5348</del></a> changed ProcessCcd to the point where past config files are no longer valid as stuff has moved a lot (see <a href=\"https://community.lsst.org/t/backward-incompatible-changes-to-processccdtask-and-subtasks/581\" class=\"external-link\" rel=\"nofollow\">https://community.lsst.org/t/backward-incompatible-changes-to-processccdtask-and-subtasks/581</a>)</p><p>This ticket is to go through past configs and create a new config file to reproduce the reductions done, or at least make something sensible come out the end of processCcd</p>\n",
            "<p>On <a href=\"https://jira.lsstcorp.org/browse/DM-5084\" title=\"PropagateVisitFlags doesn&#39;t work with other pipeline components\" class=\"issue-link\" data-issue-key=\"DM-5084\"><del>DM-5084</del></a> <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a> switched PropagateVisitFlags to match against icSrc instead of src because we weren\\'t yet matching `icSrc` to `src` in ProcessCcdTask.  That\\'s now been done on <a href=\"https://jira.lsstcorp.org/browse/DM-4692\" title=\"Refactor ProcessCcdTask and sub-tasks\" class=\"issue-link\" data-issue-key=\"DM-4692\"><del>DM-4692</del></a>, so we can revert this.</p><p>After doing so, please verify with ci_hsc that this is working, as that\\'s where the only test of this feature lives.</p>\n",
            "<p>When the data for a table is completely loaded fire another action such as TABLE_NEW_LOADED_DONE. This way the xyplots and the image overlays know to go fetch the data.</p><p>4/22/2026 from the pull request:<br/>added new action TABLE_NEW_LOADED to table; fired when table is completely loaded.<br/>added table error handling.<br/>fix active table not updating after an active tab is removed.</p>\n",
            "<p>Parameters are not sent to the server when requests are posted via fetchUrl.</p>\n",
            "nan\n",
            "<p>Make XYPlot expandable</p>\n",
            "<p>To get jointcal to build in the stack, we need to satisfy the SuiteSparse dependency by creating an external package for SuiteSparse.</p><p>Assuming it builds cleanly, this should satisfy the remaining requirement of <a href=\"https://jira.lsstcorp.org/browse/RFC-153\" title=\"Add SuiteSparse external package (has LAPACK/BLAS dependency)\" class=\"issue-link\" data-issue-key=\"RFC-153\"><del>RFC-153</del></a>, now that the licensing question has been answered there.</p>\n",
            "<p>Test table to make sure it can be resized under a variety of layout.</p>\n",
            "<p><tt>python/lsst/ci/hsc/validate.py</tt> in <tt>ci_hsc</tt> <a href=\"https://github.com/lsst/ci_hsc/blob/69c7a62f675b8fb4164065d2c8c1621e296e40ad/python/lsst/ci/hsc/validate.py#L78\" class=\"external-link\" rel=\"nofollow\">says</a>:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">def</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> validateMatches(</span><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">self</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, dataId):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        </span><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># XXX lsst.meas.astrom.readMatches is gone!</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p><tt>readMatches</tt> (or its successor) should be back in place as of <a href=\"https://jira.lsstcorp.org/browse/DM-3633\" title=\"Add readMatches back to meas_astrom\" class=\"issue-link\" data-issue-key=\"DM-3633\"><del>DM-3633</del></a>. Please enable this test.</p>\n",
            "<p>Implement <a href=\"https://jira.lsstcorp.org/browse/RFC-62\" title=\"Make config files and command line specifications of configurations consistent\" class=\"issue-link\" data-issue-key=\"RFC-62\"><del>RFC-62</del></a> by using <tt>config</tt> rather than <tt>root</tt> in config override files for the root of the config.</p><p>Note that I propose not modifying astrometry_net_data configs because those are numerous and hidden. They have their own special loader in LoadAstrometryNetObjectsTask._readIndexFiles which could easily be updated later. if desired. An obvious time to make such a transition would be when overhauling the way this data is unpersisted.</p>\n",
            "<p>Add a linear background gradient fit to the integrated pre-subtraction and dipole fitter (for testing).<br/>This will eventually be implemented in the measurement plugin.</p>\n",
            "<p>Implement <a href=\"https://jira.lsstcorp.org/browse/RFC-167\" title=\"Temporarily add esutil to the stack\" class=\"issue-link\" data-issue-key=\"RFC-167\"><del>RFC-167</del></a> for adding esutil to the stack.  This will be done in the same way as proposed to add scipy.</p>\n",
            "<p>As of <a href=\"https://jira.lsstcorp.org/browse/DM-5532\" title=\"Change star selectors to return stars instead of PSF candidates\" class=\"issue-link\" data-issue-key=\"DM-5532\"><del>DM-5532</del></a> a few config files need updating to not refer to star selector config fields as registries (not ones run by our normal CI, which is how I missed this).</p>\n",
            "<p>Write the simple zoom options popup that is show when the user clicks zoom too fast or the zoom level exceeds  the maximum size.</p><p>activate this popup from visualize/ui/ZoomButton.jsx</p>\n",
            "\"<p>Adding scipy as a stack dependency is still a nebulous term to me.  David is going to follow up on how to do this exactly (it's already in conda_packages.txt).</p>\"\n",
            "\"<p>Before we start digging into jointcal, it'd be good to get the whitespace/oldpython/indentation/lint/etc. questions sorted out. This ticket is for that.</p>\"\n",
            "<p>Some of the outside modules that we have brought in have a z-index.  We need to make sure that our dialog components stay on top of them.</p>\n",
            "nan\n",
            "<p>Create a composable, validating InputField so it can use outside of the form/submit use-case.</p>\n",
            "<p>This task is composed of:</p><ul class=\"alternate\" type=\"square\">\\t<li>adding text view option to TablePanel</li></ul>\n",
            "<p>IRSA is contributing to Firefly development. We need to mentor the new developers.</p>\n",
            "<p>IRSA is contributing to the Firefly package development.  we need to put in time to mentor the developers. </p>\n",
            "nan\n",
            "<p>TablePanel and BasicTable now accept optional renderers.<br/>For each column, you can set a custom renderer for the header, cell, or both.<br/>Also, created several commonly used renderer for images, links, and input field.</p>\n",
            "<p>The astrometry histogram generated by validateDrp.py conflates astrometric and photometric calibration because it uses magnitude for brightness, and this relies on the accuracy of the photometric calibration. <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ctslater\" class=\"user-hover\" rel=\"ctslater\">Colin Slater</a> suggests (and I agree) that brightness should be based on signal to noise ratio, thus making the astrometry histogram independent of photometric calibration.</p>\n",
            "<p>Create a docgen from the LSE-140 content in Enterprise Architect.</p>\n",
            "<p>Deliverable: together with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=pingraham\" class=\"user-hover\" rel=\"pingraham\">Patrick Ingraham</a>, identify the changes needed and develop initial content in EA.</p>\n",
            "<p>Review LCR-603, \"LSE-74 document revision\"</p>\n",
            "<p>Review the LSE-70 and LSE-209 drafts submitted with change requests LCR-567 and LCR-568 in January 2016.</p>\n",
            "<p>Prepare for, attend, and follow up on the OCS-subsystems teleconference on December 9, 2015. This story covers work related to LSE-70 and LSE-209; LSE-74 work was also done under a separate epic.</p>\n",
            "<p>Prepare for, attend, and follow up on the OCS-subsystems teleconference on October 8, 2015.</p>\n",
            "<p>We need a simple way to hold index files that will be easy to use and simple to set up.</p>\n",
            "<p>The LSST Publication Board requests a JIRA project for managing its workload. </p>\n",
            "<p>After working on a script to test the astrometric matcher, I decided to put together a plan to run similar tests on our algorithmic code.  The rough plan is here:<br/><a href=\"https://confluence.lsstcorp.org/display/SQRE/Stack+Testing+Plan\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/SQRE/Stack+Testing+Plan</a></p>\n",
            "<p>Due to the incomplete state of the stack documentation and tutorials, I decided to write down various \"tips and tricks\" for using the stack as I learn them.<br/><a href=\"https://confluence.lsstcorp.org/display/SQRE/Tips+and+Tricks+for+using+the+Stack\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/SQRE/Tips+and+Tricks+for+using+the+Stack</a></p>\n",
            "<p>rproc::TableMerger seems to be replaced with rproc::InfileMerger, so this class could certainly be removed easily. </p>\n",
            "\"<p>The lsstcorp.org/LegalNotices/</p>{LsstLicenseStatement.txt  LsstSourceCopyrightNotice.txt}<p> need to be updated to reference AURA/LSST. The referenced list of LSST partner institutions needs to be either resurrected or the reference deleted.</p><p>The git repository for devenv/templates needs the Copyright templates to be  updated.</p><p>LsstLicenseStatement.txt needs to be updated to include recent additions of 3rd party tools' Licenses (~10 tools)  to the DM stack  and all the QSERV 3rd party tools' Licenses (~25 tools).</p><p>The Copyright banner in all software needs to be updated to reflect the new reality of AURA/LSST in place of LSST Corporation.  Files with no Copyright banner, need to add it.</p><p>Update may occur 'the next time' the code file is updated. THis needs to be broadcast to the developers once the Copyright templates and the website versions are updated.</p>\"\n",
            "<p><a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1126\" class=\"external-link\" rel=\"nofollow\">HSC-1126</a> contains a number of unrelated bug fixes. Given the nature of that ticket, it\\'s not immediately clear which might already have been ported to LSST, which don\\'t apply, and, of the others, what dependencies they have on code which might still be in the queue for merger.</p><p>We need to dig through that ticket and ensure that everything is properly merged.</p>\n",
            "<p>We identified in <a href=\"https://jira.lsstcorp.org/browse/DM-5162\" title=\"Audit the LSST and HSC codebases for differences\" class=\"issue-link\" data-issue-key=\"DM-5162\"><del>DM-5162</del></a> several changesets that still need to be ported from HSC to LSST:</p><ul>\\t<li>daee24edba01b01a0412df7f9b4cf70be5b10860: CameraMapper: allow a default filter name to be provided</li>\\t<li>e3fee95d6a1850dd2309d3ebe4e3ef3ffe38eef0: CameraMapper: normalize path names, and remove leading double slash</li>\\t<li>476b6ddccd9d0cceb2b89ca34bee7d0fdcd70694: preserve timestamps in cameraMapper.backup()</li>\\t<li>b2491ef60e5e23afa7d9f0297f257e694aa1af35: Only attempt to update Wcs if it\\'s available</li>\\t<li>9f62bcce588fa9abc8e1e44ff2f0275e5230f629: Registry: hold registry cache for a single thread only (HSC-1035)</li>\\t<li>412f03b95b7a5e82003ab33a61bd43adbf465188: Registry: use a pool of registries to avoid having too many open files</li></ul>\n",
            "<p>Obtaining a quote from a company in Canada for a special clad cable for the Tololo-Pachon link</p>\n",
            "<p>Hold conversations with the two major fiber laying contractors to prepare the path from Tololo to Pachon with a trench</p>\n",
            "<p>The plots output by the qa analysis script (see <a href=\"https://jira.lsstcorp.org/browse/DM-4393\" title=\"Get analysis script working for HSC/LSST stack comparisons\" class=\"issue-link\" data-issue-key=\"DM-4393\"><del>DM-4393</del></a>) currently do not display any information regarding the selection/rejection criteria used in making the figures and computing the basic statistics.  This includes magnitude and clipping thresholds.  This information should be added to each plot such that the figures can be interpreted properly.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mfisherlevine\" class=\"user-hover\" rel=\"mfisherlevine\">Merlin Fisher-Levine</a> recently figured out how to set up his system to run a remote IPython kernel on <tt>lsst-dev</tt> and interact with it from his laptop, including streaming image display from the remote system to a local instance of <tt>ds9</tt>.</p><p>He will write all this up so that others in the community can easily do the same.</p>\n",
            "<p>Command-line argument parsing of data IDs for <tt>CmdLineTask</tt> s is currently defined at the class level, which means that we cannot make data ID definitions dependent on task configuration.  That in turn requires custom <tt>processCcd</tt> scripts for cameras that start processing at a level other than \"raw\" (SDSS, DECam with community pipeline ISR, possibly CFHT).</p><p>Instead, we should let <tt>CmdLineTask</tt> <b>instances</b> setup command-line parsing; after a <tt>CmdLineTask</tt> is constructed, it will have access to its final configuration tree, and can better choose how to parse its ID arguments.</p><p>I\\'ve assigned this to Process Middleware for now, since that\\'s where it lives in the codebase, but it may make more sense to give this to <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rowen\" class=\"user-hover\" rel=\"rowen\">Russell Owen</a>, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a>, or <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a>, just because we\\'ve already got enough familiarity with the code in question that we could do it quickly.  I\\'ll leave that up to <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=swinbank\" class=\"user-hover\" rel=\"swinbank\">John Swinbank</a>, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=krughoff\" class=\"user-hover\" rel=\"krughoff\">Simon Krughoff</a>, and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mgelman2\" class=\"user-hover\" rel=\"mgelman2\">Margaret Gelman</a> to decide.</p>\n",
            "nan\n",
            "nan\n",
            "<p>See summary</p>\n",
            "<p>See summary</p>\n",
            "\"<p>See Description (it's currently called PsfMatch)</p>\"\n",
            "<p>See Summary.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>The DMS and Astro Glossaries in Confluence define a set of technical terms used in their respective domains. Some of the definitions are placeholders, and other terms used in the SWUG, DM Space, and DM Developer Guide have yet to be defined in one glossary or the other. It is time to update these docs.</p>\n",
            "<p>Examine how python packages such as astropy structure and implement their sphinx docs.</p>\n",
            "<p>click and highlight a point.  Is on when mouse readout \"Lock by Click\" is on. However, can me turned on externally by adding toolbar context menu options.</p>\n",
            "<p>There is a growing list of known package dependencies in the sandbox-stackbuild repo and a need to use this information for independent environments (such as CI).  This list of packages should be lifted out into an independent puppet module that can be reused.</p>\n",
            "<p>Eliminate the image origin argument for butler get and put when dealing with image-like objects.</p>\n",
            "<p>It is confusing that photocal is in meas_astrom.  I assume that is historical.  I think it could probably live in pipe_tasks.</p>\n",
            "<p>Eliminate the ImageOrigin enum and argument from image-like classes.</p>\n",
            "<p>Currently the example of the IsrTask takes a fake dataref.  This is hard to use with real data.  In <a href=\"https://jira.lsstcorp.org/browse/DM-1113\" title=\"Make the API for ISR explicit\" class=\"issue-link\" data-issue-key=\"DM-1113\"><del>DM-1113</del></a> we will update IsrTask to not take a dataRef.  This will make it easy to update the example script to work with real data.</p><p>This ticket will also include removing from the unit tests any fake dataRefs that have become unnecessary as a result of <a href=\"https://jira.lsstcorp.org/browse/DM-1299\" title=\"Implement and test the new API\" class=\"issue-link\" data-issue-key=\"DM-1299\"><del>DM-1299</del></a>.</p>\n",
            "<p>Restore the names of methods that return pixel iterators and pixel locators on image-like classes. (This is part of the final stage of eliminating LOCAL pixel indexing).</p>\n",
            "<p>Image-like classes have a getBBox method and various constructors that use an ImageOrigin argument which in most or all cases defaults to LOCAL. As the first stage in cleaning this up, try to break code that uses the default as follows:</p><ul>\\t<li>Remove the default from getBBox(ImageOrigin) so an origin must be specified.</li>\\t<li>Change the default origin of constructors to a temporary new value UNDEFINED</li>\\t<li>Modify code that uses image origin to fail if origin is needed (it is ignored if bbox is empty) and is UNDEFINED.</li></ul><p>Note: this is less safe than changing constructors to not have a default value for origin, because the error will be caught at runtime rather than compile time. However, that is messy because then the bounding box will also have to be always specified, and possibly an HDU, so it would be a much more intrusive change.</p>\n",
            "\"<p>It's unclear exactly how much effort will be involved in making a change to how the XY0 is used.  If the parent/child argument is removed completely this change could be quite invasive and wide reaching.</p>\"\n",
            "<p>As part of making PARENT the default for image origin, change the data butler to require that imageOrigin be specified if bbox is specified when reading or writing image-like objects.</p><p>Note: this ticket turns out to be unnecessary, as all the few necessary change are done as part of <a href=\"https://jira.lsstcorp.org/browse/DM-840\" title=\"Change code so ImageOrigin must be specified (temporary)\" class=\"issue-link\" data-issue-key=\"DM-840\"><del>DM-840</del></a>.</p>\n",
            "<p>The version of anaconda distributed with the stack is too outdated to be used with pip (and probably other things). The issue is an unsafe version of ssh.</p><p>A workaround is to issue this command while anaconda is setup:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">conda update conda</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Warning: it is unwise to try to update anaconda itself (with \"conda update anaconda\") because that will revert some of the changes and may result in an unusable anaconda.</p><p>I think what is required is an obvious change to ups/eupspkg.cfg.sh</p><p>The current version of anaconda is 2.0.1 based on <a href=\"http://repo.continuum.io/archive/\" class=\"external-link\" rel=\"nofollow\">http://repo.continuum.io/archive/</a></p><p>Note: there is no component for anaconda. I will submit another ticket.</p>\n",
            "<p>Create a `validation_data_decam` to provide a few images for DECam validation tests.</p><p>Use the COSMOS field data as currently available on NCSA being processed by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=nidever\" class=\"user-hover\" rel=\"nidever\">David Nidever [X]</a>.</p><p>Select just a few images for now.</p>\n",
            "<p>1. Make sure <tt>ci_hsc</tt> is buildable by <tt>lsstsw</tt> / <tt>lsst_build</tt>  <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/><br/>2. Add <tt>ci_hsc</tt> to lsstsw/etc/repos.yaml so that one can request that Jenkins builds it.  <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/><br/>3. Verify that the test in <tt>ci_hsc</tt> fails on known broken tags and passes on known successful tags. <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></p><p>No dependencies will be added to <tt>lsst_sims</tt> or <tt>lsst_distib</tt>.<br/>This is meant to provide the ability to request that Jenkins do these builds and to fail if something has broken them.</p><p>This will later be expanded to new packages <tt>ci_cfht</tt>, <tt>ci_decam</tt>, and <tt>ci_sim</tt>.</p><p>The key goal is to make sure one hasn\\'t broken obs_ packages in their butler interface or in their processCcd</p><p>Additional Notes and Thoughts from HipChat Discussion<br/><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ktl\" class=\"user-hover\" rel=\"ktl\">Kian-Tat Lim</a><br/>Sounds good to me; we might have an \"lsst_ci\" top-level metapackage depending on all of them which is what Jenkins would run regularly.</p><p> If the goal is to test obs_ packages, then my first instinct would be to put that in the obs_ package.<br/>Longer term goal to test the stack with different precursor datasets.<br/>If this is testing obs_ packages on a slower cadence than the built-in tests, it\\'s OK for that to be a separate package.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a><br/>Eventually, I think we need to run a CI dataset for each camera, then run some camera generic tests on each of those, then run some camera-specific tests on each of those.\\xe2\\x80\\x82\\xe2\\x80\\x82So we don\\'t want to go too far down a road in which all tests are camera-specific, but maybe we don\\'t have a choice until we have some better unifying framework for them.<br/>I\\'ve certainly been putting some checks in <tt>ci_hsc</tt> that would be valid for all other cameras, if we had a CI package for them that went through to coadd processing.</p>\n",
            "<p>We need to periodically review the status of the third party software packages that Firefly depends on. Making a plan to do upgrade if needed. <br/>package.json lists out the dependencies Firefly has on the third party software. The attached file was last modified 2016-02-09.</p><p>package.json_version lists the current version of the third party packages, major changes were indicated by (M). The attached file was created on 2016-02-29. </p><blockquote><p></p></blockquote><p>    \"babel\"     : \"5.8.34\",                           6.5.2 (M)<br/>    \"history\"   : \"1.17.0\",                           2.0.0 (M)<br/>    \"icepick\"   : \"0.2.0\",                            1.1.0 (M)          <br/>    \"react-highcharts\": \"5.0.6\",                      7.0.0 (M)<br/>    \"react-redux\": \"3.1.2\",                           4.4.0 (M)<br/>    \"react-split-pane\": \"0.1.22\",                     2.0.1 (M)<br/>    \"redux-thunk\": \"0.1.0\",                           1.0.3 (M)<br/>    \"redux-logger\": \"1.0.9\",                          2.6.1 (M)<br/>    \"validator\" : \"4.5.0\",                            5.1.0 (M)<br/>    \"chai\": \"^2.3.0\",                                 3.5.0 (M)<br/>    \"esprima-fb\": \"^14001.1.0-dev-harmony-fb\",        15001.1001.0-dev-harmony-fb (M)<br/>    \"babel-eslint\"      : \"^4.1.3\",                   5.0.0 (M)<br/>    \"babel-loader\"      : \"^5.3.2\",                   6.2.4 (M)<br/>    \"babel-plugin-react-transform\": \"^1.1.0\",         2.0.0 (M)<br/>    \"babel-runtime\"     : \"^5.8.20\",                  6.6.0 (M)<br/>    \"eslint\"            : \"^1.10.3\",                  2.2.0 (M)<br/>    \"eslint-config-airbnb\": \"0.1.0\",                  6.0.2 (M) works with eslint 2.2.0<br/>    \"eslint-plugin-react\": \"^3.5.1\",                  4.1.0 (M)  works with eslint 2.2.0<br/>    \"extract-text-webpack-plugin\": \"^0.8.0\",          1.0.1 (M)<br/>    \"html-webpack-plugin\": \"^1.6.1\",                  2.9.0 (M)<br/>    \"karma-sinon-chai\": \"^0.3.0\",                     1.2.0 (M)<br/>    \"redux-devtools\"    : \"^2.1.2\",                   3.3.1 (M)<br/>    \"webpack\": \"^1.8.2\"                               1.12.14, 2.1.0 beta4 (M)</p>\n",
            "<p>Read through and run the `ci_hsc` tests and plan for how this module and efforts should relate to `validate_drp`.</p><p>a. Add capabilities to `validate_drp` to run the tests in `ci_hsc`.  <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/><br/>b. Compare frameworks. <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/><br/>c. Plan for how such validation and continuous integration data sets should be constructed. <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/check.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></p>\n",
            "<p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.py /lsst3/HSC/data/ --output /raid/price/test --id visit=904400 ccd=50</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[...]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.solver.loadAN: Loading reference objects using center (1023.5, 2091) pix = Fk5Coord(319.8934727, -0.0006943, 2000.00) sky and radius 0.111920792477 deg</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd FATAL: Failed on dataId={\\'taiObs\\': \\'2013-11-03\\', \\'pointing\\': 672, \\'visit\\': 904400, \\'dateObs\\': \\'2013-11-03\\', \\'filter\\': \\'HSC-Y\\', \\'field\\': \\'STRIPE82L\\', \\'ccd\\': 50, \\'expTime\\': 30.0}: Could not find flux field(s) y_camFlux, y_flux</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_base/10.1-4-g6ba0cc7+15/python/lsst/pipe/base/cmdLineTask.py\", line 320, in __call__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = task.run(dataRef, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_base/10.1-4-g6ba0cc7+15/python/lsst/pipe/base/timer.py\", line 118, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_tasks/10.1-28-gf9582e4+2/python/lsst/pipe/tasks/processCcd.py\", line 85, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = self.process(sensorRef, postIsrExposure)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_base/10.1-4-g6ba0cc7+15/python/lsst/pipe/base/timer.py\", line 118, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_tasks/10.1-28-gf9582e4+2/python/lsst/pipe/tasks/processImage.py\", line 160, in process</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    calib = self.calibrate.run(inputExposure, idFactory=idFactory)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_base/10.1-4-g6ba0cc7+15/python/lsst/pipe/base/timer.py\", line 118, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_tasks/10.1-28-gf9582e4+2/python/lsst/pipe/tasks/calibrate.py\", line 457, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    astromRet = self.astrometry.run(exposure, sources1)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_base/10.1-4-g6ba0cc7+15/python/lsst/pipe/base/timer.py\", line 118, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/meas_astrom/10.1-19-g6e01b25+5/python/lsst/meas/astrom/anetAstrometry.py\", line 177, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    results = self.astrometry(sourceCat=sourceCat, exposure=exposure, bbox=bbox)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_base/10.1-4-g6ba0cc7+15/python/lsst/pipe/base/timer.py\", line 118, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/meas_astrom/10.1-19-g6e01b25+5/python/lsst/meas/astrom/anetAstrometry.py\", line 292, in astrometry</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    astrom = self.solver.determineWcs(sourceCat=sourceCat, exposure=exposure, bbox=bbox)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/meas_astrom/10.1-19-g6e01b25+5/python/lsst/meas/astrom/anetBasicAstrometry.py\", line 409, in determineWcs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return self.determineWcs2(sourceCat=sourceCat, **margs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/meas_astrom/10.1-19-g6e01b25+5/python/lsst/meas/astrom/anetBasicAstrometry.py\", line 437, in determineWcs2</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    astrom = self.useKnownWcs(sourceCat, wcs=wcs, **kw)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/meas_astrom/10.1-19-g6e01b25+5/python/lsst/meas/astrom/anetBasicAstrometry.py\", line 308, in useKnownWcs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    calib = None,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_base/10.1-4-g6ba0cc7+15/python/lsst/pipe/base/timer.py\", line 118, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/meas_algorithms/10.1-15-g0d3ecf6/python/lsst/meas/algorithms/loadReferenceObjects.py\", line 173, in loadPixelBox</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    loadRes = self.loadSkyCircle(ctrCoord, maxRadius, filterName)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/pipe_base/10.1-4-g6ba0cc7+15/python/lsst/pipe/base/timer.py\", line 118, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/meas_astrom/10.1-19-g6e01b25+5/python/lsst/meas/astrom/loadAstrometryNetObjects.py\", line 141, in loadSkyCircle</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    fluxField = getRefFluxField(schema=refCat.schema, filterName=filterName)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/lsstsw/stack/Linux64/meas_algorithms/10.1-15-g0d3ecf6/python/lsst/meas/algorithms/loadReferenceObjects.py\", line 40, in getRefFluxField</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    raise RuntimeError(\"Could not find flux field(s) %s\" % (\", \".join(fluxFieldList)))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">RuntimeError: Could not find flux field(s) y_camFlux, y_flux</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>We should be able to fix this by setting config parameters (e.g., <tt>calibrate.astrometry.solver.defaultFilter</tt> or <tt>calibrate.astrometry.solver.filterMap</tt>), but how do we keep that synched with the choice of reference catalog?  And once we get past astrometry, we also have the same problem in photocal.</p>\n",
            "<p>LSE-69 declares that there are two categories of Conditions data (telemetry) required by DM from the Camera: those items that are needed for Alert Production (for which the AP components at the Base will need a whitelist, and for which the Camera has a tighter latency requirement), and those that are not (but are then presumably needed in DRP or other deferred productions).  It states that the subset needed for AP should be enumerated in LSE-130.</p><p>The action here is to create an initial version of that list.</p>\n",
            "<p>These parameters may be useless (see <a href=\"https://jira.lsstcorp.org/browse/DM-4395\" title=\"Update cmsd configuration for multi-node tests\" class=\"issue-link\" data-issue-key=\"DM-4395\"><del>DM-4395</del></a>). If yes they can be removed to simplify configuration procedure.</p>\n",
            "<p>Generate JSON output from validate_drp for inclusion in a test harness.</p><p>Generate a file that summarizes the key metrics calculated by `validate_drp`.  </p><p>Develop naming conventions that will make it easy to plug into the eventual harness being developed as part of <a href=\"https://jira.lsstcorp.org/browse/DM-2050\" title=\" Integration and test monitoring architecture Part I\" class=\"issue-link\" data-issue-key=\"DM-2050\"><del>DM-2050</del></a>.</p>\n",
            "<p>if ci_hsc fails for any reason, (or is cancelled) it must start from the beginning of processing again. This is because of the use of functools.partial to generate dynamic function. These differ enough in their byte code that scons thinks each build has a new function definition passed to the env.command function. Using lambda would suffer from the same problem. This ticket should change how the function signature is calculated such that scons can be resumed.</p><p>This work does not prevent this from being used as a ci tool, as the .scons directory can be deleted which will force the whole SConstruct file to run again.</p>\n",
            "<p><tt>MeasureMergedCoaddSourcesTask.setIsPrimaryFlag()</tt> and <tt>ProcessCoaddTask.setIsPrimaryFlag()</tt> are effectively the same code. Please split this out into a separate task which both of the above can call.</p><p>This is a (partial) port of <a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1112\" class=\"external-link\" rel=\"nofollow\">HSC-1112</a> and should include fixes from <a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1297\" class=\"external-link\" rel=\"nofollow\">HSC-1297</a>.</p>\n",
            "<p>Since <a href=\"https://jira.lsstcorp.org/browse/DM-4235\" title=\"HSC backport: countInputs and per object variance functions\" class=\"issue-link\" data-issue-key=\"DM-4235\"><del>DM-4235</del></a> was merged, we see a bunch of messages along the lines of:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.measurement WARNING: Error in base_Variance.measure on record 427969358631797076: The center is outside the Footprint of the source record</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>in the output from <tt>lsst_dm_stack_demo</tt>. (See e.g. <a href=\"https://ci.lsst.codes/job/stack-os-matrix/label=centos-6/7482/console#console-section-3\" class=\"external-link\" rel=\"nofollow\">here</a>). It\\'s not fatal, but the warnings are disconcerting and could be indicative of a deeper problem.</p>\n",
            "<p>The <tt>meas_base</tt> framework includes <tt>SafeCentroidExtractor</tt>, a convenience routine for extracting a centroid from a source record, setting a consistent set of flags if that\\'s not possible or if the centroid is in some way compromised. This consistent flag handling is made possible by the use of the <tt>FlagHandler</tt> class.</p><p>Unfortunately, <tt>FlagHandler</tt> is not meaningfully usable from Python, not least because it\\'s impossible to define flags:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;&gt;&gt; </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> lsst.meas.base as measBase</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;&gt;&gt; measBase.FlagDefinition(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"flag\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"doc\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[...]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">TypeError: __init__() takes exactly </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> argument (</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">3</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> given)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;&gt;&gt; fd </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> measBase.FlagDefinition()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;&gt;&gt; fd.name </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"flag\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[...]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">AttributeError: You cannot add attributes to &lt;lsst.meas.base.baseLib.FlagDefinition; proxy of &lt;Swig </span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Object</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> of </span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">type</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'lsst::meas::base::FlagDefinition *\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> at </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x10a82b900</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt; &gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Looking further, even were we able to create <tt>FlagDefinitions</tt>, the <tt>FlagHandler</tt> is initialized with pointers to the beginning/end of a container of them, which seems like a stretch for Python code.</p><p>Please add Python support for these routines.</p>\n",
            "<p>When download an image,  the proper name needs to be resolved based on the URL and <br/>the information about the image.  In Java code, it has the following three methods:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> encodeUrl</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeFileName</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeTitleFileName</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>These method should be ported to javascript.  Thus, the javascript version of the FitsDownloadDialog will save the file in the same manner. </p>\n",
            "<p>This is just a report of the amount of time it takes to run ShapeletPsfApprox and CModel over 10000 galaxies from GalSim</p>\n",
            "<p>Attend the weekly meeting and answer questions as needed</p>\n",
            "<p>Enhance docs by covering</p><ul class=\"alternate\" type=\"square\">\\t<li>Images as links</li>\\t<li>Table spans</li>\\t<li>Abbreviations</li>\\t<li>:file: semantics, etc.</li></ul>\n",
            "<p>Search through the stack for all the uses of our Wcs implementation (Wcs, TanWcs, makeWcs, and any other hidden objects) and make a list of all of those uses (on Community for example). This list should note whether the usage is in C++ or python.</p>\n",
            "<p>Identify required resources for Verification runs and communicate them to NCSA. </p>\n",
            "<p>Add the dropdown to the vis tool bar</p>\n",
            "<p>See <a href=\"https://mariadb.atlassian.net/browse/MDEV-9389\" class=\"external-link\" rel=\"nofollow\">https://mariadb.atlassian.net/browse/MDEV-9389</a></p>\n",
            "nan\n",
            "nan\n",
            "<p>In Histogram, when the data points fall on the bin edges,  the following rules are used:</p><ol>\\t<li>For each bin, it contains the data points fall inside the bin and the data point fall on the left edge.  For example, if binSize=2, the bin<span class=\"error\">&#91;0&#93;</span> is in the range of <span class=\"error\">&#91;0,2&#93;</span>.  The data value 0 is in bin<span class=\"error\">&#91;0&#93;</span> .</li>\\t<li>For each bin, the data point falls on the right edge is not included in the number point count. For example if binSize=2, the bin<span class=\"error\">&#91;0&#93;</span> is having the range of <span class=\"error\">&#91;0,2&#93;</span>.  The data value 0 is in bin<span class=\"error\">&#91;0&#93;</span> but the data value 2 is not in the bin<span class=\"error\">&#91;0&#93;</span>.</li>\\t<li>For the last bin, the data points fall inside the bin or fall on the left or right bin are counted as the number of bin points.</li></ol><p>The last rule is newly introduced.  </p>\n",
            "<p>During the processing of the COSMOS data for the verification dataset work I ran many jobs of processCcdDecam.py on the new linux server, bambam.  The performance was very slow, 4x longer than running a single job at a time.  Figure out what is going on.</p>\n",
            "<p>Currently czar caches empty chunk list after it reads the list from file. This complicates things when we need to update the list, integration test for example has to restart czar process after it loads new data to make sure that czar updates its cached list. Would be nice to have simpler mechanism to resetting cached list in czar without restarting it completely. It could be done via special query (abusing FLUSH for example) or via sending signal (problematic if czar runs remotely).</p><p>This can be potentially useful even after we replace empty chunk list file with some other mechanism as I expect that cache will stay around even for that.</p>\n",
            "<p>Async command execution causes unpredictable and unreliable results.  Switches to synchronous where possible.  Also add additional description to the release notes.</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Create a sample search processor, which returns images in a given directory.</li>\\t<li>It should be using an external python task</li>\\t<li>Update search form configuration to use this search processor to return image metadata</li></ul>\n",
            "<p>When reloading the same 500MB RAFT image into an image viewer (see the script below), it was discovered that single node Firefy server with 3G memory runs out of memory after ~15 reloads</p><p>Test case: keep reloading the html file with the following Javascript, creating an image viewer with 500MB image:</p><p>function onFireflyLoaded() {<br/>        var iv2= firefly.makeImageViewer(\"plot\");<br/>        iv2.plot(</p>{             \"Title\"      :\"Example FITS Image\\'\",             \"ColorTable\" :\"16\",             \"RangeValues\":firefly.serializeRangeValues(\"Sigma\",-2,8,\"Linear\"),             \"URL\"        :\"http://localhost/demo/E000_RAFT_R01.fits\"}<p>);<br/>}</p><p>Follow up:</p><p>The bug was traced to java.awt.image.BufferedImage objects not being evicted from VIS_SHARED_MEM cache.</p><p>Further search showed that java.awt.image.BufferedImage (along with java.io.BufferedInputStream) is in src/firefly/java/edu/caltech/ipac/firefly/server/cache/resources/ignore_sizeof.txt, which lists the classes that have to be ignored when calculating the size of cache.</p><p>Testing on single node server (VIS_SHARED_MEM cache is not replicated), using <span class=\"error\">&#91;host:port&#93;</span>/fftools/admin/status page:</p><p>BEFORE (java.awt.image.BufferedImage was commented out in ignore_sizeof.txt)</p><p>After 14 reloads:<br/>Memory</p><ul class=\"alternate\" type=\"square\">\\t<li>Used                      :      3.7G</li>\\t<li>Max                       :     3.55G</li>\\t<li>Max Free                  :    488.0M</li>\\t<li>Free Active               :    488.0M</li>\\t<li>Total Active              :     3.55G<br/>   Caches: <br/>\\tVIS_SHARED_MEM @327294449<br/>\\tStatistics     : [  Size:15  Expired:0  Evicted:0  Hits:246  Hit-Ratio:NaN  Heap-Size:1120MB  ]<br/>OUT OF MEMORY on next reload</li></ul><p>AFTER THE CHANGE (Commented java.awt.image.BufferedImage in ignore_sizeof.txt)</p><p>After 36 reloads:<br/>Memory</p><ul class=\"alternate\" type=\"square\">\\t<li>Used                      :   1672.9M</li>\\t<li>Max                       :     3.55G</li>\\t<li>Max Free                  :   1968.0M</li>\\t<li>Free Active               :   1468.0M</li>\\t<li>Total Active              :      3.6G<br/>  Caches: <br/>\\tVIS_SHARED_MEM @201164543<br/>\\tStatistics     : [  Size:3  Expired:0  Evicted:34  Hits:659  Hit-Ratio:NaN  Heap-Size:1398MB  ]</li></ul>\n",
            "<p>The LSST buildbot infrastructure recently changed to building everything with --std=c++0x, which broke the partition package, and hence automated Qserv builds. While debugging this, I discovered that the partition package does not build on OSX 10.9, and considering how minimal its dependencies are, it really should. The OSX issue can be fixed by avoiding <tt>using boost::make_shared</tt>.</p><p>The partition package should be cleaned up to avoid all use of <tt>using</tt>. If we decide to use C++11 in Qserv, then the codebase should also be modernized (in particular, there are use-cases for static_assert, nullptr, etc... ).</p>\n",
            "nan\n",
            "<p>Attend UIUC weekly meeting and give support as needed. </p>\n",
            "nan\n",
            "<p>DM boot camp tutorial.</p>\n",
            "<p>Create a template repository for LSST (DM/SQuaRE) technical reports that are written in reStructuredText, built with Sphinx and published with RTD</p>\n",
            "<p>Attend DM boot camp to learn more about DM stack, butler, and task. </p>\n",
            "<p>Attend UIUC weekly meeting and give support as needed. </p>\n",
            "<p>Attend UIUC weekly meeting and give support as needed. </p>\n",
            "<p>Convert LDM-129 from Word to restructuredText and deploy onto readthedocs.org</p>\n",
            "<p>Remove es6-promise, react-modal, other cleanup</p>\n",
            "\"<p>lodash has become a superset of underscore, providing more consistent API behavior, more features, and more thorough documentation. We'd like to convert our underscore package dependencies to lodash while we have only ~20 calls to underscore functions</p>\"\n",
            "\"<p>Prototype is now getting to the point where a wire-protocol package like capnproto or protobuf is needed.  capnproto is the new hotness, and we're probably going to want to migrate qserv from protobuf-&gt;capnproto at some point.</p><p>This task is to go ahead and get capnproto packaged and published for use in the replication prototype.</p>\"\n",
            "<p>Modify CSS structures to support DROP TABLE, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-1896\" title=\"Design CSS schema to support table deletion\" class=\"issue-link\" data-issue-key=\"DM-1896\"><del>DM-1896</del></a>.</p>\n",
            "<p>This is a port of the standalone changesets:<br/><a href=\"https://github.com/HyperSuprime-Cam/pipe_tasks/commit/e9db5c0dcdca20e8f7ba71f24f8b797e71699352\" class=\"external-link\" rel=\"nofollow\">calibrate: make astrometry failures non-fatal</a><br/><a href=\"https://github.com/HyperSuprime-Cam/pipe_tasks/commit/c2d89396923f9d589822c043ed8753647e70f3f6\" class=\"external-link\" rel=\"nofollow\">fixup! calibrate: make astrometry failures non-fatal</a><br/>(the above is a fixup, so will likely be squashed)<br/><a href=\"https://github.com/HyperSuprime-Cam/pipe_tasks/commit/cf5724b852937cfcef1b71b7a372552011fda670\" class=\"external-link\" rel=\"nofollow\">make failure to match sources non-fatal</a><br/><a href=\"https://github.com/HyperSuprime-Cam/pipe_tasks/commit/ab6cb9e206d0456dc764c5ef78ac80ece937c610\" class=\"external-link\" rel=\"nofollow\">calibrate: restore original Wcs after initial astrometry solution</a><br/><a href=\"https://github.com/HyperSuprime-Cam/pipe_tasks/commit/08a8ec029dd52ac55e47b707a6905df061a40506\" class=\"external-link\" rel=\"nofollow\">move CalibrateTask from ProcessImageTask into ProcessCcdTask</a><br/><a href=\"https://github.com/HyperSuprime-Cam/pipe_tasks/commit/9e8563fd8d630dad967786387b1f27b6bc7ee039\" class=\"external-link\" rel=\"nofollow\">processCoadd: set detection to use the declared variances</a><br/><a href=\"https://github.com/HyperSuprime-Cam/obs_subaru/commit/52733a7ab1731a15cbb93151851f57cec276f928\" class=\"external-link\" rel=\"nofollow\">adapt to removal of CalibrateTask from ProcessImageTask in pipe_tasks</a><br/>and HSC tickets:<br/><a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1085\" class=\"external-link\" rel=\"nofollow\">HSC-1085: background not saved in processCcd</a> and<br/><a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1086\" class=\"external-link\" rel=\"nofollow\">HSC-1086: psf - catalog scatter is very large in some coadds</a></p>\n",
            "<p>To switch from QservAdmin to CssAccess interface in our Python tools we will need to replace zookeeper with mysql implementation because we do not have C++ KvInterface implementation for zookeeper.</p>\n",
            "<p>I\\'m seeing test segfaults in ip_diffim on gcc 4.8, similar to those resolved on <a href=\"https://jira.lsstcorp.org/browse/DM-1725\" title=\"stack build fails on gcc 4.8 with opt=3\" class=\"issue-link\" data-issue-key=\"DM-1725\"><del>DM-1725</del></a>, but with no similar smoking gun yet.  Preliminary indication is that the problem is actually in meas_algorithms.</p>\n",
            "<p>Expose image XY readout at cursor point function in JavaScript API</p>\n",
            "<p>Collect the information for the tables populated for Bremerton end-to-end exercise. Use them in SUI/T so we can access them using the DAX API. </p>\n",
            "\"<p>Should produce the numeric values required (or an explanation of why they aren't available) together with a description of the process for generating them (incl. the data processed, scripts used for plotting, etc).</p>\"\n",
            "\"<p>Solve fit-and-finish issues with the stock readthedocs.org Sphinx template when rendering DM design documents. Issues include:</p><ul>\\t<li>Sections need to be numbered and those numbers need to appear in TOC</li>\\t<li>RTD's TOC does not properly collapse sub-topics</li>\\t<li>Appropriate styling for document title and author list</li>\\t<li>Wrapping the changelog table</li>\\t<li>Adapt section references so that just the section number can be referenced, independently of the section number and title in combination</li>\\t<li>Section labels given explicitly in the reST markup are different from the anchors that Sphinx gives to the {{&lt;hN&gt;}}tags; the former are simply divs inserted in the HTML.</li></ul><p>The solutions may involve</p><ol>\\t<li>reconfiguring the Sphinx installation of individual documents</li>\\t<li>forking the RTD HTML template, and/or</li>\\t<li>developing extensions for Sphinx in <tt>sphinxkit</tt>.</li></ol>\"\n",
            "\"<p>This issue will add limited N-way spatial matching of multiple catalogs with identical schemas, sufficient for measuring FY15 KPMs.  It will be a simple wrapper on our existing 2-way matching code in afw, and will not be intended for long term use (as it won't be an efficient algorithm or an ideal interrface).</p>\"\n",
            "<p>The scons build system is unaware of extra flags which may be set in SCONSFLAGS environment variable, which are used from scons utils. This will cause the build to fail. The package needs to behave properly and build in the presence of these flags</p>\n",
            "<p>Support of xrootd within the stack is currently complicated by the fact that qserv depends on features that are not available on upstream master (only available on an upstream non-master branch).  Since we can currently only publish packages from master, this means that our lsst fork of xrootd cannot be a \"pure\" fork &#8211; we end up merging/rebasing from an upstream branch, then force-pushing the downstream master.  Upstream and downstream xrootd repos thus have completely different branch topologies, labels, etc., and history of master in the lsst fork is being continually rewritten to carry local patches forward.  The processes of both adopting upstream changes into the lsst fork and the pushing lsst changes back upstream are cumbersome, confusing, and labor intensive.</p><p>It is proposed that we extend our tools to allow publishing components from branches other than master.  This would allow us to have xrootd for example be a \"pure\" fork of upstream &#8211; we could then create our own branch based off any upstream branch, carry our downstream patches there, and release off of that.</p><p>This functionality could be used similarly for any of our current \"t&amp;p\" components where it would be convenient to track the upstream repo directly and/or carry changes in git instead of in an agglomerated patch file (e.g. when we might want to update frequently and/or contribute general purpose changes back upstream regularly with pr\\'s, etc.)</p>\n",
            "<p>In 10.0, processCcdDecam.py could process decam images to completion (whether the WCS was read correctly is a different question). Now it fails on makeWcs() (see traceback below), and I suspect this change in behavior is related to <a href=\"https://jira.lsstcorp.org/browse/DM-2883\" title=\"wcslib is unable to read PTF headers with PV1_{1..16} cards\" class=\"issue-link\" data-issue-key=\"DM-2883\"><del>DM-2883</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-2967\" title=\"Fix to DM-2883 isn&#39;t quite right\" class=\"issue-link\" data-issue-key=\"DM-2967\"><del>DM-2967</del></a>.</p><p>Repository with both data and code to reproduce:<br/><a href=\"http://www.astro.washington.edu/users/yusra/reproduce/reproduceMakeWcsErr.tar.gz\" class=\"external-link\" rel=\"nofollow\">http://www.astro.washington.edu/users/yusra/reproduce/reproduceMakeWcsErr.tar.gz</a><br/>(apologies for the size)</p><p>The attachment is a document describing the WCS representation in the images from the community pipeline, courtesy of Francisco Forster.</p><p>Please advise. This ticket captures any changes made to afw. </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">D-108-179-166-118:decam yusra$ processCcdDecam.py newTestRepo/ --id visit=0232847 ccdnum=10 --config calibrate.doPhotoCal=False calibrate.doAstrometry=False calibrate.measurePsf.starSelector.name=\"secondMoment\" doWriteCalibrateMatches=False --clobber-config</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: Loading config overrride file \\'/Users/yusra/lsst_devel/LSST/repos/obs_decam_ya/config/processCcdDecam.py\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: Config override file does not exist: \\'/Users/yusra/lsst_devel/LSST/repos/obs_decam_ya/config/decam/processCcdDecam.py\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: input=/Users/yusra/decam/newTestRepo</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: calib=None</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: output=None</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CameraMapper: Loading registry registry from /Users/yusra/decam/newTestRepo/registry.sqlite3</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcdDecam: Processing {\\'visit\\': 232847, \\'ccdnum\\': 10}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">makeWcs WARNING: Stripping PVi_j keys from projection RA---TPV/DEC--TPV</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcdDecam FATAL: Failed on dataId={\\'visit\\': 232847, \\'ccdnum\\': 10}: </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"src/image/Wcs.cc\", line 130, in void lsst::afw::image::Wcs::_initWcs()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    Failed to setup wcs structure with wcsset. Status 5: Invalid parameter value {0}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">lsst::pex::exceptions::RuntimeError: \\'Failed to setup wcs structure with wcsset. Status 5: Invalid parameter value\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/yusra/lsst_devel/LSST/DMS5/DarwinX86/pipe_base/10.1-3-g18c2ba7+49/python/lsst/pipe/base/cmdLineTask.py\", line 320, in __call__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = task.run(dataRef, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/yusra/lsst_devel/LSST/DMS5/DarwinX86/pipe_base/10.1-3-g18c2ba7+49/python/lsst/pipe/base/timer.py\", line 118, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/yusra/lsst_devel/LSST/repos/obs_decam_ya/python/lsst/obs/decam/processCcdDecam.py\", line 77, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    mi = exp.getMaskedImage()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/yusra/lsst_devel/LSST/DMS5/DarwinX86/daf_persistence/10.1-1-g6edbc00+28/python/lsst/daf/persistence/readProxy.py\", line 41, in __getattribute__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    subject = oga(self, \\'__subject__\\')</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/yusra/lsst_devel/LSST/DMS5/DarwinX86/daf_persistence/10.1-1-g6edbc00+28/python/lsst/daf/persistence/readProxy.py\", line 136, in __subject__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    set_cache(self, get_callback(self)())</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/yusra/lsst_devel/LSST/DMS5/DarwinX86/daf_persistence/10.1-1-g6edbc00+28/python/lsst/daf/persistence/butler.py\", line 242, in &lt;lambda&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    innerCallback(), dataId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/yusra/lsst_devel/LSST/DMS5/DarwinX86/daf_persistence/10.1-1-g6edbc00+28/python/lsst/daf/persistence/butler.py\", line 236, in &lt;lambda&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    location, dataId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/yusra/lsst_devel/LSST/repos/obs_decam_ya/python/lsst/obs/decam/decamMapper.py\", line 118, in bypass_instcal</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    wcs         = afwImage.makeWcs(md)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/Users/yusra/lsst_devel/LSST/DMS5/DarwinX86/afw/10.1-26-g9124caf+1/python/lsst/afw/image/imageLib.py\", line 8706, in makeWcs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return _imageLib.makeWcs(*args)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">RuntimeError: </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"src/image/Wcs.cc\", line 130, in void lsst::afw::image::Wcs::_initWcs()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    Failed to setup wcs structure with wcsset. Status 5: Invalid parameter value {0}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">lsst::pex::exceptions::RuntimeError: \\'Failed to setup wcs structure with wcsset. Status 5: Invalid parameter value\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "nan\n",
            "nan\n",
            "<p>The current runner scripts are in tcsh and bash.  There is no good excuse for this, except that it was easy to implement.  Since we need both multi-threading and better parameter parsing, this will be replaced with a python script.</p>\n",
            "<p>ingestImages.py provides a camera-agnostic manner of creating a data repository (including a registry).  The HSC fork contains multiple improvements not present on the LSST side.  We need these in order to ingest the HSC data.</p>\n",
            "<p>HSC data becomes public 18 months after it was taken, so data taken during commissioning are now available.  We would like to use this data for testing the LSST pipeline.  It needs to be downloaded from Japan.</p>\n",
            "nan\n",
            "<p>Following CCB recommendation of approval of LSE-130 draft, convert Word draft to SysML and provide a docgen to Robert McKercher for final posting.</p>\n",
            "<p>Create a change request for LSE-75, the TCS - to - DM ICD.</p>\n",
            "<p>Work associated with Workshop IV in the series, held at NCSA July 8-10, 2015.</p>\n",
            "<p>Prepare for and attend a half-day teleconference on OCS issues.</p>\n",
            "<p>Carry out the CCB review, respond to questions, support final implementation of updated document.</p>\n",
            "<p>IRSA needs to be able to read in the FITS cube generated by Herschel project. We need to support and guide the effort so the code is generic enough for non-Herschel data. </p>\n",
            "<p>In early this year, the decision all data types would be converted to float in FitsRead.  Thus,the bitpixel is not relevant.  In Zscale, it still uses bitpixel to test the data type.  It should be refactored in the same manner as FitsRead etc. </p>\n",
            "nan\n",
            "<p>A meeting in Santiago  with Reuna and Telefonica to discuss the difference in price for the new path from Tololo to Pachon</p>\n",
            "<p>Changes in the way  jfryman/nginx 0.2.7 handles tls cert files since 0.2.6 have run awful of selinux permissions issues.</p>\n",
            "<p>Getting comments, testing, hipchat/JIRA changes</p>\n",
            "nan\n",
            "<p>Add features to make it easier to debug communication problems. Particularly, record the source of a message, and remove extraneous messages.</p>\n",
            "<p>This is a port of <a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1005\" class=\"external-link\" rel=\"nofollow\">HSC-1005</a>.</p>\n",
            "<p>We should set the default measurement task in ProcessImageTask to SingleFrameMeasurementTask, and note that SourceMeasurementTask and the old forced photometry drivers are deprecated.</p>\n",
            "<p>Following discussion on qserv-l, we only need to generate \"secondary\" index for director table, no other table is supposed to have it. Need to modify data loader to recognize which table is director table and generate index only for that table.</p>\n",
            "<p>When I wrote the initial version of display_firefly I found a few minor issues in the way I\\'d designed the Display class; at the same time, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=lauren\" class=\"user-hover\" rel=\"lauren\">Lauren MacArthur</a> found some missing functions in the backward-compatibility support for ds9.</p><p>Please fix these;  note that this implies changes to afw, display_ds9, and display_firefly.</p>\n",
            "<p>Request a full focal plane of Psf images. Write code to allow them to be stored in a way which allows us to sample randomly from a full focal plane.  There will be multiple such focal planes, so we also need to be able to pass the information to the measurement algorithm which will allow us to categorize measurements by visit.  This will be done in the Psf Library building code, and will then be passes to the measurement algorithm through the great3sims code which constructs the data for the measurement algorithm.</p>\n",
            "nan\n",
            "nan\n",
            "<p>XY plot was relying on a table request object to cache previously loaded tables.  This was done for performance reason.  However, table request is not reliable since the same request may be submitted multiple times.</p>\n",
            "<p>IpacTableParser fail to load IPAC table with extra wide headers and columns.<br/>Replace the logic for reading headers and columns information so that it will support any file/size.</p>\n",
            "<p>Integrate javascript build tools webpack with gradle.</p>\n",
            "<p>This is an additional script for great3sims to allow simple configuration of the great3sims.run().  Most of the parameters which need to be set are in great3sims.constants.py, though some additional command line parameters may be needed for the run method.</p>\n",
            "<p>Currently integration tests use root account as default user - this should be changed to qsmaster for the future.</p>\n",
            "<p>The Foreman implementation passes a TaskQueue pointer corresponding to running tasks down to the task scheduler without holding a lock. This means that the scheduler can inspect the running task list (usually to determine its size) while it is being mutated.</p>\n",
            "<p>_integrityHelper() from wsched/BlendScheduler inspects a map of tasks and is sometimes called without holding the corresponding mutex. My theory is that it is observing the map in an inconsistent state, leading to assert failure and hence worker death, and finally to hangs/timeouts on the czar.</p>\n",
            "<p>Firefly Tools API: Add advance region support<br/>Improve firefly\\'s region functionality to support a \"dynamic region\".  Data can be added or removed from this region by API calls.  Allow any amount of region lines to be added or removed.  Make sure performance is good.<br/>Also, document the current Firefly region support.</p>\n",
            "<p>The meas_astrom AstrometryTask returns a match list that has distance = 0 for all elements. Neither the matcher nor the WCS fitter are setting this field, and both ought to.</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>create accounts</li>\\t<li>update umask on stack  to each account</li>\\t<li>provide easy ssh config if possible</li>\\t<li>setup up build procedure (each developer can build Qserv using tag git and \\'git\\' version is set up by default on all the Qserv if ti exists)</li></ul>\n",
            "<p>Vaikunth had some \"expected\" troubles playing with data loader options for his <a href=\"https://jira.lsstcorp.org/browse/DM-1570\" title=\"Create integration test case using data duplicator\" class=\"issue-link\" data-issue-key=\"DM-1570\"><del>DM-1570</del></a> ticket. Main issue I believe is the absence of the documented use cases and their corresponding data loader options. I\\'ll try to add a bunch of common use cases to RST documentation and also verify that all options behave as expected.</p>\n",
            "<p>The GREAT3 simulations have a fixed postage stamp size (though this may differ between branches).  A first step at modifying the simulation scripts to meet our needs would be to try to change the postage stamp.</p><p>This is one of several issues that together will replace <a href=\"https://jira.lsstcorp.org/browse/DM-1132\" title=\"create galaxy simulations for shapelet approximation and truncation tests\" class=\"issue-link\" data-issue-key=\"DM-1132\"><del>DM-1132</del></a> (which was just a planning stand-in for these more detailed issues).</p>\n",
            "<p>The following tests in meas_algorithms need to be ported to the meas_base framework:</p><p>measure.py<br/>psfSelectTest.py<br/>testPsfDetermination.py<br/>ticket2019.py<br/>testCorrectFluxes.py (though this cannot be done until the algorithm exists)</p>\n",
            "nan\n",
            "\"<p>We should be able to use multiple-aperture flux results in slots.  While this is technically possible already by setting specific aliases, it doesn't work through the usual mechanisms for setting up slots (the define methods in SourceTable and the SourceSlotConfig in meas_base).</p><p>After addressing this, we should remove the old SincFlux and NaiveFlux algorithms, as the new CircularApertureFlux algorithm will be able to do everything they can do.</p>\"\n",
            "<p>The classification algorithm claims it can never fail.  It can, and should report this.</p>\n",
            "<p>Many meas_base Plugins and Algorithms have poor documentation, including several whose documentation is a copy/paste relic from some other algorithm.  These need to be fixed.</p>\n",
            "\"<p>We need to be able to return values at the same time that an error<br/>flag is set.</p><p>The easiest way to do this is to have Algorithms take a Result object<br/>as an output argument rather than return it.  We'll revisit this design<br/>later.</p>\"\n",
            "<p>Now that all tasks that use catalogs explicitly set the table version, it should be relatively straightforward to set the default version to 1 in afw.  Code that cannot handle version &gt; 0 tables should continue to explicitly set version=0.</p>\n",
            "<p>The addition of schema aliases on <a href=\"https://jira.lsstcorp.org/browse/DM-417\" title=\"finish adding aliases to afw::table::Schema\" class=\"issue-link\" data-issue-key=\"DM-417\"><del>DM-417</del></a> should allow us to clean up some of the transitional code added on <a href=\"https://jira.lsstcorp.org/browse/DM-545\" title=\"ensure pipe_tasks, obs*, and other packages are compatible with meas_base\" class=\"issue-link\" data-issue-key=\"DM-545\"><del>DM-545</del></a>, as we can now alias new versions of fields to the old ones and vice versa.</p>\n",
            "<p>While trying to track down some bugs on <a href=\"https://jira.lsstcorp.org/browse/DM-641\" title=\"Port shapelet PSF fitting code to LSST\" class=\"issue-link\" data-issue-key=\"DM-641\"><del>DM-641</del></a>, I\\'ve grown frustrated with the difficulty of testing the deeply-buried (i.e. interfaces I want to test are private) shapelet evaluation code there.  That sort of code really belongs in the shapelet package (not meas_multifit) anyway, where I have a lot of similar code, so on this issue I\\'m going to move it there and refactor the existing code so it all fits together better.</p>\n",
            "\"<p>We should follow RHL's example for detailed task documentation and document all meas_base tasks.</p>\"\n",
            "\"<p>The meas_base version of SdssShape produces slightly different outputs from the original version in meas_algorithms, but these should be identical.  We should understand this difference rather than assume its benign just because it's small.</p>\"\n",
            "<p>All done bar obtaining some release notes. </p>\n",
            "<p>Attend database talks, in particular the MaxScale proxy talk (<a href=\"http://www.socallinuxexpo.org/scale/13x/presentations/advanced-query-routing-and-proxying-maxscale?utm_campaign=north-american-trade-shows&amp;utm_source=hs_email&amp;utm_medium=email&amp;utm_content=16099082&amp;_hsenc=p2ANqtz-_MFjfxvpCdmV_Ax2RKDdOGypHPQ85UL-UMuy0eRs_MrlJ2qJVp-MXx-g7_-dAQsq0trpA61hkZrzO-3gp6bKVkpK52fQ&amp;_hsmi=16099082\" class=\"external-link\" rel=\"nofollow\">http://www.socallinuxexpo.org/scale/13x/presentations/advanced-query-routing-and-proxying-maxscale?utm_campaign=north-american-trade-shows&amp;utm_source=hs_email&amp;utm_medium=email&amp;utm_content=16099082&amp;_hsenc=p2ANqtz-_MFjfxvpCdmV_Ax2RKDdOGypHPQ85UL-UMuy0eRs_MrlJ2qJVp-MXx-g7_-dAQsq0trpA61hkZrzO-3gp6bKVkpK52fQ&amp;_hsmi=16099082</a>).</p><p>If anyone has questions they would like me to ask, please post them here as well.</p><p>I will post notes to this issue.</p>\n",
            "<p>This include past experience, collection of use cases.</p>\n",
            "\"<p>We can make address a lot of dependency issues if we move the Source classes to meas_base, because we'll no longer have low-level code (e.g. afw::table persistence) in the same module as very high-level code (e.g. slots).   It will also put all the slot code in the same place, instead of spreading it across two pacakges.</p><p>This should be straightforward, except that we'll have a lot of downstream code to (trivially) change, and there's a good chance Swig will get confused somewhere along the way.</p>\"\n",
            "nan\n",
            "<p>Needed to run Qserv on CC-IN2P3 cluster.</p>\n",
            "<p>Follow up metadata store schema development to ensure SUI will be able to use it. Define the fields that should go into Data Definition table. Define the fields that must be present in the image metadata table, which SUI will be searching.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>After changing the implementation of GaussianFlux to use the shape slot rather than estimate the shape itself by re-running the SdssShape code, Perry saw a 5-15% difference in the fluxes (I\\'m not sure of the sign).  The new behavior (using the shape) is consistent with what we\\'d have gotten with the old code when the little-used \"fixed\" config option was enabled (not surprising, as that just looked up the SdssShape measurement by name, instead of via slots).</p><p>I suspect the difference is coming in because of the factor of two between SdssShape\\'s \"raw\" measurements - the actual Gaussian-weighted moments - and the factor of 2 it applies to make its measurements equivalent to ideal unweighted moments.  The correct weight function to use for GaussianFlux includes this factor of 2 (i.e. it\\'s larger than the \"raw\" moments), and it\\'s likely either the old code wasn\\'t including this or the new code isn\\'t.  We need to determine which one, and if necessary, fix the new code.</p>\n",
            "nan\n",
            "<p>Brian Selvy is producing a SysML version of the LSE-72 updated edited by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=gpdf\" class=\"user-hover\" rel=\"gpdf\">Gregory Dubois-Felsmann</a>.  The action here is to proofread the docgen of that version once it is ready.</p>\n",
            "<p>Provide slides and other information needed for CD-2, mainly relative to the open questions around LSE-130</p>\n",
            "<p>Russell writes:</p><blockquote><p>I think our system for getting code reviewed using JIRA needs some improvements. It seems that people don\\'t always know that they have been assigned to review a ticket. Also, even if I know I have been assigned to review a ticket, I find it hard to find on JIRA.</p><p>More concretely, I would like to see these improvements:</p><ul class=\"alternate\" type=\"square\">\\t<li>Much clearer notification that one has been assigned as a reviewer. Presently the email is quite generic and easy to miss. In fact I find that most JIRA notifications are rather hard to read &#8211; it\\'s not always easy to see what has changed and thus why I should care. The signal to noise ratio is poor.</li></ul><ul class=\"alternate\" type=\"square\">\\t<li>By default a user should see which issues they have been assigned as reviewer when they log into JIRA. (If there is a way to reconfigure the dashboard for this, I\\'d like to know about it, but it really should be the default). One way to fix this, of course, is to reassig the ticket when putting it into review, but we have good reasons to avoid that.</li></ul><p>&#8211; Russell</p></blockquote><p>and I added:</p><blockquote><p>In fact, you don\\'t know that the ticket has passed into review unless you scroll all the way to the bottom of the comment.  If the comment associated with the change in status is long and you don\\'t scroll all the way down, then you may not know that you were assigned to review.  With Trac, the important information was at the top of the e-mail.</p></blockquote>\n",
            "<p>This include file was damaged somewhat by the addition of slot routines to work with the flattened field definitions.  It would be nice to put the Measurement abstraction back in place &#8211; or get rid of it.  We need to decide whether the old slot and compound key mechanisms from SourceTable version 0 are going to be continued for doing this.</p>\n",
            "<p>Complete any review-driven revisions of LSE-140 and support the CCB meeting and following final document preparation.</p>\n",
            "<p>Used \"pip\" to install it. \"Conda\" should work as well. Therefore, it should be easy to make it part of the delivered system: VM, container, tar file, after the fact download, etc. It has documentation, uses the MIT license, under active development and available from PyPI. DB connection is straight forward and requires little experience to get meaningful work done.</p>\n",
            "<p>This works well, at least for a simple case. You can move directly from a query statement to a Pandas data frame for analysis in just a few lines of code. Here is the start of an iPython Qserv session showing how easy it is.</p><p>In <span class=\"error\">&#91;6&#93;</span>: import pandas as pd<br/>In <span class=\"error\">&#91;7&#93;</span>: import pymysql as db</p><p>In <span class=\"error\">&#91;8&#93;</span>: conn = db.connect(host=\\'lsst-db1.ipac.caltech.edu\\',port=4040, user=\\'qsmaster\\', passwd=\\'\\', db=\\'LSST\\')</p><p>In <span class=\"error\">&#91;11&#93;</span>: df = pd.read_sql(\"select deepCoaddId, tract, patch, ra, decl from DeepCoadd\", conn)</p><p>In <span class=\"error\">&#91;12&#93;</span>: df<br/>Out<span class=\"error\">&#91;12&#93;</span>:<br/>    deepCoaddId  tract   patch        ra      decl<br/>0      26607706      0  406,11  0.669945  1.152218<br/>1      26673242      0  407,11  0.449945  1.152218<br/>2      26804242      0   409,2  0.011595 -0.734160<br/>3      26673154      0   407,0  0.449945 -1.152108<br/>\\xe2\\x80\\xa6</p>\n",
            "nan\n",
            "nan\n",
            "<p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">fjammes@clrlsst-dbmaster-vm:~</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/src/qserv</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> (u</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/fjammes/DM-627</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> $%) $ qserv-</span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">test</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-</span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">head</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.sh -h</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Usage: qserv-</span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">test</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-</span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">head</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.sh [options]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  Available options:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    -h          this message</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    -q          quick: only rebuild</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/install</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> new Qserv code,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">                and perform </span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">test</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">case</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">#01</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  Rebuild from scratch, configure and run integration tests against</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  a Qserv git repository.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  Pre-requisite:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">source</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> loadLSST.</span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">bash</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    setup qserv_distrib -t qserv</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    setup -k -r ${QSERV_SRC_DIR}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  Can be used with </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'git bisect\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> :</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">cd</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ${QSERV_SRC_DIR}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    git bisect start</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    git bisect bad</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    git bisect good git-commit-</span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">id</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    git bisect run </span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/home/fjammes/src/qserv_testdata/bin/qserv-test-head</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.sh</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Code is in <a href=\"https://jira.lsstcorp.org/browse/DM-627\" title=\"Switch to using new partitioner, loader\" class=\"issue-link\" data-issue-key=\"DM-627\"><del>DM-627</del></a> ticket branch.</p>\n",
            "<p>We\\'ve never figured out how to handle wrapping multiple-aperture photometry algorithms.  They can\\'t use the existing Result objects - at least not out of the box.</p><p>We should try to write a new multiple-aperture photometry algorithm from the ground up, using the old ones on the HSC branch as a guide, but not trying to transfer the old code over.  The new one should:</p><ul class=\"alternate\" type=\"square\">\\t<li>Have the option of using elliptical apertures (as defined by the shape slot) or circular apertures.</li>\\t<li>Have a transition radius at which we switch from the sinc photometry algorithm to the naive algorithm (for performance reasons).</li></ul>\n",
            "<p>Similar to <a href=\"https://jira.lsstcorp.org/browse/DM-441\" title=\"Setup of four new measurement algorithms for processCcd testing\" class=\"issue-link\" data-issue-key=\"DM-441\"><del>DM-441</del></a> for flux algorithms GaussianFlux and NaiveFlux</p><p>Unit tests for major config options, just to be sure that they do something reasonable.</p><p>Test of at least one exception <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/flag.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/></p>\n",
            "<p>SkyCoord was moved to <a href=\"https://jira.lsstcorp.org/browse/DM-441\" title=\"Setup of four new measurement algorithms for processCcd testing\" class=\"issue-link\" data-issue-key=\"DM-441\"><del>DM-441</del></a> - done in Python</p><p>Classification is also simple if done in Python</p><p>Pixel Keys will be done in C++</p><p>Some work left from SdssShape will be done with this ticket</p><p>Also, since these are out only two Python algorithms in the base set, I will add the exception handling and base fail() methods at this time.</p>\n",
            "nan\n",
            "<p>Test for compatibility of NaiveFlux, GaussianFlux, and PsfFlux against meas_algorithms</p>\n",
            "nan\n",
            "<p>Audit TCT recommendations to ensure that all standards updates were installed into Standards documents.</p><p>It was found that the meeting recorded in: <a href=\"https://dev.lsstcorp.org/trac/wiki/Winter2012/CodingStandardsChanges\" class=\"external-link\" rel=\"nofollow\">https://dev.lsstcorp.org/trac/wiki/Winter2012/CodingStandardsChanges</a> failed to include two recommendations: </p><ul>\\t<li>recommended: 3-30: I find the Error suffix to be usually more appropriate than Exception.\\t<ul>\\t\\t<li>current: 3-30. Exception classes SHOULD be suffixed with Exception.</li>\\t</ul>\\t</li></ul><ul>\\t<li>recommended but not specifically included: Namespaces in source files: we should use namespace blocks in source files, and prefer unqualified (or less-qualified) names within those blocks over global-namespace aliases.\\t<ul>\\t\\t<li>Rule 3-6 is an amalgam of namespace rules which doesn\\'t quite have the particulars desired. FYI: The actual vote was to:  \"Allow namespace blocks in source code (cc) files.\"</li>\\t</ul>\\t</li></ul><p>To simplify the future audit, all other recommendations in that specific meeting were verified as installed into the standards.</p>\n",
            "<p>Deliverable: circulate a Word-based draft of LSE-68 in which the \"push\" interface is removed, and the \"pull\" interface is refined to include the guider and other Summer 2014 work.</p><p>Note that the use of \"pull\" for the guider applies whether or not the proposed guider redesign is accepted.</p>\n",
            "<p>Create an LCR, including a summary of changes, for LSE-68.</p>\n",
            "\"<p>GaussianFlux relies on the shape slot, and puts noisy warnings in the logs when the shape slot fails.</p><p>However, we probably don't want to add a new flag for GaussianFlux to indicate this failure mode, because it'd be entirely redundant with the shape slot flag.  We should figure out some other way to squash this warning - how we do that may depend on whether this is addressed before or after the C++ redesign.</p><p>We should also consider having GaussianFlux add an alias to the schema to point back at the shape slot flag, creating what looks like a specific flag for this failure while actually just being a link back to the shape slot flag.  That's probably not worth doing within the current C++ interface, however, as it'd require some unpleasant mucking around with ResultMappers.</p>\"\n",
            "<p>Schema aliases should support more than one level (i.e. an alias may resolve to another alias).</p>\n",
            "<p>-------- Original Message --------<br/>Subject: <span class=\"error\">&#91;LSST-data&#93;</span> Swig 3.0 is out (with C++11 support)<br/>Date: Mon, 17 Mar 2014 08:26:05 -0400<br/>From: Robert Lupton the Good &lt;rhl@astro.princeton.edu&gt;<br/>To: LSST Data &lt;lsst-data@lsstcorp.org&gt;</p><p>I tried a pre-release on os/x 10.7.5 and it failed some tests, but I haven\\'t tried this version.</p><p>I had some discussion about this with William, but haven\\'t had time to follow through.</p><p>\\t\\t\\t\\t\\t\\t\\tR</p><p>&gt; Date: Sun, 16 Mar 2014 22:44:42 +0000<br/>&gt; From: William S Fulton &lt;wsf@fultondesigns.co.uk&gt;<br/>&gt; <br/>&gt; *** ANNOUNCE: SWIG 3.0.0 (16 Mar 2014) ***<br/>&gt; <br/>&gt; <a href=\"http://www.swig.org\" class=\"external-link\" rel=\"nofollow\">http://www.swig.org</a><br/>&gt; <br/>&gt; We\\'re pleased to announce SWIG-3.0.0, the latest SWIG release.<br/>&gt; <br/>&gt; What is SWIG?<br/>&gt; =============<br/>&gt; <br/>&gt; SWIG is a software development tool that reads C/C++ header files and<br/>&gt; generates the wrapper code needed to make C and C++ code accessible<br/>&gt; from other programming languages including Perl, Python, Tcl, Ruby,<br/>&gt; PHP, C#, Go, Java, Lua, Scheme (Guile, MzScheme, CHICKEN), D, Ocaml,<br/>&gt; Pike, Modula-3, Octave, R, Common Lisp (CLISP, Allegro CL, CFFI, UFFI).<br/>&gt; SWIG can also export its parse tree in the form of XML and Lisp<br/>&gt; s-expressions.  Major applications of SWIG include generation of<br/>&gt; scripting language extension modules, rapid prototyping, testing,<br/>&gt; and user interface development for large C/C++ systems.<br/>&gt; <br/>&gt; Availability<br/>&gt; ============<br/>&gt; The release is available for download on Sourceforge at<br/>&gt; <br/>&gt;      <a href=\"http://prdownloads.sourceforge.net/swig/swig-3.0.0.tar.gz\" class=\"external-link\" rel=\"nofollow\">http://prdownloads.sourceforge.net/swig/swig-3.0.0.tar.gz</a><br/>&gt; <br/>&gt; A Windows version is also available at<br/>&gt; <br/>&gt;      <a href=\"http://prdownloads.sourceforge.net/swig/swigwin-3.0.0.zip\" class=\"external-link\" rel=\"nofollow\">http://prdownloads.sourceforge.net/swig/swigwin-3.0.0.zip</a><br/>&gt; <br/>&gt; Please report problems with this release to the swig-devel mailing list,<br/>&gt; details at <a href=\"http://www.swig.org/mail.html\" class=\"external-link\" rel=\"nofollow\">http://www.swig.org/mail.html</a>.<br/>&gt; <br/>&gt; Release Notes<br/>&gt; =============<br/>&gt; SWIG-3.0.0 summary:<br/>&gt; - This is a major new release focusing primarily on C++ improvements.<br/>&gt; - C++11 support added. Please see documentation for details of supported<br/>&gt;   features: <a href=\"http://www.swig.org/Doc3.0/CPlusPlus11.html\" class=\"external-link\" rel=\"nofollow\">http://www.swig.org/Doc3.0/CPlusPlus11.html</a><br/>&gt; - Nested class support added. This has been taken full advantage of in<br/>&gt;   Java and C#. Other languages can use the nested classes, but require<br/>&gt;   further work for a more natural integration into the target language.<br/>&gt;   We urge folk knowledgeable in the other target languages to step<br/>&gt;   forward and help with this effort.<br/>&gt; - Lua: improved metatables and support for %nspace.<br/>&gt; - Go 1.3 support added.<br/>&gt; - Python import improvements including relative imports.<br/>&gt; - Python 3.3 support completed.<br/>&gt; - Perl director support added.<br/>&gt; - C# .NET 2 support is now the minimum. Generated using statements are<br/>&gt;   replaced by fully qualified names.<br/>&gt; - Bug fixes and improvements to the following languages:<br/>&gt;   C#, Go, Guile, Java, Lua, Perl, PHP, Python, Octave, R, Ruby, Tcl<br/>&gt; - Various other bug fixes and improvements affecting all languages.<br/>&gt; - Note that this release contains some backwards incompatible changes<br/>&gt;   in some languages.<br/>&gt; - Full detailed release notes are in the changes file.</p>\n",
            "<p>In-place build is available and documented.</p>\n",
            "nan\n",
            "<p>qserv_distrib will be a meta-package embedding qserv, qserv_testdata and partition.</p>\n",
            "<p>Fabrice</p><p>I am getting \"out of range value\" when I run the qserv-testdata:</p><p>Are you seeing that too?</p><p>2014-05-09 18:11:55,975 </p>{/usr/local/home/becla/qserv/1/qserv/build/dist/lib/python/lsst/qserv/admin/commons.py:134}<p> INFO     stderr : /usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'calib_detected\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'calib_psf_candidate\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'calib_psf_used\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_negative\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_badcentroid\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'centroid_sdss_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_edge\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_interpolated_any\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_interpolated_center\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_saturated_any\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_saturated_center\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_cr_any\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_cr_center\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'centroid_gaussian_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'centroid_naive_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'shape_sdss_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'shape_sdss_centroid_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'shape_sdss_flags_unweightedbad\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'shape_sdss_flags_unweighted\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'shape_sdss_flags_shift\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'shape_sdss_flags_maxiter\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flux_psf_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flux_psf_flags_psffactor\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flux_psf_flags_badcorr\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flux_naive_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flux_gaussian_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flux_gaussian_flags_psffactor\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flux_gaussian_flags_badcorr\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flux_sinc_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_psf_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_psf_flags_maxiter\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_psf_flags_tinystep\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_psf_flags_constraint_r\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_psf_flags_constraint_q\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_dev_flux_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_dev_flags_psffactor\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_dev_flags_badcorr\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_dev_flags_maxiter\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_dev_flags_tinystep\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_dev_flags_constraint_r\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_dev_flags_constraint_q\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_dev_flags_largearea\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_exp_flux_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_exp_flags_psffactor\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_exp_flags_badcorr\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_exp_flags_maxiter\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_exp_flags_tinystep\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_exp_flags_constraint_r\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_exp_flags_constraint_q\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_exp_flags_largearea\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_combo_flux_flags\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_combo_flags_psffactor\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'multishapelet_combo_flags_badcorr\\' at row 1<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'calib_detected\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'calib_psf_candidate\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'calib_psf_used\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_negative\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_badcentroid\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'centroid_sdss_flags\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_edge\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_interpolated_any\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_interpolated_center\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_saturated_any\\' at row 2<br/>  self.cursor.execute(stmt)<br/>/usr/local/home/becla/qserv/1/qserv/build/dist/bin/loader.py:99: Warning: Out of range value for column \\'flags_pixel_saturated_center\\' at row 2<br/>  self.cursor.execute(stmt)</p>\n",
            "<p>Presence of <tt>.my.cnf</tt> file in the user HOME directory crashes <tt>qserv-configure.py</tt> script if parameters in <tt>.my.cnf</tt> conflict with parameters in <tt>qserv.conf</tt>.</p><p>How to reproduce:</p><ul>\\t<li>create .my.cnf file in the home directory:<p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[client]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">user     = anything</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># host/port and/or socket</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">host     = 127.0.0.1</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">port     = 3306</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">socket   = /tmp/mysql.sock</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/></li>\\t<li>try to run <tt>qserv-configure</tt>, it fails with error:<p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/usr/local/home/salnikov/qserv-run/u.salnikov.DM-595/tmp/configure/mysql.sh: connect: Connection refused</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/usr/local/home/salnikov/qserv-run/u.salnikov.DM-595/tmp/configure/mysql.sh: line 13: /dev/tcp/127.0.0.1/23306: Connection refused</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ERROR 2003 (HY000): Can\\'t connect to MySQL server on \\'127.0.0.1\\' (111)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/></li></ul><p>It looks like <tt>~/.my.cnf</tt> may be a left-over from some earlier qserv installation. If I remove it and re-run <tt>qserv-configure.py</tt> now it\\'s not created anymore. Maybe worth adding some kind of protection to <tt>qserv-configure.py</tt> in case other users have this file in their home directory.</p>\n",
            "<p>After yesterday\\'s merge of <a href=\"https://jira.lsstcorp.org/browse/DM-58\" title=\"package zookeeper, kazoo and db\" class=\"issue-link\" data-issue-key=\"DM-58\"><del>DM-58</del></a> into master automated tests do not work any more. The part which is broken now is loading of metadata into qserv. We need to replace old script which created metadata with something different that creates metadata using new CSS. </p><p>The code which loads metadata in tests is in QservDataLoader class, createQmsDatabase() method (in tests/python/lsst/qserv/test/ directory).</p>\n",
            "<p>When we installed apr and apr_utils packages (as a dependency of new log4cxx package, see <a href=\"https://jira.lsstcorp.org/browse/DM-772\" title=\"Package log4cxx\" class=\"issue-link\" data-issue-key=\"DM-772\"><del>DM-772</del></a>) we discovered that both these packages only build static libraries but no shared libs are installed. This is problematic if mixed with shared libs and we use shared libs everywhere else. We certainly need to build shared libs for these packages, this ticket is to follow up on this problem.</p>\n",
            "<p>Running automated tests for some queries I observe python exceptions in czar log which look like this:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">20140529 19:47:19.364371 0x7faacc003550 INF &lt;py&gt; Query dispatch (7) toUnhandled exception in thread started by &lt;function waitAndUnlock at 0x18cd8c0&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/usr/local/home/salnikov/qserv-master/build/dist/lib/python/lsst/qserv/czar/proxy.py\", line 78, in waitAndUnlock</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    lock.unlock()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/usr/local/home/salnikov/qserv-master/build/dist/lib/python/lsst/qserv/czar/proxy.py\", line 65, in unlock</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    self._saveQueryMessages()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/usr/local/home/salnikov/qserv-master/build/dist/lib/python/lsst/qserv/czar/proxy.py\", line 87, in _saveQueryMessages</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    self.db.applySql(Lock.writeTmpl % (self._tableName, chunkId, code, msg, timestamp))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/usr/local/home/salnikov/qserv-master/build/dist/lib/python/lsst/qserv/czar/db.py\", line 95, in applySql</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    c.execute(sql)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/u2/salnikov/STACK/Linux64/mysqlpython/1.2.3+8/lib/python/MySQL_python-1.2.3-py2.7-linux-x86_64.egg/MySQLdb/cursors.py\", line 174, in execute</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    self.errorhandler(self, exc, value)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/u2/salnikov/STACK/Linux64/mysqlpython/1.2.3+8/lib/python/MySQL_python-1.2.3-py2.7-linux-x86_64.egg/MySQLdb/connections.py\", line 36, in defaulterrorhandler</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    raise errorclass, errorvalue</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">_mysql_exceptions.ProgrammingError: (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \\'r\\' AND sce.tract=0 AND sce.patch=\\'159,3\\';\\', 1401410839.000000)\\' at line 1\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ok 0.000532 seconds</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I believe this is due to how query string is being constructed in czar/proxy.py:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> Lock:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    writeTmpl </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"INSERT INTO %s VALUES (%d, %d, \\'%s\\', %f);\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># ...................</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">            </span><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">self</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.db.applySql(Lock.writeTmpl </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">%</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> (</span><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">self</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">._tableName, chunkId, code, msg, timestamp))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>If <tt>msg</tt> happens to contain quotes then resulting query is broken. One should not use Python formatting to construct query strings, instead the parameters should be passed directly to <tt>cursor.execute()</tt> method.</p>\n",
            "<p>To complete the DRP deblender sprint from May the changes must be pushed to master. This ticket includes pushing the required changes to scarlet and updating <tt>meas_extensions_scarlet</tt>, <tt>pipe_tasks</tt>, and <tt>pipe_drivers</tt> with the appropriate changes so that scarlet v0.5 can be run on LSST.</p>\n",
            "<p>ts_salobj 4 cannot seem to communicate with ts_sal v3.10.0. The symptoms are that events and commands are transmitted, but command acknowledgement is not received. Also I have seen segfaults if I create the SALPY object and the salobj Domain and Remote in the same process, when things finish shutting down. But this does not seem to happen if they are in separate processes.</p><p>Add a unit test for this that uses SALPY_Test. Add ts_sal as an optional dependency of ts_salobj since the SALPY_Test module will be there.</p><p>I tried to use the ADLink Tester tool but it cannot find anything to connect to. so I get no information from it, alas.</p>\n",
            "<p>Investigate pipeline optimization (code profiling and assessment of routines).</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Investigate resource manager options for kubernetes commons  - Understanding AA and SSO for k8s deplyment</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>It looks like the template PSF is not warped in image differencing. See lines 407-411 of <tt>imagePsfMatch.py</tt> in <tt>ip_diffim</tt>. This leads to a much broader PSF being used for calculating the matching kernel if the template is at a finer plate scale than the science image. Also, if the PSF is elliptical, it may end up with the wrong rotation, and this may be causing an increase in \"quadrupole\" mis-subtractions.</p>\n",
            "<p>Participate on meetings leading to the design of the plan of deliverables concerning the components of the Dome Control System software. The first phase is to get a simulator version we can utilize to exercise the TCS dome interface.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Ingest files into a Gen2 butler.</p>\n",
            "<p>To develop statement of work that leads to generate purchase order for getting Linux upgrade software to be utilize in main telescope HVAC system</p>\n",
            "<p>Update the ts_wep to Use the eimage. The <a href=\"https://jira.lsstcorp.org/browse/DM-19837\" class=\"external-link\" rel=\"nofollow\">DM-19837</a> had updated the phosim_utils and obs_lsst to ingest the eimage by butler.</p>\n",
            "<p>Try extracting a PixelScaleBoundedField object from some joint cal runs. \\xc2\\xa0Use that to develop a polynomial model for HSC distortion that can be used when fitting donuts.</p>\n",
            "<p>\\xc2\\xa0<br/> Clean up Electrometer python code and add limits when applies (for example integration time should be limited). Also create a docker image for deployment.</p><p>Update:\\xc2\\xa0</p><ul>\\t<li>Configuration to use the API from salobj</li>\\t<li>update intensity in events to \"CurrentValue\" or \"Measurement\" according to Patricks comments in\\xc2\\xa0<a href=\"https://github.com/lsst-ts/ts_xml/pull/83#discussion-diff-279486587R15\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-ts/ts_xml/pull/83#discussion-diff-279486587R15</a></li></ul>\n",
            "<p>This task is to re-package electrometer to follow new standards and make it work with dm-stack (and Tiagos Docker image).</p>\n",
            "<p>In C++, <tt>lsst.afw.typehandling.GenericMap</tt> is a class template with a single template parameter, the key type. Since the key is likely to only be \"simple\" types like integer or strings, <tt>GenericMap</tt> is well-suited for use with <tt>lsst.utils.TemplateMeta</tt>.</p><p>Priority: minor, as currently there is only a string version of <tt>GenericMap</tt> in Python and no demand for alternatives.</p><p>Note that this will make the Python API slightly more confusing, since the new Python <tt>GenericMap</tt> would have the restriction that all keys must be of the same type, but not of any particular type. (Though in practice, I can\\'t imagine a use case for heterogeneous keys.)</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-18735\" title=\"Convert dax_ppdb to use Pandas data frames (rather than afw::table) as an interface\" class=\"issue-link\" data-issue-key=\"DM-18735\"><del>DM-18735</del></a> created code paths for reading and writing Pandas into the Ppdb using the standard Pandas sql interfaces. It\\'s not currently known now efficient these interfaces are for read/writes. This ticket will investigate this using <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=salnikov\" class=\"user-hover\" rel=\"salnikov\">Andy Salnikov</a>\\'s test code in dax_ppdb and ap_pipe the difference in run time between the two methods.</p>\n",
            "\"<p>Processing Decam data from raw images currently requires downloading the bad pixel mask files from NOAO, then ingesting them into the calibration repository. It would be much more convenient if we included these with obs_decam itself, pending the ok to do so from NOAO. Our understanding is that we could create a default calibration repository in obs_decam, which would be the parent of users' calibration repos. We will also likely want to convert the provided files from mask images into tables of bounding boxes.</p>\"\n",
            "<p>Create a Jenkins job to build the SAL library RPMs, push them to the AWS S3 buckets and then push them into the Nexus3 yum repo.</p>\n",
            "<p>Create documentation for:</p><ul>\\t<li>Document how M2 is connected to the computer</li>\\t<li>Document how to configure AuxTel Dome cRios\\xc2\\xa0</li>\\t<li>Document how to configure PI Hexapod</li></ul>\n",
            "<p>Continue <a href=\"https://jira.lsstcorp.org/browse/DM-17555\" title=\"Process DC2 imsim one tract of data \" class=\"issue-link\" data-issue-key=\"DM-17555\"><del>DM-17555</del></a>, reprocess some DC2 imsim data at /datasets/DC2/repo/</p>\n",
            "<p>The <tt>prometheus-operator</tt> chart, in addition to providing CRDs for configuring prometheus scraping, bundles some extra goodies, such as grafana dashboard, that are not present in the <tt>prometheus</tt> chart.</p>\n",
            "<p>Add simulation mode to CBP CSC. Commands should return sensible values.</p><p>Add settings and configuration to CBP CSC.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Get the tests for ts_sal running on a Jenkins program. Tei wei has a method for doing this user docker containers. The python\\\\ environment will be downloading either using lsstsw or the newinstall script.\\xc2\\xa0</p>\n",
            "<p>There are currently no tests for the `get_closest_state` definition. This task is aimed to get some code coverage on it, specifically making sure that the binary schema I implemented is working correctly. I only have done some minor interpreter testing.</p>\n",
            "<p>Upgrade LTS-158 ICS document, to include a thermal command and a crane and rear status event</p>\n",
            "<p>MultiProFit currently fits ellipse shapes using the major axis, axis ratio, position angle parameterization. While easily understood, the position angle is problematic - it is unconstrained for near-circular ellipses and has periodic boundary conditions. This ticket will switch to fitting sigma_x, sigma_y and rho from the covariance matrix [<span class=\"error\">&#91;sigma_x**2, rho*sigma_x*sigma_y&#93;</span>, <span class=\"error\">&#91;rho*sigma_x*sigma_y, sigma_y**2&#93;</span>], which is well-behaved and has reasonable limits of sigma_x, sigma_y &gt;= 0 and -1 &lt;= rho &lt;= 1.</p>\n",
            "<p>TMA Software Workshop in Spain with vendor.</p>\n",
            "<p>Prepare for the upcoming workshop, review code and build instructions, review documentation and suggest improvement, update agenda and add details</p>\n",
            "<p>Run further tests to the EFD to ensure:</p><ul>\\t<li>We can create almost all tables (for now with the exception of the tables with more than 512 attributes)</li>\\t<li>We can record a big amount o data per table (this may vary among TIERS). As a result of this point, it will need to be documented how to change configuration to handle more data per table + cons of doing this.</li>\\t<li>Create replicable tests to ensure that after any change, all keeps working as expected (this could be either manual tests or automatic tests)</li></ul>\n",
            "<p>The test should set a starting altitude, azimuth and tracking_duration. It will then check that as tracking occurs that no CSCs go into a fault state.\\xc2\\xa0</p>\n",
            "<p>Rebuild the SAL  V3.9 and OpenSplice V6.9 for the Raspberry Pi environment and create an SDK image for use by the EAS contractor</p>\n",
            "<p>set up windows ASC host, get SpatialAnalyze license sorted out, connect to T2SA application, exchange information between ASC and T2SA</p>\n",
            "\"<p>It's been requested to provide a container for the HeaderService. The primary usage of this should be to provide an estable version to spun new instances for development. At the moment the baseline is to use puppet to deploy this services at NCSA and Tucson. This could become useful when/if we decide to move CSCs into containers.</p>\"\n",
            "<p>Deferring normalization for these objects adds unnecessary complexity, delays error reporting, and <a href=\"https://confluence.lsstcorp.org/display/DM/Butler+Major+Design+Questions%2C+2019-05-28#ButlerMajorDesignQuestions,2019-05-28-ImmutableDatasetTypes,DataIds,andDatasetRefsimmutable-datasettypes-dataids-and-datasetrefs\" class=\"external-link\" rel=\"nofollow\">leads to incorrect behavior in DatasetType comparisons</a>.</p><p>This work has already been started on <a href=\"https://jira.lsstcorp.org/browse/DM-17023\" title=\"Refactor to reduce code complexity in Dimensions system\" class=\"issue-link\" data-issue-key=\"DM-17023\">DM-17023</a>, but I\\'m spinning it off here to keep that from growing too large.</p>\n",
            "<p>For the commissioning papers (and overview paper) we need a scheme for managing author lists in a standardized way.  The overview paper has some infrastructure for this but the scripts need to be modified to separate the author list for a specific paper from the author full name and affiliation.</p><p>In theory the name and affiliation information should come from contacts DB. In the interim I will use an intermediary YAML file.</p>\n",
            "<p>Support the use of PhoSim eimage in scientific pipeline. After the discussion with Simon, it looks valuable to support this function in obs_lsst level.</p><p>\\xc2\\xa0</p><p>He suggested to create a task class inherited from PhosimParseTask in:</p><p><a href=\"https://github.com/lsst/obs_lsst/blob/master/python/lsst/obs/lsst/phosim.py\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/obs_lsst/blob/master/python/lsst/obs/lsst/phosim.py</a></p><p>Override the\\xc2\\xa0getDestination() in\\xc2\\xa0ParseTask class for the hard coded \"raw_filename\":</p><p><a href=\"https://github.com/lsst/pipe_tasks/blob/master/python/lsst/pipe/tasks/ingest.py\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/pipe_tasks/blob/master/python/lsst/pipe/tasks/ingest.py</a></p><p>Use the ingest.py for the retargeting of eimage if it is needed:</p><p><a href=\"https://github.com/lsst/obs_lsst/blob/master/config/phosim/ingest.py\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/obs_lsst/blob/master/config/phosim/ingest.py</a></p><p>We should be able to ingest the eimage directly by the changing of configuration.</p><p>\\xc2\\xa0</p><p>For the data access, we could just reuse the template in eimage in\\xc2\\xa0lsstCamMapper.yaml:</p><p><a href=\"https://github.com/lsst/obs_lsst/blob/master/policy/lsstCamMapper.yaml\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/obs_lsst/blob/master/policy/lsstCamMapper.yaml</a></p><p>This means we should not need to modify the code to access the eimage data. When the data butler tries to get the data, we only need to set the data set as the \"eimage\".</p>\n",
            "<p>The ATHeaderService, which is running on `dm-hs-node-01` at the Tucson test stands\\xc2\\xa0needs to be updated to run using version v3.10.0_001 of the ts_sal rpms. In addition several pre-req packages needed to be updated.</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">pip3 install pyyaml</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install https:</span><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">//centos7.iuscommunity.org/ius-release.rpm</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install python36u python36u-devel python36u-pip</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ln -s /usr/bin/python3.</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">6</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> /usr/bin/python3</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">install-fitsio.sh</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>\\xc2\\xa0</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SAL_VERSION=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">3.10</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.0_001</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">OPSL_VERSION=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">6.9</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># Add the lsst-ts repo</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">wget https:</span><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">//lsst-web.ncsa.illinois.edu/~felipe/packages/lsst-ts.repo</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">mv -v lsst-ts.repo /etc/yum.repos.d</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># These are the ones we\\'ve needed </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> now</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install OpenSpliceDDS-$OPSL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install ATHeaderService-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install ATCamera-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install ATArchiver-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install EFD-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install Scheduler-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install ATPtg-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install ATMCS-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install ATSpectrograph-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install ATTCS-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># Needed by ATArchiver</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install CatchupArchiver-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install MTArchiver-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install MTCamera-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">yum -y install PromptProcessing-$SAL_VERSION</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># Get the setup conf</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">wget https:</span><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">//lsst-web.ncsa.illinois.edu/~felipe/packages/setup_SAL.env -O /opt/lsst/setup_SAL.env</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p>Continue summit work, including ATTCS unit tests, slewing and dome integration tests, hitting e-stop button when we accidentally slew the telescope into a crane, etc.</p><p>Returning to Tucson fri/sat</p>\n",
            "<p>Shadow Tiago, learn about integration, work on auxiliary telescope slewing, develop unit tests for ATTCS</p>\n",
            "<p>This sprint will literally be this. <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ecoughlin\" class=\"user-hover\" rel=\"ecoughlin\">Eric Coughlin</a> Don\\'t forget to fill this out.</p>\n",
            "<p>This whole sprint is this. <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ecoughlin\" class=\"user-hover\" rel=\"ecoughlin\">Eric Coughlin</a> don\\'t forget to fill this out.</p>\n",
            "\"<p>I haven't enforced a consistent style in the MultiProFit code (Python or C++) and I still have a few features to add/update, so now would be a good time to start.</p>\"\n",
            "<p>Integrate ts_MTAOS with PhoSim for the AOS close loop simulation. This task will update the xml file for the intra- and extra-focal visits.</p>\n",
            "<p>Update the scripts in ts_standardscripts to work with dds ts_salobj and schema+dds ts_scriptqueue</p>\n",
            "<p>Participate in the SSSC Sprint #2.</p><p>Prepare the materials for the LSST status update presentation, update the SSSC github with most recent source code and binaries.</p>\n",
            "<p>There are regular IVOA Exec and IVOA Technical Control Group telecons. Prepare for and call into those.</p>\n",
            "<p>Set up test coverage monitoring for OpenOrb (our adopted orbit integration engine).</p><p>This includes:\\xc2\\xa0</p><ul>\\t<li>Having a make target to run the test coverage tools as \\'make coverage\\'</li>\\t<li>Have this target automatically invoked by one of the CI runs</li>\\t<li>Have the results uploaded to a cloud test coverage visualization service.</li></ul><p>We will be using <a href=\"http://codecov.io\" class=\"external-link\" rel=\"nofollow\">codecov.io</a> as the service for visualization of coverage reports.</p><p>The work will be on\\xc2\\xa0<a href=\"https://github.com/mjuric/oorb/tree/ci-and-codecov\" class=\"external-link\" rel=\"nofollow\">https://github.com/mjuric/oorb/tree/ci-and-codecov</a>,\\xc2\\xa0and will be PR-ed upstream upon completion. It depends on <a href=\"https://jira.lsstcorp.org/browse/DM-17814\" title=\"Modernize OpenOrb build system\" class=\"issue-link\" data-issue-key=\"DM-17814\"><del>DM-17814</del></a> being merged.</p>\n",
            "<p>Set up continuous integration\\xc2\\xa0for OpenOrb (our adopted orbit integration engine).</p><p>This includes:\\xc2\\xa0</p><ul>\\t<li>Building on Mac and Linux with Anaconda compilers with Python 2.7, 3.6, 3.7</li>\\t<li>Building on Linux (Ubuntu 16.04) with Ubuntu-supplied compilers and Python 2.7 and 3.5</li>\\t<li>Builds are to be triggered by pushes/PRs to GitHub repository</li></ul><p>We will be using the Azure Pipelines service, as we did with pytrax (<a href=\"https://jira.lsstcorp.org/browse/DM-17027\" title=\"Set up initial CI for pytrax\" class=\"issue-link\" data-issue-key=\"DM-17027\"><del>DM-17027</del></a>).</p><p>The work will be on\\xc2\\xa0<a href=\"https://github.com/mjuric/oorb/tree/ci-and-codecov\" class=\"external-link\" rel=\"nofollow\">https://github.com/mjuric/oorb/tree/ci-and-codecov</a>,\\xc2\\xa0and will be PR-ed upstream upon completion. It depends on <a href=\"https://jira.lsstcorp.org/browse/DM-17814\" title=\"Modernize OpenOrb build system\" class=\"issue-link\" data-issue-key=\"DM-17814\"><del>DM-17814</del></a> being merged.</p>\n",
            "<p>Create a Gen3 Butler repo containing HSC-RC2 data (raw, calib, refcat..) based on Oracle registry.</p><p>The goal is to do Gen3 ingestion if possible.  Otherwise, bootstrap the Gen3 repo from Gen2 repos (gen2convert).</p>\n",
            "<p>learn about scripting tools, and write integration test for aux tel slewing</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-19384\" title=\"Investigate MultiProFit COSMOS galaxy model initialization and runtimes\" class=\"issue-link\" data-issue-key=\"DM-19384\"><del>DM-19384</del></a> found that there are fairly tight relations between the sizes &amp; fluxes of single Sersic fits. This ticket is to test whether one can improve the initialization of fixed (e.g. exponential, de Vaucouleurs) and free-n multi-Gaussian Sersic fits given the parameters from another (typically faster Gaussian) fit.</p>\n",
            "<p>Update FiberSpectrograph code to use sal 3.10. Create and test release 2 version.</p>\n",
            "<p>The new jointcal and obs_lsst functionality was great this past week. It was like you built us a bunch of toys and then let me be the first to play with them.  (Will show you tomorrow). Only thing I\\'ve noticed is missing: </p><p>Three configs for jointcal or processCcd reruns:</p><p>Declination diff all looks very different as it should for 3 reruns:<br/><a href=\"https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/processCcd/i/tract-3633/visit-204706/plot-v204706-matches_dec-psfMagHist.png\" class=\"external-link\" rel=\"nofollow\">https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/processCcd/i/tract-3633/visit-204706/plot-v204706-matches_dec-psfMagHist.png</a><br/><a href=\"https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/jointcal_default/i/tract-3633/visit-204706/plot-v204706-matches_dec-psfMagHist.png\" class=\"external-link\" rel=\"nofollow\">https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/jointcal_default/i/tract-3633/visit-204706/plot-v204706-matches_dec-psfMagHist.png</a><br/><a href=\"https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/jointcal_simple_3_1mas/i/tract-3633/visit-204706/plot-v204706-matches_dec-psfMagHist.png\" class=\"external-link\" rel=\"nofollow\">https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/jointcal_simple_3_1mas/i/tract-3633/visit-204706/plot-v204706-matches_dec-psfMagHist.png</a></p><p>But distance all looks the same. <br/>From same runs of visit analysis (behold timestamps). Repos are clean. </p><p><a href=\"https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/processCcd/i/tract-3633/visit-204706/plot-v204706-matches_distance-psfMagHist.png\" class=\"external-link\" rel=\"nofollow\">https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/processCcd/i/tract-3633/visit-204706/plot-v204706-matches_distance-psfMagHist.png</a><br/><a href=\"https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/jointcal_default/i/tract-3633/visit-204706/plot-v204706-matches_distance-psfMagHist.png\" class=\"external-link\" rel=\"nofollow\">https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/jointcal_default/i/tract-3633/visit-204706/plot-v204706-matches_distance-psfMagHist.png</a><br/><a href=\"https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/jointcal_simple_3_1mas/i/tract-3633/visit-204706/plot-v204706-matches_distance-psfMagHist.png\" class=\"external-link\" rel=\"nofollow\">https://lsst-web.ncsa.illinois.edu/~yusra/QA_DC2/jointcal_simple_3_1mas/i/tract-3633/visit-204706/plot-v204706-matches_distance-psfMagHist.png</a></p><p>I don\\'t really know how this would be possible, except that they\\'re not using jointcal. </p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2019_22. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Ingest RC2 data set into Oracle, to initialize repo for RC2 Gen3 runs.</p>\n",
            "<p>Analysis of Oracle trace files during ci_hsc runs with Gen3 Pegasus.</p>\n",
            "<p>pyvo\\'s build is broken due to an upstream astropy change, and I need to get the build green before any more new development can proceed.</p><p>\\xc2\\xa0</p><p>Here\\'s a link to the failure:</p><p><a href=\"https://travis-ci.org/astropy/pyvo/jobs/539464337\" class=\"external-link\" rel=\"nofollow\">https://travis-ci.org/astropy/pyvo/jobs/539464337</a></p>\n",
            "<p>investigate Mike\\'s question in <a href=\"https://community.lsst.org/t/qserv-group-by-question/3540\" class=\"external-link\" rel=\"nofollow\">https://community.lsst.org/t/qserv-group-by-question/3540</a>\\xc2\\xa0and propose a solution (or implement if trivial)</p>\n",
            "<p>MultiProFit and the COSMOS fitting code (<a href=\"https://jira.lsstcorp.org/browse/DM-15354\" title=\"Fit COSMOS galaxies with pyprofit\" class=\"issue-link\" data-issue-key=\"DM-15354\"><del>DM-15354</del></a>) were designed to fit a total flux and ratios for each component in each source, partly so that one could put a prior on the total flux and also fix the total (e.g. to unity for a PSF model). However, it should also support fitting individual component fluxes, particularly to allow for linear fitters (like least squares/NNLS, see <a href=\"https://jira.lsstcorp.org/browse/DM-18105\" title=\"Implement linear fitter in MultiProFit\" class=\"issue-link\" data-issue-key=\"DM-18105\"><del>DM-18105</del></a>).</p>\n",
            "<p>In working on <a href=\"https://jira.lsstcorp.org/browse/DM-19189\" title=\"Update flux limit for computing statistics to be based on S/N \" class=\"issue-link\" data-issue-key=\"DM-19189\">DM-19189</a>, I have been looking at the S/N distributions of the various fluxes \\xc2\\xa0(raw instrumental and calibrated) from single frame processing (where here <tt>S/N = flux/fluxErr</tt> from the catalog). \\xc2\\xa0The S/N distributions look as expected for the raw instrumental fluxes, the calibrated values based on application of the photoCalib of <tt>jointcal</tt> outputs, and the <tt>meas_mosaic</tt> solution using the \"old style\" calibration (i.e. using <tt>meas_mosaic</tt>\\'s own <tt>applyMosaicResultsExposure()</tt> function \\xe2\\x80\\x93 which uses the persisted <tt>fcr</tt>\\xc2\\xa0dataset to apply the calibration). \\xc2\\xa0However, the S/N distribution when applying the <tt>photoCalib</tt> from <tt>meas_mosaic</tt> is not at all as expected (plots to be attached). Look further into this pathology and what might be causing it.</p>\n",
            "<p>Create a notebook using updated fit results from <a href=\"https://jira.lsstcorp.org/browse/DM-18707\" title=\"Update MultiProFit COSMOS analysis with new models/linear fits\" class=\"issue-link\" data-issue-key=\"DM-18707\"><del>DM-18707</del></a> to investigate whether fast Gaussian fits can be used to 1) improve Sersic model initialization and 2) set reasonable joint flux-size priors</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-15597\" title=\"Analyse results of COSMOS galaxy fits\" class=\"issue-link\" data-issue-key=\"DM-15597\"><del>DM-15597</del></a> introduced a notebook for analyzing the results of MultiProFit fits to COSMOS galaxies. The existing notebook has become large and unwieldy and needs to be refactored into a package with relevant plotting functions and a separate notebook for each specific science question.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Both <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ikedahr\" class=\"user-hover\" rel=\"ikedahr\">Hiroyuki Ikeda</a> and I have encountered some difficult to reproduce errors in the background application stage of coaddDriver.py which looks like:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31] Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]   File \"/ana/products.7.4/stack/miniconda3-4.5.12-1172c30/Linux64/ctrl_pool/7.0-hsc/python/lsst/ctrl/pool/parallel.py\", line 509, in logOperation</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]     yield</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]   File \"/ana/products.7.4/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_drivers/7.4-hsc/python/lsst/pipe/drivers/coaddDriver.py\", line 262, in warp</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]     self.makeCoaddTempExp.runDataRef(patchRef, selectDataList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]   File \"/ana/products.7.4/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_base/7.0-hsc/python/lsst/pipe/base/timer.py\", line 150, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]     res = func(self, *args, **keyArgs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]   File \"/ana/products.7.4/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/7.0-hsc/python/lsst/pipe/tasks/makeCoaddTempExp.py\", line 345, in runDataRef</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]     self.applySkyCorr(calExpRef, calExp)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]   File \"/ana/products.7.4/stack/miniconda3-4.5.12-1172c30/Linux64/pipe_tasks/7.0-hsc/python/lsst/pipe/tasks/makeCoaddTempExp.py\", line 555, in applySkyCorr</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]     calexp -= bg.getImage()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31] TypeError: __isub__(): incompatible function arguments. The following argument types are supported:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]     1. (self: lsst.afw.image.maskedImage.maskedImage.MaskedImageF, arg0: float) -&gt; lsst.afw.image.maskedImage.maskedImage.MaskedImageF</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]     2. (self: lsst.afw.image.maskedImage.maskedImage.MaskedImageF, arg0: lsst.afw.image.maskedImage.maskedImage.MaskedImageF) -&gt; lsst.afw.image.maskedImage.maskedImage.MaskedImageF</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]     3. (self: lsst.afw.image.maskedImage.maskedImage.MaskedImageF, arg0: lsst.afw.image.image.image.ImageF) -&gt; lsst.afw.image.maskedImage.maskedImage.MaskedImageF</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]     4. (self: lsst.afw.image.maskedImage.maskedImage.MaskedImageF, arg0: lsst::afw::math::Function2&lt;double&gt;) -&gt; lsst.afw.image.maskedImage.maskedImage.MaskedImageF</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[31]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>When I\\'d isolate the patch that failed and reran it, it would then infuriatingly succeed. So at first I thought these were transient GPFS errors, but it only appears when reading backgrounds.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a> pointed me to the line that eats the Fits error: <a href=\"https://github.com/lsst/afw/blob/master/python/lsst/afw/math/backgroundList.py#L185\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/afw/blob/master/python/lsst/afw/math/backgroundList.py#L185</a></p><p>Setting a loop to read background files and re-raising the FitsError eventually yielded:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt; /home/yusra/lsst_devel/LSST/DMS/afw/python/lsst/afw/math/backgroundList.py(191)readFits()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-&gt; break</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">(Pdb) e</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">FitsError(\\'cfitsio error: attempt to open too many files (103) : Opening file \\'/datasets/hsc/repo/rerun/DM-13666/WIDE/01052/HSC-G/corr/BKGD-0011602-073.fits\\' with mode \\'r\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">cfitsio error stack:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  failed to find or open the following file: (ffopen)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  /datasets/hsc/repo/rerun/DM-13666/WIDE/01052/HSC-G/corr/BKGD-0011602-073.fits</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\')</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Bingo.</p><p>BackgroundList needs to close its fits files after reading and constructing the BackgroundList.</p><p>(SPs include not only time to fix but time the time scratching my head today and during the deblender sprint)</p>\n",
            "<p>This story will represent the incremental expenses charged for Power and Cooling,\\xc2\\xa0 The Story points on this story will be updated monthly to reflect the percentage of the budget that we have used.</p><p>\\xc2\\xa0</p>\n",
            "<p>To use AST in the stack, we need to be clear what our different transformations (AST:Mappings) and endpoints (AST:Frames) are going to be so we can create the chain of transformations (AST:FrameSets) that will be used throughout the stack. This applies to both images and CameraGeom. We may want to produce similar descriptions for other stack objects.</p><p>This ticket is the high-level Frames equivalent to the mathematical Mapping description in <a href=\"https://jira.lsstcorp.org/browse/DM-5918\" title=\"What transforms do we currently need?\" class=\"issue-link\" data-issue-key=\"DM-5918\"><del>DM-5918</del></a>.</p><p>This will help us determine how we can put our current input/output image frames into the new system.</p>\n",
            "<p>set up the review slide deck .. help to structure the sessions ahead of DMLT F2F</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Work with Cindy to design the SUIT UI to include HSC data</p>\n",
            "<p>Using the framework and content provided in <a href=\"https://jira.lsstcorp.org/browse/DM-9317\" title=\"Creates online help for SUIT\" class=\"issue-link\" data-issue-key=\"DM-9317\"><del>DM-9317</del></a>, update the the content as need for PDAC purpose. </p>\n",
            "<p>Run full ci_hsc in Gen3 using weekly software release and Pegasus. Use Oracle backend if possible, otherwise sqlite3. Report any issues to appropriate dev teams.</p>\n",
            "<p>This ticket is to effectively repeat the relevant portions of the DMTN-006/DMTN-021 analysis for our current HiTS processing to bound our false positive rates.  This ticket is simply to perform the work in a notebook, but it is expected that future work will incorporate relevant portions into the metrics system.</p>\n",
            "<p>Create sets of simulated images that have variable seeing, but with everything else the same between each set. The range of seeing should increase between each set, starting with a very narrow range and increasing by ~10% between sets. </p><p>These simulations are needed to quantify the impact of including higher seeing observations on the DCR model algorithm.</p>\n",
            "\"<p>The Header Service reads in the primary and segment hdu from templates that define the content of the headers. The fitsio (Erin Sheldon's) module doesn't not preserve or store this at the moment. We need to make a request to make sure that these can be read, stored and passed on to the output files created by the HeaderServiuce.</p>\"\n",
            "<p>The script makeSkyMap.py currently uses command line tasks to create and ingest a skymap into a gen2 butler. This ticket will create an equivalent script for the gen3 butler.</p><p>This ticket will have a simple command line parser that will not attempt to capture all options or allow setting configs from the command line. That work will be captured by a future ticket which will encompass command line parsing for scripts in a generic way to work across all gen3 middleware scripts.</p>\n",
            "<p>Building on recent work to enable bootstrapping the Gen3 ci_hsc dataset with minimal reliance on gen2convert (<a href=\"https://jira.lsstcorp.org/browse/DM-19614\" title=\"Write transmission curves in writeCuratedCalibrations\" class=\"issue-link\" data-issue-key=\"DM-19614\"><del>DM-19614</del></a>, <a href=\"https://jira.lsstcorp.org/browse/DM-19615\" title=\"Change raw storage class in isr task\" class=\"issue-link\" data-issue-key=\"DM-19615\"><del>DM-19615</del></a>, <a href=\"https://jira.lsstcorp.org/browse/DM-19622\" title=\"Make PosixDatastore&#39;s internal table lowercase\" class=\"issue-link\" data-issue-key=\"DM-19622\"><del>DM-19622</del></a>, <a href=\"https://jira.lsstcorp.org/browse/DM-19531\" title=\"Add option to include regions when ingesting gen3 images\" class=\"issue-link\" data-issue-key=\"DM-19531\"><del>DM-19531</del></a>, <a href=\"https://jira.lsstcorp.org/browse/DM-19272\" title=\"Make script for creating skymaps in gen3 bulter\" class=\"issue-link\" data-issue-key=\"DM-19272\"><del>DM-19272</del></a>) and improvements to gen2convert itself (<a href=\"https://jira.lsstcorp.org/browse/DM-18023\" title=\"Describe the DM-EFD deployment in SQR-029\" class=\"issue-link\" data-issue-key=\"DM-18023\"><del>DM-18023</del></a>), write a task/script that can be used to similarly bootstrap other Gen3 repos, starting with RC2.</p><p>Steps will include:</p><ul>\\t<li>register instrument(s)</li>\\t<li>add curated calibrations, via Instrument.writeCuratedCalibrations</li>\\t<li>register skymaps(s)</li>\\t<li>ingest raws, via RawIngestTask</li>\\t<li>add Gen2-calib-repo calibrations, refcats, and BrightObjectMasks via explicit, lower-level calls to gen2convert code in daf_butler.</li></ul><p>I do not currently plan to include actually creating the empty repository, which will save this task from having to somehow read in and apply overrides to butler yaml configuration.</p>\n",
            "<p>Under what conditions do we get 504s in JupyterHub?  How do we make it stop?</p>\n",
            "<p>When testing adding reference stars to fgcmcal, use the RC2 dataset to check that things are working and investigate questions of color terms / signal-to-noise / etc from the PS1 reference catalog.</p>\n",
            "nan\n",
            "nan\n",
            "<p>The use case for creating calibration products requires making creation of the Dataset distinct from (and prior to) the identification of its validity range.\\xc2\\xa0 That suggests we should replace the ExposureRange DataUnit with something like a \"CalibIdentifier\" (currently imagines as a string provided explicitly when running calib-creation PipelineTasks).\\xc2\\xa0 CalibIdentifier would also serve as the primary key of a new table with validity range fields, which would be used to define a view for a traditional DataUnitJoin between CalibIdentifier and Exposure.\\xc2\\xa0 That should remove the need for some special-casing of ExposureRange in preflight added on <a href=\"https://jira.lsstcorp.org/browse/DM-16482\" title=\"Add limited support for ExposureRange to Pre-flight\" class=\"issue-link\" data-issue-key=\"DM-16482\"><del>DM-16482</del></a>, and make it easier to refactor DataUnit code later.</p>\n",
            "<p>string.Template and string interpolation are quite weak, some additional feature would be welcomed :</p><ul class=\"alternate\" type=\"square\">\\t<li>interpolation interprets wrongly \"%d\" in template files as template</li>\\t<li>string.template doesn\\'t manage correctly non referenced template parameters present in template files.</li></ul>\n",
            "<p>After the work in <a href=\"https://jira.lsstcorp.org/browse/DM-18103\" title=\"Revisit SQuaSH InfluxDB data model\" class=\"issue-link\" data-issue-key=\"DM-18103\">DM-18103</a> document the SQuaSH InfluxDB data model.</p>\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/DM-18103\" title=\"Revisit SQuaSH InfluxDB data model\" class=\"issue-link\" data-issue-key=\"DM-18103\">DM-18103</a> we revisit the SQuaSH InfluxDB data model. </p><p>You can use this notebook to try different strategies mapping <tt>lsst.verify</tt> data to InfluxDB. You can also use it to \"manually\" synchronize the SQuaSH production database with an InfluxDB instance. </p>\n",
            "<p>Update the AOCLC (simulation only, not a CSC) to use the WEP and OFC interface classes). This is to make Chris easier to integrate the PhoSim with MTAOS. This is because both the simulation (without MTAOS) and control modes (with MTAOS + SAL) will use the same WEP and OFC interface classes.</p>\n",
            "<p>Implement a stress safety limit based off discussions with Ed and Doug.</p><p>\\xc2\\xa0</p><p>Ed is providing the matlab code to be implemented in C++.</p>\n",
            "<p>Rewrite ts_salobj to use OpenSplice dds and IDL files generated by ts_sal, instead of SALPY libraries.</p>\n",
            "<p>Implement <a href=\"https://jira.lsstcorp.org/browse/RFC-591\" title=\"Use schemas to define script configuration\" class=\"issue-link\" data-issue-key=\"RFC-591\"><del>RFC-591</del></a>: validate script configuration using jsonschema </p><p>Update ts_scriptqueue and also existing scripts in ts_standardscripts and ts_externalscripts</p>\n",
            "<p>Update ts_ScriptQueue to use the version of ts_salobj based on dds. This is primarily intended to exercise the new version of ts_salobj.</p>\n",
            "<p>During working on <a href=\"https://jira.lsstcorp.org/browse/DM-17825\" title=\"Examine bad subtractions\" class=\"issue-link\" data-issue-key=\"DM-17825\">DM-17825</a>, some missing docstrings marked as TODO in <a href=\"https://jira.lsstcorp.org/browse/DM-17458\" title=\"Complete docstrings in ip_diffim\" class=\"issue-link\" data-issue-key=\"DM-17458\">DM-17458</a> were updated.</p>\n",
            "<p>Option \"mysql_options( m, MYSQL_OPT_LOCAL_INFILE, 0 );\" is added to all C++ sql client instance due to common sql interface, but is only required on master (for merging results) is it possible: </p><ul class=\"alternate\" type=\"square\">\\t<li>to remove LOCAL keyword (on czar virtfile is on the same machine that mariadb server)</li>\\t<li>or to set it in Qserv czar/master configuration</li>\\t<li>or to set it in master MariaDB instance only?</li></ul>\n",
            "<p>The conda package versions should be updated as part of general house keeping at the start of each dev/release cycle.</p>\n",
            "nan\n",
            "<p>Bucket for writing and working on my IVOA Paris talk!</p>\n",
            "<p>This task is to track the effort to update the SAL messaging tests.\\xc2\\xa0 I want to maintain the individual message testing, so updating the scripts that generate the tests will be somewhat tricky.</p>\n",
            "<p>This task is to track the effort to update the SAL messaging tests.\\xc2\\xa0 I want to maintain the individual message testing, so updating the scripts that generate the tests will be somewhat tricky.</p>\n",
            "\"<p>I am preparing the visit to Paris' LSST team of Nick Mondrick from Harvard :</p><p>We will work on the Gemini measurement of Aerosols.</p>\"\n",
            "<p>Run full ci_hsc in Gen3 using weekly software release and Pegasus. Use Oracle backend if possible, otherwise sqlite3. Report any issues to appropriate dev teams.</p>\n",
            "<p>Development on New Scarlet during the Deblender Integration Sprint was rapid. Run the latest version of the scarlet and subsequent steps (which will run without crashing) the the chosen validation dataset. </p>\n",
            "<p>Modify multiband.py deblender command line task to use meas_extensions_scarlet instead of the scarlet functionality in meas_deblender</p>\n",
            "<p>Fix the two bugs identified by Yusra in <a href=\"https://jira.lsstcorp.org/browse/DM-19759\" title=\"Count Exception rates from New Scarlet\" class=\"issue-link\" data-issue-key=\"DM-19759\"><del>DM-19759</del></a>:</p><p>1. When exposures have different sized PSFs in different bands it fails AFW fails to make a PSF image.<br/>2. Some sources have so little flux that the sum of flux across all bands is less than zero, indicating that the source is just noise.</p><p>To fix (1) the plan is to fix <tt>afw.MultibandExposure.computePsfImage</tt> in <tt>meas_extensions_scarlet.deblend</tt> for the current sprint, and implement the change into <tt>afw</tt> next week.</p><p>To fix (2) the plan is to skip all sources that are too faint to be initialized as a <tt>PointSource</tt>.</p>\n",
            "nan\n",
            "<p>Due to an incompatibility between the stack and <tt>pytorch</tt>, it would be beneficial to switch the gradient calculation in scarlet from <tt>pytorch</tt> to <tt>autograd</tt>.</p>\n",
            "<p>MySQL password in written in multiple file during configuration procedure.<br/>One single file (QSERV_RUN_DIR/tmp/my.cnf) should be used, and removed at the end of configuration procedure. qserv-meta.conf also contains MySQL password and should be also secured (move password to qserv-configure.py cmd line?).</p>\n",
            "<p>Run full ci_hsc in Gen3 using weekly software release and Pegasus. Use Oracle backend if possible, otherwise sqlite3. Report any issues to appropriate dev teams.</p>\n",
            "\"<p>Chiller and White Light CSCs were separated at some point in the past because they were going to be in different languages and written by different people. Now they're both python and I'm working on both. So we've decided to simplify them a single CSC rather than a pair of CSCs with a third CSC coordinating.</p><p>This task is to bring the currently-existing code for the chiller into the White Light CSC, merge their SAL topics, and get a docker environment up and running for the new unified CSC.</p>\"\n",
            "<p>Put a glossary file in lsst-texmf\\xc2\\xa0 and let everyone know its there if they want to use glossary.</p><p>Provide script to give CSV for back loading to Magic Draw (include the acronyms ?)</p><p>Provide Script to modify tex files\\xc2\\xa0 and markup the found glossary items - for manual run by authors. (Does that include acronyms ?) ..</p><p>\\xc2\\xa0</p>\n",
            "<p>Integrate the WEP into MTAOS.</p>\n",
            "<p>Submit cases to the ADlink issue management system and assist with <br/>investigation on the LSST side (of dds native python interface usage)</p>\n",
            "<p>Attend planning meetings, review documents and software in preparation  for<br/>the planned June workshop on TMA software at Tekniker</p>\n",
            "<p>Prototype a SAL API based in the OpenSpliceDDS native python interface,<br/>and add distribution to ts_opensplice for V6.9 community including the python<br/>asserts pre-built</p>\n",
            "<h2><a name=\"%C2%A0\"></a>\\xc2\\xa0</h2><p>start software development of chiller csc.</p><p>Phase 1 includes planning and developing hardware communications layer</p><p>this ticket duplicates TSS-3458, which was accidentally created under the wrong project.\\xc2\\xa0</p>\n",
            "<p>Run full ci_hsc in Gen3 using weekly software release and Pegasus. Use Oracle backend if possible, otherwise sqlite3. Report any issues to appropriate dev teams.</p>\n",
            "<p>Run full ci_hsc in Gen3 using weekly software release and Pegasus. Use Oracle backend if possible, otherwise sqlite3. Report any issues to appropriate dev teams.</p>\n",
            "<p>Update ts_phosim (from ts_tcs_wep_phosim) to use eups and documenteer and add dependency to ts_wep. This is to unify the package manager and reduce the code redundancy. This task will also update the configuration files to use the yaml format.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2019_18. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Monthly test to catch issues early</p>\n",
            "<p>Update logging on ATHS to be directed to a file in addition that to the scree.</p>\n",
            "\"<p>Write an external script utilizing the scriptqueue BaseScript class that utilizes two linear stages which are at right angles. The TunableLaser will propagate at a wavelength or wavelength ranges. The linear stages will then move in step increments as the laser is propagating. The electrometer will then be read from as each increments occurs. The data from each CSC will then be put into a data file. Then a plot(not part of script) will be generated from the resulting data.</p><p>The idea is to use test-driven development to ensure that a. unit tests are written and b. that code logic is good. Unit tests using CSCs have been written using a Harness which wraps certain calls in mocks to ensure that only consistent software logic is being used.</p><p>The task ultimately became a part of Nick's visit as outlined by dm-17694 and dm-17943. Because of some issues with SAL and the private network along with some weird CSC. This task produced an early version of the script without the laser but is configurable to run in such a manner with or without the laser as part of the script.</p>\"\n",
            "nan\n",
            "<p>This shall let the MTAOS to use the functions in WEP with the simulated PhoSim images. At this moment, only ComCam is supported. The integration with corner WFS will hold until the SIMS supports the obs_lsst.</p>\n",
            "nan\n",
            "<p>Investigate Kafka for Influx EFD implementation.</p>\n",
            "<p>Vendor released latest version of pointing component. Initial tests showed some issues with the component that need to be addressed and may have shown an issue with SAL 3.9/SalObj 3.11.0. This task will be used to continue testing the pointing component  and SAL. </p><p>Following Dave\\'s suggestion I will spin up a EFD for the components to monitor the SAL traffic. I will also use this task to document a procedure on running integration and test on stage machines. </p><p>Documentation will go here: </p><p><a href=\"https://confluence.lsstcorp.org/display/LTS/Integration+Testing+and+Deployment+Development+Procedure\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/LTS/Integration+Testing+and+Deployment+Development+Procedure</a></p>\n",
            "<p>At the <a href=\"https://confluence.lsstcorp.org/display/DM/DM+Leadership+Team+Face-to-Face+Meeting%2C+2017-11-01+to+03\" class=\"external-link\" rel=\"nofollow\">DMLT face to face meeting in November 2017</a>\\xc2\\xa0it was requested that the Level 1 requirements in DMSR (as defined by LDM-148) be flowed down into LDM-602 to seed the L1 System Requirements. This ticket is to do that flowdown in the MagicDraw model and to issue a first draft of LDM-602.</p>\n",
            "<p>This task will cover the effort going over the TMA Agenda which will include meetings with Shawn to go over and assist in any activities. Meeting with Sandrine to cover high level view of the TMA project that she has agreed to go over with me. And reading documentation with Tiago to gather knowledge and better assist in identifying what requirements we are missing or need from Tekniker.\\xc2\\xa0</p>\n",
            "<p>The proposal here is to apply the same framework established in imgserv to build a standalone container image for metaserv, to be taken out of webserv container, which can then be deployed to lss-lsp-int and lsst-lsp-stable.</p><p>After this work, the webserv container, which built lsst_stack from source, can be retired from DAX.</p>\n",
            "<p>Each alert packet should record the version of the schema which was used to generate it.</p><p>Also include some instructions for backwards compatibility.</p>\n",
            "<p>The QA dashboard project will require some way to look up information on source matching between visits and coadds.  As <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=lauren\" class=\"user-hover\" rel=\"lauren\">Lauren MacArthur</a> and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=yusra\" class=\"user-hover\" rel=\"yusra\">Yusra AlSayyad</a> and I discussed a few weeks ago, one simple way to do this would be to write a match table that persists this information.  This table would be per-tract, and indexed by coadd ID, contain a column for each visit, the contents of which would be the best match ID (if exists) from the corresponding visit table.</p><p>The actual matching algorithm can be improved in the future; for now, I will implement what I was doing before when I was making MatchedCatalog objects for the visit-level notebook visualization stuff I was previously working on.</p>\n",
            "<p>Give demo of LSST science platform at AURA member reps</p><p>Time allocated for each demo is 25 +10 mins.\\xc2\\xa0 There will be 3 *\\xc2\\xa0 25+10 min identical presentations to 3 groups in the one afternoon.</p>\n",
            "<p>As part of the testing of and development of CSC, and in particular for the L1 NCSA Test Stand we need a utility that can test and verify the reception and acks of command for transitioning states. This is particularly useful when testing new version of SAL.</p>\n",
            "<p>Add standalone dax_imgserv, and dax_metaserv docker builds to Jenkins CI, under the old webserv, as moniker.</p><p>\\xc2\\xa0</p><p>As Josh suggested, this is to be done via a PR on lsst-sqre/jenkins-dm-jobs.</p>\n",
            "<p>Add option to add regions to gen3 butler when ingesting raw images</p>\n",
            "\"<p>Jointcal does some odd things when building its RefStar catalog (<tt>Associations::collectRefStars</tt>), including creating fake errors (maybe because the original reference catalogs didn't have useful errors?), making a magnitude from the flux (is that really necessary? Why can't we work in flux units here?), and making <tt>BaseStars</tt> followed by a cast, when it should just be able to make <tt>RefStars</tt>.</p>\"\n",
            "<p>The configuration loading and logging are common across all services.   This should be moved into the base class to avoid code duplication and/or errors in referencing.</p>\n",
            "<p>Prepare a poster for the Planetary Defence Conference describing pytrax and the comparison between it and classical MOPS described in <a href=\"https://jira.lsstcorp.org/browse/DM-16760\" title=\"Validation of MPC Pytrax\" class=\"issue-link\" data-issue-key=\"DM-16760\"><del>DM-16760</del></a></p>\n",
            "<p>Transmission curves should be written to the butler when writing human curated calibration products</p>\n",
            "<p>Have discussions (with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=fritzm\" class=\"user-hover\" rel=\"fritzm\">Fritz Mueller</a>) and plan design for features needed at web service level for workers and out of replication framework to get the information we need out of them for a Qserv devops level dashboard.</p>\n",
            "<p>The butler yaml configuration system might need some tweaking. Investigate <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mgower\" class=\"user-hover\" rel=\"mgower\">Michelle Gower</a>\\'s problem and possibly adjust how overrides work.</p>\n",
            "nan\n",
            "<p>Going to split out the deployment scripts into 3: one for dev (google), one for int (NCSA) and one for stable (NCSA).</p>\n",
            "nan\n",
            "<p>Our LaTeX templates are current part of <a href=\"https://github.com/lsst/lsst-texmf.\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/lsst-texmf.</a>\\xc2\\xa0Let\\'s move them into the centralized templates repository so that we can make it available to sqrbot/templatebot.</p>\n",
            "<p>Migrate the cookiecutter templates for creating reStructuredText technotes into <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/templates</a> so that they can become available through templatekit and SQuaRE Bot on Slack:</p><ul class=\"alternate\" type=\"square\">\\t<li><a href=\"https://github.com/lsst-sqre/lsst-technote-bootstrap\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/lsst-technote-bootstrap</a> (reStructuredText)</li></ul>\n",
            "<p>WLS CSC needs to implement state transitions:</p><p>-upon receiving relevant SAL commands</p><p>-upon receiving an error signal from the KiloArc hardware</p><p>-in the event of communication loss between host computer and ADAM hardware</p>\n",
            "<p>The purpose of this ticket is to implement <tt>templatekit.yaml</tt> files in the templates repository. These files customize and refine the experience of generating files and projects from Slack with tempatekit and templatebot. <tt>templatekit.yaml</tt> files are being concurrently designed in <a href=\"https://jira.lsstcorp.org/browse/DM-18405\" title=\"Support configuration in templates for Slack-based usage\" class=\"issue-link\" data-issue-key=\"DM-18405\"><del>DM-18405</del></a>.</p>\n",
            "<p>STScI has asked me (<a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jsick\" class=\"user-hover\" rel=\"jsick\">Jonathan Sick</a>) to give an engineering colloquium about LSST\\'s documentation engineering work. Although this is a general talk, it\\'s relevant to the\\xc2\\xa0 <a href=\"https://jira.lsstcorp.org/browse/DM-16250\" title=\"technote creation via squarebot \" class=\"issue-link\" data-issue-key=\"DM-16250\">DM-16250</a>\\xc2\\xa0epic because such a talk describes in detail the template ecosystem that technote creation via Slack exists within.</p>\n",
            "<p>Understand numerical description data (size of files, required RAM and disk space)</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2019_14. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>When running `constructDark.py` on an auxtel dark (2019030800135, see below), the following error appears:\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>lsst::pex::exceptions::LengthError: \\'Too many CR pixels (max 500000)\\'</p><p>\\xc2\\xa0</p><p>Visual inspection of\\xc2\\xa0</p><p>\"AT_O_20190308_000135-ats-wfs_ccd.fits\" (see directory below) shows that there are not as many CR\\'s.</p><p>-Data (see IMGTYPE in headers for types, which follows the entry in\\xc2\\xa0<a href=\"https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=SYSENG&amp;title=LogBook+for+AuxTel+camera+diagnostic+data+taking\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=SYSENG&amp;title=LogBook+for+AuxTel+camera+diagnostic+data+taking</a> under MAR08, 2019):\\xc2\\xa0</p><p>/project/plazas/data/auxtel_DMCS_images_2019-03-08/cal</p><p>-ID:\\xc2\\xa0</p><p>WARN: Unable to process DataId(initialdata={\\'imageType\\': \\'DARK\\', \\'dayObs\\': \\'2019-03-08\\', \\'visit\\': 2019030800135, \\'detector\\': 0, \\'detectorName\\': \\'S00\\'}</p><p>-Command run:\\xc2\\xa0</p><ul>\\t<li>constructDark.py /project/plazas/calibrations_auxtel_mar20_REPO --calib /project/plazas/calibrations_auxtel_mar20_CALIB/ --output /project/plazas/calibrations_auxtel_mar20_OUTPUT/ --id imageType=\\'DARK\\' --batch-type none --clobber-config</li></ul><p>stack: \"w_2019_11\" with branch \"tickets/<a href=\"https://jira.lsstcorp.org/browse/DM-18051\" title=\"Get defect machinery working for the AuxTel\" class=\"issue-link\" data-issue-key=\"DM-18051\"><del>DM-18051</del></a>\" of \"obs_lsst\"</p>\n",
            "<p>Registering a skymap with a gen3 butler should be done in a transaction block, this should greatly speed up registering.</p>\n",
            "<p>Speed up certain operations by allowing vectorized dimention entry inserts.</p>\n",
            "nan\n",
            "nan\n",
            "<p>1) Build disk pools on the SFA 7990</p><p>2) Create GPFS L1 Cluster on the SFA 7990</p><p>3) Create GPFS L1 File System on the SFA 7990</p><p>4) Create racking/un-racking procedures for the SFA 7990</p>\n",
            "<p>MultiProFit supports Gaussian mixture models, which can be fit using linear fitters (<a href=\"https://jira.lsstcorp.org/browse/DM-18105\" title=\"Implement linear fitter in MultiProFit\" class=\"issue-link\" data-issue-key=\"DM-18105\"><del>DM-18105</del></a>), e.g. after initializing from a Sersic multi-Gaussian approximation. This implements an intermediate method of fitting the sizes of Gaussian mixture models by keeping the ratios of the sizes of groups of Gaussians fixed while fitting a single multiplicative scale radius, analogous to the Sersic profile\\'s effective radius.</p>\n",
            "<p>MTDome SW Planning Meetings at Vendor Site (EIE-Italy)</p>\n",
            "<p>Part 2 of the thermal software skeleton.</p>\n",
            "<p>LDM-503-09a \\xe2\\x80\\x9cPipelines Release Fall 2018\\xe2\\x80\\x9d</p><p>Pending release procedure ... though the test we run should not depend on that,.</p>\n",
            "<p>LDM-503-07 \"Camera Data Processing\" originally to be done post review.\\xc2\\xa0 The test is supposed to be in Novemeber.</p>\n",
            "<p>This task will use the yaml to manage the configuration files. This task is the phase 2. I need to merge the lsst an comcam configuration files.</p>\n",
            "<p>Get tests from Tony and include in SAL - or at least make them like SalObj tests</p>\n",
            "<p>status.lsst.codes died.  Replace with a similar thing this time, but also plan to k8sify it.</p>\n",
            "nan\n",
            "<p>I\\'m seeing artifacts along patch boundaries in difference images, anywhere a source falls exactly on the boundary. My guess is this is caused by the model at the edge of the patch being cut off right at the bounding box, and then shifted for DCR. The DCR shift should be applied first to a larger region with a buffer of several pixels around the edges, and only trimmed to the bounding box later. <span class=\"image-wrap\" style=\"\"><img src=\"https://jira.lsstcorp.org/secure/attachment/37321/37321_Screen+Shot+2019-03-20+at+2.17.33+PM.png\" style=\"border: 0px solid black\" /></span></p>\n",
            "<p>Investigate storing and retrieving of a defects list calibration product from gen 3 butler.</p><p>It\\'s not yet clear where the code for doing this would end up. Special formatters will need to be written to ensure that \"list of defect\" is returned and not an afw Catalog. Need to decide whether it\\'s meas_algorithms or obs_base.</p>\n",
            "<p><b>Reran RC2 dataset through the following 3 configurations:</b></p><ul>\\t<li>coaddDriver/multiband lanczos5 rerun (to be used for scientific performance studies): e.g. see <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=dtaranu\" class=\"user-hover\" rel=\"dtaranu\">Dan Taranu</a>\\'s <a href=\"https://nbviewer.jupyter.org/github/lsst-dm/modelling_research/blob/master/jupyternotebooks/psf_models_rc2.ipynb\" class=\"external-link\" rel=\"nofollow\">https://nbviewer.jupyter.org/github/lsst-dm/modelling_research/blob/master/jupyternotebooks/psf_models_rc2.ipynb</a></li></ul><p><tt>/datasets/hsc/repo/rerun/private/yusra/RC2/w_2019_06_lanczos5</tt></p><ul>\\t<li>lanczos5 makeCoaddTempExp rerun for metadata extraction:<tt>/datasets/hsc/repo/rerun/private/yusra/RC2/w_2019_06_lanczos5_dir</tt></li></ul><ul>\\t<li>lanczos3 makeCoaddTempExp rerun for metadata extraction:<br/> <tt>/datasets/hsc/repo/rerun/private/yusra/RC2/w_2019_06_lanczos3_dir</tt></li></ul>\n",
            "<p>Per <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=bvan\" class=\"user-hover\" rel=\"bvan\">Brian Van Klaveren</a>,</p><p><em>imgserv should parse the authentication token, added to the incoming URL request, and log the user name only. The token is expected to be in [JWT |<a href=\"https://en.wikipedia.org/wiki/JSON_Web_Token\" class=\"external-link\" rel=\"nofollow\">https://en.wikipedia.org/wiki/JSON_Web_Token</a>] format.</em></p><p>\\xc2\\xa0</p>\n",
            "<p>Update Generic Camera CSC to be more ATCamera-like.</p>\n",
            "<p>Get the 2 L1 Handoff Servers set up with a base image and prepare them so that they can be provisioned and re-provisioned once installed at the base.\\xc2\\xa0</p><p>1) Build OS Raid virtual disk</p><p>2) Get MAC addresses for\\xc2\\xa0integration with base xcat</p>\n",
            "<p>This task will evaluate the integration between influxDB and influx_writer of SAL. This task will also benchmark the performance of InfluxDB to use the SSD, NVME, or hard disk.</p><p>Compare the MariaDB quary language and InfluxDB quary language.</p><p>Evaluation steps:</p><ol>\\t<li>Check with the AT CSC owners with the telemetry rate according to the page: <a href=\"https://confluence.lsstcorp.org/display/SYSENG/Auxiliary+Telescope+Control+Computers+in+Tucson\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/SYSENG/Auxiliary+Telescope+Control+Computers+in+Tucson</a></li>\\t<li>Clone the ts_sal repository to the /home/ttsai. Install the SAL and build the AT CSC test scripts I need. Make sure the sal version is 3.9 and opensplice version is 6.9.</li>\\t<li>Change the test telemetry script to run infinity times (iseq in C++)\\xc2\\xa0with the correct telemetry frequency (delay_1s in C, the first argument is sec and the second is nano-sec).</li>\\t<li>Run the test for SSD, NVME, and Disk.</li>\\t<li>The path variable of \"LSST_EFD_HOST\" gives the IP_address of influxDB.</li>\\t<li>I can do \"./some_writer &gt;&amp; log.1 &amp;\" to run the writer in the background. And I can use \"tail -f log.1 to see the log file\".</li>\\t<li>Once I changed the cpp file, I can go to the \"stand_alone\" directory and do \"make -f Makefile.sacpp_blahblak_pub\" to build the code in the same directory.</li>\\t<li>I can also do the above modifications by python.</li></ol>\n",
            "<p>Apparently coincident with the merge of <a href=\"https://jira.lsstcorp.org/browse/DM-18643\" title=\"Move AstrometryTask source selection from &quot;matcher&quot; into AstrometryTask\" class=\"issue-link\" data-issue-key=\"DM-18643\"><del>DM-18643</del></a>, there was a significant regression in astrometric metrics associated with validate_drp as tracked by SQuaSH. (e.g. between 2019-04-13 and 2019-04-16, AM1 went from 7.9 to 12.3 mas, AD1 from 14.6 to 119.6 mas, etc). Please investigate what happened and (if appropriate) put in a fix.</p>\n",
            "<p>While validating the fix in <a href=\"https://jira.lsstcorp.org/browse/DM-19265\" title=\"Jacobian lost in meas_mosaic photometric solution\" class=\"issue-link\" data-issue-key=\"DM-19265\"><del>DM-19265</del></a>, it was noted that there are differences in the uber calibration results from both <tt>jointcal</tt> and <tt>meas_mosaic</tt> between recent weekly runs of the RC2 dataset.  As the plots on <a href=\"https://jira.lsstcorp.org/browse/DM-19265\" title=\"Jacobian lost in meas_mosaic photometric solution\" class=\"issue-link\" data-issue-key=\"DM-19265\"><del>DM-19265</del></a> show, there have been some subtle changes from <tt>w_2019_06</tt>&#45;to&#45;<tt>w_2019_10</tt>&#45;to&#45;<tt>w_2019_14</tt>.  The differences are small (stdev of difference is at the sub mmag level), but it is still important that we understand where they originated.  Since both algorithms are affected, the route cause must be something that effects both.  A first guess would be something about how object selection is being done.</p>\n",
            "<p>The two `countsTo*` methods that operate in-place on SourceCatalogs in PhotoCalib are marked \"not implemented\" due <a href=\"https://jira.lsstcorp.org/browse/RFC-322\" title=\"Rename &quot;*_flux&quot; fields to &quot;*_instFlux&quot; in SourceCatalogs\" class=\"issue-link\" data-issue-key=\"RFC-322\"><del>RFC-322</del></a>. Once that RFC is completed and the necessary key name changes are in place, we can finally implement those methods.</p><p>We might want to consolidate them into a single <tt>countsToFluxAndMagnitude</tt>, since if we\\'re iterating over the catalog anyway, might as well do all the math at once.</p>\n",
            "nan\n",
            "<p>Need to update EXPTIME to capture the request exposure time from the takeImages command.</p><p>The computed exposure time from shutter motion profile will be now directed to\\xc2\\xa0SHTTIME. Finally,\\xc2\\xa0DATE-BEG will be added to comply with LSE-400.</p>\n",
            "<p>This ticket is\\xc2\\xa0to\\xc2\\xa0gather information for numerical data display for LSST data in SUIT.\\xc2\\xa0</p><p>Current Firefly displays 6 digits after decimal point by default. This may not be best for some data. We need to have a plan either specify the precision for each column in table data, or have a guideline for precision for different type of data, i.e ra, dec, magnitude, flux, error, ...</p>\n",
            "<p>OCSBridge is not currently logging. Since Forwarder logging seems to be stable, we should integrate logging style from Forwarder to OCSBridge.</p>\n",
            "<p>MultiProFit should use a linear fitter when fitting models with linear parameters, namely source/component fluxes. This is already implemented in meas_modelfit for CModel but would be useful any multi-component, single-source model, as well as multi-source fitting.</p>\n",
            "<p>MTDome SW Planning Meetings at Vendor Site (EIE-Italy)</p>\n",
            "<p>Add unit test framework to\\xc2\\xa0<a href=\"https://github.com/oorb/oorb\" class=\"external-link\" rel=\"nofollow\">OpenOrb</a> (our adopted orbit integration engine).</p><p>This includes:\\xc2\\xa0</p><ul>\\t<li>A make target so running \\'make test\\' will execute all unit and integration tests</li>\\t<li>A few example unit tests (for versioning functionality)</li>\\t<li>Running the python/test.py integration test</li></ul><p>Unit test framework will use pytest. The idea is that all code (including command line utilities) will be tested via pytest drivers (to maintain uniformity).</p><p>The work will be on\\xc2\\xa0<a href=\"https://github.com/mjuric/oorb/tree/build-system-rework,\" class=\"external-link\" rel=\"nofollow\">https://github.com/mjuric/oorb/tree/build-system-rework,</a>\\xc2\\xa0and will be PR-ed upstream upon completion.</p>\n",
            "<p>pyvo.describe throws an exception, so when you run:</p><p>\\xc2\\xa0</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> pyvo</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">service </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> pyvo.dal.TAPService(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'https://lsst-lsp-stable.ncsa.illinois.edu/api/tap\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">service.describe()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Throws this:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">TypeError: homogeneous list must contain only objects of type \\'&lt;class \\'pyvo.io.vosi.voresource.SecurityMethod\\'&gt;\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>\\xc2\\xa0</p><p>It looks like it is choking on the security method parts of the capabilities file, but I\\'m not exactly sure why yet.</p>\n",
            "<p>In order to easily parallelize validate_drp\\'s data loading, we need, at minimum, to be able to pickle/unpickle <tt>afw.table.Schema</tt> objects. This may or may not be made more difficult by the <tt>SchemaImpl</tt> design: I suspect a pybind11 master would have some ideas for how to do this relatively quickly.</p><p>Pickling support pybind11 docs for reference:<br/><a href=\"https://pybind11.readthedocs.io/en/stable/advanced/classes.html#pickling-support\" class=\"external-link\" rel=\"nofollow\">https://pybind11.readthedocs.io/en/stable/advanced/classes.html#pickling-support</a></p>\n",
            "<p>This also involves updating how <tt>validate_drp</tt> discovers specs in the report making process.</p>\n",
            "<p>Produce a single jumping-off point for documentation on all aspects of Level 3, on Confluence.  Ensure that flowdown for existing Level 3 requirements in SysML is modeled.  Describe the high-level conceptual design.</p>\n",
            "<p>Review existing requirements in this area.  Find all relevant existing project-controlled and other key documents.</p>\n",
            "<p>Many of the EAS sensors have a requirement for SAL support on an embedded system<br/>(Raspberry Pi). Create a reference implementation and consult with the developers to deinfe the appropriate generic EAS XML for the various sensor types</p>\n",
            "<p>Time spent going to Labview training.\\xc2\\xa0</p>\n",
            "<p>C++ files have log directory set to current running directories. Those log files should move out from the repo and store at the place where config file specifies log directory is.</p>\n",
            "<p>Get three hosts in NCSA nebular system to deploy the current Firefly application. The goal is workout the possible issues and identify the software needed to be installed for the hosts. Clarify which team is responsible to install what third-party software packages.</p>\n",
            "<p>We have had multiple request for the search panel drop down to be able to be resizable in certain cases such as the TAP search panel, catalog search panel and the image search panel.</p><p>Implement an option so that a search panel can be resizable based on available space.\\xc2\\xa0 Implement this in the TAP search panel.\\xc2\\xa0 You could do the Image search panel if time permits.</p>\n",
            "<p>I was testing the new metadata translator on FITS file I had lying around in testdata repositories and I see that our calibration products do not seem to have a reasonable set of headers.  The only indication this is a HSC calibration file rather than an LSST one is the path name to the root directory.</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">SIMPLE  =                    T / file does conform to FITS standard             </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">BITPIX  =                  -32 / number of bits per data pixel                  </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">NAXIS   =                    2 / number of data axes                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">NAXIS1  =                 2048 / length of data axis 1                          </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">NAXIS2  =                 4176 / length of data axis 2                          </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">EXTEND  =                    T / FITS dataset may contain extensions            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">COMMENT   FITS (Flexible Image Transport System) format is defined in \\'Astronomy</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">COMMENT   and Astrophysics\\', volume 376, page 359; bibcode: 2001A&amp;A...376..359H </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">OBSTYPE = \\'bias    \\'                                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_CREATION_DATE = \\'2016-03-28\\'                                     </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_CREATION_TIME = \\'16:16:33 EDT\\'                                   </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_CREATION_ROOT = \\'/tigress/HSC/HSC/rerun/dm-5124/calib\\'           </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_0 = \\'(904542,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_1 = \\'(904544,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_2 = \\'(904546,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_3 = \\'(904548,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_4 = \\'(904550,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_5 = \\'(904552,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_6 = \\'(904554,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_7 = \\'(904556,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_8 = \\'(904558,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_9 = \\'(904560,)\\'                                            </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_10 = \\'(904562,)\\'                                           </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_11 = \\'(904564,)\\'                                           </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH CALIB_INPUT_12 = \\'(904566,)\\'                                           </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CALIB_ID= \\'filter=NONE calibDate=2013-11-03 ccd=50\\'                             </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">HIERARCH MD5_IMAGE = \\'6185bb72f20de7e81c45e6e6591eb6ad\\'                         </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CRVAL1A =                    0 / Column pixel of Reference Pixel                </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CRVAL2A =                    0 / Row pixel of Reference Pixel                   </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CRPIX1A =                    1 / Column Pixel Coordinate of Reference           </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CRPIX2A =                    1 / Row Pixel Coordinate of Reference              </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CTYPE1A = \\'LINEAR  \\'           / Type of projection                             </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CTYPE2A = \\'LINEAR  \\'           / Type of projection                             </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CUNIT1A = \\'PIXEL   \\'           / Column unit                                    </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">CUNIT2A = \\'PIXEL   \\'           / Row unit                                      </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>At minimum there should be INSTRUME/TELESCOP headers but ideally we should be able to construct a full header based on all the input headers (propagating headers that are identical and indicating which headers define bounds). The latter is what I implemented at the JCMT Science Archive for all data products.  It might be that another approach is to at least be able to generate a standard set of headers from the information the Butler (Gen 3) knows about each dataset.</p>\n",
            "<p>Following conversations around Feb. 8th 2019 in #dm-bootcamps (for some reason) it is noted that `obs_lsst` will need to be extended/enhanced to support BOT* data when it becomes available.</p><p>How this looks will depend on exactly when that happens, and whether version-able cameras are a reality by then, as this data will necessitate that.</p><p>*Bench for Optical Test - the IR2 test station where real data from the real camera will be taken as it is populated with rafts</p>\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/DM-5466\" title=\"obs_decam calibration ingest uses fragile relative paths\" class=\"issue-link\" data-issue-key=\"DM-5466\"><del>DM-5466</del></a>, we needed to pass the results from <tt>ParseTask.getInfo()</tt> to the butler as a dataId. This is normally valid, since both are dictionaries, and even though <tt>getInfo()</tt> often contains extraneous entries that aren\\'t relevant, the butler will usually ignore them. However, when parsing calibration files this dictionary contains some values that are set to <tt>None</tt>, since they will be filled in later. These extraneous keys are then placed in <tt>ButlerLocation.additionalData</tt> (<a href=\"https://github.com/lsst/daf_persistence/blob/master/python/lsst/daf/persistence/butlerLocation.py#L221\" class=\"external-link\" rel=\"nofollow\">butlerLocation.py:221</a>), which throws an exception as it is a PropertySet and does not support python <tt>None</tt> as a value.</p><p><a href=\"https://jira.lsstcorp.org/browse/DM-5466\" title=\"obs_decam calibration ingest uses fragile relative paths\" class=\"issue-link\" data-issue-key=\"DM-5466\"><del>DM-5466</del></a> has a work-around that strips these None values from the dictionary, but this is inelegant. The main driver for excluding None from PropertySet seems to compatibility with FITS headers. This seems like an unwarranted mixing of data model and persistence formats. Unless there is some advantage to not being able to store None in our dictionary-like objects, it seems preferable to shift the burden of accommodating FITS\\'s peculiarities onto the persistence layer rather than PropertySet. </p>\n",
            "<p>Following discussions on <a href=\"https://jira.lsstcorp.org/browse/DM-18170\" title=\"Create command line ingest arg to force header key\" class=\"issue-link\" data-issue-key=\"DM-18170\">DM-18170</a> and with Robert Lupton, I am going to add infrastructure support to astro_metadata_translator to allow files to be written that will contain updates to headers.</p><p>I am proposing:</p><p>1. Pre-examine the header, determine the instrument and obsid.<br/>2. Look for a file of name relating to the OBSID (yaml or maybe JSON containing override values for specific headers).<br/>3. Apply the corrections from that file to the header.</p><p>There will be a standalone function for automatically updating a header, and support inside the ObservationInfo constructor to apply the correction automatically. The location of the correction files is an interesting discussion but will probably be per-translator specific but allow overrides using a PATH-like environment variable.</p>\n",
            "<p>It is necessary for a datastore to be able to specify a list of datasetTypes that are supported, or a list that are unsupported. For posixdatastore this can currently happen by a StorageClass not being listed as a formatter, but a more general approach is needed. In particular, it may be that an InMemoryDatastore should only cache a subset of datasettypes when used as part of a ChainedDatastore.</p><p>I think we need to support allow lists and deny lists, although it only makes sense to specify one of those options in a particular configuration (allow means only those listed should be allowed so deny becomes superfluous).</p>\n",
            "<p>Install  and test the EFD writers for Influxdb built against the latest OpenSplice</p>\n",
            "\"<p>Peak culling was introduced to remove false detections around bright stars. Now it's been observed (with better sky subtraction and deeper images) that real sources are being culled. Ikeda-san is trying different parameter combinations.</p>\"\n",
            "<p>The <tt>deprecated</tt> package will probably not be available by the time I\\'m ready to merge <a href=\"https://jira.lsstcorp.org/browse/DM-10156\" title=\"Replace all uses of Calib with PhotoCalib\" class=\"issue-link\" data-issue-key=\"DM-10156\"><del>DM-10156</del></a>. This is unfortunate, but I don\\'t want to delay merging that ticket, given the number of packages involved. I\\'m going to implement the various deprecated interfaces there, but they will only provide deprecation warnings at the C++ level, not python.</p><p>This ticket is to add deprecation warnings to the python layer for all <tt>getCalib</tt>, <tt>setCalib</tt>, <tt>hasCalib</tt> methods in afw. <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ktl\" class=\"user-hover\" rel=\"ktl\">Kian-Tat Lim</a> and I may have to iterate on exactly how best to do that deprecation decoration.</p>\n",
            "<p>Do the research of InfluxDB and Kafka and learn how to use them. This is based on the discussion of EFD meeting:</p><p><a href=\"https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=LTS&amp;title=2019-03-29+EFD+Meeting+notes\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=LTS&amp;title=2019-03-29+EFD+Meeting+notes</a></p><p>\\xc2\\xa0</p>\n",
            "<p>Validate performance on the SFA 7990 with understanding that it is currently only populated with 20 drives for the initial configuration.</p>\n",
            "nan\n",
            "<p>Test ATDome CSC at the summit, for this task I will need the ATDome CSC ready for deployment. Initially is planned for the first week of April but can change depending on\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rowen\" class=\"user-hover\" rel=\"rowen\">Russell Owen</a> feedback.</p>\n",
            "<p>Modify the lua plugin so that the SELECT statement used to return results to workers is entirely generated by the Qserv C++ code.</p>\n",
            "<p>Develop a skeleton for the M1M3 thermal system software.</p>\n",
            "<p>Update the WEP package to use the eups package manager. This is to fulfill the requirement of LTS-186 to put the WEP into the scientific pipeline. The OFC is using the eups now. This task will need to fix the pep-8 syntax error by flake8 and follow the naming convention of test script. This task will also add the package dependency to the eups configuration file. This task may also need to fix the bugs for the new version of scientific pipeline and phosim_utils. The previous scientific pipeline used in WEP is w_2019_02.</p>\n",
            "\"<p>Integrate and test the MTAOS usage of OFC's controller interfaces.</p>\"\n",
            "<p>The ticket echos one of the tasks listed by C. Stubbs on <a href=\"https://confluence.slac.stanford.edu/display/LSSTDESC/AuxTel+effort\" class=\"external-link\" rel=\"nofollow\">https://confluence.slac.stanford.edu/display/LSSTDESC/AuxTel+effort</a></p><p>\"build system to interrogate and delivery satellite-based ozone measurements, with appropriate metadata and uncertainties\"</p><p>A first version of the script has been written which retrieves from the NASA server the ozone value for a given date and given site.</p><p>It could be further expended to access other parameters.</p>\n",
            "nan\n",
            "<p>DESC reported that running jointcal on Run2.1i did not improve the photometric repeatability (esp. wrt the reference catalog) relative to processCcd.  This is not surprising because:<br/>1) The reference catalogs are near perfect and to full depth &lt; 23.  They essentially are the input catalogs, and therefore jointcal\\'s benefit of bootstrapping deeper stars is not realized.<br/>2) There is no vignetting or sub-ccd throughput variability in the imsim images in Run2.1i.  Therefore, the photoCalTask model of \"1 zeropoint per ccd\" is the correct model, and jointcal\\'s ability to have variable throughput across the focal plane and per ccd is not needed.</p><p>However, various test plots (either via <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jchiang\" class=\"user-hover\" rel=\"jchiang\">James Chiang</a> or the <tt>visitAnalysis</tt> scripts) show that the calibrated photometry is only consistent with the reference catalogs at the 13-16 mmag level, which is <em>much</em> larger than I would expect for clean simulated data for bright stars (basically, I would expect few mmag consistency).</p><p>This ticket is to describe work to see where in processCcd/jointcal things are going wrong.</p>\n",
            "<p>I came across the following log record from processCcd-ing HSC data <tt>--id visit=38950 ccd=64</tt></p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.charImage.measurePsf.makePsfCandidates WARN: Failed to make a psfCandidate from star </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">33458070113746946</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"src/image/Image.cc\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">84</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">static</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> lsst::afw::image::ImageBase&lt;PixelT&gt;::_view_t lsst::afw::image::ImageBase&lt;PixelT&gt;::_makeSubView(</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> Extent2I&amp;, </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> Extent2I&amp;, </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> _view_t&amp;) [with PixelT = </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">float</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">; lsst::afw::image::ImageBase&lt;PixelT&gt;::_view_t = boost::gil::image_view&lt;boost::gil::memory_based_2d_locator&lt;boost::gil::memory_based_step_iterator&lt;boost::gil::pixel&lt;</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">float</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, boost::gil::layout&lt;boost::mpl::vector1&lt;boost::gil::gray_color_t&gt; &gt; &gt;*&gt; &gt; &gt;; lsst::geom::Extent2I = lsst::geom::Extent&lt;</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">int</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    Box2I(Point2I(</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">470</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">,-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">),lsst::geom::Extent2I(</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">21</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">,</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">21</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)) doesn\\'t fit in image 2048x4176 {</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"src/PsfCandidate.cc\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">182</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in std::shared_ptr&lt;lsst::afw::image::MaskedImage&lt;ImagePixelT1, </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">int</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">float</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt; &gt; lsst::meas::algorithms::PsfCandidate&lt;PixelT&gt;::extractImage(unsigned </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">int</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, unsigned </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">int</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">) </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> [with PixelT = </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">float</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    Extracting image of PSF candidate {</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">lsst::pex::exceptions::LengthError: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'Box2I(Point2I(470,-1),lsst::geom::Extent2I(21,21)) doesn\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">t fit in image 2048x4176 {</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}; Extracting image of PSF candidate {</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Then the processing carries on and finished processCcd just fine.  This \"LengthError\" didn\\'t appear by using <tt>w_2018_17</tt> but appeared using <tt>w_2018_18</tt>.   It still appears with the most recent weekly of <tt>w_2018_28</tt>.  </p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=krughoff\" class=\"user-hover\" rel=\"krughoff\">Simon Krughoff</a> when testing <tt>dispatch_verify.py</tt> with the Flask based SQuaSH RESTful API I noticed some specifications without the corresponding metric in <tt>verify_metrics</tt></p><p>For instance:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">{</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'metadata_query\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: {},</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'name\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'release.AD3.FY19\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'tags\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: [],</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'threshold\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: {</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'operator\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'&lt;=\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'unit\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'marcsec\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'value\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">30.0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">},</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'type\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'threshold\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">},</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>When loading the specs to SQuaSH I get:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">{</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'message\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'Metric `release.AD3` not found. You must provide a valid name for the metric associated with this specification.\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>I could ignore that to get the current metrics and specifications registered in SQuaSH,  for example:</p><p><a href=\"https://github.com/lsst-sqre/squash-rest-api/blob/master/app/resources/specification.py#L234\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/squash-rest-api/blob/master/app/resources/specification.py#L234</a></p><p>but we should enforce that specifications are consistent with metric definitions.</p>\n",
            "<p>Need to purge topic when receiving the dreaded:</p><p>Error in DomainParticipant.create_topic: Creation failed: invalid handle</p>\n",
            "<p>Fix forwarder sender so that it can be used in multiple test stands.</p>\n",
            "<p>While going through the log files on Forwarder, it seems that Forwarder tried to continue executing the codes after not being able to fetch header file. At that point, it should halt and publish telemetry_status.</p>\n",
            "nan\n",
            "nan\n",
            "<p>As part of <a href=\"https://jira.lsstcorp.org/browse/DM-16406\" title=\"Plot astrophysical objects and sources from HiTS 2015 processing\" class=\"issue-link\" data-issue-key=\"DM-16406\"><del>DM-16406</del></a> <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mrawls\" class=\"user-hover\" rel=\"mrawls\">Meredith Rawls</a> identified systematic correlations between the lightcurves of various HiTS sources.  This ticket is to investigate the cause of that correlation.</p>\n",
            "nan\n",
            "<p>At present, there is automated workspace cleanup based on a free space threshold.\\xc2\\xa0 This doesn\\'t solve the case of forcing a mass cleanup when the workspace(s) for a job have corrupted state. Previously, an option to force a cleanup was provided on several jobs. However, this would only cleanup the workspace(s) in which the triggered build would be running and not all workspace(s) associated with that job.\\xc2\\xa0 A mechanism is clearly need to allow either all workspace(s) for all jobs to be cleaned up as the \"nuclear option\" or to allow all of the workspace(s) for a signal job to be purged.</p>\n",
            "<p>Some CCDs in the HSC-RC2 reprocessing show this warning:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher WARN: Number of matches is smaller than request</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This probably should be an error on the matcher, but it seems to be passed to the fitter and then report as a successful fit.</p><p>A few data IDs of interest are <tt>visit=1872 ccd=11</tt> <tt>visit=1868 ccd=13</tt> <tt>visit=22648 ccd=4</tt>.</p><p>The first CCD</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astromRefObjLoader INFO: Loaded 1580 reference objects</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Purged 661 sources, leaving 113 good sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Matched 25 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher WARN: Number of matches is smaller than request</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Purged 661 sources, leaving 113 good sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Matched 1 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher WARN: Number of matches is smaller than request</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry INFO: Fit WCS iter 2 failed; using previous iteration: </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"src/sip/CreateWcsWithSip.cc\", line 131, in lsst::meas::astrom::sip::CreateWcsWithSip&lt;MatchT&gt;::CreateWcsWithSip(const std::vector&lt;T&gt;&amp;, const lsst::afw::geom::SkyWcs&amp;, int, const lsst::geom::Box2I&amp;, int) [with MatchT = lsst::afw::table::Match&lt;lsst::afw::table::SimpleRecord, lsst::afw::table::SourceRecord&gt;]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    Number of matches less than requested sip order {0}</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">lsst::pex::exceptions::LengthError: \\'Number of matches less than requested sip order\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry INFO: Matched and fit WCS in 1 iterations; found 25 matches with scatter = 0.028 +- 0.019 arcsec</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The second</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astromRefObjLoader INFO: Loaded 1840 reference objects</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Purged 595 sources, leaving 133 good sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Matched 27 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher WARN: Number of matches is smaller than request</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Purged 595 sources, leaving 133 good sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Matched 4 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher WARN: Number of matches is smaller than request</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry INFO: Fit WCS iter 2 failed; using previous iteration: All matches rejected in iteration 1</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry INFO: Matched and fit WCS in 1 iterations; found 27 matches with scatter = 0.092 +- 0.049 arcsec</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>And the third</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astromRefObjLoader INFO: Loaded 1441 reference objects</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Purged 1109 sources, leaving 99 good sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Matched 47 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Purged 1109 sources, leaving 99 good sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Matched 49 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Purged 1109 sources, leaving 99 good sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher INFO: Matched 27 sources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry.matcher WARN: Number of matches is smaller than request</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">processCcd.calibrate.astrometry INFO: Matched and fit WCS in 3 iterations; found 27 matches with scatter = 0.029 +- 0.020 arcsec</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The logs are from using the <tt>w_2019_10</tt> stack. But the <tt>LengthError</tt> has appeared since <tt>w_2019_07</tt>, and the <tt>Number of matches is smaller than request</tt> warnings have been around for longer.</p>\n",
            "<p>Software/scripts to be run on the AuxTel machine initiating the transfers to NCSA.</p>\n",
            "<p>Upgrade Oracle Trace File Analyzer, used for analysis and problem resolution.</p>\n",
            "<p>Develop process by which users acquire new Oracle accounts, including Oracle wallet setup.</p>\n",
            "<p>Prepare some donut update slides to get feedback from Jim Gunn and Robert Lupton on recent results regarding modeling HSC pupil obscuration and distortion.</p>\n",
            "nan\n",
            "nan\n",
            "\"<p>It's time to summarize my tests with PPDB prototype that are now spread across many Jira tickets and notebooks.</p>\"\n",
            "\"<p>Rebuild the pLAN EFD with the tables corresponding to tag 3.8.41<br/>and prepare RPM's for switch to 3.9.0. Install OpenSplice debug tools</p>\"\n",
            "<p>This is one of the action items from <a href=\"https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=~tjohnson&amp;title=Camera+Image+Visualization+meeting+with+IPAC\" class=\"external-link\" rel=\"nofollow\">SLAC-IPAC meeting</a>:</p><p>Once implementation of channels/request object/user defined actions is complete, provide demo/example</p>\n",
            "<p>We perform initial testing for batch job submissions to CC-IN2P3 Sun Grid engine queues, where we check, amongst various things,\\xc2\\xa0 on ability to utilize LSST software in /cvmfs, LSST software in singularity images, access /sps,\\xc2\\xa0 target machines with various profiles, etc.\\xc2\\xa0 \\xc2\\xa0We also test HTCondor glide-in scenarios to NCSA (HTCondor startd\\xc2\\xa0 running as the \"job\" submitted to CC-IN2P3 batch compute nodes, connecting to HTCondor Central Manager at NCSA for payload job submission, orchestration, etc.)\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>We test transfer approach for a campaign of processing outputs to examine issues that may be encountered in such transfer from CC-IN2P3 to NCSA. We observe the significance of using \"pipes/tar\" versus naively performing a recursive copy for a directory spaces with a large number of directories and files (potentially small files).</p>\n",
            "<p>Attend Spatial Analyzer training event in Los Angeles, March 12-14, plus travel days</p>\n",
            "<p>Prepare and give a brown bag-style overview of how l1dbproto and AssociationTask work.</p>\n",
            "\"<p>Test take narrowband data script with Patrick down in lab.\\xc2\\xa0</p><p>Updated Patrick's script to write a csv file and download fits files corresponding to the appropriate data.</p><p>Help Patrick configure parameters of script.</p>\"\n",
            "<p>Currently the name associated with a Posix data store includes the path to the directory root. This is usually a full path and the name is used to indicate to the butler registry that the named datastore has a particular dataset.</p><p>If a datastore is moved to another location the name will change and the config file must be edited to reflect the new root location.  This will not update the name associated with the datasets already known to the registry.  Root can be a relative path but it is relative to the person using the butler and not relative to the butler directory.</p><p>Things sort of work by luck at the moment since butler never calls <tt>getDatasetLocations</tt>.</p><p>The posix datastore config also specifies a name for the <tt>records.table</tt> which must be unique. It is not related to the name at all and I wonder if it would be easier if it was.</p><p>For this ticket I will:</p><ul>\\t<li>Investigate specifying a <tt>name</tt> field in posix datastore config and using that instead of the root.</li>\\t<li>Consider allowing root to be specified relative to butler root to allow the simple case of relocating a posix datastore with butler sqlite registry.</li>\\t<li>Consider deriving the name of table.records from datastore name without having to specify a unique string in two places.</li></ul><p>Opinions welcomed.</p>\n",
            "\"<p>Translate the LabVIEW code (ts_tcs_ofc) related to the coordination transformation from ZEMAX to subsystems to Python code (ts_ofc, I renamed the ts_tcs_ofcPython to ts_ofc to fulfill the eups package name requirement). This is to translate the OFC calculated DOF in ZEMAX coordinate to the hexapod position and actuator forces in the subsystem's coordinate system.</p>\"\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>It appears that phosim assumes the eimages it produces are always oriented in focal plane coordinates when it pastes on the rough WCS.  This is true of all science detectors, but appears not to be true for the wavefront sensors, which are rotated 90 deg in each subsequent corner raft.</p><p>This leads to a rough WCS that is wrong for the WFS chips.  See the following figure.  RA and Dec labeled as inferred from the attached WCS.  Red circles are the pixel positions from the phosim <tt>centroid.txt</tt> file.  The blue circles are the RA/Dec positions from the input file to phosim.  All circles are annotated with: object identifier, RA/x, Dec/y.</p><p>As you can see the relative positions of object 0 and object 1 are flipped in RA/Dec relative to x/y.  My interpretation is that this means the translation from RA/Dec to pupil coordinates in phosim and the ray tracing step are being done correctly.  I think the issue just comes from an incorrect assumption for <tt>CRPIX</tt> and possibly the <tt>CD</tt> matrix when computing the WCS.</p><p> <span class=\"image-wrap\" style=\"\"><img src=\"https://jira.lsstcorp.org/secure/attachment/37317/37317_labeled.png\" style=\"border: 0px solid black\" /></span></p><p>P.S. It\\'s possible the bulk offset is due purely to distortions in the optics that the simple WCS does not account for. </p>\n",
            "<p>display_ds9 doc/status has already been done, so I will go through and upgrade to numpydoc status.\\xc2\\xa0</p>\n",
            "<p>SQuaSH store code changes for each CI run with respect to the previous one. This information must be added to InfluxDB and displayed by Chronograf.</p><p>To display that in Chronograf, we need the ability to add links to external pages into the Chronograf table cells.</p>\n",
            "<p>Transfer raw image files from the CCOB to NCSA.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=yusra\" class=\"user-hover\" rel=\"yusra\">Yusra AlSayyad</a> points out that there is an increase in the \"wired\" wPerp Principal Color scatter for tract 9697 between the <tt>w_2018_36</tt> and <tt>w_2018_38</tt> HSC RC2 processing runs (and it has persisted ever since).  This is the blue \"wired\" curves: <a href=\"https://lsst-web.ncsa.illinois.edu/~hchiang2/RC2_w_2018_36/pipe_analysis/qaPlots/color/tract-9697/plot-t9697-griPSF-wFit-fit.png\" class=\"external-link\" rel=\"nofollow\">https://lsst-web.ncsa.illinois.edu/~hchiang2/RC2_w_2018_36/pipe_analysis/qaPlots/color/tract-9697/plot-t9697-griPSF-wFit-fit.png</a> vs. <a href=\"https://lsst-web.ncsa.illinois.edu/~hchiang2/RC2_w_2018_38/pipe_analysis/qaPlots/color/tract-9697/plot-t9697-griPSF-wFit-fit.png\" class=\"external-link\" rel=\"nofollow\">https://lsst-web.ncsa.illinois.edu/~hchiang2/RC2_w_2018_38/pipe_analysis/qaPlots/color/tract-9697/plot-t9697-griPSF-wFit-fit.png</a><br/>Investigate the cause.</p>\n",
            "<p>Try to use table spaces to allocate tables in different disks for TIER purposes. This seems to be a better solution than having multiple instances (one for each TIER).</p><p>This test will be performed in a virtualized environment.</p>\n",
            "<p>Write a script to test the integration of ATDomeTrajectory, ATDome and ATMCS. Put it in ts_standardscripts.</p>\n",
            "<p>Currently only the commands in c++ are being done. This task is to complete tcl scripts to produce the events into a single file.</p>\n",
            "<p>Currently only the commands in c++ are being generated into a single file. This task is to complete tcl scripts to produce the telemetry tests into a single file as well.</p>\n",
            "<p>Currently only the commands in c++ are being tested from a single file. This task is to complete tcl scripts to produce the telemetry tests into a single file as well.</p>\n",
            "<p>Qserv build system use system swig, it should be fixed to use eups swig. </p>\n",
            "<p>Consult with Opensplice reps</p>\n",
            "<p>The basic experience of generating a file or project from a Templatekit-based template (e.g. <a href=\"https://github.com/lsst/templates)\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/templates)</a>\\xc2\\xa0is largely driven from the template\\'s cookiecutter.json file. However, in implementing <a href=\"https://jira.lsstcorp.org/browse/DM-18110\" title=\"Implement template file creation in templatebot\" class=\"issue-link\" data-issue-key=\"DM-18110\"><del>DM-18110</del></a> it\\'s clear that the experience can be vastly improved if we can add a configuration file to individual templates that customizes how the template is presented to Slack-based users.</p><p>Some key types of configuration are:</p><ul>\\t<li>Customize name of template in selection menu and place it in a hierarchical context</li>\\t<li>Configure what fields appear in the dialog (Slack limits it to 5)</li>\\t<li>Create composite selection menus that provide presets that drive multiple boolean-type cookiecutter configurations.</li>\\t<li>Customize labels for dialog items (can be up to 75 characters)</li>\\t<li>Customize selection menu item labels (can be up to 75 characters)</li>\\t<li>Customize title of dialog (can be up to 24 characters)</li>\\t<li>Customize type of text field (a text area versus field, and also subtypes of the field).</li></ul><p>This can be implemented with a <tt>templatekit.yaml</tt> file that appears in each template directory.</p><p>This ticket will design the schema of the templatekit.yaml file and add support for it in templatekit and templatebot.</p>\n",
            "<p>Need to include metadata from the execution environment in the InfluxDB data model. In particular data from the HSC re-processing at NCSA is not being inserted in InfluxDB after <a href=\"https://jira.lsstcorp.org/browse/DM-16660\" title=\"Deploy SQuaSH API to production and update InfluxDB with validate_drp results\" class=\"issue-link\" data-issue-key=\"DM-16660\"><del>DM-16660</del></a>. </p>\n",
            "\"<p>Something has happened at an org level and now I'm getting failure messages from Travis about my build.</p><p>\\xc2\\xa0</p><p>Sadly, there's a fair amount of work that needs to happen here to get this to work, as much as I would like to, and some of them I can't do now.</p><p>\\xc2\\xa0</p><p>Things that need to happen:</p><ol>\\t<li>We use non-open Oracle plugins, which require signing into an Oracle Account.\\xc2\\xa0 This means I need to get some kind of creds into Travis to get them to be able to pull down the oracle connector from the maven repository.</li>\\t<li>Even if #1 worked, the tests fail because I'm using a private branch of the cadc-adql code that hasn't been merged yet.\\xc2\\xa0 This was to get the catalog.schema.table names working.\\xc2\\xa0 It is in the plan for Patrick @ CADC to merge this, but it hasn't happened yet.</li>\\t<li>Because of #2, I'm calling a monkeypatch script to get things to work, and disabling tests in the build currently.\\xc2\\xa0 So I'd need to get Travis to call the build.sh script instead.</li></ol><p>Right now, I'm just going to say it's not worth it, but in a month or so, it might be.</p>\"\n",
            "<p>SAL v3.9 contains two new features</p><ul>\\t<li>RPM packagaing</li>\\t<li>Combined interface modules</li></ul><p>This task covers the effort required to update the tests for these new features.</p><p>There is also a desire to improve/increase the level of Java testing at the SAL layer.  This task also covers some time to work on this.</p>\n",
            "<p>Write a new set of XML for a generic camera CSC and implement it with ts_salobj.</p><p>Required items:</p><ul>\\t<li>Set Exposure Time</li>\\t<li>Set ROI\\t<ul>\\t\\t<li>Top, Left, Width, Height</li>\\t</ul>\\t</li>\\t<li>Set Full Frame (short cut for the set ROI command)</li>\\t<li>Start Live View</li>\\t<li>Stop Live View</li>\\t<li>Event indicating live view ip / tcp port for image data</li>\\t<li>Event indicating current exposure time</li>\\t<li>Event indicating current ROI</li>\\t<li>Event for camera specific properties (key / value pair basically)</li>\\t<li>Event for camera make / model</li>\\t<li>Telemetry for temperature</li></ul>\n",
            "<p>Run my AP prototype on ccqserv150 with databases storage on SSD/NVMe and add performance figures here.</p>\n",
            "<p>Using my AP prototype script produce some performance numbers and plots for L1 database operations. Do it for baseline schema as defined in current baseline (cat package) and also try to get somewhat improved mysql schema (I know already that baseline indices do not work very well for Object table).</p>\n",
            "<p>Prototype use of Elastic Log Search.</p>\n",
            "nan\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2019_10. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Characterization Report for 17.0 release is required.</p>\n",
            "<p>Remove any use of Antlr 2 and related code (refactor or remove as appropriate) from qserv.</p>\n",
            "<p>Use the yaml format instead of txt format to do the configuration file management. The yaml is the standard in DM team for the configuration files. Since I never use the yaml before, this task will take some time for me to learn the use of yaml with Python.</p>\n",
            "<p>This ticket is to integrate file and snippet instantiation from <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/templates</a>\\xc2\\xa0templates in templatebot (<a href=\"https://jira.lsstcorp.org/browse/DM-17865\" title=\"Set up SQuaRE Events microservice for creating projects/files from templates\" class=\"issue-link\" data-issue-key=\"DM-17865\"><del>DM-17865</del></a>) for Slack based handling.</p><p>Some of the objectives are:</p><ul>\\t<li>Manage local clones of a templates repository in templatebot</li>\\t<li>Introspect the templates repository to get a list of file templates and drive the inital template listing from that</li>\\t<li>Introspect the cookiecutter.json files of templates to populate the dialog boxes.</li>\\t<li>Generate files</li>\\t<li>Send files back to a user on Slack (following the proof-of-concept in <a href=\"https://jira.lsstcorp.org/browse/DM-17865\" title=\"Set up SQuaRE Events microservice for creating projects/files from templates\" class=\"issue-link\" data-issue-key=\"DM-17865\"><del>DM-17865</del></a>)</li></ul><p>This ticket will focus on file templates, rather than projects, since they\\'re simpler both in terms of configurations (typically) and because they don\\'t require instantiating github repositories).</p>\n",
            "<p>Go through the teams Confluence page. Reorganize so that finding documentation becomes easier. Have had multiple conversations with team members and Jonathan Sick before making the actual changes as well as a tech talk where team members can give input.\\xc2\\xa0</p>\n",
            "<p>Write an integration test for ATPtg to ATMCS as a SAL script and add it to ts_standardscripts.</p><p>There may be some overhead because this is the first script added to that package.</p>\n",
            "<p>This will give us versioned secrets.</p>\n",
            "<p>After discussion with Google experts, they suggested us to look into an alternative way for server discovery to replace the needs of multicast. (Multicast does not work in GKE if the Firefly server pods are on different nodes).\\xc2\\xa0</p><p><a href=\"http://www.smartjava.org/content/service-discovery-docker-and-consul-part-1/\" class=\"external-link\" rel=\"nofollow\">http://www.smartjava.org/content/service-discovery-docker-and-consul-part-1/</a></p><p>\\xc2\\xa0</p><p>This will involve modifying Firefly to read the configuration at build time to decide on the library to use for service auto discovery. When it is in k8s environment, other software package may need to be installed. We need to document this in SUIT deployment procedure <a href=\"https://jira.lsstcorp.org/browse/DM-16670\" title=\"SUIT(portal) deployment procedure document\" class=\"issue-link\" data-issue-key=\"DM-16670\">DM-16670</a></p>\n",
            "<p>Determine additional details and present plan to DMLT.</p>\n",
            "<p>Cisco Xenpack for extra long distance 10Gbs</p>\n",
            "<p>Need to run a grid of config parameters to find the best combination. Many of the defaults were adopted from SafeClip. </p><ul>\\t<li>temporalThreshold/maxNumEpochs:</li>\\t<li>spatialThreshold:<br/> + <p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        self.assembleStaticSkyModel.sigmaClip = 1.5</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        self.assembleStaticSkyModel.clipIter = 3</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        self.detect.thresholdValue = 5</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        self.detect.nSigmaToGrow = 2</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        self.detect.minPixels = 4</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        self.detect.isotropicGrow = True</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        self.detect.thresholdType = \"pixel_stdev\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/></li></ul>\n",
            "<p>Update supported browser list. We usually do this every 12 to 18 months.</p><p>Typically we try to support the current browser version plus 2 back or any browser version in the last year.</p><p>Update support browser list:\\xc2\\xa0</p><ul>\\t<li>Safari 9 =&gt; 10\\xc2\\xa0 (current: 12)</li>\\t<li>Chrome 62 =&gt; 67\\xc2\\xa0 (current: 71)</li>\\t<li>Firefly 56 =&gt; 60 (current: 65)</li>\\t<li>Edge\\xc2\\xa0 14 =&gt; 16 (current: 18)</li></ul><p>Upgrading the supported list provides the following:</p><ul>\\t<li>Allows for more confidence in the testing of our products.</li>\\t<li>Allows for more stable version of library since they are limited in testing of old browsers</li>\\t<li>Give opportunity to use newer HTML/CSS features such as Grid layout</li>\\t<li>Requires less polyfills and code transforms. This allows more native code and smaller load sizes.</li></ul>\n",
            "<p>Loi has introduced jest as Javascript testing framework for Firefly.</p><p>We need to</p><ul class=\"alternate\" type=\"square\">\\t<li>Update SUIT to use jest for javascript testing</li>\\t<li>Move LSST specific java tests (LSSTDbServTest.java and LSSTImgServ.java) to suit.</li></ul>\n",
            "<p>This ticket is to capture the work done to deploy and configure InfluxDB + kafka connect in the efd-kafka cluster while the deployment is not fully automated by Terraform. See <a href=\"https://jira.lsstcorp.org/browse/DM-16776\" title=\"Configure the InfluxDB sink connector to consume topics from the mock SAL Kafka producer\" class=\"issue-link\" data-issue-key=\"DM-16776\"><del>DM-16776</del></a>, <a href=\"https://jira.lsstcorp.org/browse/DM-17513\" title=\"Create database and retention policies with terraform-provider-influxdb\" class=\"issue-link\" data-issue-key=\"DM-17513\"><del>DM-17513</del></a>, <a href=\"https://jira.lsstcorp.org/browse/DM-17531\" title=\"Custom configuration for confluent-kafka\" class=\"issue-link\" data-issue-key=\"DM-17531\"><del>DM-17531</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-17754\" title=\"Monitor status of influxdb-sink kafka connector\" class=\"issue-link\" data-issue-key=\"DM-17754\"><del>DM-17754</del></a>.</p>\n",
            "<p>SAL text-based messages are converted to Avro by <tt>saltransform</tt> in <a href=\"https://jira.lsstcorp.org/browse/DM-17282\" title=\"Transform SAL text-based Kafka messages to Avro\" class=\"issue-link\" data-issue-key=\"DM-17282\"><del>DM-17282</del></a>. <tt>saltransform</tt> also initializes the schema registry with the schema for the <tt>lsst.sal.*</tt> topics.</p><p>In <a href=\"https://jira.lsstcorp.org/browse/DM-17461\" title=\"Configure cp-kafka-connect in the terraform-efd-kafka deployment\" class=\"issue-link\" data-issue-key=\"DM-17461\"><del>DM-17461</del></a> we create the connector for InfluxDB and deployed the connector as part of the <tt>terraform-efd-Kafka</tt> deployment. If we want to auto-discover the <tt>lsst.sal.*</tt> topics from the schema registry when creating the connector, <tt>saltransform</tt> should be added to the <tt>terraform-efd-kafka</tt> deployment as well.</p><p>In this ticket, we compare two deployment strategies involving Terraform. First, we use the Terraform kubernetes provider to create the kubernetes objects needed to deploy <tt>saltransform</tt>. Second, we create a Helm chart to deploy <tt>saltransform</tt> and use the Terraform Helm provider to install the helm chart.</p>\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/DM-17461\" title=\"Configure cp-kafka-connect in the terraform-efd-kafka deployment\" class=\"issue-link\" data-issue-key=\"DM-17461\"><del>DM-17461</del></a> we implemented a command to configure the <tt>influxdb-sink</tt> connector and deployed it initially as a k8s Job.</p><p>However, we need it working as a daemon to:</p><p>1) try creating the connector until the <tt>cp-kafka-connet</tt> REST API is ready<br/>2) monitor the connector status and reset the connector if status is FAILED.</p><p>See <a href=\"https://docs.confluent.io/3.0.0/connect/userguide.html#connect-administration\" class=\"external-link\" rel=\"nofollow\">https://docs.confluent.io/3.0.0/connect/userguide.html#connect-administration</a></p><p>This also makes the deployment easier, we can use the <tt>kubernetes_deployment</tt> resource from the Terraform k8s provider instead of the <tt>kubernetes_job</tt> resource which is not implemented in the official provider yet.</p>\n",
            "<p>The  <tt>confluent-kafka</tt> chart needs some custom config that:</p><p>1) increases the broker\\'s disk to 15G and configures a retention policy for the topic offsets and the kafka logs of 24h in <tt>cp-kafka</tt>. That will avoid filling up the disks as seen during the SAL Mock experiment</p><p>2) uses a specific docker image for <tt>cp-kafka-connect</tt> which adds the Landoop InfluxDB Sink connector and overrides the <tt>plugin.path</tt> configuration.  Our implementation uses the Landoop InfluxDB Sink Connector to connect kafka and InfluxDB, see SQR-029 for details.</p><p>3) sync our cp-helm-chart fork with recent changes in the <a href=\"https://github.com/confluentinc/cp-helm-charts/commits/master/values.yaml\" class=\"external-link\" rel=\"nofollow\">upstream repo</a>. That is required for 2.</p>\n",
            "<p>We use the terraform-provider-influxdb to create the database and the retention policy for the EFD database in InfluxDB.</p>\n",
            "<p>Implement new command group in <tt>kafkaefd</tt> to create the connector configuration and upload to the <tt>cp-kafka-connect</tt> REST API.</p><p>See\\xc2\\xa0\\xc2\\xa0<a href=\"https://docs.confluent.io/3.2.0/connect/managing.html\" class=\"external-link\" rel=\"nofollow\">https://docs.confluent.io/3.2.0/connect/managing.html</a></p><p>Then create a k8s deployment that executes the <tt>kafkaefd</tt> command.</p>\n",
            "<p>Some SAL topics have array data type which, when converted to Avro, are not supported by the InfluxDB sink connector.</p><p>Example:</p><p><a href=\"https://github.com/lsst-sqre/kafka-efd-demo/blob/master/schemas/ts_xml/develop/MTMount_Elevation.json#L103\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/kafka-efd-demo/blob/master/schemas/ts_xml/develop/MTMount_Elevation.json#L103</a></p><p>This is the error message we get from <tt>Kafka-connect</tt>:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. (org.apache.kafka.connect.runtime.WorkerSinkTask)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">java.lang.IllegalArgumentException: You can\\'t select * from the Kafka Message. Field:\\'Elevation_Interlocks\\' resolves to a Schema \\'ARRAY\\' which will end up with a type not supported by InfluxDB API.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>The mock SAL Kafka producer (<a href=\"https://jira.lsstcorp.org/browse/DM-16692\" title=\"Create a mock SAL Kafka producer\" class=\"issue-link\" data-issue-key=\"DM-16692\"><del>DM-16692</del></a>) use random numbers to emulate the topics using the SAL Avro schemas.</p><p>The InfluxDB Sink connector must be configured to consume those topics.</p>\n",
            "<p>Keep the Notebook Aspect working with current-released version of JL and other components.</p>\n",
            "<p>This task covers time to discuss with the TSSW team the particular needs of application building and packaging for deployment.\\xc2\\xa0 Most of the pieces already exist, but the process needs to be documented and formalized.</p>\n",
            "<p>It would be helpful to have easily interpretable plots for multi-band fitting showing all bands at once, rather than having to look at each band separately.</p>\n",
            "<p>Develop and support the active optics closed-loop simulation. This task will integrate the modules of ts_tcs_wep_phosim, ts_tcs_wep, and ts_tcs_ofcPython. This task will be a prototype of active optics closed-loop simulation. The prototype here will support the simulation of main telescope active optics system (MTAOS) in the final. This task is in the phase 3 of the development.</p>\n",
            "<p>learn about how to package the CSC with docker, according to the grand LSE-150 plan. This has been ongoing for a while but will be a success when I have a docker container that runs the component and has all the required dependencies.</p>\n",
            "<p>As part of <a href=\"https://jira.lsstcorp.org/browse/DM-17488\" title=\"Write LinearStage-Electrometer-TunableLaser Coordination ExternalScript\" class=\"issue-link\" data-issue-key=\"DM-17488\"><del>DM-17488</del></a>, I wrote a baseline script that used the linearstage and electrometer during the two weeks of Nick\\'s visit outlined in\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-17943\" title=\"Support Laser Characterization Scripting Efforts Part 2\" class=\"issue-link\" data-issue-key=\"DM-17943\"><del>DM-17943</del></a>\\xc2\\xa0and\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-17694\" title=\"Support Laser Characterization Scripting Efforts\" class=\"issue-link\" data-issue-key=\"DM-17694\"><del>DM-17694</del></a>. I made a design decision which allowed for a configurable script that would eventually allow for full functionality of script as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-17488\" title=\"Write LinearStage-Electrometer-TunableLaser Coordination ExternalScript\" class=\"issue-link\" data-issue-key=\"DM-17488\"><del>DM-17488</del></a>.\\xc2\\xa0</p><p>This script is located in ts_externalscripts as es_coordination_laser_001.py uses the two linear stages mounted at right angles to move them in a grid pattern while the electrometer takes data. The parameters of the test outlining the position of the linear stages and the url containing the fits file of data of the electrometer is written to a txt file.\\xc2\\xa0</p><p>The manual parts of the test included the TunableLaser and CBP.\\xc2\\xa0 The TunableLaser was propagating at a set wavelength with a fiber optic cable attached that was transmitting light to the integrating sphere of the CBP which was at a fixed position.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Put requirements into spreadsheet for ingestion to MagicDraw.</p>\n",
            "<p>On the Feb. 11th-20th 2019, Nick Mondrik from Harvard University will be using the TunableLaser, Electrometer and Linear Stages to do characterization of the laser testing. This task is for providing software support for his efforts.</p>\n",
            "\"<p>For the week of the 17th through the 21st, support Nick again.</p><p>We used scriptqueue to run a script which moved the one linear stage up a vertical track and then iterated the second linear stage on a horizontal track. The electrometer would then take data. The laser was propagating through fiber spectre cable that was inserted into the collimated beam projector. We got the electrometer managing to take data, with some small bugs along the way. The url that is returned does not actually return the ip address of the computer hosting the fits files. We tested Tiago's request_script.py which worked out pretty good except for some mildly annoying bugs but nothing breaking the scripts.</p><p>We also discovered that two electrometer CSCs can't be hosted on the same pc, at least as far as we tried. The manual did say that it had not been tested.</p>\"\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=boutigny\" class=\"user-hover\" rel=\"boutigny\">Dominique Boutigny</a>\\'s work on selecting reference sources by S/N and magnitude might help improve the refcat that jointcal uses. But <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a> made a <tt>ReferenceSourceSelectorTask</tt> that we can configure for this purpose, instead of having code internal to jointcal.</p><p>This ticket is to convert <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=boutigny\" class=\"user-hover\" rel=\"boutigny\">Dominique Boutigny</a>\\'s work in the u/fix_outliers branch (specifically this commit: <a href=\"https://github.com/lsst/jointcal/commit/e8393ac2e21117c15458156423445b19f75b503a\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/jointcal/commit/e8393ac2e21117c15458156423445b19f75b503a</a> ) to use <tt>ReferenceSourceSelectorTask</tt>, add a unittest to demonstrate that it does affect the fit, and update the other tests to reflect any changes in the fit metrics.</p>\n",
            "<p>Read the current version of DMTN-002 and comment.</p><p>Write new sections describing the overall architecture and the expected role of SuperTask in the system.</p>\n",
            "<p>This task covers the re-training on M1M3 control in support of Mirror Lab testing.</p>\n",
            "<p>Representatives (M. Fisher-Levine, A. Plazas, A. Nomerotski, P. Antilogus, P. Astier) from DM and SAWG (DESC) had a telecon to discuss the topics to address during the joint DM-SAWG session at the next DESC winter meeting at Berkeley (2/27/19). The first topic will be a presentation from DM (by A. Plazas) on the state of the ISR, CPP pipelines (e.g., order of current ISR corrections, plan for generating calibration inputs, precision of current corrections, tests, etc).\\xc2\\xa0</p><p>This ticket will track the work on that, gathering input from DM people such as R. Lupton, C. Waters, and M. Fisher-Levine.\\xc2\\xa0</p>\n",
            "<p>Need to discuss between NCSA teams and with Chilean folks how the network is going to look at the base when we move in. What options do we have for connectivity, L2 networks/L3 networks &amp; design</p>\n",
            "<p>Implement fast (C++) pixel-convolved Gaussian evaluation in MultiProFit with the covariance matrix parameterization, compare performance with existing ellipse parameterization and determine if gradients could be returned</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Work with DDN on quote for storage for OODS. Whether JBOD or SFA will depend on discussions about network and base design</p>\n",
            "<p>Work with Dell to get quotes for machines for the two OODS nodes, make sure warranty/support in Chile is understood. Make sure speck requirements from developers are met (mainly memory &amp; network bandwidth)\\xc2\\xa0</p>\n",
            "<p>Based on the API arrived at in <a href=\"https://jira.lsstcorp.org/browse/DM-16925\" title=\"Provide backwards-compatibility with Calib API\" class=\"issue-link\" data-issue-key=\"DM-16925\"><del>DM-16925</del></a>, file an RFC describing the plans for transitioning to PhotoCalib. In particular, this should describe changes that science users will have to make to their code to support this transition.</p><p>The story point count includes work to file the RFC, participate in discussion, and make minor changes to the plan based on the results. If significant further work is required before proceeding, that should be captured on other tickets.</p><p>The adopted RFC should trigger <a href=\"https://jira.lsstcorp.org/browse/DM-10156\" title=\"Replace all uses of Calib with PhotoCalib\" class=\"issue-link\" data-issue-key=\"DM-10156\"><del>DM-10156</del></a>.</p>\n",
            "<p>The obs_lsst package should be included in the upcoming v17 pipelines release.</p><p>Note that this can only be done after:</p><ul>\\t<li>It has been renamed from obs_lsstCam to obs_lsst;</li>\\t<li>The package has appropriate tests;</li>\\t<li>The package has been appropriately reviewed;</li>\\t<li>An RFC has been passed.</li></ul><p>This ticket exists to cover the process of shepherding it through that process.</p>\n",
            "<p>Need to improve how defaults are handled in qserv_admin. There seems to be some desire to warn when values are not set--how about setting defaults and just printing what configuration is being used? If this is something human-created, we should have reasonable defaults and not bother the user, unless no default is viable. I think we should only be strict on machine-generated input, where we would like to catch bugs as soon as possible. </p><p>(This came up in the review of <a href=\"https://jira.lsstcorp.org/browse/DM-56\" title=\"Zookeeper-based CSS (v1)\" class=\"issue-link\" data-issue-key=\"DM-56\"><del>DM-56</del></a>, the review comments are captured in <a href=\"https://jira.lsstcorp.org/browse/DM-225\" title=\"Review existing CSS design / prototype\" class=\"issue-link\" data-issue-key=\"DM-225\"><del>DM-225</del></a>)</p>\n",
            "<p>Implementation of RFC will require an approved LCR adding the relevant data products to the DPDD (LSE-163) and DMSR (LSE-61). (This will then trigger an LDM-151 update, but that\\'s outside the scope of this ticket.)</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=xiuqin\" class=\"user-hover\" rel=\"xiuqin\">Xiuqin Wu</a> (or delegate) will start this process by proposing wording for the DPDD and DMSR that will satisfy SUIT needs.</p><p>We\\'ll run that by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ktl\" class=\"user-hover\" rel=\"ktl\">Kian-Tat Lim</a> to sanity check in terms of the sizing model.</p><p>Then work with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=tjenness\" class=\"user-hover\" rel=\"tjenness\">Tim Jenness</a> or <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=swinbank\" class=\"user-hover\" rel=\"swinbank\">John Swinbank</a> to submit it to the CCB.</p>\n",
            "<p>Update LDM-503 with the new document tree and ATM test approach</p>\n",
            "<p>Write a demo showing how to simulate fake sources\\xc2\\xa0 in the\\xc2\\xa0 tasks, including some background in how it works.\\xc2\\xa0 Test audience is the deblending task force on Feb 18th. Please attach slides.\\xc2\\xa0</p>\n",
            "<p>When a user clicks on a button in an interaction message, SQuaRE Bot Jr needs to both recieve the POST from Slack corresponding to that message, and then also forward that message to a Kafka topic. See\\xc2\\xa0<a href=\"https://api.slack.com/messaging/interactivity/enabling\" class=\"external-link\" rel=\"nofollow\">https://api.slack.com/messaging/interactivity/enabling</a></p><p>This is needed to enable the basic interactive messages created by templatebot in <a href=\"https://jira.lsstcorp.org/browse/DM-17865\" title=\"Set up SQuaRE Events microservice for creating projects/files from templates\" class=\"issue-link\" data-issue-key=\"DM-17865\"><del>DM-17865</del></a>.</p>\n",
            "<p>A new version of flake8 came out last night.  This is breaking pull requests because the flake8 used by Travis is not pinned.  On this ticket I will add new versions of pycodestyle and flake8 and determine how big the issue is, fixing things if that is feasible. If this is a large issue then the alternative is to consider editing every setup.cfg file to pin the flake8 version.</p>\n",
            "<p>With the release of new versions of pycodestyle and flake8 that support max-doc-length, we can update our eups packages to allow packages to use max-doc-length in their setup.cfg files.</p>\n",
            "<p>Final testing and planning for Feb. PM</p>\n",
            "<p>Add kafka high data rate writers to the end machine in the mirror lab.<br/>Run on a separate machine as well. Verify binary log backups</p>\n",
            "<p>This is a continuation of <a href=\"https://jira.lsstcorp.org/browse/DM-17366\" title=\"Get Pointing Component to build in the TSSW CI\" class=\"issue-link\" data-issue-key=\"DM-17366\"><del>DM-17366</del></a>.\\xc2\\xa0 That task ended up only comprising getting the Ptg Component to build.\\xc2\\xa0 This task covers time needed to get the vendor-supplied automated tests running in the TSSW CI environment.</p>\n",
            "\"<p>Build and deploy SAL runtime as a set of RPM's (per CSC)</p>\"\n",
            "<p>Review of Besalco contract documents...</p>\n",
            "<p>Write a simulator for the ATPneumatics CSC.</p>\n",
            "<p>This task covers</p><ul>\\t<li>time to research and learn about Docker.</li>\\t<li>create a Docker image configured for testing.\\t<ul>\\t\\t<li>miniconda or scl/ius for Python3 support</li>\\t\\t<li>Robot-Framework</li>\\t\\t<li>XML parser</li>\\t\\t<li>dependencies</li>\\t</ul>\\t</li></ul>\n",
            "<p>development of error code reporting and responding to bugs found during testing</p>\n",
            "<p>execute tests which involve manual voltage setting on the test hardware</p>\n",
            "<p>Move all the SAL unit tests into a single file so that when running under an automated test environment it is much faster to finish testing.\\xc2\\xa0</p><p>It is faster because unlike how it currently is, you need to start SAL services for every single topic. By having all the tests in a single file the SAL services only needs to start once.</p>\n",
            "<p>Many of the EAS sensors have a requirement for SAL support on an embedded system<br/>(Raspberry Pi). Create a reference implementation and consult with the developers to deinfe the appropriate generic EAS XML for the various sensor types</p>\n",
            "<p>Debug network configuration issues involved in establishing remote access<br/>(via reverse VPN to gateway pc) to EFD in mirror lab for test campaign</p>\n",
            "\"<p>Write a simulator for the ATMCS CSC in Python. I'm not positive it will have the necessary performance, but it's quick to try.</p>\"\n",
            "<p>This task covers the time spent to review the test results for the v0.2 Release of the Pointing Component.</p>\n",
            "<p>Create a standalone program that can run on multiple machines.\\xc2\\xa0</p>\n",
            "<p>This task captures the time spent learning pybind 11. I have a standalone program that I have been working on as well which I used as a sandbox. Doing this helped with the learning curve jumping onto the templates used for ts_sal.\\xc2\\xa0</p>\n",
            "<p>Develop and support the active optics closed-loop simulation. This task will integrate the modules of ts_tcs_wep_phosim, ts_tcs_wep, and ts_tcs_ofcPython. This task will be a prototype of active optics closed-loop control (AOCLC) in the simulation mode. It is noted that in the control mode, the control system will be added/ integrated with the control systems of wavefront estimation pipeline (WEP) and optical feedback control (ofc). This task is in the phase 1 of the development.</p>\n",
            "<p>Technically the code is there, but has not been functionally tested. In order to be complete, it must be tested and working. This allows the TunableLaser to start emitting the light beam and stop emitting through SAL state transitions. The component API already implements this functionality. Had Russell Owen look over the current implementation and he had some suggestions. I will be making those changes as part of this task.</p><p>The CSC now demonstrates basic state transitions including substates for propagating the laser. It demonstrates both local host functionality and network functionality with the chesterfield script machine. It can start propagating when in the enabled state. It can also stop propagating and be in the enabled state or if disabled will also stop propagating. Revamped the hardware wrapper api based on better understanding of hardware itself, updated the firmware to gain access to several error registers. Revamped unit tests to a slight degree. There is also a very simple settings api. Added all temperature sensors to telemetry in preparation for some stability(plus the fact that we don\\'t know which ones are important). Added changedWavelength event to indicate that the wavelength has changed(may be redundant if wavelength is published as telemetry).\\xc2\\xa0</p><p>\\xc2\\xa0</p><p><a href=\"https://github.com/lsst-ts/ts_TunableLaser/pull/8\" class=\"external-link\" rel=\"nofollow\">Github Pull Request</a></p>\n",
            "<p>Comparing HSC-RC2 reprocessing by stack w_2019_02 and w_2019_06, we\\'ve got a new set of processCcd errors. They fail at calibrate.astrometry.matcher with </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20181012/stack/miniconda3-4.5.4-fcd27eb/Linux64/meas_astrom/16.0-24-gfa57b64+1/python/lsst/meas/astrom/matchPessimisticB.py\", line 278, in matchObjectsToSources</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    raise RuntimeError(\"Unable to match sources\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The 60 data ids of the new failure set is as follows</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34338 ccd=75</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34362 ccd=38</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34382 ccd=43</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34384 ccd=88</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34402 ccd=61</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34422 ccd=42</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34424 ccd=2</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34448 ccd=79</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34450 ccd=25</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34478 ccd=21</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34482 ccd=50</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34644 ccd=72</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34690 ccd=39</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36140 ccd=30</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36170 ccd=18</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36182 ccd=80</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36212 ccd=34</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36234 ccd=82</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36240 ccd=0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36258 ccd=73</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36428 ccd=61</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36432 ccd=23</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36492 ccd=50</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=34942 ccd=44</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36762 ccd=18</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36774 ccd=24</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36792 ccd=34</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36808 ccd=26</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36828 ccd=16</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=36828 ccd=73</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=26046 ccd=32</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=26050 ccd=74</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=26058 ccd=34</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=26060 ccd=70</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">-id visit=26072 ccd=12</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=26080 ccd=66</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=26084 ccd=64</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=23864 ccd=12</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=1308 ccd=40</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=23224 ccd=59</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=23232 ccd=32</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=27106 ccd=33</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=27106 ccd=41</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=27128 ccd=26</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=27134 ccd=28</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=440 ccd=92</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=452 ccd=35</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=452 ccd=42</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=472 ccd=30</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=1246 ccd=19</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=19696 ccd=20</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=30500 ccd=20</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=1180 ccd=89</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=1184 ccd=26</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=1194 ccd=26</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=360 ccd=26</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=22628 ccd=18</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=22664 ccd=26</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=23046 ccd=26</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">--id visit=23050 ccd=84</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>After the new matcher (Pessimistic B) became default on <a href=\"https://jira.lsstcorp.org/browse/DM-14857\" title=\"Switch the default matcher to PessimisticB.\" class=\"issue-link\" data-issue-key=\"DM-14857\"><del>DM-14857</del></a>, the astrometric metrics recorded on SQuaSH regressed (for both HSC and CFHT). Reproduce this locally and understand what happened. Fix if this is a matcher problem; if it\\'s a validate_drp problem, ticket that for future work.</p>\n",
            "\"<p>Community members are interested in the new Pessimistic matcher due to it's ablity to successfully match sources in ultra dense, galactic plane pointings. Write a short post on LSST community describing its current workings.</p>\"\n",
            "<p>Thereby implementing <a href=\"https://jira.lsstcorp.org/browse/RFC-491\" title=\"Make MatchPessimisticB the default astrometry matcher in place of MatchOptimisticB\" class=\"issue-link\" data-issue-key=\"RFC-491\"><del>RFC-491</del></a>.</p><p>Also implement the speedup discussed on that RFC. </p>\n",
            "<p>This enables us to set it as the global default matcher.</p>\n",
            "<p>The result of this RFC will be a proposal to the SE subsystem.  It will be put forward to the CCB and if approved, become a change controlled LSE document.  At that point, we can also add a requirement to the OSS that refers to that LSE document, if desired.</p>\n",
            "<p>The focus while developing the algorithm for correcting DCR in coadds and image differencing has been on the quality of the results, and not on efficiency. However, some components that were chosen for ease of initial development are unnecessarily wasteful, and could be sped up considerably with a small amount of effort. For example, the DcrModel that is passed to <tt>warpImage</tt> in each iteration is a <tt>maskedImage</tt>, but only the image plane is used even though the mask and variance planes are also warped.   This ticket is to switch the DcrModel to use only the image plane throughout.</p>\n",
            "<p>A new version of ts_sal, ts_xml and ts_opensplice has been tagged, this is v3.8.41, and the HeaderService need to be tested against this new version. In addition a new build and install need to be tested against this.</p>\n",
            "<p>Currently TS8 data are handled as a single raft definition shared for all rafts from a single manufacturer. There is a ts8itl and ts8e2v specialization.  In this ticket we will change the organization such that each raft exists as a real raft named RTM-nnn after the actual raft name. Then each raft YAML file defines its own sensors in the normal way and the e2v/itl specialization can be removed.  There will be a single definition of TS8 that allows you to retrieve data by actual raft name or sensor name without risk of confusion.</p>\n",
            "<p>This ticket follows on\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-17024\" title=\"MVP deployment of new Kafka-based SQuaRE Bot slack bot\" class=\"issue-link\" data-issue-key=\"DM-17024\"><del>DM-17024</del></a>\\xc2\\xa0and adds the ability to encode and produce Avro+Kafka messages for Slack Events API messages:</p><ul>\\t<li>message events (message.im, message.channel, message.mpim, message.group varieties)</li>\\t<li>app mentions (app_mention event)</li></ul><p>There should likely be two Kafka topics:</p><ul>\\t<li>sqrbot.message (all message.* events)</li>\\t<li>sqrbot.sqrbot_mention (all app_mention and message.im events)</li></ul><p>Thus an app that works by responding to messages direct to it can just subscribe to the <tt>sqrbot.sqrbot_mention</tt> topic. Apps that monitor all Slack traffic (that the bot is a privy to) can monitor the <tt>sqrbot.message</tt> topic.</p><p>This is still an MVP effort. The Kafka topics can be manually created and the schemas can be manually uploaded.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2019_06. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>For backwards compatibility, we will want to be able to de-persist data processed with old stacks that have {{Calib}}s in them, and produce a PhotoCalib. We should be able to keep the old CalibFactory object and its registration and have it produce a PhotoCalib instead.</p>\n",
            "<p><a href=\"https://dmtn-098.lsst.io/\" class=\"external-link\" rel=\"nofollow\">DMTN-098</a> speculates that it may be possible to write an adapter that allows the same <tt>MetricTask</tt> to be used with both Butler 2 and Butler 3 workflows. However, the details depend substantially on how the new Butler works and how much custom information the adapter needs (in particular, it\\'s not clear how to create a <tt>DatasetTypeDescriptor</tt>,  one of the classes the <tt>PipelineTask</tt> API must return). While we can\\'t <em>implement</em> such an adapter until Butler output of measurements is supported, knowing whether or not an adapter is possible affects the best way to implement <tt>MetricTask</tt> and its subclasses.</p><p>This issue is to spend some time investigating how Butler 3 and <tt>PipelineTask</tt> interact, and what is \"missing\" from the Butler 2 equivalents.</p><p>Note that the middleware development team is also working on something that will allow <tt>CmdLineTasks</tt> to be used as <tt>PipelineTasks</tt>. Their solution may or may not satisfy our requirements, for the following reasons:</p><ul>\\t<li>it may only work on <tt>CmdLineTask</tt>, which the metrics support framework does not use</li>\\t<li>even in the Butler 2 context, <tt>MetricTask</tt> reports the dataset(s) it needs as input. An adapter that can translate this information to a Butler 3 representation may be simpler than one that needs to get the same information from an external source</li>\\t<li>it is not actually clear whether the middleware team\\'s solution is an adapter in the OOD sense, or whether it only maps <tt>PipelineTask.run</tt> to <tt>Task.runDataRef</tt> while leaving other <tt>PipelineTask</tt> capabilities (i.e., dataset management) unsupported</li></ul><p>This potential conflict/redundancy can be addressed once we have a clearer picture of our own requirements.</p>\n",
            "<p>Camera geometry used to be defined using PAF (policy) files, which are now deprecated. As part of the transition to the refactored camera geometry scheme, scripts were introduced to convert from the PAF files to the new camera geometry configuration scheme which uses FITS files and a python file to describe the camera. These scripts are still part of the obs_* packages, and some people rely on them for making changes to the camera description. On the other hand, the generated FITS files and python file are also first-class members of the obs_* packages. This means that we have two sources of the same information, which is dangerous.</p><p>For obs_lsstSim, obs_decam, obs_cfht and obs_sdss, we want these scripts to be the primary source of information.  This means we should delete the generated files, and create them at build time.  We should also standardise the name of the script used to generate these.</p>\n",
            "<p>Create a task to force photometer difference images and PVIs at DiaObject locations. This ticket only creates the task. Further tickets will integrate it into ap_association and ap_pipe.</p>\n",
            "<p>Move the\\xc2\\xa0<a href=\"https://github.com/lsst-dm/pyprofit\" class=\"external-link\" rel=\"nofollow\">pyprofit</a> code into a new <a href=\"https://github.com/lsst-dm/multiprofit\" class=\"external-link\" rel=\"nofollow\">multiprofit</a> repository</p>\n",
            "<p>Many (all?) unit tests are currently built as static executables which include all needed object files. This has several issues associated with it:</p><ul class=\"alternate\" type=\"square\">\\t<li>many files are compiled twice, once as *.os files for shared libraries, second time as *.o file for unit tests</li>\\t<li>unit tests do not test actual code in the shared libraries but instead separately-built copy of the same code</li></ul><p>We should change our procedure and make unit test to link against shared libraries to avoid these problems.</p>\n",
            "<p>Add FunctorKeys for simple, common, calculated fields, including:</p><ul class=\"alternate\" type=\"square\">\\t<li>Magnitudes from fluxes</li>\\t<li>Coords from Points, Points from Coords</li>\\t<li>Ellipse conversions and radius/ellipticity extraction</li></ul>\n",
            "<p>Here\\'s what should be added to qserv-configure.py :</p><ul class=\"alternate\" type=\"square\">\\t<li>edit $QSERV_RUN_DIR/admin/qserv.conf and change Qserv instance dir to current one (which qserv-configure.sh),</li>\\t<li>check compliance of QSERV_RUN_DIR with new Qserv instance (version check ?) and/or update configuration files,</li>\\t<li>re-initialize services, if needed, without breaking already loaded data.</li></ul>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-1755\" title=\"Create an integration test case with GB-sized data\" class=\"issue-link\" data-issue-key=\"DM-1755\"><del>DM-1755</del></a> has been done before this feature was available. It uses rsync over ssh which require use to have an ssh-key on lsst-dev.</p><p>NSCA rsync server can now be accessed with next syntax:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">rsync</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> -av lsst-</span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">rsync</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.ncsa.illinois.edu::qserv</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/qserv_testdata/datasets/case04/data/DeepSource</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.csv.gz .</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># LIST FILES AVAILABLE IN THE MODULE NAMED \"qserv\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">rsync</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> lsst-</span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">rsync</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.ncsa.illinois.edu::qserv</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: #008200; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"># To add content to this module/group, you can copy files into the following path:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  </span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/lsst/rsync/qserv/</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>rsync over ssh feature should be kept, in order to distribute private data are distributed.</p>\n",
            "<p>Qserv packaging procedure requires to often rebuild Qserv and relaunch integration tests.</p><p>IN2P3 Openstack platform offer next virtual machines :</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[fjammes@ccage030 ~]$ nova flavor-list</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><div class=\\'table-wrap\\'><table class=\\'confluenceTable\\'><tbody><tr><td class=\\'confluenceTd\\'> ID </td><td class=\\'confluenceTd\\'> Name              </td><td class=\\'confluenceTd\\'> Memory_MB </td><td class=\\'confluenceTd\\'> Disk </td><td class=\\'confluenceTd\\'> Ephemeral </td><td class=\\'confluenceTd\\'> Swap </td><td class=\\'confluenceTd\\'> VCPUs </td><td class=\\'confluenceTd\\'> RXTX_Factor </td><td class=\\'confluenceTd\\'> Is_Public </td></tr><tr><td class=\\'confluenceTd\\'> 1  </td><td class=\\'confluenceTd\\'> m1.tiny           </td><td class=\\'confluenceTd\\'> 512       </td><td class=\\'confluenceTd\\'> 0    </td><td class=\\'confluenceTd\\'> 0         </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 1     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 15 </td><td class=\\'confluenceTd\\'> cc.windows.small  </td><td class=\\'confluenceTd\\'> 4096      </td><td class=\\'confluenceTd\\'> 20   </td><td class=\\'confluenceTd\\'> 0         </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 2     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 16 </td><td class=\\'confluenceTd\\'> cc.windows.xlarge </td><td class=\\'confluenceTd\\'> 8192      </td><td class=\\'confluenceTd\\'> 50   </td><td class=\\'confluenceTd\\'> 0         </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 4     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 2  </td><td class=\\'confluenceTd\\'> m1.small          </td><td class=\\'confluenceTd\\'> 2048      </td><td class=\\'confluenceTd\\'> 10   </td><td class=\\'confluenceTd\\'> 20        </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 1     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 3  </td><td class=\\'confluenceTd\\'> m1.medium         </td><td class=\\'confluenceTd\\'> 4096      </td><td class=\\'confluenceTd\\'> 10   </td><td class=\\'confluenceTd\\'> 40        </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 2     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 4  </td><td class=\\'confluenceTd\\'> m1.large          </td><td class=\\'confluenceTd\\'> 8192      </td><td class=\\'confluenceTd\\'> 10   </td><td class=\\'confluenceTd\\'> 80        </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 4     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 5  </td><td class=\\'confluenceTd\\'> m1.xlarge         </td><td class=\\'confluenceTd\\'> 16384     </td><td class=\\'confluenceTd\\'> 10   </td><td class=\\'confluenceTd\\'> 160       </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 8     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 6  </td><td class=\\'confluenceTd\\'> cc.lsst.medium    </td><td class=\\'confluenceTd\\'> 4096      </td><td class=\\'confluenceTd\\'> 20   </td><td class=\\'confluenceTd\\'> 40        </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 2     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> False     </td></tr><tr><td class=\\'confluenceTd\\'> 7  </td><td class=\\'confluenceTd\\'> cc.lsst.large     </td><td class=\\'confluenceTd\\'> 16384     </td><td class=\\'confluenceTd\\'> 20   </td><td class=\\'confluenceTd\\'> 160       </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 8     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> False     </td></tr><tr><td class=\\'confluenceTd\\'> 9  </td><td class=\\'confluenceTd\\'> cc.lsst.xlarge    </td><td class=\\'confluenceTd\\'> 40000     </td><td class=\\'confluenceTd\\'> 20   </td><td class=\\'confluenceTd\\'> 160       </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 20    </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> False     </td></tr></tbody></table></div><p>cc.lsst.xlarge would allow a quick build/test of new Qserv release.</p>\n",
            "<p>Qserv packaging procedure requires to often rebuild Qserv and relaunch integration tests.</p><p>IN2P3 Openstack platform offer next virtual machines :</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[fjammes@ccage030 ~]$ nova flavor-list</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><div class=\\'table-wrap\\'><table class=\\'confluenceTable\\'><tbody><tr><td class=\\'confluenceTd\\'> ID </td><td class=\\'confluenceTd\\'> Name              </td><td class=\\'confluenceTd\\'> Memory_MB </td><td class=\\'confluenceTd\\'> Disk </td><td class=\\'confluenceTd\\'> Ephemeral </td><td class=\\'confluenceTd\\'> Swap </td><td class=\\'confluenceTd\\'> VCPUs </td><td class=\\'confluenceTd\\'> RXTX_Factor </td><td class=\\'confluenceTd\\'> Is_Public </td></tr><tr><td class=\\'confluenceTd\\'> 1  </td><td class=\\'confluenceTd\\'> m1.tiny           </td><td class=\\'confluenceTd\\'> 512       </td><td class=\\'confluenceTd\\'> 0    </td><td class=\\'confluenceTd\\'> 0         </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 1     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 15 </td><td class=\\'confluenceTd\\'> cc.windows.small  </td><td class=\\'confluenceTd\\'> 4096      </td><td class=\\'confluenceTd\\'> 20   </td><td class=\\'confluenceTd\\'> 0         </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 2     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 16 </td><td class=\\'confluenceTd\\'> cc.windows.xlarge </td><td class=\\'confluenceTd\\'> 8192      </td><td class=\\'confluenceTd\\'> 50   </td><td class=\\'confluenceTd\\'> 0         </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 4     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 2  </td><td class=\\'confluenceTd\\'> m1.small          </td><td class=\\'confluenceTd\\'> 2048      </td><td class=\\'confluenceTd\\'> 10   </td><td class=\\'confluenceTd\\'> 20        </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 1     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 3  </td><td class=\\'confluenceTd\\'> m1.medium         </td><td class=\\'confluenceTd\\'> 4096      </td><td class=\\'confluenceTd\\'> 10   </td><td class=\\'confluenceTd\\'> 40        </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 2     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 4  </td><td class=\\'confluenceTd\\'> m1.large          </td><td class=\\'confluenceTd\\'> 8192      </td><td class=\\'confluenceTd\\'> 10   </td><td class=\\'confluenceTd\\'> 80        </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 4     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 5  </td><td class=\\'confluenceTd\\'> m1.xlarge         </td><td class=\\'confluenceTd\\'> 16384     </td><td class=\\'confluenceTd\\'> 10   </td><td class=\\'confluenceTd\\'> 160       </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 8     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> True      </td></tr><tr><td class=\\'confluenceTd\\'> 6  </td><td class=\\'confluenceTd\\'> cc.lsst.medium    </td><td class=\\'confluenceTd\\'> 4096      </td><td class=\\'confluenceTd\\'> 20   </td><td class=\\'confluenceTd\\'> 40        </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 2     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> False     </td></tr><tr><td class=\\'confluenceTd\\'> 7  </td><td class=\\'confluenceTd\\'> cc.lsst.large     </td><td class=\\'confluenceTd\\'> 16384     </td><td class=\\'confluenceTd\\'> 20   </td><td class=\\'confluenceTd\\'> 160       </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 8     </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> False     </td></tr><tr><td class=\\'confluenceTd\\'> 9  </td><td class=\\'confluenceTd\\'> cc.lsst.xlarge    </td><td class=\\'confluenceTd\\'> 40000     </td><td class=\\'confluenceTd\\'> 20   </td><td class=\\'confluenceTd\\'> 160       </td><td class=\\'confluenceTd\\'>&nbsp;</td><td class=\\'confluenceTd\\'> 20    </td><td class=\\'confluenceTd\\'> 1.0         </td><td class=\\'confluenceTd\\'> False     </td></tr></tbody></table></div><p>cc.lsst.xlarge would allow a quick build/test of new Qserv release.</p>\n",
            "nan\n",
            "<p>We setup a configuration of running rsync file transfers/syncs over an stunnel\\xc2\\xa0 as a strawman installation for data transfer for AuxTel.\\xc2\\xa0 \\xc2\\xa0</p>\n",
            "<p>This ticket implements a set of tooling in documenteer that allows us to rendering installation documentation in pipelines.lsst.io that is exactly appropriate for the EUPS tag of the stack being documented. Some examples of functionality are:</p><ul>\\t<li>Include the right EUPS tag in the <tt>eups distrib install</tt> documentation line.</li>\\t<li>Reference the right Python/Conda dependency files for the EUPS tag</li>\\t<li>Populate the version labels throughout the documentation.</li></ul><p>Inside the stack documentation build container we can use the <tt>EUPS_TAG</tt> environment variable. (<a href=\"https://github.com/lsst-sqre/jenkins-dm-jobs/blob/master/pipelines/lib/util.groovy#L1155)\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/jenkins-dm-jobs/blob/master/pipelines/lib/util.groovy#L1155)</a></p><p>An alternative would be to use the EUPS APIs to figure out what tag is currently installed (this might be useful for local builds by developers, but in that case perhaps it would be better have some sort of default fallback).</p>\n",
            "\"<p>Hisanori Furusawa at NAOJ has developed an artifact masking <tt>CmdLineTask</tt> that runs after <tt>ProcessCcdTask</tt> and optionally <tt>meas_mosaic</tt>.  This ticket will make that code compatible with the latest version of the LSST stack and clean it up to meet LSST coding standards.</p><p>If doing so is easy, this will become a new <tt>CmdLineTask</tt> in <tt>pipe_tasks</tt> that delegates to an <tt>obs_base</tt> interface that is optionally implemented in derived <tt>obs_*</tt> packages (with the initial implementation existing only for HSC).  If that is hard or otherwise problematic, we'll just define an HSC-specific <tt>CmdLineTask</tt> directly in <tt>obs_subaru</tt> and refactor it into a more generic interface later.</p><p>In either case, we will also modify the mapper definition files and coaddition tasks to take these new masks as an optional input (disabled by default in all cameras but HSC).</p>\"\n",
            "<p>Realistic quasar SEDs are needed in simulations to test the DCR algorithms.  This ticket will add point-like objects with quasar spectra, appropriate fluxes, and a range of redshifts.</p>\n",
            "<p>The pipeline task conversion processes involves separating all code which needs access to io from algorithm code. In some cases this is not yet possible (such as with IdFactories)  as the middleware necessary for doing this does not yet exist.</p><p>However, to make process on the bulk of the conversion process it is possible to use stand in code to allow conversion and testing in place of a final solution.</p><p>This ticket will cover the work of going back to all the places where this occurs and fixing it up to a final solution once the required middleware exists.</p>\n",
            "<p>pycodestyle has accepted our patch to support W505 warnings for long docstrings.  Flake8 now needs to be modified to allow the max docstring length to be included and propagated to pycodestyle.  This is necessary because all of our checks rely on flake8 to call pycodestyle. The required steps are:</p><ul>\\t<li>Beg pycodestyle to make a release with W505 enabled.</li>\\t<li>Make a pull request for flake8 adding the new functionality.</li>\\t<li>Update our pycodestyle EUPS package (or patch it locally).</li>\\t<li>Apply the patch locally to our flake8 package until a new flake8 release is made.</li></ul>\n",
            "<p>Develop GUI and Unittest for ATHexapod.</p><p>This task should deliver:</p><ul>\\t<li>set of unittests to test the behavior of the CSC\\t<ul>\\t\\t<li>values out of range</li>\\t\\t<li>state transitions</li>\\t\\t<li>try position limits</li>\\t\\t<li>move command\\xc2\\xa0</li>\\t\\t<li>offset command</li>\\t\\t<li>stop command</li>\\t\\t<li>settingsApplied events</li>\\t\\t<li>appliedSettingsMatchStart</li>\\t\\t<li>settingsVersions</li>\\t</ul>\\t</li>\\t<li>A very <b>basic</b> GUI to control the CSC</li></ul>\n",
            "\"<p>Per minrk's suggestion the proxy should be in its own container.</p>\"\n",
            "<p>Set up communication protocol between master and worker loader service.</p>\n",
            "<p>Set up communication protocols between the master and worker loader service.</p>\n",
            "<p>beginning to plan what will be done in the Feb. PM and start testing\\xc2\\xa0</p>\n",
            "<p>With the new ISR order implemented in obs_decam (<a href=\"https://jira.lsstcorp.org/browse/DM-15862\" title=\"Reduce ISR code duplication between ip_isr, obs_subaru, and obs_decam\" class=\"issue-link\" data-issue-key=\"DM-15862\"><del>DM-15862</del></a>), it is necessary to rerun processCcd when making new coadds from hits2014 \"template\" images to be self-consistent with the processCcd that happens on the hits2015 \"science\" images in ap_pipe. This ticket is to do all that to make new DCR coadds (<a href=\"https://jira.lsstcorp.org/browse/DM-16864\" title=\"Investigate relative DcrModel option\" class=\"issue-link\" data-issue-key=\"DM-16864\"><del>DM-16864</del></a>) and a corresponding new ap_pipe rerun.</p>\n",
            "<p>LSST has \"Proof of Concept\" work with Google in GKE.\\xc2\\xa0 There was issue with multicast capability that Firefly\\xc2\\xa0cache relies on for its auto-discovery broadcast. According to <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=vaikunth\" class=\"user-hover\" rel=\"vaikunth\">Vaikunth Thukral</a>, this issue has been resolved with Weave net. We need to test Firefly servers on GKE to confirm it that multiple Firefly servers can communicate with each other.</p>\n",
            "nan\n",
            "<p>See  <a href=\"https://jira.lsstcorp.org/browse/DM-11531\" title=\"Add OAuth 2.0 for the squash-restful-api microservice\" class=\"issue-link\" data-issue-key=\"DM-11531\">DM-11531</a> which will be implemented first.</p>\n",
            "<p>Use bokeh templates to create this page layout for the drill down plots.</p><p><a href=\"https://bokeh.pydata.org/en/latest/docs/user_guide/embed.html\" class=\"external-link\" rel=\"nofollow\">https://bokeh.pydata.org/en/latest/docs/user_guide/embed.html</a></p>\n",
            "<p>Since version 0.12.3 of bokeh <a href=\"http://bokeh.pydata.org/en/latest/docs/releases/0.12.3.html\" class=\"external-link\" rel=\"nofollow\">http://bokeh.pydata.org/en/latest/docs/releases/0.12.3.html</a> data tables can have editable fields. </p><p>In the monitor app table we can have a new field \"Comments\" for entering comments on a specific job (e.g. user wants to make annotations about a metric deviation)</p>\n",
            "<p>The following iptables rule exist in hieradata/03/datacenters/npcf.yaml:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'0340 kubernetes allowed from NCSA 141.142.181.0/24\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    ensure: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'present\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    proto: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'tcp\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    dport: [ </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'10250\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'6443\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'6783\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    action: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'accept\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    source: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'141.142.181.0/24\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This should tentatively be changed to:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'0340 kubernetes allowed from NCSA 141.142.182.128/25\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    ensure: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'present\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    proto: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'tcp\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    dport: [ </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'10250\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'6443\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'6783\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    action: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'accept\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    source: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'141.142.182.128/25\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>It may be possible to restrict this further with more testing. There are also some other weave specific rules that may need changed if using NOT NAT is a possibility. These updates will be made in a separate ticket when I get there.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "\"<p>In the near future, once I get the TAP service that is deployed at NCSA up to at least some level of stability, I need to provide a reference notebook that uses pyvo to access the data and allows people to run queries.</p><p>I've got the notebooks for the demos, but I think also adding in some of the other queries on Fritz's list of example queries is a good idea.\\xc2\\xa0 (as they become supported, most use qserv_ funcs that as of today aren't supported)</p><p>This also means bringing in pyvo into the container build, which shouldn't be a problem.</p>\"\n",
            "<p>From the query monkey it seems like there is some kind of problem where the TAP service connection pool to qserv can get stuck:</p><p>\\xc2\\xa0</p><p><span class=\"error\">&#91;2&#93;</span> errors in a row. Running <span class=\"error\">&#91;SELECT &#39;monkey&#39;, ra, decl FROM wise_00.allwise_p3as_mep WHERE CONTAINS(POINT(&#39;ICRS&#39;, ra, decl), BOX(&#39;ICRS&#39;, 295.0426569335857, 79.31794246418082, 0.09614271869047619, 0.9002164336445476)) = 1&#93;</span> threw [PoolExhaustedException: <span class=\"error\">&#91;http-nio-8080-exec-431&#93;</span> Timeout: Pool empty. Unable to fetch a connection in 20 seconds, none available<span class=\"error\">&#91;size:10; busy:10; idle:0; lastwait:20000&#93;</span>.]</p><p>\\xc2\\xa0</p><p>I\\'ve saved the log from the TAP service and restarted it to get things going again.\\xc2\\xa0 This might be some kind of misconfiguration of the tomcat jdbc pool.</p>\n",
            "<p>Since the base detector type is <tt>SCIENCE</tt> the Corner rafts are inheriting the same type.  I need to add some detector types that implement the other enumerations.</p>\n",
            "<p>Once <a href=\"https://jira.lsstcorp.org/browse/DM-16554\" title=\"Write metadata translators for obs_lsst cameras\" class=\"issue-link\" data-issue-key=\"DM-16554\"><del>DM-16554</del></a> is merged there will be two metadata translators in obs_lsst. This ticket will replace the translation logic in the butler gen2 translator with astro_metadata_translator logic. It looks like I can subclass ParseTask and insert an ObservationInfo constructor. Then most of the translators can be replaced with a trivial data type conversion rather than duplicated camera logic.</p>\n",
            "\"<p>Running PipelineTasks with ctrl_mpexec with -j can lead to SQLite errors about the database being locked.\\xc2\\xa0 It's unclear whether it's just not blocking long enough or not blocking at all, and also unclear whether we need to fix this by adding our own blocking or somehow informing SQLAlchemy or SQLite to do it.</p><p>(It's also possible we do have a genuine deadlock bug, but I doubt it.)</p>\"\n",
            "\"<p>Currently the parser+Intermediate representation unit tests depend on the old (antlr2) parser to generate IR that gets compared with the IR generated by the new (antlr4) parser.</p><p>We need to stop using the antlr2-generated IR in unit tests, and instead have a concise, readable, way to generate a specific IR tree to be used as the 'expected' value for comparison with the (new) parser-generated IR tree.</p><p>The reason for this is we have reached a point where we want the IR generated by the 2 parsers for the same query to diverge (for example so we can use a plugin to put the where clause into disjunctive normal form instead of relying on the parser to build it that way). This allows the parser-generated IR to reflect the query in as natural &amp; accurate a way as possible, and any needed transformations can be applied (selectively, even) later on.</p>\"\n",
            "nan\n",
            "<p><a href=\"http://www.fig.sh/\" class=\"external-link\" rel=\"nofollow\">http://www.fig.sh/</a><br/> coordinate with @GregDaues who is also investigating fig.</p>\n",
            "<p>Learn Docker basics and then package a Qserv mono-node instance.</p>\n",
            "<p>Install procedure described in READMEs.txt is complex and error prone.</p><p>It could be encapsulated in two scripts :</p><p>1. the first for installing Qserv current version in the eups stack, following the LSST official install procedure,<br/>2. the second, developer-oriented, for installing Qserv from a git repository to the eups stack installed during 1.</p><p>This two scripts logs could be colorized for better ergonomy.</p>\n",
            "<p>Add to <a href=\"https://sqr-029.lsst.io:\" class=\"external-link\" rel=\"nofollow\">https://sqr-029.lsst.io:</a></p><ul>\\t<li>Write 2.1 The Confluent Platform</li>\\t<li>Add a new section between \"Deploying Confluent Kafka and InfluxData\" and \"Connecting Kafka and InfluxDB\" that talks about Avro schemas and the Python transformer.</li></ul>\n",
            "\"<p>makeCoaddTempExp's lowest-level work method <tt>createTempExp</tt> interacts with  disk via the Butler.  When building coadds in Spark, or example, this required us to re-write an implementation of <tt>createTempExp</tt> instead of reusing the stack. <tt>createTempExp</tt> currently takes a list of dataRefs corresponding to the calexps that overlap the patch for a particular visit.  These reads could be pushed to the higher-level calling method at the expense of memory.  </p><p>Making <tt>createTempExp</tt> more reusable would require either:<br/>a) Making <tt>createTempExp</tt> able to accept either a list of dataRefs or just a list of calexps. This actually appears to be the intent of the docstring writer). &lt;-- naively, I suspect this will win.<br/>b) Holding 4 full calexps in memory (or 4 partial calexps in memory)<br/>c) Easily reproducible container that can interact with the disk, database etc...</p><p>This ticket involve investigating the computational feasibility, and implementing  best option. </p>\"\n",
            "<p>The requirements associated with Level 2 in LDM-148 (and those referenced in the Level 2 test spec document) need to be explicitly copied into LDM-562.</p>\n",
            "<p>Under <a href=\"https://jira.lsstcorp.org/browse/DM-17059\" title=\"Deploy legacy DAX services on lsst-lsp-int.ncsa.illinois.edu\" class=\"issue-link\" data-issue-key=\"DM-17059\"><del>DM-17059</del></a>, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=cbanek\" class=\"user-hover\" rel=\"cbanek\">Christine Banek</a> has re-established the legacy DAX services under Kubernetes control on <tt>lsst-lsp-int</tt>.</p><p>We now should re-establish the legacy PDAC portal at that address, using Kubernetes for deployment, and in a way which derives the DAX services\\' URLs from the base URL for the deployment in a relocatable way.</p>\n",
            "<p>At the moment SAL messaging is not working, the issue is related to IPTables definition on the puppet configuration for the SAL machines.</p><p>Audit IPtables on CSCs L1 Stand Machines to make sure SAL connection works</p>\n",
            "<p>Create a YAML file for default OODS values, add optional config override to command line, and integrate configuration information into the code.</p>\n",
            "<p>Create a decorator to mark features for deprecation, which includes the version of the stack that will no longer include the feature. The decorator will be used to both warn users of deprecation and to keep track of all features set for removal in a certain version. It will autogenerate note in the sphinx documentation to mark the feature as deprecated.</p><p>Once this is completed an update should be made to the developer docs.</p>\n",
            "<p>It wound up being out-of-scope in <a href=\"https://jira.lsstcorp.org/browse/DM-14762\" title=\"Rerun complete HiTS 2015 data processing on the VC\" class=\"issue-link\" data-issue-key=\"DM-14762\"><del>DM-14762</del></a> to exclude edges (and any other bad/flagged CCD regions) from the object/source plots I made while completing that ticket. It is possible to do now by digging into the diaSrc catalogs, but that will be slow, so we may be better off waiting for the association database to include xy pixel information for sources.</p>\n",
            "<p>Currently, only the star-flat term (determined from multiple exposures) is allowed to be spatially variable in fgcm.\\xc2\\xa0 All other throughput terms (from the atmospheric model and the final gray correction) are only computed per-ccd.\\xc2\\xa0 This ticket adds the option to compute the ccd gray correction with a 2d chebyshev polynomial of configurable order.</p>\n",
            "<p>For ap_pipe and ap_verify we want symmetry between table creation and the configs of the two database interface options currently implemented.</p><p>This ticket will create a create_tables methods on AssociationL1DBProto that will call the \"create schema\" method in AssociationDBSqlite.<br/>It will also add a db_name override to the AssociationL1DBProto config allowing it to behave similarly to that of AssociationDBSqlite.</p>\n",
            "<p>Perform final tweaks, enter into JIRA, submit final plan to the project control specialist. </p>\n",
            "<p>To address the problems observed in detection efficiency in HSC, we\\'d like try the following modifications to either SourceDetectionTask or DetectCoaddSources (since this only needs to happen on coadds):</p><ol>\\t<li>Do not rescale the coadd variance plane.</li>\\t<li>Start with a preliminary detection step with an aggressive threshold (2-4 sigma) to identify regions that may contain objects.  Grow these footprints as usual.</li>\\t<li>Run background estimation, ignoring the just-detected footprints as usual.</li>\\t<li>Add a temporary set of sky objects and measure PSF fluxes on them.</li>\\t<li>Use the ratio of the empirical RMS (\"rms\") of the sky object flux to the mean of its quoted uncertainty (\"err\") to determine an \"effective\" threshold for final detection from the configured (\"nominal\") threshold: effective = nominal*err/rms.</li>\\t<li>Proceed with normal detection as it currently exists in SourceDetectionTask, discarding the temporary sky objects.</li></ol><p>We may also be able to use the mean of the sky object flux to determine the correction to the background, instead of running background estimation instep (3) before adding the sky objects.  This should be possible via a config option - we don\\'t know whether the finite number sky objects will give us sufficient S/N to estimate the background, and we also don\\'t know if subtracting the background after a more aggressive detection step will yield a mean sky object flux that is consistent with zero.</p><p>In testing, we\\'ll need to tune the threshold for the first aggressive detection phase and test that the final \"reEstimateBackground\" step in SourceDetectionTask doesn\\'t degrade the quality of the background (by looking at the regular sky objects added later).</p><p>Removing the coadd variance scaling will also change the reported uncertainties for our measurements.  I think the reported uncertainties were already wrong, but this may make them slightly more wrong.  We could consider scaling all of the uncertainties by (rms/err) in a manner similar to how we apply the aperture corrections, which should push them closer to being correct (it would only be exact for PSF fluxes on faint point sources, I think).  But we should at least make sure that (rms/err) is recorded for each patch so we could let the science users apply that factor if applied.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=rhl\" class=\"user-hover\" rel=\"rhl\">Robert Lupton</a>, please check that all of the above makes sense to you (using another background estimation step instead of sky objects to correct for the mean offset was Tanaka-san\\'s idea; I think it\\'s worth trying both approaches).  At the HSC telecon on 12/12 we agreed that <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a> would try to implement this after getting the y-band background subtraction in.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2019_02. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>This is the second of of implementation of <a href=\"https://jira.lsstcorp.org/browse/RFC-554\" title=\"Refactoring of pipe_supertask\" class=\"issue-link\" data-issue-key=\"RFC-554\"><del>RFC-554</del></a>. pipe_supertask has been split into two packages now, things in pipe_base should be mostly OK, but modules in ctrl_mpexec need serious re-factoring to make them more reusable for other potential clients.</p>\n",
            "nan\n",
            "<p>Teach David (PhD student in Stanford University) the background knowledge of active optics and the use of AOS codes (contains ts_tcs_wep, ts_tcs_wep_phosim, and ts_tcs_ofc). Discuss the AOS closed-loop simulation with PhoSim.</p>\n",
            "<p>To have this task done, the CSC should:</p><ul>\\t<li>read configurations from configuration files</li>\\t<li>publish settingsApplied for configurations used\\xc2\\xa0</li>\\t<li>publish settingsAppliedMatchStart when applies</li>\\t<li>publish settingVersions when first running the CSC</li>\\t<li>publish detailedState\\xc2\\xa0</li>\\t<li>Publish telemetry\\xc2\\xa0positionStatus with current position</li>\\t<li>accept and execute commands: moveToPosition,\\xc2\\xa0applyPositionLimits,\\xc2\\xa0applyPositionOffset,\\xc2\\xa0stopAllAxes,\\xc2\\xa0pivot</li>\\t<li>Publish detailedState when the state change</li>\\t<li>Publish settings Applied for:\\xc2\\xa0settingsAppliedPositionLimits,\\xc2\\xa0settingsAppliedPivot,\\xc2\\xa0settingsAppliedTcp</li>\\t<li>Publish\\xc2\\xa0positionUpdate when position command change try to move\\xc2\\xa0</li></ul>\n",
            "<p>THIS IS GEN2 BUTLER.</p>\n",
            "\"<p>When transactions are nested, any raised exception that propagates through a <tt>with</tt> block will trigger a rollback on higher-level <tt>with</tt> blocks, even if that exception is caught immediately outside the innermost <tt>with</tt> block (which is generally the on added by the <tt>transactional</tt>\\xc2\\xa0decorator.</p><p>This gives the illusion of fully nested transactions, while in reality we only provide per-Butler transactions in which nesting is a no-op.\\xc2\\xa0 We should (ideally) find a better way to map the transactions we do support to Python language constructs.\\xc2\\xa0 Failing that, we should at least prevent <tt>transactional-</tt> decorated methods from triggering higher-level rollbacks when they don't have to (e.g. when <tt>Registry.addDataset</tt> sees a conflict before it even tries to add anything).</p>\"\n",
            "<p>Robert\\'s input #9, <a href=\"https://jira.lsstcorp.org/browse/DM-7321\" title=\"Adapt display_firefly to new Firefly API, and to py3\" class=\"issue-link\" data-issue-key=\"DM-7321\"><del>DM-7321</del></a></p><p>disp.pan(0, 0) is ignored (I think anything below (0.5, 0.5) fails). I\\'d expect to be able to pan any point to the centre of the display, but I\\'d certainly expect that it\\'d clip to a valid coord not silently ignore my request)</p>\n",
            "<p>CADC has introduced a couple of build breaking changes that I have to fix.\\xc2\\xa0 Luckily those are contained in this readme:</p><p><a href=\"https://github.com/opencadc/uws/blob/master/README.md\" class=\"external-link\" rel=\"nofollow\">https://github.com/opencadc/uws/blob/master/README.md</a></p>\n",
            "<p>Add Sphinx support to meas_astrom package.</p>\n",
            "<p>The base tests provided by <tt>obs_base</tt> require test data to run on.  Because of this, we will need to pick at least one on sky image per instrument to run the tests.</p>\n",
            "<p>There are base tests that can be subclassed and will provide good coverage of basic functionality of the obs_lsst package.  The <tt>obs_test</tt> package has an <a href=\"https://github.com/lsst/obs_test/blob/master/tests/test_obs_test.py\" class=\"external-link\" rel=\"nofollow\">example</a> for how this would be done.  There will need to be one test for each of the instruments serviced by <tt>obs_lsst</tt>.</p>\n",
            "<p>Currently, the classes in <tt>lsst.verify.compatibility</tt> do not use any Gen 3 elements, including <tt>lsst.pipe.base.InputDatasetConfig</tt> and <tt>lsst.pipe.base.OutputDatasetConfig</tt>. However, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=czw\" class=\"user-hover\" rel=\"czw\">Christopher Waters</a> <a href=\"https://github.com/lsst/ap_verify/pull/55#discussion_r241553699\" class=\"external-link\" rel=\"nofollow\">suggested</a> that these config classes can be used in Gen 2 task configs without inadvertent side effects. Adopting them as part of the <tt>MetricTask</tt> API now will make it much easier to transition to Gen 3.</p><p>This ticket covers the following work:</p><ul>\\t<li>Update <tt>MetricTask</tt> documentation to require that subclasses use <tt>*DatasetConfig</tt> appropriately.</li>\\t<li>Rewrite <tt>MetricTask</tt> input/output methods to use the configs in a way that is compatible with Gen 2 repositories.</li>\\t<li>Rewrite <tt>TimingMetricTask</tt> (and any other extant <tt>MetricTasks</tt>) in terms of <tt>*DatasetConfig</tt>. This should reduce the amount of source code at the cost of an extra config field.</li></ul>\n",
            "<p>In\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-16932\" title=\"SQuaRE Events infrastructure prototype / Kafka-based services\" class=\"issue-link\" data-issue-key=\"DM-16932\"><del>DM-16932</del></a>, the SQuaRE Bot becomes less an application that knows the specifics of different commands, and more a router from Slack messages/events into Kafka topics. This ticket is to create the MVP deployment of SQuaRE Bot Jr (the next generation SQuaRE Bot). The goal is to have an app that can be registered with the Slack API. Emitting Kafka topics will be done in subsequent tickets.</p><p>Some specific features:</p><ul>\\t<li>Demonstrate an app based on aiohttp.web (<a href=\"https://aiohttp.readthedocs.io/en/stable/)\" class=\"external-link\" rel=\"nofollow\">https://aiohttp.readthedocs.io/en/stable/)</a>\\xc2\\xa0as a proof-of-concept of an asyncio-based app, rather than something like our typical synchronous Flask apps. This does mean figuring out logging, configuration, routing, and deployment methods.</li>\\t<li>Since we need a staging environment (rather than using api.lsst.codes) this ticket will also stand up a Kubernetes cluster and explore new methods of ingress with Let\\'s Encrypt certificates.</li>\\t<li>Add a Travis-based Docker build pipeline.</li></ul>\n",
            "nan\n",
            "<p>Implementing <a href=\"https://jira.lsstcorp.org/browse/RFC-554\" title=\"Refactoring of pipe_supertask\" class=\"issue-link\" data-issue-key=\"RFC-554\"><del>RFC-554</del></a>, there will be a lot of renaming but some code needs dependency cleanup and API change.</p><p>This ticket covers moving modules from pipe_supertask into pipe_base and new package ctrl_mpexec. Further re-factoring of ctrl_mpexec contents will be done on a separate ticket.</p>\n",
            "<p><tt>git clone <a href=\"https://github.com/guyonnet/slitless_image_reduction/\" class=\"external-link\" rel=\"nofollow\">https://github.com/guyonnet/slitless_image_reduction/</a></tt></p><p>clone croaks &amp; install it</p><p>Install and configure SExtractor</p><p>Get the pipeline running.</p><p>Then port it to py3 so it can be run from the same env as the stack.</p><p>\\xc2\\xa0</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_50. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Testing running multiple instances of the ingress controllers and rules to deviate traffic either way</p>\n",
            "<p>This is to create a git-lfs repository to hold the test data necessary for running the test script provided by RHL in <a href=\"https://github.com/lsst-dm/ci_lsst\" class=\"external-link\" rel=\"nofollow\">ci_lsst</a>.</p>\n",
            "<p>There is very little code in <tt>ci_lsst</tt>.  I think we should merge that code into <tt>obs_lsst</tt> proper.  This is somewhat counter to how some other packages do this, but since the script is very specific to <tt>obs_lsst</tt>, I think that may be the most helpful thing to do.</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Redeploy InlfuxDB with a persistent volume for <tt>/data</tt> in the <tt>influxdb-demo</tt> cluster.</li>\\t<li>Use the method outlined in <a href=\"https://jira.lsstcorp.org/browse/DM-15888\" title=\"Influxdata stack demonstration\" class=\"issue-link\" data-issue-key=\"DM-15888\"><del>DM-15888</del></a> to write SQuaSH prod results to InfluxDB.</li>\\t<li>Deploy the SQuaSH API to production after <a href=\"https://jira.lsstcorp.org/browse/DM-16300\" title=\"Implement a celery task in the SQuaSH API to save time series data to InfluxDB \" class=\"issue-link\" data-issue-key=\"DM-16300\"><del>DM-16300</del></a></li>\\t<li>Update metric definitions and specs</li></ul>\n",
            "nan\n",
            "nan\n",
            "<p>Begin preparations for support the stack tutorial and/or other needs at the American Astronomical Society meeting January 6-10: system setup, login creation, install DM tools, etc.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Some of the fields in <tt>sample-avro-alert</tt> no longer appear in the DPDD. This ticket is to update the schemas accordingly and produce an average size estimate relevant to <a href=\"https://jira.lsstcorp.org/browse/RFC-538\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/RFC-538</a></p>\n",
            "<p>for the query <tt>SELECT objectId,ra_PS FROM Object WHERE objectId BETWEEN 417857368235490 AND 420949744686724;</tt></p><p>the integration test fails, the <tt>qserv</tt> and <tt>qserv_async</tt> results are much shorter than the <tt>mysql</tt> results.</p><p>\\xc2\\xa0</p>\n",
            "<p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import lsst.cp.pipe.makeBrighterFatterKernel as kernelGen</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">biases, means, xcorrs  = kernelGen.calcBiasCorr([70000, 90000, 110000], (2000,1000), useTaskCode=False, nSigma=5, repeats=3)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>and</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">biases2, means2, xcorrs2 = kernelGen.calcBiasCorr([70000, 90000, 110000], (2000,1000), useTaskCode=True, nSigma=5, repeats=3)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>differ, and they shouldn\\'t. Investigate and fix.</p><p>\\xc2\\xa0</p><p>Furthermore, as per what was originally <a href=\"https://jira.lsstcorp.org/browse/DM-15401\" title=\"Fix default xcorrCheckRejectLevel value back to nominal\" class=\"issue-link\" data-issue-key=\"DM-15401\"><del>DM-15401</del></a>: something seems to not be quite right in the calculation of cross-correlations in <tt>MakeBrighterFatterKernelTask</tt>, as the sum of the cross-correlations are coming out much higher than they should be (I think, based on the code it was ported from at least).</p><p>Find out why, and once that\\'s done, put the config value\\xc2\\xa0<tt>xcorrCheckRejectLevel</tt> back to the nominal value of 0.2 (or was it 0.1, check Will\\'s code), if appropriate.</p><p>Given that these may be related, these are being combined.</p>\n",
            "<p>Currently a quantum graph does not contain information about arguments to be passed to the _<em>init</em>_ function of a pipelinetask. This causes init input arguments to not be copied to a new collection during processing. This ticket will add init input arguments to the quantum graph.</p>\n",
            "<p>The QA dashboard can be much more useful for drill-down exploration if custom callbacks were attached to the interactive plots.  As a first step toward allowing users to implement custom callbacks, identify and implement one or more callbacks of this sort that would be generally useful, and put this into the prototype dashboard.</p>\n",
            "<p>The QA dashboard prototype (<a href=\"https://jira.lsstcorp.org/browse/DM-10619\" title=\"Build a prototype bokeh server implementation to demonstrate desired interactive QA plots\" class=\"issue-link\" data-issue-key=\"DM-10619\"><del>DM-10619</del></a>) has been developed in parallel with learning how bokeh works.  Once this initial learning phase is mostly over (that is, when I understand how to use the key bokeh features required for the QA dashboard as planned), I will need to reorganize and clean up the dashboard-implementing code.  After doing this, move development to a qa-dashboard repo under LSST-DM.</p>\n",
            "\"<p>Optimize pyprofit's multi-Gaussian Sersic model evaluation with (or for fitting) pixel-convolved multi-Gaussian PSFs. In this case the model evaluation is one Gaussian function per component per pixel, which is easy to optimize in C++, avoiding the overhead in creating GalSim objects.</p>\"\n",
            "<p>Displaying CModels and residuals is currently done with matplotlib. There are hooks for additional backends, and one should be added for afw display</p>\n",
            "<p>Test the build and release process.  This includes making all the relevant branches and mocking a feature branch that needs to be included (i.e. more than one release candidate).</p>\n",
            "<p>coaddAnalysis with HSC-RC2 tract=9615 filter=HSC-R data gave the following error:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20181012/stack/miniconda3-4.5.4-fcd27eb/Linux64/pipe_base/16.0-13-gb122224+8/python/lsst/pipe/base/cmdLineTask.py\", line 388, in __call__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result = self.runTask(task, dataRef, kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack_20181012/stack/miniconda3-4.5.4-fcd27eb/Linux64/pipe_base/16.0-13-gb122224+8/python/lsst/pipe/base/cmdLineTask.py\", line 447, in runTask</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return task.runDataRef(dataRef, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/hchiang2/stack/pipe_analysis/python/lsst/pipe/analysis/coaddAnalysis.py\", line 334, in runDataRef</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    postFix=\"_unforced\")</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/hchiang2/stack/pipe_analysis/python/lsst/pipe/analysis/coaddAnalysis.py\", line 577, in plotSizes</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    labeller=StarGalaxyLabeller(), flagsCat=flagsCat,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/home/hchiang2/stack/pipe_analysis/python/lsst/pipe/analysis/analysis.py\", line 104, in __init__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    self.good = np.isfinite(self.quantity) &amp; np.isfinite(self.mag) if self.quantity is not None else None</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ValueError: operands could not be broadcast together with shapes (23872,) (23873,)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Other tracts/filters in HSC-RC2 finish without errors. A command to reproduce is </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">coaddAnalysis.py /datasets/hsc/repo/ --calib /datasets/hsc/repo/CALIB  --rerun RC/w_2018_42/DM-16095:private/user/name/coaddAnalysis  --id tract=9615 filter=HSC-R </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>This used to finish fine in early September with <tt>w_2018_36</tt> (before the <a href=\"https://jira.lsstcorp.org/browse/DM-15869\" title=\"Fix for renaming *_flux to *_instFlux \" class=\"issue-link\" data-issue-key=\"DM-15869\"><del>DM-15869</del></a> issue). </p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_48. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Per <a href=\"https://jira.lsstcorp.org/browse/RFC-133\" title=\"No full table scans on Level 1 catalogs\" class=\"issue-link\" data-issue-key=\"RFC-133\"><del>RFC-133</del></a>, users will sometimes need to do full table scan through L1 catalogs, and our baseline does not allow for full scans on the L1 catalog. It\\'d be good to maintain a replica of L1 for such scans. This story involves changing LDM-141 and adding hardware for the replica. </p>\n",
            "<p>I might have misinterpreted this in the documentation I read, so if this is completely incorrect, please ignore this.</p><p>LDM-141 says the images are 16-bits per pixel.  LCR-131 says this info is now 18-bits per pixel.  The Confluence pagehttps://confluence.lsstcorp.org/display/LKB/LSST+Key+Numbers  says that the images are 16-bits per pixel.  The Key numbers page <a href=\"http://lsst.org/scientists/keynumbers\" class=\"external-link\" rel=\"nofollow\">http://lsst.org/scientists/keynumbers</a> says Dynamic Range is 18 bits.</p><p>Some of the documentation says we\\'re handling 16-bits per pixel, and some says we\\'re dealing with 18-bits per pixel.  Now, I believe that it\\'s settled on 18-bits.</p><p>A lot of calculations in LDM-141 use 16-bits per pixel, which cascades throughout the rest of the spreadsheet.  (examples otherInput!H10, otherInput!H12).</p>\n",
            "nan\n",
            "<p>While running coaddDriver with the PDR1 data, using <tt>w_2018_15</tt>, I got 8 cases with the following IndexError</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">coaddDriver WARN: lsst-verify-worker23:129753: Caught IndexError while detection on DataId(initialdata={\\'tract\\': 16972, \\'filter\\': \\'HSC-G\\', \\'patch\\': \\'0,7\\'}, tag=set()): cannot do a non-empty take from an empty axes.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">coaddDriver INFO: lsst-verify-worker23:129753: Traceback:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/stack/miniconda3-4.3.21-10a4fa6/Linux64/ctrl_pool/15.0-1-ga91101e+7/python/lsst/ctrl/pool/parallel.py\", line 512, in logOperation</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    yield</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_drivers/15.0-3-ga03b4ca+9/python/lsst/pipe/drivers/coaddDriver.py\", line 321, in coadd</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    detResults = self.detectCoaddSources.runDetection(coadd, idFactory, expId=expId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_tasks/15.0-5-g389937dc+5/python/lsst/pipe/tasks/multiBand.py\", line 301, in runDetection</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    varScale = self.scaleVariance.run(exposure.maskedImage)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_tasks/15.0-5-g389937dc+5/python/lsst/pipe/tasks/scaleVariance.py\", line 116, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    factor = self.pixelBased(maskedImage)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/stack/miniconda3-4.3.21-10a4fa6/Linux64/pipe_tasks/15.0-5-g389937dc+5/python/lsst/pipe/tasks/scaleVariance.py\", line 155, in pixelBased</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    q1, q3 = np.percentile(snr[isGood], (25, 75))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/lib/function_base.py\", line 4269, in percentile</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    interpolation=interpolation)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/lib/function_base.py\", line 4011, in _ureduce</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    r = func(a, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/lib/function_base.py\", line 4386, in _percentile</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    x1 = take(ap, indices_below, axis=axis) * weights_below</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 134, in take</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return _wrapfunc(a, \\'take\\', indices, axis=axis, out=out, mode=mode)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File \"/software/lsstsw/stack3_20171023/python/miniconda3-4.3.21/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 57, in _wrapfunc</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    return getattr(obj, method)(*args, **kwds)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">IndexError: cannot do a non-empty take from an empty axes.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The traceback have similarities to but are not exactly the same as <a href=\"https://jira.lsstcorp.org/browse/DM-13563\" title=\"IndexError in coaddBase.scaleVariance warps with low coverage \" class=\"issue-link\" data-issue-key=\"DM-13563\"><del>DM-13563</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-13517\" title=\"&quot;IndexError: cannot do a non-empty take from an empty axes&quot; in making coadd\" class=\"issue-link\" data-issue-key=\"DM-13517\"><del>DM-13517</del></a>. The 8 cases include 2 in UDEEP, 5 in DEEP, and 1 in WIDE.  To reproduce, their data IDs are: </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">UDEEP: --id tract=8766 filter=HSC-G patch=8,3 --selectId ccd=0..8^10..103 visit=9830^9832^9834^9836^9874^9878^11626^11628^11642^11644^11660^11662^42346^42348^42350^42352^42354^42356</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">UDEEP: --id tract=9571 filter=HSC-Y patch=7,7 --selectId ccd=0..8^10..103 visit=318^322^324^326^328^330^332^340^344^346^348^350^352^354^356^358^360^362^1856^1868^1870^1872^1874^1876^1880^1882^11716^11718^11720^11722^11724^11726^11728^11730^11732^11734^11736^11740^22604^22606^22608^22626^22628^22630^22632^22642^22644^22646^22648^22658^22660^22662^22664</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">DEEP: --id tract=9708 filter=HSC-G patch=7,6 --selectId ccd=0..8^10..103 visit=9796^9798^9812^9820^34488^34496^34504^34512</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">DEEP: --id tract=9812 filter=HSC-G patch=5,3 --selectId ccd=0..8^10..103 visit=29308^29310^29316^29318^29328^29332^29342^29346^29354^29358</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">DEEP: --id tract=8766 filter=HSC-I patch=0,5 --selectId ccd=0..8^10..103 visit=46860^46864^46866^14220^14222^14224^14226^14246^14248^14252^14254^14264^14266^14268</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">DEEP: --id tract=9707 filter=HSC-I patch=6,6 --selectId ccd=0..8^10..103 visit=7240^7242^7244^7246^7256^7258^7264^7266^35978^35982^35984^35988^35990^35996^35998^36004^36006</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">DEEP: --id tract=9707 filter=NB0816 patch=6,6 --selectId ccd=0..8^10..103 visit=37318^37320^37322^37324^37326^37328^37330^37796^37798^37800^38474</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">WIDE: --id tract=16972 filter=HSC-G patch=0,7 --selectId ccd=0..8^10..103 visit=29530^29536^29538^34210^34212^34214^34216^34218</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p> One can run <p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">coaddDriver.py /datasets/hsc/repo --calib /datasets/hsc/repo/CALIB --rerun DM-13666/[DEEP|UDEEP|WIDE]:private/username/abcd  .... </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/></p><p>with the above IDs to reproduce. </p>\n",
            "<p>I wrote an example script to download HSC images with the quarry tool and PSF images from the picker tool and fit them. This is available at <a href=\"https://github.com/lsst-dm/pyprofit/blob/master/examples/hsc.py\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/pyprofit/blob/master/examples/hsc.py</a> . I attached an example of an r-band fit to a GAMA galaxy from HSC-wide. This is meant as a publicly-available precursor to integration with the stack - it\\'s not very useful on its own since the footprints aren\\'t publicly available, but could be expanded to test other deblenders like Scarlet.</p><p>Pycharm run configurations for HSC tests are available here; this will be kept up to date:</p><p><a href=\"https://github.com/lsst-dm/pyprofit/blob/master/.idea/runConfigurations/pyprofit_fit_hsc.xml\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/pyprofit/blob/master/.idea/runConfigurations/pyprofit_fit_hsc.xml</a></p><p>At the time of writing, the command to run the HSC example is</p><p>python3 $PROJECT_DIR$/examples/hsc.py</p><p>Galaxy cutout arguments:</p><p>-radec 134.67675665 0.19143266 -size 19.9asec</p><p>There are further options enabled in other tickets like galsim integration (<a href=\"https://jira.lsstcorp.org/browse/DM-14648\" title=\"Add GalSim support to pyprofit\" class=\"issue-link\" data-issue-key=\"DM-14648\"><del>DM-14648</del></a>) and other optimizers (<a href=\"https://jira.lsstcorp.org/browse/DM-14635\" title=\"Add support for pagmo2 optimizers in pyprofit\" class=\"issue-link\" data-issue-key=\"DM-14635\"><del>DM-14635</del></a>) but the defaults should always work as long as a cutout is available at that location.</p>\n",
            "<p><tt>IS NULL</tt> in <tt>SUBMIT SELECT COUNT<img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/star_yellow.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/> FROM wise_00.allwise_p3as_mep WHERE spt_ind IS NULL;</tt><br/>causes the following error message:<br/>&gt; ERROR 4110 (Proxy): Query processing error: QI=?: Failed to instantiate query: ParseException:enterIsNullPredicate not supported.</p><ol>\\t<li>improve the error message so it\\'s clear to the user that the query could not be handled/processed, add the specific unsupported portion of the query if possible (in this case a message like \"IS NULL is not supported by qserv at this time\" would be very helpful.</li>\\t<li>the parser needs to be extended to support IS NULL</li>\\t<li>add an integration test for IS NULL</li></ol>\n",
            "nan\n",
            "\"<p>Currently, <tt>ap_verify</tt> is configured to use an SQLite association database (this assumption is, in particular, hard-coded into the <tt>measurements</tt> subpackage). Switch <tt>ap_verify</tt> over to using <tt>l1dbproto</tt> so that <tt>ap_association</tt> can remove support for SQLite, preferably in a way that doesn't couple <tt>ap_verify</tt> to future changes in how databases are handled.</p>\"\n",
            "<p>Update the documentation at pipelines.lsst.io for the v14.0 release.</p>\n",
            "<p>The Kafka Confluent Platform deployment in <a href=\"https://github.com/lsst-sqre/kafka-efd-demo\" class=\"external-link\" rel=\"nofollow\">efd-kafka-demo</a> includes a <tt>confluent-kafka-cp-kafka-connect</tt> pod but no connectors are configured.</p><p>The idea is to use the Kafka Connect REST API to create and configure the <a href=\"https://docs.confluent.io/current/connect/kafka-connect-influxdb/influx-db-sink-connector/index.html\" class=\"external-link\" rel=\"nofollow\">InfluxDB Sink Connector</a> which will let us to consume specific kafka topics and save them  InfluxDB.</p><p>This ticket includes a new deployment of  <a href=\"https://github.com/lsst-sqre/kafka-efd-demo\" class=\"external-link\" rel=\"nofollow\">efd-kafka-demo</a> and  <a href=\"https://github.com/lsst-sqre/ick-deployment\" class=\"external-link\" rel=\"nofollow\">ick-deployment</a> in the same cluster.</p>\n",
            "<p>Create a mock of SAL in the <a href=\"https://github.com/lsst-sqre/kafka-efd-demo\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/kafka-efd-demo</a> to generate SAL messages at arbitrary data rates with random data (though with the actual SAL schemas).</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=afausti\" class=\"user-hover\" rel=\"afausti\">Angelo Fausti</a> will work on ingesting this data into InfluxDB.</p>\n",
            "<p>The IAU Minor Planet Center (MPC) has developed a new linking algortihm (HelioLinC,\\xc2\\xa0 Holman, M.J., et a. 2018. <em>The Astronomical Journal</em>, <em>156</em>(3), p.135.) that promises to be an efficient alternative to the classical\\xc2\\xa0moving object processing system (MOPS) linking.</p><p>HelioLinC is currently under development as part of the \"Pytrax\" package (M. Lackner, 2018).\\xc2\\xa0</p><p>In order to evaluate the potential of HelioLinC to reduce complexity and increase efficiency in the LSST-MOPS ecosystem, the package needs to be locally installed and tested against the classical MOPS (epyc.astro.washington.edu).</p><p>Since the package was custom built for the MPC the installation requires code modification that have to be performed together with the code author M. Lackner via teleconferencing.</p><p>DELIVERABLES:</p><p>1) Create a conda enviroment to install and run Pytrax on the local machine epyc</p><p>2) Test the installation using standard tests collected in a Jupyter notebook provided by the MPC</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "\"<p>Submission of an abstract to the 2019 IAA Planetary Defense Conference (PDC) describing the LSST moving object processing system.</p><p>In accordance with the LSST deputy director and the organizing committee of the PDC, an abstract is submitted detailing the current layout and future capabilities of LSST MOPS in light of the LSST's potentially significant future contribution to asteroid discovery and planetary defense.\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>DELIVERABLES:</p><p>Abstract</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\"\n",
            "<p>We want to answer this question :</p><ul>\\t<li>What is the sensitivity of calibrated magnitudes to non-gray components of atmosphere ?</li></ul><p>My contribution consists in providing realistic atmospheric condition .</p><p>Here is an illustration of PWV in 2017 at LSST site\\xc2\\xa0</p><p>\\xc2\\xa0</p><p><span class=\"image-wrap\" style=\"\"><img src=\"https://jira.lsstcorp.org/secure/attachment/32303/32303_pwv2017.png\" style=\"border: 0px solid black\" /></span></p><p>\\xc2\\xa0</p><p><span class=\"image-wrap\" style=\"\"><img src=\"https://jira.lsstcorp.org/secure/attachment/32302/32302_pwv1year.png\" style=\"border: 0px solid black\" /></span></p><p>\\xc2\\xa0</p><p>I now have to find representative distributions for the other parameters.\\xc2\\xa0</p>\n",
            "<p>Shepherd the finalization of LSST-MPC MOU text, taking into account any concerns on the LSST side. This includes the collection of feedback from LSST senior management, and incorporation of feedback into the MOU text. It also includes keeping in touch with the MPC to understand any concerns their management has raised, and respond to them if possible.</p><p>The deliverable the MOU text that the LSST is able to sign.</p>\n",
            "<p>Prepare change request documentation including timeline and set of milestones for MOPS development with focus on the upcoming sprint.</p><p>\\xc2\\xa0Deliverables: Preliminary MOPS development GANTT chart / timeline</p>\n",
            "<p>Create accounts for the Minor Planet Center staff on the epyc machine at UW, and set up a basic PostgreSQL server. The MPC staff will use this to set up a replica of the internal MPC database, running on SSDs. This will later be used to test the existing database throughputs, and whether they can scale to LSST requirements.</p>\n",
            "<p>Related to <a href=\"https://jira.lsstcorp.org/browse/DM-16333\" title=\"push ap_verify results to squash\" class=\"issue-link\" data-issue-key=\"DM-16333\"><del>DM-16333</del></a>, we want to retroactively load the <tt>ap_verify</tt> CI jobs into SQuaSH to have the <a href=\"https://ci.lsst.codes/blue/organizations/jenkins/scipipe%2Fap_verify/activity\" class=\"external-link\" rel=\"nofollow\">complete history of these runs</a>.</p><p>With this ticket we\\'ll also test a change introduced by <a href=\"https://jira.lsstcorp.org/browse/DM-16300\" title=\"Implement a celery task in the SQuaSH API to save time series data to InfluxDB \" class=\"issue-link\" data-issue-key=\"DM-16300\"><del>DM-16300</del></a> into the SQuaSH API. Now <tt>verify</tt> metrics are also sent to InfluxDB and can be visualized using the <a href=\"https://chronograf-demo.lsst.codes\" class=\"external-link\" rel=\"nofollow\">Chronograf UI</a>.</p><p>We\\'ll first do this on the SQuaSH demo instance and then replicate to production in another ticket when <a href=\"https://jira.lsstcorp.org/browse/DM-16333\" title=\"push ap_verify results to squash\" class=\"issue-link\" data-issue-key=\"DM-16333\"><del>DM-16333</del></a> is complete.</p>\n",
            "<p>This notebook demonstrates the InfluxDB stack. We run InlfuxDB + Chronograf + Kapacitor using the docker compose configuration in this repo. We show different ways to write data to InfluxDB using the CLI utility, the HTTP API and the Python client. We send SQuaSH metrics to InfluxDB and use Chronograf UI for creating a dashboard.</p>\n",
            "<p>Based on the reprocessed HiTS 2014 data from <a href=\"https://jira.lsstcorp.org/browse/DM-15080\" title=\"Process HiTS 2014, build template coadds\" class=\"issue-link\" data-issue-key=\"DM-15080\"><del>DM-15080</del></a>, and the DCR-corrected template construction code from <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=sullivan\" class=\"user-hover\" rel=\"sullivan\">Ian Sullivan</a>, build DCR corrected templates.</p>\n",
            "<p>There are several SearchProcessors that insist on saving the results as IPAC table before passing it on.\\xc2\\xa0 \\xc2\\xa0This may cause lost of meta information because IPAC table does not have the facility to store them.\\xc2\\xa0 Identify and fix these processors.</p>\n",
            "<p>Involves understanding new StorageInterface and formaters being developed for the Butler.</p>\n",
            "<p>Add support for hue preserving rgb. Might need a variant of set_stretch function.</p>\n",
            "<p>Modify Confluent\\'s helm charts to set up LoadBalancers, or alternatively modify <a href=\"https://github.com/Yolean/kubernetes-kafka\" class=\"external-link\" rel=\"nofollow\">https://github.com/Yolean/kubernetes-kafka</a> to do everything the Confluent stuff does.</p>\n",
            "<p>In the first run of calibration of S18a with FGCM (<a href=\"https://jira.lsstcorp.org/browse/DM-15545\" title=\"Run FGCM on HSC S18A\" class=\"issue-link\" data-issue-key=\"DM-15545\"><del>DM-15545</del></a>) there is a bimodality in the comparison between HSC r-band and Gaia G-band.\\xc2\\xa0 This could be due to disconnected regions or due to assumptions about the HSC-R and HSC-R2 filters (or something else).\\xc2\\xa0\\xc2\\xa0</p>\n",
            "<p>The purpose of this ticket is to understand how message consumption latency is affected by load in the messaging system. Specifically, by frequency of messages in a single topic, and by the overall number of topics.</p><p><a href=\"https://github.com/lsst-sqre/kafka-efd-demo\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/kafka-efd-demo</a> is the testbed for this experiment. The producers and consumers will all be run inside the same GKE cluster.</p>\n",
            "\"<p><tt>AstromFit::Minimize</tt> has a <tt>while (true)</tt> loop and it's not clear that the loop will always exit. We should try to specify a clear ending condition (say, limit it to 100 steps), or show that it will always finish after a reasonable number of steps.</p>\"\n",
            "<p>A story to capture the LOE needed to support project-science related communication with Alert Production Lead, DM Subsystem Scientist, and LSST Project Scientist.</p>\n",
            "<p>Implement multi-Gaussian approximations to the exponential and de Vaucouleurs profile as in Hogg &amp; Lang 2013 (<a href=\"http://adsabs.harvard.edu/abs/2013PASP..125..719H)\" class=\"external-link\" rel=\"nofollow\">http://adsabs.harvard.edu/abs/2013PASP..125..719H</a>).</p>\n",
            "<p>Test the shape optimization algorithm by:</p><ul>\\t<li>Running the unit tests built during the coding of the algorithm</li>\\t<li>Optimizing against a known elliptical Gaussian of differing S/N</li></ul>\n",
            "<p>Use the info determined in <a href=\"https://jira.lsstcorp.org/browse/DM-14891\" class=\"external-link\" rel=\"nofollow\">DM-14891</a> to code a corresponding c++ class for use in the StarGalaxyShape prior.</p>\n",
            "<p>Become familiar with looking at the butler though sql to investigate problems and or looking at output. This involves brushing up on sql, and learning about how all the information is stored in our database. </p>\n",
            "<p>The implementation of the footprints viewer in <a href=\"https://jira.lsstcorp.org/browse/DM-15823\" title=\"Implement a source catalog / footprint browser for Firefly\" class=\"issue-link\" data-issue-key=\"DM-15823\"><del>DM-15823</del></a> uses a VOTableFile to include the variable-length spans and peaks. The table is serialized as <tt>tabledata</tt> format. Prototyping has shown that that the table can be made 3 times smaller by outputting as <tt>binary2</tt> format. This ticket is to implement <tt>binary2</tt> format in a manner that works with Firefly\\'s current libraries and that also passes STILTS <tt>votlint</tt>. </p><p>Some Markdown items in the example notebook will also be improved.</p>\n",
            "<p>One or more design meetings to discuss the details of the handoff.</p><p>Deliverable is a\\xc2\\xa0sufficient outline of the design to enable design documentation to be written.</p>\n",
            "\"<p>for more realistic tests I'd like to add support for running ap_proto on many hosts, maybe using MPI or some other sort of IPC (it should be a low-level data exchange so there is no critical point here).</p>\"\n",
            "<p>Ingest raw imsim data to (proto-)DBB at <tt>/scratch/mgower/dbb-beta/</tt> </p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Add a personalized text in the login page</li>\\t<li>Set default page to /dashboards</li>\\t<li>Place /dashboards as first option in the menu since it is now the default</li>\\t<li>Remove /hosts, /logs and /config from the side navigation bar if the user role is different than admin.</li>\\t<li>Requires Editor role for creating Alerting Rules</li></ul>\n",
            "nan\n",
            "<p>SSIA</p>\n",
            "<p>With larger numbers of DCR subfilters (e.g. 5) the dcrModel solution can sometimes oscillate between iterations of forward modeling. This results in premature termination of the modeling loop, because the convergence may improve by a large amount in one iteration, and by a very small amount in the next, triggering the convergence end condition. One solution is to set a small enough gain on the new model solutions so that modeling converges smoothly, but then more iterations are required to reach the same level of convergence. Instead, the gain should adapt to how well the model is improving compared to predictions.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_46. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Write short 4 page paper for the ADASS proceedings related to the poster written in <a href=\"https://jira.lsstcorp.org/browse/DM-16176\" title=\"Write ADASS Butler Poster\" class=\"issue-link\" data-issue-key=\"DM-16176\"><del>DM-16176</del></a>. The paper draft must be submitted by November 9th and will have to be reviewed by the LSST Publication Board. The final submission date is end of November.</p>\n",
            "<p>Attempt to reproduce results DMTN-037 based on the stackified DCR code (<a href=\"https://jira.lsstcorp.org/browse/DM-9613\" title=\"Refactor DCR algorithm to be compatible with the LSST stack (continued from F17)\" class=\"issue-link\" data-issue-key=\"DM-9613\"><del>DM-9613</del></a>). If there are any changes, account for them and fix regressions or update the technote to reflect improvements.</p><p>(Spend no more than a couple of days on this; if you find major discrepancies which need more work, file tickets to investigate them.)</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-16467\" title=\"isrTask conversion to pipelineTask\" class=\"issue-link\" data-issue-key=\"DM-16467\"><del>DM-16467</del></a> cannot be completed until we have\\xc2\\xa0ExposureRange some support in pre-flight. Minimum support that we need for that is to be able to specify\\xc2\\xa0ExposureRange in DatasetTypes, support in user filter query can be implemented later.</p>\n",
            "<p>See if IOPS were really our problem by using SSD rather than spinning disk.</p>\n",
            "nan\n",
            "<p>Prepare list of project needs, milestones, activities, and current status as input into planning process.</p>\n",
            "\"<p>Running Kafka in k8s isn't too hard.  Piping messages into it from the outside world is tricky.</p>\"\n",
            "nan\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-15826\" title=\"Improvements on reading VOTable in Firefly\" class=\"issue-link\" data-issue-key=\"DM-15826\"><del>DM-15826</del></a> requires the augmentation of the Firefly internal table data model DataGroup, adding meta data about the table and fields from VOTable to DataGroup. All the newly added meta data need to be persistent in the Firefly DB for later table operations. Rendering of the data need pass the regression test.\\xc2\\xa0</p><p>Rendering of the new types of data like link will be captured in a different ticket.</p>\n",
            "<p>We noticed a significant performance degradation on the SQuaSH API after <a href=\"https://jira.lsstcorp.org/browse/DM-16300\" title=\"Implement a celery task in the SQuaSH API to save time series data to InfluxDB \" class=\"issue-link\" data-issue-key=\"DM-16300\"><del>DM-16300</del></a> when posting verification jobs to InfluxDB. I suspect that the problem is flask, redis, and celery running on the same pod with increasing memory usage so that the pods get evicted.  But we need more instrumentation to understand what\\'s going one. I have started this with the honeycomb python client. Since we are using influxdb+chronograf for the science pipelines metrics I think telegraf is a good option for the SQuaSH API monitoring. </p>\n",
            "<p>Attend the LSP workshop at NCSA.\\xc2\\xa0</p>\n",
            "<p>attend LSP workshop at NCSA</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_44. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/DM-14259\" title=\"Try and document running ap_pipe on the Verification Cluster with SLURM\" class=\"issue-link\" data-issue-key=\"DM-14259\"><del>DM-14259</del></a>, we can run the AP pipeline on the verification cluster and following <a href=\"https://jira.lsstcorp.org/browse/DM-15080\" title=\"Process HiTS 2014, build template coadds\" class=\"issue-link\" data-issue-key=\"DM-15080\"><del>DM-15080</del></a> we have new templates. Use them to process HiTS 2015, difference it with those templates, and record the results.</p><p>Aim to come up with the fastest/least manual possible procedure for this, so that we can easily perform regular reprocessing using the same commands.</p>\n",
            "\"<p>The\\xc2\\xa0<tt>getCurrent()</tt> method in salpytools should have the ability to return None (or False) when no telemetry is present for the topic requested. At the moment, when no SAL information can be retrieved, it is returning an uninitialized SAL data object (i.e. myData) which by default contains zeros for floats and integers and empty '' for strings. This behavior is not desired, as it doesn't keep undefined values as defined in the header templates.   </p>\"\n",
            "<p>The SQuaSH API already has the capability of executing Celery tasks, e.g. we have a task to upload verification jobs to S3.</p><p>It makes sense to implement another task to send the time series data (metric values, tags, and timestamps) to InfluxDB.</p><p>The transformation of  a SQuaSH job to InfluxDB line maps each verification package to an InfluxDB measurement, job metadata to InfluxDB tags and metric names and values to fields.</p>\n",
            "nan\n",
            "<p>Update the matrix of allowed transitions for CSCs. This is the states.py libraries inside salpytools.</p>\n",
            "<p>Add a few function overloads to support working with Eigen matricies in mixture models</p>\n",
            "<p>Add the configuration necessary to turn on flake8 linting and travis CI to <tt>ctrl_pool</tt>.  This will require fixing any linting errors.</p>\n",
            "<ul>\\t<li>clone the demo notebook <a href=\"https://github.com/lsst-sqre/notebook-demo\" class=\"external-link\" rel=\"nofollow\">repository</a>.</li>\\t<li>check out the <tt>prod</tt> branch</li>\\t<li>branch the <tt>prod</tt> branch to a personal branch: e.g. <tt>u/jcarlin/<a href=\"https://jira.lsstcorp.org/browse/DM-15123\" title=\"Refine SQuaRE demo notebooks\" class=\"issue-link\" data-issue-key=\"DM-15123\"><del>DM-15123</del></a></tt></li>\\t<li>make  and commit a change.</li>\\t<li>push personal branch back to github.</li></ul>\n",
            "<p>Start the container as an only semi-privileged user whose role is to provision the actual user and then sudo to it.</p>\n",
            "<p>The new API of ap_association in <a href=\"https://jira.lsstcorp.org/browse/DM-15588\" title=\"Remove home-brewed SQLite PPDB\" class=\"issue-link\" data-issue-key=\"DM-15588\"><del>DM-15588</del></a> assumes that all SourceCatalogs fed into are calibrated data products with column names close to that of the DPDD and Ppdb schema.</p><p>This ticket creates a task to convert outputs from ip_diffim into a usable format for ap_association to be use in association and set to the PPDB to be written.</p>\n",
            "<p>To begin a new round of Rucio testing we needed to update our installation on lsst-dbb-rucio.ncsa.illinois.edu to support the latest\\xc2\\xa0Rucio 1.18.0 \"Invisible Donkey\" release.\\xc2\\xa0 \\xc2\\xa0For this dependencies were checked and update, Rucio was installed, the database table were created fresh, and the overall configuration in /opt/rucio/etc/rucio.cfg was examined.\\xc2\\xa0 The server itself also required renewed certificates, and a basic security check was done to set the https config to project targets.\\xc2\\xa0</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_28. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>ap_pipe is the prototype alert production pipeline, which actually does some image differencing. There\\'s some documentation at <a href=\"https://github.com/lsst/ap_pipe/tree/master/doc/lsst.ap.pipe\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/ap_pipe/tree/master/doc/lsst.ap.pipe</a> (albeit just as raw restructured text). Experiment with it, and try using it to process some data.</p><p>If necessary, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mrawls\" class=\"user-hover\" rel=\"mrawls\">Meredith Rawls</a> should be able to point you in the right direction when you hit snags.</p>\n",
            "<p>Support deployment and development for Alert distribution system</p>\n",
            "<p>Split apart the thin inheritance relationship of MergeDetectionsTask and MergeMeasurementsTask by removing MergeSourcesTask. The separated classes should be pulled out into their own files in the refactoring.</p><p>This change both makes each class more manageable on its own, but will also simplify the conversion to PipelineTasks.</p><p>This ticket will not remove the MergeSourcesTaskRunner, as it will only be around while the gen2 middleware exists anyway.</p>\n",
            "<p>Once <a href=\"https://jira.lsstcorp.org/browse/DM-15914\" title=\"Use astro_metadata_translator in daf_butler\" class=\"issue-link\" data-issue-key=\"DM-15914\"><del>DM-15914</del></a> merges switch the VisitInfo translators in obs_decam and obs_cfht to use the astro_metadata_translator infrastructure.</p>\n",
            "<p>Document filesystem policy in appropriate project location(s).</p>\n",
            "nan\n",
            "nan\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_38. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_42. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/DM-14259\" title=\"Try and document running ap_pipe on the Verification Cluster with SLURM\" class=\"issue-link\" data-issue-key=\"DM-14259\"><del>DM-14259</del></a>, we can run the AP pipeline on the VC using SLURM. Use that capability to process the HiTS 2014 data and build template coadds.</p>\n",
            "<p>Implement initial Task documentation in packages (such as <tt>lsst.pipe.tasks</tt>) based on the in-development template ( <a href=\"https://jira.lsstcorp.org/browse/DM-15422\" title=\"First draft of task documentation topic-type\" class=\"issue-link\" data-issue-key=\"DM-15422\"><del>DM-15422</del></a>) and using the custom Sphinx roles and directives (<a href=\"https://jira.lsstcorp.org/browse/DM-15472\" title=\"Create a directive for auto-documenting task configuration\" class=\"issue-link\" data-issue-key=\"DM-15472\"><del>DM-15472</del></a> ).</p>\n",
            "<p>The pipelines.lsst.io documentation is topic-based, which means that each type of content needs to have a corresponding template. This ticket is to create a template for task documentation.</p><p>The template itself will be in <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/templates</a> and documentation will be added to <a href=\"https://developer.lsst.io/stack/task-topic-type.html\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/stack/task-topic-type.html</a></p>\n",
            "<p>antlr4 parser errors are not always useful to users, and often (always?) contain backtrace &amp; debug output info. the parser needs to be changed to provide error information helpful to users (e.g. \"could not parser query because &lt;this&gt; at or around query fragment &lt;some sql&gt;\", or something like that.) The parser <b>also</b> needs to emit useful trace &amp; error information to the log.</p><p>To do this I need to take some time to better understand the exception structure &amp; reporting in qserv.</p><p>As noted by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=gapon\" class=\"user-hover\" rel=\"gapon\">Igor Gaponenko</a>, in qserv we have <tt>util::Issue</tt> which captures useful information about where the error happened: <tt>_<em>FILE</em><em>, __LINE</em><em>, __func</em>_</tt></p>\n",
            "<p>Based on the tests in <a href=\"https://jira.lsstcorp.org/browse/DM-15658\" title=\"Test data transfer with GCS\" class=\"issue-link\" data-issue-key=\"DM-15658\"><del>DM-15658</del></a>, transfer LSST30 dataset to the europe-west1 bucket, then to us-central1 within the cloud.</p>\n",
            "<p>Provide documentation from DAX team to try running Qserv in the cloud. Make sure <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jammes\" class=\"user-hover\" rel=\"jammes\">Fabrice Jammes</a> and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mtlong2\" class=\"user-hover\" rel=\"mtlong2\">Matthew Thomas Long</a> are connected with Jim and Robinson to work together as resident LSST k8s expertise.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_41. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>The github-oauth plugin does not provide fine grained enough permissions to enable end-users to cancel a builds.</p>\n",
            "<p>Add limits and restrictions to the pod deployment within the cluster</p>\n",
            "<p>Currently, the overscan region is defined by the cameraGeom. This ticket is to add the ability to optionally use the header information to define the overscan region for ctio0m9 data.</p><p>The functionality is pretty general, and should probably be moved it into obs_base at some point, but this ticket is just to implement a (likely quite hacky) way of doing it for obs_ctio0m9 data.</p>\n",
            "\"<p>The gain, as measured by eotest's PTC task, should be ~the same as that measured by bfTask.estimateGains().</p><p>Runs some data through and see how they compare.</p><p>Ticket does not involve fixing differences found, simply reporting measured numbers for HSC chips.</p><p>Needs to be done after eotest's PTC task has been ported.</p><p>Present the results at SAWG meeting.</p>\"\n",
            "<p>Various updates are needed in the comparison scripts. \\xc2\\xa0Namely, some plotting limits and missing comparison plots as well as fixing the task runner such that the output rerun directory can be specified by the <b>&#45;&#45;rerun inDir:outDir</b> method which is currently broken due to the implementation of the <b>&#45;&#45;rerun2 in2Dir</b> (i.e. the comparison directory).</p>\n",
            "<p>Add IMAGE_ID val to xfer_params messages to CSCs so that Fwdrs can use a more efficient internal job representation.</p>\n",
            "\"<p>The rmq-setup.sh script will need to be amended, a 'send telemetry' message added to Forwarder, and the necessary addition to the ats device component.</p>\"\n",
            "<p>Patrick and Robert need feedback from the system while testing that informs them of any non-fatal problems that the system encounters while running. They also should know when an image is successfully archived; which this channel will also provide.</p>\n",
            "<p>This command will invoke a method where any needed diagnostic action can be placed to assure that the DMCS is ready to work after a FAULT action occurred. This could be as simple as a health check of various components, or could even call iDRAC instructions to reboot a troublesome instance. Policy on what will be needed is still being determined.</p><p>After diagnostics are performed, the system will be placed in \"OFFLINE\" state.</p>\n",
            "<p>The implementation of this RFC includes:</p><ol>\\t<li>strip \"_instFlux\" from the base_Blendedness_raw_instFlux and base_Blendedness_abs_instFlux names</li>\\t<li>move \"_instFlux\" to the end of the name in the fields with actual flux units, thus</li>\\t<li>base_Blendedness_raw_instFlux_child --&gt; base_Blendedness_raw_child_instFlux</li>\\t<li>base_Blendedness_raw_instFlux_parent --&gt; base_Blendedness_raw_parent_instFlux</li>\\t<li>base_Blendedness_abs_instFlux_child --&gt; base_Blendedness_abs_child_instFlux</li>\\t<li>base_Blendedness_abs_instFlux_parent --&gt; base_Blendedness_abs_parent_instFlux</li>\\t<li>an update to the doc strings to make a clear distinction/description between \"raw\" and \"abs\"</li></ol>\n",
            "<p>1. Robinson demonstrate that pd are not mounted inside pods, this need to be fixed.<br/>2. An extra additional pod is created, fix it<br/>3. Attach pd directly to GCE instance<br/>4. Check what happen to pd if cluster is resized</p>\n",
            "<p>In working on some new diagnostics plots, I noted a large area in the COSMOS field that was not getting any detections. \\xc2\\xa0In an effort to make sure I understood the cause and consequences, I looked more deeply into the images, masks, catalogs, and logs from the processing and became suspicious that something was amiss. \\xc2\\xa0This ticket is to document the further exploration and observations in order to diagnose/confirm any issues.</p>\n",
            "<p>For the ADASS conference in November we are presenting a poster on the butler gen 3.  This ticket covers writing the poster, not writing the paper.</p>\n",
            "\"<p>Generating concrete classes from authoritative docs (if machine readable) is okay, but not necessary, and should not degrade code readability or documentation.</p><p>Machine-verifying concrete classes against authoritative docs (if we don't generate them) is also nice, but also not necessary.</p><p>Should use SP estimate to strictly time-box effort spent generating/machine-verification.</p>\"\n",
            "<p>Implement Python QuantumGraph class as described in DMTN-056.</p>\n",
            "<p>Write detailed unit tests that simulate the usage of <tt>Registry::makeDataGraph</tt> and DataUnitMap by SuperTask preflight.</p><p>These should cover simulated versions of all steps currently in the HSC pipeline, using the <tt>ci&#95;hsc</tt> test database, and explore several common user expressions.</p>\n",
            "\"<p>In order to proceed in earnest with CmdLineTask-&gt;SuperTask conversion, we need a way to be able to run at least a single Quantum easily with the command-line, even if this requires all inputs explicitly provided by the caller.\\xc2\\xa0 We expect this functionality to be removed once a complete command-line executor is available, and it's possible that (some part of) that functionality is close enough that we could skip this step entirely.</p>\"\n",
            "<p>Routines that parse raw FITS metadata in the form of PropertyLists sometimes (but not always) provide an option to strip parsed keywords.\\xc2\\xa0 This functionality should be extended to all such routines, and we should also provide routines to strip without constructing objects in cases where the latter is expensive.\\xc2\\xa0 Finally, ExposureInfo needs to provide a routine to parse and/or strip metadata that delegates to all of its children.</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Presents the main concepts of the Honeycomb tool</li></ul><ul class=\"alternate\" type=\"square\">\\t<li>Illustrates an workflow where metrics values are collected, stored in SQuaSH and sent to Honeycomb for analysis</li></ul><ul class=\"alternate\" type=\"square\">\\t<li>In particular it creates a squash-demo dataset for the SQuaSH metrics, and uses liboney to send those metrics to Honeycomb, it shows how to use the Markers API for plot annotations and the Triggers API for configuring alerts based on metric specs obtained from the SQuaSH API.</li></ul>\n",
            "<p>In this notebook we introduce the main concepts of Prometheus. We run a Prometheus server, and look at a few metrics to illustrate the Prometheus interface and the PromQL query language.</p><p>Then we use the Prometheus python client to instrument a small app and expose metrics to the Prometheus server.</p><p>Finally we exemplify alerting with Prometheus.</p>\n",
            "<p>On your new computer, follow the tutorial at pipelines.lsst.io.</p>\n",
            "<p>The measured spectrum of simulated sources that are recovered after modeling with DcrCoadds appears to be inverted from the input simulations. There appears to be a bug in either the sign of the direction of DCR in the simulations or the modeling code, or there is a bug later when assigning wavelength ranges to DCR subfilters.</p>\n",
            "<p>Run it and make sure that the default value is sensible.</p><p>On another ticket in the future, use this code to see how this value depends on the inputs, <em>e.g.</em> flux levels, CCD shape, others, to see how much one fixed value is applicable across cameras/sensors.</p>\n",
            "nan\n",
            "\"<p>Update and test the HeaderService to use Erin Sheldon's ignore_empty on the newest version of fitsio. This allows writing more than one empty (no data) hdu, as needed by the HeaderService. The testing will be done on the Tucson Test Stand for the ATS.</p>\"\n",
            "<p>Building upon installations started in <a href=\"https://jira.lsstcorp.org/browse/DM-15298\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/DM-15298</a>\\xc2\\xa0, we test the server installation and configurations using Scitokens generated with the Demo Issuer at <a href=\"https://demo.scitokens.org/\" class=\"external-link\" rel=\"nofollow\">https://demo.scitokens.org</a>\\xc2\\xa0.\\xc2\\xa0</p>\n",
            "<p>Initial transfer of each of 5 areas discovered during initial investigation \\xe2\\x80\\x93 provides a start of a mirror between SLAC and NCSA. 3 are on nfs\\xc2\\xa0filesystem, 2 are on gpfs\\xc2\\xa0with underlying HSM tape; these differences require different transfers. This story covers the 3 nfs\\xc2\\xa0filesystem areas: BNL test stand, vendor data, and early SLAC test stand.</p>\n",
            "<p><tt>afw.display</tt> provides methods for setting mask plane colors and transparencies. These should be \"sticky\" in the display_firefly backend, meaning that once they are set for a Display object, they should be applied when an image is sent again to that display.</p><p>The display_firefly backend also needs to ignore masks whose color is set to \"ignore\" or \"IGNORE\".\\xc2\\xa0</p><p>Related to this, <tt>afw.display</tt> provides <tt>setDefaultMaskTransparency</tt> and <tt>setDefaultMaskPlaneColor</tt> which are used when Display instances are created. Fix a small bug in <tt>setDefaultMaskTransparency</tt> and verify that both of these work with the display_firefly backend.</p>\n",
            "<p>Until jupyterlab-manager is published for 0.35 we have to pin JL back to 0.34 and keep extensions at a compatible level.</p>\n",
            "<p>Most recent release of\\xc2\\xa0Tomcat is version 9. Firefly is running in Tomcat 7 and 8 currently. We need to be able to support version 9.\\xc2\\xa0</p>\n",
            "<p>(From IPAC LSST group meeting today)</p><p>We would like to move to Java 10 for the deployment of Firefly servers in LSST, both just to keep moving forward, and specifically because Java 10 is substantially better-integrated with Docker and therefore more suitable for LSST\\'s Kubernetes deployment environment.</p><p>This may trigger moving forward from Tomcat 7 to Tomcat 8 or 9, because the pre-built containers available at <a href=\"https://hub.docker.com/r/_/tomcat/\" class=\"external-link\" rel=\"nofollow\">https://hub.docker.com/r/_/tomcat/</a> do not include a Tomcat-7-for-Java-10 build. (Both Tomcat 8 and 9 have base containers available for both Java 8 and Java 10.)</p><p>We need to think about what to do with the IPAC development environments in this context, including testing and our K8s deployments. Ideally we would keep the <tt>dev</tt> branch compatible with both Java 8 and Java 10 for the foreseeable future.</p><p>This is clearly a FireflyCCB issue.</p><p>Note 8/28/2018 (Trey)- We don\\'t plan to start writing Java 10 code until all the projects have gone though a deployment cycle.\\xc2\\xa0 Currently we want to be able to deploy on both Java 8 and Java 10 and the related Tomcats.\\xc2\\xa0 When all projects have deployed on Java 10 then we will start using Java 10 features.</p>\n",
            "<p>Once the AP packages are in <tt>lsst_distrib</tt>, we can add them to <tt>pipelines.lsst.io</tt> following the procedure in the <a href=\"https://developer.lsst.io/stack/add-a-package-to-pipelines-lsst-io.html\" class=\"external-link\" rel=\"nofollow\">developer guide</a>. This ticket is to register all the documentation, including:</p><ul>\\t<li>Updating to the latest <a href=\"https://developer.lsst.io/stack/package-documentation-topic-types.html\" class=\"external-link\" rel=\"nofollow\">documentation standards</a>, including removing the package-level docs for code repositories and overhauling the ones for datasets.</li>\\t<li>Checking inter-package links in the Sphinx documentation, which have until now gone untested.</li>\\t<li>Updating cross-references from non-Sphinx documentation (e.g., readmes) to point to the published pages.</li></ul>\n",
            "nan\n",
            "<p>The main improvement is in the test steps formatting:</p><ul>\\t<li>have them in a table</li>\\t<li>differentiate the steps from an included test case</li></ul><p>\\xc2\\xa0</p><p>However, more changes are required in order to make the generation of the document consistent with the approach described in\\xc2\\xa0<a href=\"https://confluence.lsstcorp.org/display/DM/DM+Test+Approach\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/DM+Test+Approach</a>\\xc2\\xa0</p>\n",
            "<p>Make Camera persistable.\\xc2\\xa0 I was originally expecting this to be a natural outcome of the combination of <a href=\"https://jira.lsstcorp.org/browse/DM-14980\" title=\"Reinstate the ability of a Detector to find the Camera in which it lives\" class=\"issue-link\" data-issue-key=\"DM-14980\"><del>DM-14980</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-14363\" title=\"Make afw::cameraGeom::Detector table-persistable\" class=\"issue-link\" data-issue-key=\"DM-14363\"><del>DM-14363</del></a>, but I\\'ve changed approaches on those.</p>\n",
            "<p>Adding appropriate users and passwords; Authenticate client requests (telegraf); Authorize users with privileges</p>\n",
            "<p>Write a community post telling people about the new star galaxy classifier and how to use it.</p>\n",
            "nan\n",
            "<p>Add <tt>ap_verify</tt> to <tt>lsst_distrib</tt>, and add <tt>ap_pipe</tt> and its dependencies to <tt>lsst_apps</tt>. This includes:</p><ol>\\t<li>Moving the packages to the <tt>lsst</tt> organization, and assigning admin privileges as described in the <a href=\"https://developer.lsst.io/stack/adding-a-new-package.html\" class=\"external-link\" rel=\"nofollow\">developer guide</a>. <span class=\"error\">&#91;Note: this step cannot have an associated pull request&#93;</span>.</li>\\t<li>Confirming that packages follow Stack conventions (e.g., directory structure).</li>\\t<li>Registering any missing packages with <tt>repos.yaml</tt>.</li>\\t<li>Double-checking that any data package that is an optional dependency of a non-data package is also in <tt>manifest.remap</tt>.</li>\\t<li>Adding <tt>ap_verify</tt> and <tt>ap_pipe</tt> to their respective top-level packages\\' table files.</li></ol>\n",
            "<p>As part of the new LSST Science Pipelines documentation architecture (<a href=\"https://dmtn-030.lsst.io),/\" class=\"external-link\" rel=\"nofollow\">https://dmtn-030.lsst.io),</a>\\xc2\\xa0we\\'re refreshing how we document Tasks (with an eye on <tt>PipelineTasks</tt> as well). One of the objectives to include configurations more integrally with the Task documentation. Task configuration has a fair amount of complexity as there are several types of configuration fields that behave differently. The objective of this ticket is to research and understand these configuration fields and then produce non-functional prototypes that how to document these configurations.</p>\n",
            "<p>Daf_butler put documentation says that it will take a DatasetRef, DatasetType, or string. However, if given a DatasetType it attempts to use it as a string, calling the DatasetType lookup function, which fails in its sql query. If the user passes a DatasetType, the function should use it and skip the lookup.</p>\n",
            "<p>Make sure that the lsst-dm/alert_stream package contains an overview document describing the current state of the mini broker, together with detailed documentation on how to start, stop, run, test, etc all of the code within it; include details of how to deploy on AWS.</p><p>This could be Sphinx documentation, but for now just text files in the alert_stream repository would be ok.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-15104\" title=\"Move SourceDeblendTask out of MeasureCoaddSources\" class=\"issue-link\" data-issue-key=\"DM-15104\"><del>DM-15104</del></a> introduced some undefined variable names into MultibandDriver.py. Because there are no automated checks in in place for pipe_drivers (no unit tests or Travis) these were missed.</p><p><tt>--reuse deblendCoaddSources</tt> will not work:<br/><a href=\"https://github.com/lsst/pipe_drivers/blob/master/python/lsst/pipe/drivers/multiBandDriver.py#L419\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/pipe_drivers/blob/master/python/lsst/pipe/drivers/multiBandDriver.py#L419</a></p>\n",
            "<p>Create a notebook that will show how to use dask.  Bonus points for using a large dataset and for using next generation visualization tools.</p>\n",
            "<p>All jenkins jobs that use <tt>lsstsw</tt> consume couscous amounts of disk space and require periodic manual workspace purging.  This should either be moved to a jenkins plugin or an automated script.</p>\n",
            "nan\n",
            "<p>Add reference catalog defaults to at least obs_subaru to facilitate running jointcal on the HSC biweeklies. </p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=Parejkoj\" class=\"user-hover\" rel=\"Parejkoj\">John Parejko</a>  I assigned it to you, but I can just as easily do it if one of you sends me the command to run jointcal on the RC2 dataset so I can test that the configs make it do what we expect.  </p>\n",
            "<p>Provide capabilities and support for LSP demo and Stack Club activities during the LSST2018 Project and Community Workshop.</p>\n",
            "nan\n",
            "<p>The database performance metrics promoted from LDM-135 and the ability to calculate the key performance metrics specified in OSS, must be submitted to project CCB for approval. If there are any performance metrics we rely on but which are not yet in LSE-61 now would be a good time to add them.</p>\n",
            "<p>Use functions in salpytols to write utility script to clear up the dreaded DDS_RETCODE_PRECONDITION_NOT_MET that plagues CSCs.</p>\n",
            "<p>This story deals with getting copy of adm01 backups and they are pushed to backup01, from where it is getting backed up to the tape.</p>\n",
            "<p>This work deals with optimizing performance of current DR backup system by making code changes to reporting and transfer code base.</p>\n",
            "<p>To test <a href=\"https://jira.lsstcorp.org/browse/DM-15663\" class=\"external-link\" rel=\"nofollow\">DM-15663</a>, it we be necessary to test using the preflight solver that Andy has been working on. This ticket captures the work that will go into learning that tool to execute tests.</p>\n",
            "\"<p>There have been issues with getting a successful transfer of readout params to the forwarders. This seemed a sometimes intermittent problem that was caused by\\xc2\\xa0</p><p>not getting a proper ack from the forwarder about 10% of the time. After analysis, the xfer_params ack is returning SO quickly that calling the 'clear_forwarder_response_state'</p><p>method immediately after publishing the xfer_params message \\xc2\\xa0left too litle time for the ack response code to begin listening, as the response is returned in another thread. The fix here was simple, and painfully obvious in hindsight - clear the state first and then publish the xfer_params message. The debug timer has also been replaced with a progressive ack timer.<br/>This is an important fix, because a FAULT state is entered when time exceeds the limit for the xfer_params_ack to return.</p>\"\n",
            "<p>Instructions have been provided by the Google team for testing a transfer for our data files to different storage buckets. Test transfer performance from both NCSA and IN2P3 before moving the full datasets.</p>\n",
            "\"<p>For the Sphinx-based task topic documentation, we want to be able to show the signature of the task's Python API (particularly its <tt>_<em>init</em>_</tt> and <tt>run</tt> methods). This shouldn't replace the canonical source of documentation as generated by <tt>automodapi</tt>, but it should instead give users a quick summary and entrypoint into that API documentation.</p><p>One scenario is to show the signatures of the tasks's constructor and methods, and make those signatures clickable so that a user can access the API docs quickly.</p><p>Another approach might be to also show the full docstring of things like the constructor and run method.</p><p>The best approach is TBD.</p>\"\n",
            "<p>The DMCS currently allows OCS Commands sent for start up and shutdown, to respond positively when the DMCS is, say, asked to move from Disable to Disable state. When this ticket is Done, the DMCS (via the OCS_Bridge) will respond with a negative ACK and include command error number -324 that designates that the CSC is already in the requested state. This will not generate a FAULT however. In the description field of the ACK, the DMCS should briefly explain that the OCS is asking to move to Disable (as an example) while Disable is already the current state of the CSC.</p><p>The detection of this condition is simple, however a meaningful description of the error will take a bit of time. It will probably rely on a static lookup table for string responses.</p>\n",
            "<p>Implementation ticket for <a href=\"https://jira.lsstcorp.org/browse/RFC-517\" title=\"Specify contents of DIAForcedSources in DPDD and include them in alerts\" class=\"issue-link\" data-issue-key=\"RFC-517\"><del>RFC-517</del></a>.</p>\n",
            "<p>Create a prototype JSON representation of all the footprints in an LSST SourceCatalog, for the regular footprints only (excluding heavy footprints), for use in Firefly.</p><p>Include bounding box information as well as the details of the individual pixels included in each footprint. Coordinate with development of <a href=\"https://jira.lsstcorp.org/browse/DM-15326\" title=\"Create LSST footprint overlay on image \" class=\"issue-link\" data-issue-key=\"DM-15326\"><del>DM-15326</del></a>.</p>\n",
            "<p>Use simulated environments to test that changes made to HeaderService and salpytools and make sure no damage was done during updates to PEP8.</p>\n",
            "<p>When <tt>textangle</tt> is provided in a region description, Firefly does not draw the associated region. The <tt>afw.display.dot</tt> method allows specifying the textangle, but when this argument is provided, the region is not displayed.</p><p>Example of region text generated by <tt>afw.display.dot</tt> that does not display:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">text 1074 110 \"Text\" # color=yellow textangle=45.0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>The format we need to support for angle is <tt>textangle=</tt> after the hash symbol.</p>\n",
            "<p>Upstream version 2.2.0 is about to be tagged (<a href=\"https://github.com/pybind/pybind11/issues/953\" class=\"external-link\" rel=\"nofollow\">https://github.com/pybind/pybind11/issues/953</a>). This release contains a fix for <a href=\"https://jira.lsstcorp.org/browse/DM-9814\" title=\"Investigate pybind11 base class data member exposure from derived\" class=\"issue-link\" data-issue-key=\"DM-9814\">DM-9814</a>.</p>\n",
            "<p>Pybind11 wrapped modules seem to be roughly twice the size of their Swig equivalents.<br/>Investigate the cause of this and suggest strategy to reduce the build size.</p>\n",
            "<p>DM overview and status , a bit of LSST status as well.</p>\n",
            "<p>Rewrote the GPFS mount check code to enable more robust handling of multiple file system mounts on a machine. \\xc2\\xa0With the beginning of the Data Backbone File System (/dbb) and the likelihood of further file systems being created in the nearish future and not all file systems being mounted on all nodes intentionally, the check needed to be fortified to handle these additional constraints. \\xc2\\xa0</p>\n",
            "<p>I would like to run the tutorial notebooks on the laptop using the docker images from sqre</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_36. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>Code for how the magic <tt>config.biasCorr</tt> should be added so that it can be used by experts to check/recalculate this number if needed.</p>\n",
            "<p>Take a look at how Jenkins works. Understand how jobs are scheduled. Think about how we could integrate a job which exercises the ap_verify system.</p><p>It would be great if this included integration with SQuaSH, but if it did nothing other than pass/fail that would also be fine in the short term.</p>\n",
            "<p>In discussions with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mgower\" class=\"user-hover\" rel=\"mgower\">Michelle Gower</a> about temporary-scratch-repo use cases, we identified that it would be nice to have a Registry implementation that supports only generalized get and put (not expressions), and hence does not need DataUnit tables.\\xc2\\xa0 This is similar in functionality (but not implementation) to a previous LimitedRegistry concept that we envisioned not using SQL at all; the new concept would use SQLite, but would have only a subset of the full Registry schema.</p><p>Whether there are any non-DataUnit tables we could drop from LimitedRegistry is an open question; one possibility is that it could also only represent a single Collection, and hence have no need for DatasetCollection either.</p>\n",
            "<p>Try k8s node taint/toleration feature to keep k8s from scheduling non-qserv pods on qserv master and db nodes</p>\n",
            "<p>Architecting how we want to handle incoming metrics data from sources that do not have built in buffering capabilities (eg. data not flowing in via telegraf). \\xc2\\xa0</p>\n",
            "<p>Following discussions at LSST2018 last week, we have decided that controlling whether a composite should be disassembled or not should be a butler configuration level item and not a storage class item. This allows disassembly to be controlled by datasetType or StorageClass name. There will be a new top level butler configuration item, name TBD.</p>\n",
            "<p>We have decided that the all datastores must provide a simple table indicating which datasets they have, but that information relating to internal details such as filenames, checksums, file sizes etc should be in an \"internal\" table under the control of each datastore.</p>\n",
            "<p>It would be useful to be able to define a hierarchy of StorageClasses in Python so that checks isinstance() checks can work and we can define related storage classes across different configuration files (currently YAML reference syntax only works within the single file).</p>\n",
            "<p>Currently the getters for formatters and templates use a name string to determine which formatter/template to use. It would be better to match the CompositesMap interface and allow DatasetType to be given.</p>\n",
            "<p>So far we are not using parameters for datastore.get. This will have to change if we wish to support efficient subsetting of large datasets.  To be able to handle ChainedDatastores properly, parameters will need to be able to be handled by formatters, and generically by using code in StorageClass assembler classes. This requires that the formatter (which will be called first) has to be able to indicate which parameters it has already handled before the remaining parameters are passed to the assembler class.</p>\n",
            "<p>When FAULT is detected and Fault State is entered, a Summary State event should be issued. A Summary State event should also be issued when FAULT is exited via the ResetFaultState event.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Take a look at the (static) plots which are being produced by the DRP group\\'s tooling as part of regular HSC RC2 reprocessing (see <a href=\"https://confluence.lsstcorp.org/display/DM/Reprocessing+of+the+HSC+RC2+dataset\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Reprocessing+of+the+HSC+RC2+dataset</a> for output locations). Understand what plots are available. Think about how they might be relevant to AP, or how something similar might be relevant to AP.</p><p>Ultimately, let\\'s discuss with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=sullivan\" class=\"user-hover\" rel=\"sullivan\">Ian Sullivan</a> if we can schedule a brown bag about this.</p>\n",
            "<p>The \"demo\" currently exists as a special snowflake feature of jenkins jobs and is not packaged as an an eups product. A script is currently invoked by the CI machinery after an <tt>lsstsw/lsst_build</tt> or <tt>eups distrib install</tt> has completed which downloads the demo repo from github as a tarball.</p><p>An unfortunate consequence of this implementation is that changes on the master branch of the demo result in previous git tags no longer working with the demo when built by <tt>ci-scripts/lsstsw</tt> and requires knowledge of the correct git ref to use after a direct <tt>eups distrib install</tt>. This also presents an irritation when tagging an official release as there is no source of truth as to where the tag should be located, requiring human intervention. For at least the third time, the demo on master has changed during the release process and now fails with the current release candidate.</p><p>A much less error prone solution would be to convert the demo into a regular eups product, which is a dependency of either <tt>lsst_distrib</tt> and/or <tt>lsst_ci</tt>. This would result in demo metadata being incorporated into eups distrib tags and solving the science-pipeline/demo version mismatch problem both for end users with a local installation and under CI.</p><p>I believe the basic tasks to accomplish this would be:</p><ul class=\"alternate\" type=\"square\">\\t<li>convert <tt>lsst/lsst_dm_stack_demo</tt> into an eups product \\xe2\\x80\\x93 essentially add a <tt>ups</tt> dir and a table while which depends on <tt>lsst_apps</tt></li>\\t<li>add <tt>lsst_dm_stack_demo</tt> as a dependency of <tt>lsst_ci</tt> and/or <tt>lsst_distrib</tt></li>\\t<li>add a test script under <tt>lsst_ci/tests/</tt> to trigger a demo run</li>\\t<li>remove <tt>lsst-sqre/ci-scripts/runManifestDemo.sh</tt> and update <tt>lsst-sqre/ci-scripts/lsstswBuild.sh</tt> to not run the demo</li>\\t<li>update various jenkins jobs in <tt>lsst-sqre/jenkins-dm-jobs</tt> to <tt>setup lsst_dm_stack_demo</tt> rather then invoking <tt>runManifestDemosh.sh</tt></li></ul>\n",
            "<p>Document goals and configuration specifics for kubernetes network separation enforcement.</p>\n",
            "<p>Firefly will get better performance when it can use local disk (SSD drives are even better) for cache.\\xc2\\xa0 Since in the multi server environment we only need to share a small amount of work area we need to change the system to have both a work area and a shared work area.\\xc2\\xa0 The shared work area will be for uploads and staging.\\xc2\\xa0 The work area is for everything else.</p>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/DM-15053\" title=\"Prototype one-filter-per-container broker\" class=\"issue-link\" data-issue-key=\"DM-15053\"><del>DM-15053</del></a>, we are running each filter in a separate Docker container, talking to a local (per-node) Kafka system.</p><p>But... how many filter-containers can we run on each node? Currently we\\'re using 20, but how far can we go (order of magnitude is fine \\xe2\\x80\\x94 obviously, it\\'ll be hardware dependent at some level)?</p>\n",
            "<p>Discuss with relevant parties regarding AST adoption by LSST pipeline. Make a list of possible solutions for Firefly.</p><p>Read:</p><p><a href=\"https://jira.lsstcorp.org/browse/RFC-193\" title=\"Adopt AST for WCS and transforms\" class=\"issue-link\" data-issue-key=\"RFC-193\"><del>RFC-193</del></a>:\\xc2\\xa0Adopt AST for WCS and transforms</p><p><a href=\"http://dmtn-010.lsst.io/\" class=\"external-link\" rel=\"nofollow\">http://dmtn-010.lsst.io/</a>:\\xc2\\xa0\\xc2\\xa0WCS and Distortion Requirements and Existing Options</p><p>Follow <a href=\"https://jira.lsstcorp.org/browse/DM-3874\" title=\"Produce a design for the new Wcs classes\" class=\"issue-link\" data-issue-key=\"DM-3874\"><del>DM-3874</del></a>:\\xc2\\xa0 Produce a design for the new Wcs classes</p><p>Two more epics related to AST:</p><p><a href=\"https://jira.lsstcorp.org/browse/DM-3875\" title=\"Implement new Wcs classes\" class=\"issue-link\" data-issue-key=\"DM-3875\"><del>DM-3875</del></a>:\\xc2\\xa0Implement new Wcs classes</p><p><a href=\"https://jira.lsstcorp.org/browse/DM-6164\" title=\"Implement the API replacing XYTransform\" class=\"issue-link\" data-issue-key=\"DM-6164\"><del>DM-6164</del></a>:\\xc2\\xa0Implement the API replacing XYTransform</p>\n",
            "<p>The simulated images being used to test the DCR algorithm work well for image differencing but are giving odd results when run through DcrMultiBand. This could be due to the lack of calibration. This ticket is to create new reference catalogs using the new(ish) HTM indexed file format, and reprocess the simulated data including calibration.</p>\n",
            "<p>As we add more configurable parameters (e.g. horizontal component scaling) we need to extend our deployment tool to understand and exploit them.</p>\n",
            "<p>Processing HSC PDR1 for <a href=\"https://jira.lsstcorp.org/browse/DM-11787\" title=\"First comparison of jointcal/meas_mosaic in validate_drp\" class=\"issue-link\" data-issue-key=\"DM-11787\"><del>DM-11787</del></a> resulted in one obviously bad astrometric fit: HSC-Y tract 15832. The jointcal log (<tt>/project/parejkoj/<a href=\"https://jira.lsstcorp.org/browse/DM-11783\" title=\"Replace meas_mosaic with Jointcal\" class=\"issue-link\" data-issue-key=\"DM-11783\"><del>DM-11783</del></a>/logs/jointcal-SSP_WIDE_15832_HSC-Y-141536.2.log</tt>)  shows a number of questionable entries leading up to the  poor final <tt>chi2/ndof=827</tt>. This ticket is to investigate why the fit was bad and see what we can do to mitigate that. A first step might be simply re-running on a newer processing of that data.</p>\n",
            "<p>Push jointcal and meas_mosaic catalogs through validate_drp, generate plots, and look at the results. <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=Parejkoj\" class=\"user-hover\" rel=\"Parejkoj\">John Parejko</a> will do a first cut look to check for obvious problems, before handing off to <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a> for the final comparison.</p><p>If changes to jointcal are necessary, we can add them to this epic and then re-compare.</p>\n",
            "\"<p>Currently, columns ROW_IDX and ROW_NUM are sent to the client for every table request.  <br/>It's only used in a few cases.  Change it so that these columns are only sent if requested and not by default.</p>\"\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_34. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_32. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Define a userful <tt>&#95;&#95;str&#95;&#95;</tt> for <tt>Butler</tt> that provides minimal useful information:<br/>So collection and root if there is a unique root, and something else (TBD) otherwise.</p>\n",
            "<p>As part of dealing with <a href=\"https://jira.lsstcorp.org/browse/DM-10302\" title=\"Rename &quot;*_flux&quot; fields to &quot;*_instFlux&quot; in SourceCatalogs\" class=\"issue-link\" data-issue-key=\"DM-10302\"><del>DM-10302</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-10933\" title=\"Fix &quot;Sigma&quot; and &quot;Err&quot; in pipeline/developer documentation\" class=\"issue-link\" data-issue-key=\"DM-10933\"><del>DM-10933</del></a>, we can do an \"easy\" thing and change <tt>fluxSigma</tt> to <tt>fluxErr</tt> in all stack code and catalogs. This is less daunting than changing Sigma everywhere, involving only 296 changes over 68 files, instead of 2117 over 287. It\\'s also a clearer change: anywhere we have <tt>fluxSigma</tt> we almost certainly meant to say <tt>fluxErr</tt>, whereas some of our <tt>Sigma}}s elsewhere are really {{Sigma</tt>.</p>\n",
            "<p>Adapt the <tt>pipe_analysis</tt> scripts to be compatible with the changes coming out of <a href=\"https://jira.lsstcorp.org/browse/RFC-498\" title=\"Homogenize naming of calibration flags\" class=\"issue-link\" data-issue-key=\"RFC-498\"><del>RFC-498</del></a>.  Also make accommodations for it to be backwards compatible with catalogs run on older, pre-<a href=\"https://jira.lsstcorp.org/browse/RFC-498\" title=\"Homogenize naming of calibration flags\" class=\"issue-link\" data-issue-key=\"RFC-498\"><del>RFC-498</del></a>, processed catalogs.</p>\n",
            "<p>Revise identified documentation with new procedure(s).</p>\n",
            "<p>Contact relevant project personnel (e.g., T/CAMs, subsystem reps) and place announcements in project forums to advertise new procedures.</p>\n",
            "<p>A major obstacle to opening up K8 at NCSA is ensuring that network level policy is enforceable and audit-able.\\xc2\\xa0 To that end, security focus on separation of \"backend services\" from \"user facing services\".\\xc2\\xa0 Aside from proper authentication and authorization there should be network level enforcement of this logical separation.\\xc2\\xa0 From the K8 security meeting notes:</p><ul>\\t<li>\\xc2\\xa0<span class=\"error\">&#91;Separation&#93;</span>\\xc2\\xa0between the users (JupyterHub) and the services (qserv, etc.)?\\t<ul>\\t\\t<li>Physical network separation\\t\\t<ul>\\t\\t\\t<li>(minus) Seems counter to the Kubernetes model (elastic computing)</li>\\t\\t\\t<li>(plus) More secure</li>\\t\\t\\t<li>(minus) More work and less automated to move hardware between networks</li>\\t\\t</ul>\\t\\t</li>\\t\\t<li>Network Policies\\t\\t<ul>\\t\\t\\t<li><em><b>Don\\'t want to blindly trust that the software implementation. How can we validate that the Network Policies are enforcing what is configured?</b></em>\\t\\t\\t<ul>\\t\\t\\t\\t<li><a href=\"https://wiki.ncsa.illinois.edu/display/~mcarras2\" class=\"external-link\" rel=\"nofollow\">Matias Carrasco Kind</a>\\xc2\\xa0and\\xc2\\xa0<a href=\"https://wiki.ncsa.illinois.edu/display/~mtlong2\" class=\"external-link\" rel=\"nofollow\">Matthew Long</a>will run a test</li>\\t\\t\\t</ul>\\t\\t\\t</li>\\t\\t</ul>\\t\\t</li>\\t</ul>\\t</li>\\t<li>Audit network traffic to uniquely identify container and user that given network traffic originated from?\\t<ul>\\t\\t<li>Still no solution. Depends on the implementation of the first goal (network isolation)</li>\\t</ul>\\t</li></ul>\n",
            "<p>The validate_drp processing of <tt>validation_data_hsc</tt> outputs results for multiple filters.  Multiple changes are needed in order to support one than one filter per dataset run.</p><ul>\\t<li>The squash data model needs to be modified to add the concept of a filter.  Be it either a one-many relationship of run to filter(s) or each filter is handled a separate run with the same <tt>id</tt>.</li>\\t<li>Filter selection widget for the dashboard plots</li></ul>\n",
            "<p>In this technote we evaluate the existing DM tools, and the the need of new tools for:</p><blockquote><ul>\\t<li>Collecting the data quality metrics from the\\xc2\\xa0<em>Single Frame Processing</em>\\xc2\\xa0pipeline;</li>\\t<li>Storing the data quality metrics in the Prompt QC database;</li>\\t<li>Publishing data quality metrics to the OCS;</li>\\t<li>Accessing the Prompt QC and EFD databases;</li>\\t<li>Implementing the Prompt Data Quality Report;</li>\\t<li>Running and publishing the Prompt Data Quality Report.</li></ul></blockquote>\n",
            "<p>We need to test ingress and egress access to the cluster and within the pods in the cluster and ways to control and limit.</p>\n",
            "<p>Test installation and deployment of mpi cluster within kubernetes</p>\n",
            "<p>After <tt>flake8</tt>, <tt>API tests</tt>\\xc2\\xa0and {docker image}} build passed, deliver to docker hub\\xc2\\xa0the resulting image. Use tag <tt>tickets-DM-####</tt> for PRs and tag <tt>latest</tt> when the PR is merged to master.</p>\n",
            "nan\n",
            "<p>Prepare list of project needs, milestones, activities, and current status as input into planning process.</p>\n",
            "<p>PyProFit (<a href=\"https://github.com/ICRAR/pyprofit/)\" class=\"external-link\" rel=\"nofollow\">https://github.com/ICRAR/pyprofit/</a>) is a python wrapper for our (Taranu, A. Robotham &amp; R. Tobar) galaxy fitting library libprofit (<a href=\"https://github.com/icrar/libprofit/)\" class=\"external-link\" rel=\"nofollow\">https://github.com/icrar/libprofit/</a>) and its R interface ProFit (<a href=\"https://github.com/ICRAR/ProFit/).\" class=\"external-link\" rel=\"nofollow\">https://github.com/ICRAR/ProFit/</a>). I adapted some of the existing examples in pyprofit into a python interface for galaxy fitting, with most of the same features as ProFit. This is now a fork of pyprofit on lsst-dm: <a href=\"https://github.com/lsst-dm/pyprofit\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/pyprofit</a>. I will use pyprofit for further exploratory work for new modelling methods/codes prior to integration in meas_modelfit.</p>\n",
            "<p>Relocate and refactor the new TAN SIP fitter from meas_astrom to afw to allow it to be used to write TAN SIP approximations to more general WCSs.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_30. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>deploy dashboard and pod/cluster monitoring into kubernetes cluster\\xc2\\xa0</p>\n",
            "<p>I am the co-chair or a primary contributor in four sessions at the PCW Aug 12 - Aug 17.  These are:</p><ul>\\t<li>Introduction to Stack Club</li>\\t<li>DM-Camera interfaces</li>\\t<li>Next generation visualization</li>\\t<li>Testing the AOS with simulations</li></ul><p>In these sessions I am either presenting information directly or I am contributing significantly to the conversation/decision making.</p>\n",
            "<p>On-hand support for sessions requiring the Science Platform Notebook service.\\xc2\\xa0</p>\n",
            "<p>The specs that specify the yearly ramps from LDM-240 do not have associated metrics.  This means that SQuaSH cannot query for them.  Add metric names to these specs so that the spec levels can be plotted on the SQuaSH traces.</p>\n",
            "<p>1. <span class=\"error\">&#91;x&#93;</span> Write up a document detailing the conceptual needs for a set of datasets to test DRP+AP at CI, Small, Medium, and Large scales.<br/>2. <span class=\"error\">&#91;x&#93;</span> Define the requirements and goals of those scales<br/>3. <span class=\"error\">&#91;x&#93;</span> Discussion connection to previous DM-SST dataset-definition work.  This will be more fully elaborated on in <a href=\"https://jira.lsstcorp.org/browse/DM-15448\" title=\"Add datasets document information to DMTN-091\" class=\"issue-link\" data-issue-key=\"DM-15448\">DM-15448</a>.<br/>4. <span class=\"error\">&#91;x&#93;</span> Provide examples.<br/>5. <span class=\"error\">&#91;x&#93;</span> Discuss limited runs on individual machines (laptop, desktop, medium AWS Jenkins worker node)</p>\n",
            "<p>That feature is missing in the current implementation because we were not able to query specifications from the API until recently. See <a href=\"https://jira.lsstcorp.org/browse/DM-15240\" title=\"Create resource in the squash-restful-api for the KPMs dashboard \" class=\"issue-link\" data-issue-key=\"DM-15240\"><del>DM-15240</del></a>.</p>\n",
            "nan\n",
            "<p>Provide instructions on how to use the test management in Jira:</p><ul>\\t<li>test case\\xc2\\xa0</li>\\t<li>test plan and runs</li></ul><p>\\xc2\\xa0</p><p>Describe the procedures involved in the generation and approval of the Test Specification and Test (Plan and) Report.</p>\n",
            "<p>In order to create the KPM dashboard we must be able to distinguish astrometry, photometry and image_quality metrics in <tt>validate_drp</tt>. This can be done by adding these tags in the metrics definition for the <tt>validate_drp</tt> package. Similarly we need to distinguish the specification thresholds minimum, design and and stretch. This is done by adding these tags in the specifications for the <tt>validate_drp</tt> package.</p>\n",
            "<p>use the antlr4 generated IR in qserv.</p><p>keep the old antlr parser. decide whether to generate IR all the time or ifdef it out.</p><p>we may want to dump old-antlr-generated IR to the log occasionally.</p>\n",
            "<p>Create a technote describing the requirements and design for notebook-based reports. These reports are initially described in the\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-14551\" title=\"Publication of report notebooks from lsst_verify data\" class=\"issue-link\" data-issue-key=\"DM-14551\"><del>DM-14551</del></a> epic.</p>\n",
            "<p>Create\\xc2\\xa0a jupyter notebook to demonstrate how to use scarlet and the new LSST deblender on multi-band images.</p>\n",
            "<p>Create a Jupyter notebook describing the results of reprocessing HiTS in <a href=\"https://jira.lsstcorp.org/browse/DM-14259\" title=\"Try and document running ap_pipe on the Verification Cluster with SLURM\" class=\"issue-link\" data-issue-key=\"DM-14259\"><del>DM-14259</del></a> along the same lines as those already in the <a href=\"https://github.com/lsst-dm/ap_pipe/tree/master/notebooks\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/ap_pipe/tree/master/notebooks</a> directory.</p><p>The notebook should contain basically the same figures and analysis as the previous notebooks (ie, we\\'re not looking for new plots here) \\xe2\\x80\\x94 it just needs to be updated to work with the latest version of the data processing.</p><p>(Edited to clarify this ticket is for the notebook created with an initial slurm reprocessing, not the Coming Soon reprocessing described in <a href=\"https://jira.lsstcorp.org/browse/DM-14762\" title=\"Rerun complete HiTS 2015 data processing on the VC\" class=\"issue-link\" data-issue-key=\"DM-14762\"><del>DM-14762</del></a> which involves new templates from <a href=\"https://jira.lsstcorp.org/browse/DM-15080\" title=\"Process HiTS 2014, build template coadds\" class=\"issue-link\" data-issue-key=\"DM-15080\"><del>DM-15080</del></a>. The data used here is the same as what was intended for <a href=\"https://jira.lsstcorp.org/browse/DM-14260\" title=\"Re-run HiTS data processing with current ap_pipe\" class=\"issue-link\" data-issue-key=\"DM-14260\"><del>DM-14260</del></a> but ultimately was split between <a href=\"https://jira.lsstcorp.org/browse/DM-14260\" title=\"Re-run HiTS data processing with current ap_pipe\" class=\"issue-link\" data-issue-key=\"DM-14260\"><del>DM-14260</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-14261\" title=\"Add holoviews JupyterLab extension\" class=\"issue-link\" data-issue-key=\"DM-14261\"><del>DM-14261</del></a>; i.e., the data used here is the present ap_verify_hits2015 dataset which includes\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ebellm\" class=\"user-hover\" rel=\"ebellm\">Eric Bellm</a>\\'s original set of hits2014 coadds for templates.)</p>\n",
            "<p>In the SummaryState event for atHeaderService, the SummaryStateValue should be filled using the summary state enumeration available in the CSC library for the correct state transition.</p>\n",
            "\"<p>The TE1, TE2 metrics have expected values on the order of 10^-6.  The current SQuaSH display defaults to showing things on the order of 10.  Scrolling in 6 orders of magnitude isn't really practical.  It's thus not possible to use the visualization to understand the performance.</p><p>Please adjust the default display range either <br/>(a) based on the range of values, with an additional requirement to include 0<br/>(b) on a hard-coded fixed range.</p>\"\n",
            "<p>Browse through notebooks in the <tt>prod</tt> branch and improve content: e.g. language, plot labels.  The repository is <a href=\"https://github.com/lsst-sqre/notebook-demo/tree/prod\" class=\"external-link\" rel=\"nofollow\">here</a>.</p>\n",
            "<p>A request has been made to determine whether or not systems to transfer, ingest, and archive data from CCOB can be made available during early testing (and then remain up).</p>\n",
            "<p>This ticket is intended to create a new microservice within the api.lsst.codes umbrella called <tt>uservice_nbreport</tt>. This service is envisioned in <a href=\"https://sqr-023.lsst.io\" class=\"external-link\" rel=\"nofollow\">https://sqr-023.lsst.io</a> (<a href=\"https://jira.lsstcorp.org/browse/DM-15003\" title=\"Draft technote on design of notebook-based reports\" class=\"issue-link\" data-issue-key=\"DM-15003\"><del>DM-15003</del></a>). This ticket will involve creating the codebase and configuring a minimally-viable deployment. Many domain specific features like customized HTML generation may be index pages will be deferred to future tickets.</p>\n",
            "<p>This ticket is to add additional commands (beyond <tt>nbreport test</tt>, <a href=\"https://jira.lsstcorp.org/browse/DM-15167\" title=\"Create nbreport test command\" class=\"issue-link\" data-issue-key=\"DM-15167\"><del>DM-15167</del></a>) to the <tt>nbreport</tt> command-line application that interact with the api.lsst.codes/nbreport microservice (<a href=\"https://jira.lsstcorp.org/browse/DM-15199\" title=\"Create uservice_nbreport project for publishing notebook-based reports\" class=\"issue-link\" data-issue-key=\"DM-15199\"><del>DM-15199</del></a>) to reserve instances and upload computed notebooks corresponding to instances.</p><p>According to the plan in <a href=\"https://sqr-023.lsst.io/v/DM-15003\" class=\"external-link\" rel=\"nofollow\">https://sqr-023.lsst.io/v/DM-15003</a> these commands are:</p><ul class=\"alternate\" type=\"square\">\\t<li><tt>nbreport init</tt></li>\\t<li><tt>nbreport render</tt></li>\\t<li><tt>nbreport compute</tt></li>\\t<li><tt>nbreport upload</tt></li>\\t<li><tt>nbreport issue</tt> (the all-in-one version of that command)</li></ul>\n",
            "<p>Per <a href=\"https://jira.lsstcorp.org/browse/RFC-504\" title=\"Add SCARLET as a 3rd party package to the stack\" class=\"issue-link\" data-issue-key=\"RFC-504\"><del>RFC-504</del></a>, scarlet will be added as a GitHub fork to the stack.</p>\n",
            "<p>Make up the characterization report for the v16 release.  This will be done on the master branch of <a href=\"https://github.com/lsst-dm/dmtr-81\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/dmtr-81</a>.</p>\n",
            "<p>It would be nice to display all the bands on one plot by disambiguating by color and linestyle. We also have to make sure we display the specifications correctly since some of them also depend on the band.</p>\n",
            "<p>This is a proof of concept based on <a href=\"https://bokeh.github.io/blog/2017/7/5/idiomatic_bokeh/\" class=\"external-link\" rel=\"nofollow\">this post </a> to create new charts in Bokeh using the Models API.</p><p>This method of development is called \"additive development\", you start with an empty canvas and  explicitly add the Bokeh Glyphs to compose the new chart opposed to removing or changing the plot defaults when using the Bokeh plotting API.</p>\n",
            "<p>After some research <tt>flasgger</tt> seems to be a good option for documenting the SQuaSH REST API based on Flask</p><ul>\\t<li><a href=\"https://github.com/rochacbruno/flasgger\" class=\"external-link\" rel=\"nofollow\">https://github.com/rochacbruno/flasgger</a></li></ul><p>it conforms with the OpenAPI 2.0 specification and potentially will support OpenApi 3.0 soon.</p><ul>\\t<li><a href=\"http://idratherbewriting.com/learnapidoc/pubapis_openapi_tutorial_overview.html\" class=\"external-link\" rel=\"nofollow\">http://idratherbewriting.com/learnapidoc/pubapis_openapi_tutorial_overview.html</a></li></ul>\n",
            "<p>The default implementation of SuperTask.runQuantum currently passes additional\\xc2\\xa0<em>output</em> data ID information to run, as this is necessary in at least some contexts in which <tt>run</tt> needs to be able to group input datasets.\\xc2\\xa0 However, the way this is passed is confusing (the kwargs generated do not have names that suggest that they are IDs), and the need for these IDs may be sufficiently rare that most SuperTasks should not be required to accept them.</p><p>One possibility for how to address this would be:</p><ul>\\t<li>runQuantum always passes just a single data ID (the quantum data ID, not the data of either inputs or outputs) to run, as an always-optional\\xc2\\xa0<tt>dataId</tt>\\xc2\\xa0keyword argument (i.e. SuperTasks must permit this argument to be None).\\xc2\\xa0 That will at least meet the needs of SuperTasks that want to use the data ID for diagnostic or custom-provenance purposes (see also <a href=\"https://jira.lsstcorp.org/browse/DM-14821\" title=\"Provide packed integer versions of Gen3 data IDs\" class=\"issue-link\" data-issue-key=\"DM-14821\"><del>DM-14821</del></a>).</li>\\t<li>SuperTasks that need to do data ID grouping in <tt>run</tt> should override <tt>runQuantum</tt> themselves.</li>\\t<li>To make the above easier / less verbose, we should look for ways to make some of the logic in the default implementation of <tt>runQuantum</tt> available to subclasses that override that method (e.g. via utility methods that do some of the work).</li></ul><p>I\\'m open to other ideas as well, and I should note that I have not thought much about how this proposal would change which of our concrete SuperTasks would need to override <tt>runQuantum.</tt></p>\n",
            "<p>C++11 methods that are declared <tt>noexcept</tt> enable compilers to streamline code that calls them, in some cases (e.g., STL code) unlocking more efficient algorithms that would be unsafe with throwing methods. These changes are most useful for low-level types, whose methods are also the most likely to be provably non-throwing.</p><p>This ticket shall add the <tt>noexcept</tt> specifier to any methods that are guaranteed not to throw and are unlikely to be modified to throw exceptions in the future (e.g., trivial getters will usually qualify, but methods for which some inputs are invalid will not even if the existing code performs no input validation). Particular attention shall be paid to constructors, assignment operators, and <tt>std::swap</tt> implementations, as these are the methods where <tt>noexcept</tt> provides the biggest gains.</p><p>The classes covered by this ticket are (based on assumed simplicity, and therefore subject to change):</p><ul>\\t<li><tt>afw::cameraGeom::CameraPoint</tt></li>\\t<li><tt>afw::cameraGeom::CameraSys</tt></li>\\t<li><tt>afw::cameraGeom::CameraSysPrefix</tt></li>\\t<li><tt>afw::cameraGeom::Orientation</tt></li>\\t<li><tt>afw::coord::Coord</tt> and its subclasses</li>\\t<li><tt>afw::coord::Observatory</tt></li>\\t<li><tt>afw::coord::Weather</tt></li>\\t<li><tt>afw::detection::Threshold</tt></li>\\t<li><tt>afw::geom::Angle</tt></li>\\t<li><tt>afw::geom::AngleUnit</tt></li>\\t<li><tt>afw::geom::Box</tt></li>\\t<li><tt>afw::geom::CoordinateBase</tt> and its subclasses</li>\\t<li><tt>afw::geom::CoordinateExpr</tt></li>\\t<li><tt>afw::geom::Span</tt></li>\\t<li><tt>afw::geom::SpherePoint</tt></li>\\t<li><tt>afw::geom::polygon::Polygon</tt></li>\\t<li><tt>afw::image::Calib</tt></li>\\t<li><tt>afw::image::Color</tt></li>\\t<li><tt>afw::image::DefectBase</tt></li>\\t<li><tt>afw::image::Filter</tt></li>\\t<li><tt>afw::image::FilterProperty</tt></li>\\t<li><tt>afw::math::FitResults</tt></li>\\t<li><tt>afw::math::Function</tt> and its subclasses</li>\\t<li><tt>afw::math::MaskedVector</tt></li>\\t<li><tt>afw::math::Statistics</tt></li>\\t<li><tt>afw::table::BaseRecord</tt> and its subclasses</li>\\t<li><tt>afw::table::ConstFunctorKey</tt></li>\\t<li><tt>afw::table::FieldBase</tt> and its subclasses</li>\\t<li><tt>afw::table::InputFunctorKey</tt> and its subclasses</li>\\t<li><tt>afw::table::KeyBase</tt> and its subclasses</li>\\t<li><tt>afw::table::Match</tt></li>\\t<li><tt>afw::table::OutputFunctorKey</tt> and its subclasses</li>\\t<li><tt>afw::table::ReferenceFunctorKey</tt></li>\\t<li><tt>afw::table::SchemaItem</tt></li>\\t<li><tt>afw::table::io::Persistable</tt></li>\\t<li><tt>afw::table::io::PersistableFacade</tt></li></ul>\n",
            "<p>Gather storage requirements for disaster recovery of managed databases.</p>\n",
            "<p>We begin installation steps on lsst-ddb-* test machines for an xrootd installation that will support oauth2/scitokens and eventually third party copy over https.    We also test generation of scitokens for use with gfal-copy, FTS against the xrootd installation.</p>\n",
            "<p>The goal is to collect input from operators regarding desired features of the offline batch processing service.</p>\n",
            "<p>Provide support, fixes and maintenance of configuration within the cluster as it is being developed. Will register incidental work such as helping with deployments, testing, etc,</p>\n",
            "<p>Univa has a resource management tool for kubernetes called naviops which provide easy access to policies, , schedulers, management of resources, users, groups and namespaces. It also provide means to allocate projects and deployments.\\xc2\\xa0</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Work to add objectives among Verification and Validation Test Cases.</p>\n",
            "<p>The multi-band deblender needs to be updated to use the new multi-band classes and fit in the same task structure as the current deblender.</p>\n",
            "<p>Running validate_drp on many full focal plane visits can be quite slow (as is necessary to complete the jointcal/meas_mosiac comparison), with most of the time spent in multiMatch. It appears there are a handful of relatively easy speedups that can be done to it, before we expend the (still necessary) effort to replace it with a fast n-way matcher.</p>\n",
            "\"<p>Lorena Mezini, an undergraduate working with Erin Sheldon, noticed that when scarlet fits positions,\\xc2\\xa0the mean position errors are ~<tt>0.15</tt> in both x and y (see attached plot). What's stranger is that one of the objects in her simulations seems to have a mean positional error of 0 in x and y while the other shows the offset.</p><p>Her dataset were generated using galsim, with very low noise and fixed bounding boxes (25 pixels) on single band images. The sources both have very small ellipticity (~.01) with random orientations, the same shear, and identical FWHM. The plot shows an example with 100k blends, each with 2 sources separated by 11 pixels.</p><p>This ticket is to investigate this behavior to understand the conditions that lead to two seemingly identical objects being deblended differently.</p>\"\n",
            "<p>The goal is to include findings regarding handling data (file transfers, cleanup) in Pegasus WMS in the technote describing detailed Pegasus evaluation.</p>\n",
            "<p>Currently we can display the unit for each column in the table display.\\xc2\\xa0</p><p>It will be very useful to display the data type for each column.\\xc2\\xa0</p><p>we should use the similar check on/off option for unit display for this option.\\xc2\\xa0</p>\n",
            "<p>MERRA-2 provides an Aerosol Optical Depth table and the question is wether it is useful for Aux.Tel. observations.</p><p>\\xc2\\xa0</p><p>I have downloaded 2-D and 3-D tables from NASA server, I have written python scripts to extract, integrate and sum mixed components. I shall now look at :</p><ul>\\t<li>Integrated aerosol (AODANA) versus mixed components :</li></ul><p>BCINC tzyx Black Carbon Mixing Ratio Analysis Increments kg kg-1<br/>DUINC tzyx Dust Mixing Ratio Analysis Increments kg kg-1<br/>OCINC tzyx Organic Carbon Mixing Ratio Analysis Increments kg kg-1<br/>SSINC tzyx Sea-salt Mixing Ratio Analysis Increments kg kg-1<br/>SUINC tzyx Sulfate Mixing Ratio Analysis Increments kg kg-1</p><p>And there associated spatial gradients.</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p>This ticket follows on <a href=\"https://jira.lsstcorp.org/browse/DM-15150\" title=\"Create APIs for rendering a templated Jupyter Notebook in nbreport\" class=\"issue-link\" data-issue-key=\"DM-15150\"><del>DM-15150</del></a> to create a command line interface for the <tt>nbreport</tt> client application.</p><p>The CLI is designed in <a href=\"https://sqr-023.lsst.io/v/DM-15003\" class=\"external-link\" rel=\"nofollow\">https://sqr-023.lsst.io/v/DM-15003</a></p><p>Specifically, this ticket will create the <tt>nbreport test</tt> test CLI. This command demonstrates most of the notebook-related workflow without involving GitHub or the api.lsst.codes/nbreport service. It will</p><ul class=\"alternate\" type=\"square\">\\t<li>Create a test report instance from a report repository</li>\\t<li>Render the notebook from the template</li>\\t<li>Execute the notebook</li></ul>\n",
            "<ul>\\t<li>Participated in a Jupyterlab tutorial, a Jupyter widgets tutorial, and a PyViz tutorial covering Holoviews and Datashader.</li>\\t<li>Sprinted on a ginga widget with Eric Jeschke (ginga lead), Pey Lian Lim (JWST ginga lead and Astropy core dev), and Matt Craig. Eric made experimental branches of aggdraw and ginga to show how drawing circles could be vectorized to improve performance.</li>\\t<li>Hacked on a Firefly extension for Jupyterlab (experimentally).</li>\\t<li>Participated in Bird of a Feather session on dashboards and plotting, with a panel of representatives from Plotly, ipywidgets, and Holoviews/Bokeh.</li>\\t<li>Attended many exciting visualization talks on ipywidgets for Plotly (Jon Mease), 3-D rendering in Jupyterlab (Maarten Breddels), and other widgets in Jupyterlab (Sylvain Corlay).</li>\\t<li>Discussed visualization with various experts including Jason Grout (Bloomberg/Jupyter), Paul Ivanov (Bloomberg/Jupyter), Jon Mease (JHUAPL), and Maarten Breddels.</li>\\t<li>Presented a non-LSST talk \"Practical Applications of Astropy\".</li></ul>\n",
            "<p>Initial investigations on using the Science Pipeline payload from within the Singularity containers.  Try to run some small examples on our LSST machines. </p>\n",
            "<p>In the DCR template generation code, when exposures are warped that operation is currently performed in-place, over-writing the array values and wcs info. This could potentially lead to bugs down the road, so either the implementation should be made more robust or checks should be put in place to verify that it is safe.</p>\n",
            "<p>The DCR code needs to be packaged so that it can be distributed with EUPS and installed with lsstsw.</p>\n",
            "<p>The prototype DCR code currently uses print statements to issue warnings and informative messages. These should be converted to use the standard logging system.</p>\n",
            "<p>It should be possible to run the new DCR template generation code from the command line.</p>\n",
            "<p>This was discussed in DMTN-031.</p>\n",
            "<p>Implement a per-object Galactic Extinction correction for use with the color-analysis QA plots to replace the per-field placeholder included in <a href=\"https://jira.lsstcorp.org/browse/DM-13154\" title=\"Refine limits and labeling for color analysis plots\" class=\"issue-link\" data-issue-key=\"DM-13154\"><del>DM-13154</del></a>. \\xc2\\xa0It looks like there is code in <tt>sims_photUtils</tt> (and dependencies) to do this, so this will be an attempt to get that working with the analysis scripts.</p><p>\\xc2\\xa0</p><p>Note that this requires the A_filter/E(B-V) extinction coefficients for the HSC filters (awaiting a response from the HSC team, the placeholder noted above is just using SDSS filter values).</p>\n",
            "<p>Write a presentation\\xc2\\xa0about the current status of the deblender for the Science Collaboration Chairs (to be presented on Tuesday, July 17, 2018).</p>\n",
            "<p>A preliminary answer to this question is in the pdf attached.<br/>And its : likely unsignificant\\xc2\\xa0!</p><p><span class=\"nobr\"><a href=\"https://jira.lsstcorp.org/secure/attachment/33369/33369_ozoneCTIO.pdf\" title=\"ozoneCTIO.pdf attached to DM-15068\">ozoneCTIO.pdf<sup><img class=\"rendericon\" src=\"https://jira.lsstcorp.org/images/icons/link_attachment_7.gif\" height=\"7\" width=\"7\" align=\"absmiddle\" alt=\"\" border=\"0\"/></sup></a></span></p>\n",
            "<p>We have decided to change how module and package documentation directories are used. The original design was to have module and package documentation directories for all packages (unless the package did not provide Python modules). The new design is to have one type of directory, but not both. This de-emphasizes the role of EUPS and packaging in our user documentation, and is future proof-for a possible mono-repo refactoring of the LSST Science Pipelines.</p><p>This means that module documentation directories now need to provide information about the project (Git repository, Jira component).</p><p>This ticket is to update the <tt>stack_package</tt>  template (<a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/templates</a>) and DMTN-030 technote (<a href=\"https://github.com/lsst-dm/dmtn-030\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/dmtn-030</a>) with this new design.</p><p>Changes to the Developer Guide documentation will be handled in <a href=\"https://jira.lsstcorp.org/browse/DM-14852\" title=\"Document how to write and build the integrated pipelines.lsst.io\" class=\"issue-link\" data-issue-key=\"DM-14852\"><del>DM-14852</del></a> and changes to <a href=\"https://github.com/lsst-dm/pipelines_lsst_io\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/pipelines_lsst_io</a> will be handled in <a href=\"https://jira.lsstcorp.org/browse/DM-11216\" title=\"Proof-of-concept for stack pipelines.lsst.io build\" class=\"issue-link\" data-issue-key=\"DM-11216\"><del>DM-11216</del></a>.</p>\n",
            "<p>Get\\xc2\\xa0some HSC sample data to make sure that Firefly can read and display them properly.</p><p>The reprocessed HSC data could be accessed from lsst-dev.ncsa.illinois.edu at\\xc2\\xa0</p><p>/datasets/hsc/repo/rerun/RC/</p><p>\\xc2\\xa0</p>\n",
            "<p>Add <tt>operator[](Box2I)</tt>, <tt>operator[](Point2I)</tt>, <tt>operator[](int, int)</tt> to C++ image interfaces, taking into account xy0.  Wrap for Python using a temporary alternate method name.</p><p>Remove old Python implementation of <tt>&#95;&#95;getitem&#95;&#95;</tt> and <tt>&#95;&#95;call&#95;&#95;</tt>.</p><p>Update any code that used the old APIs to use the new temporary ones.</p><p>Switch from temporary names to <tt>&#95;&#95;getitem&#95;&#95;</tt> and update downstream code accordingly (via regex or similar).</p>\n",
            "<p>Add tracking modes to LTD Keeper so that an Edition can track the latest EUPS release tags of different types:</p><ul>\\t<li><tt>vX_Y</tt> \\xe2\\x80\\x94 <tt>eups_major_release</tt></li>\\t<li><tt>w_YYYY_WW</tt> \\xe2\\x80\\x94 <tt>eups_weekly_release</tt></li>\\t<li><tt>d_YYYY_MM_DD</tt> \\xe2\\x80\\x94 <tt>eups_daily_release</tt></li></ul><p>It might also be prudent to, at the same time, provide variants for the Git-based tag names: </p><ul>\\t<li><tt>X.Y</tt> \\xe2\\x80\\x94 <tt>eups_git_major_release</tt></li>\\t<li><tt>w.YYYY.WW</tt> \\xe2\\x80\\x94 <tt>eups_git_weekly_release</tt></li>\\t<li><tt>d.YYYY.MM.DD</tt> \\xe2\\x80\\x94 <tt>eups_git_daily_release</tt></li></ul>\n",
            "<p>There is a need to go though the entire ui and document inconsistencies with the old UI.</p>\n",
            "<p>Work with <a href=\"https://jira.lsstcorp.org/browse/DM-8668\" title=\"Implement Period Finder Panel and do LcManager changes for LC UI\" class=\"issue-link\" data-issue-key=\"DM-8668\"><del>DM-8668</del></a> to design and how the LCManager should work</p>\n",
            "<p>What Python capabilities can we use to limit the resource usage of filters in the current (per <a href=\"https://jira.lsstcorp.org/browse/DM-13476\" title=\"Produce design for multiple parallel filters\" class=\"issue-link\" data-issue-key=\"DM-13476\"><del>DM-13476</del></a>) mini-broker system?</p><p>Can you use calls to <tt>setrlimit</tt> (or similar) to limit the resources used by processes you\\'re filtering? How about limiting things like network connections? Filesystem access?</p><p>Produce a brief report on what\\'s possible and what isn\\'t.</p>\n",
            "<p>Refactor DataGroup</p><ul>\\t<li>DataGroup was written a long time ago as a table model to\\xc2\\xa0represent and manipulate tabular data.\\xc2\\xa0 Over the years is has gotten bulky and complicated.  Refactor it with emphasis on memory footprint and larger data set.</li></ul><p>Table parsing</p><ul>\\t<li>Look into ways to improve table parsing, especially IPAC tables.</li></ul>\n",
            "<p>TablePanel was designed with built-in paging for larger data set.<br/> However, it is now used for smaller data set where paging is not necessary.<br/> Make paging optional.</p><p>\\xc2\\xa0</p><p>This is to better support the use cases like showing FITS file header,\\xc2\\xa0 the option window for table display. Those display does not need paging options since data is\\xc2\\xa0usually small enough. Making paging optional gives us more flexibilities\\xc2\\xa0when using TablePanel for display.</p>\n",
            "<p>Hold initial discussions with SLAC staff for tsting requirements, and set up the database system for testing.</p>\n",
            "<p>Integrate Oracle cluster fully into existing LSST infrastructure once configuration is stable-- security, system management (puppet), etc.</p>\n",
            "<p>Create procedures for operating the ATS System and addressing faults if they occur.</p>\n",
            "<p>Various needed improvement/additions to xCAT.</p>\n",
            "<p>Test ability for heapster (Kubernetes monitoring tool) to integrate with the LDF monitoring environment. \\xc2\\xa0</p>\n",
            "<ul>\\t<li><b>Monitoring the atmospheric throughput at Cerro Tololo InterAmerican Observatory with aTmCam</b></li></ul><p><b><a href=\"https://arxiv.org/pdf/1407.7047.pdf\" class=\"external-link\" rel=\"nofollow\">https://arxiv.org/pdf/1407.7047.pdf</a></b></p><p>\\xc2\\xa0</p><p>T. Li paper reports two campaigns of real time monitoring of PWV and AOD at CTIO. The points relevant to Aux.Tel are the followings :</p><ol>\\t<li>PWV can change by a few millimeters over one night and mostly decreases over time on any given night</li>\\t<li>PWV measurement precision :\\xc2\\xa0Assuming there is no variation in 3 minutes, the precision of the measurement is given by the sigma of the black histogram : 0.3 mm uncertainty on the measurement.</li>\\t<li>From their dataset, the authors conclude that a 1 mm monitoring implies an hourly sampling.</li></ol><ol>\\t<li>\\xc2\\xa0</li></ol><p>The authors report no detection of spatial gradient\\xc2\\xa0<img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/information.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/> From MERRA-2 0.1 mm could be expected, which is below the sensitivity of their observations.\\xc2\\xa0<br/> <span class=\"image-wrap\" style=\"\"><img src=\"https://jira.lsstcorp.org/secure/attachment/33228/33228_Capture+d%E2%80%99e%CC%81cran+2018-06-28+a%CC%80+12.06.23.png\" style=\"border: 0px solid black\" /></span></p>\n",
            "<p>Add scripts in xCAT to ensure that nodes:</p><p>(1) are automatically patched during deployment, and</p><p>(2)\\xc2\\xa0RPMs\\xc2\\xa0installed during deployment (by both xCAT and Puppet) come from managed repos to ensure consistent versions</p>\n",
            "<p>Created dashboard to monitor earthquake activity near La Serena to notify admins of earthquake activity in the region to correlate with possible equipment issues/failures.</p>\n",
            "<p>New wokflow for Sims<br/>Merge of Opsim and CATsim<br/>New workflow for PST</p>\n",
            "<p>Use Local Volume API for Qserv data persistence instead of hostPath</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_26. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Test and explore federation across clusters for deployment and future clusters deployments, including institutional clusters\\xc2\\xa0</p>\n",
            "<p>The sphinx_automodapi extension is now available as a standalone package at <a href=\"http://sphinx-automodapi.readthedocs.io/en/latest/\" class=\"external-link\" rel=\"nofollow\">http://sphinx-automodapi.readthedocs.io/en/latest/</a> / <a href=\"https://github.com/astropy/sphinx-automodapi\" class=\"external-link\" rel=\"nofollow\">https://github.com/astropy/sphinx-automodapi</a></p><p>Formerly it was part of astropy-helpers. Switching to this standalone version is good for us since it will reduce the overall weight of documenteer\\'s dependencies.</p><p>This is targeted for the 0.3 release of documenteer.</p>\n",
            "<p>Currently fgcmcal expects to work with stars that have (e.g.) all of griz observations.  This restriction can be relaxed, with the caveat that chromatic corrections will not be as accurate (or non-existent).  However, the expanded calibrated footprint is often a trade-off that is useful.</p><p>There are actually two parts to this: 1) Stars at the edges of the footprints/in chip gaps may be well-calibrated because of information from neighboring stars on the footprint.  The FGCM code supports this already, but some configuration changes and small fixes to make this work properly and efficiently; 2) There may be times that the footprint of the survey has different bands in different regions.  This will require some checks and changes.</p>\n",
            "nan\n",
            "<p>Perform system-level configuration testing-- memory, storage, etc. Resolve issues,</p>\n",
            "<p>As a precursor to trials with the \"experimental\" early versions of oauth2 / scitokens capabilitiy based tokens, we first implement a more standard legacy auth scheme<br/>(based on voms attributes, use of xrootd auth database file acc.authdb) for https access for xrootd. We install and examine plugins xrootd-voms-plugin, xrdhttpvoms, xrootd-lcmaps , and after investigation implement the scheme using libXrdHttpVOMS ( e.g., http.secxtractor /usr/lib64/libXrdHttpVOMS.so ) .</p>\n",
            "<p>The goal is to start a technote for describing findings regarding job clustering capabilities of Pegasus WMS in greater detail.</p>\n",
            "<p>The description of the SuperTask design is distributed among various sources (Confluence pages, technotes). Additionally, these documents are being quickly rendered obsolete due to rapid changes in Gen3 Butler design. \\xc2\\xa0Hence, the best place to find out what is SuperTask current design is to look directly at its source code. The goal is to read through the SuperTask code and find out what features are currently supported.</p>\n",
            "<p>In the absence of <a href=\"https://jira.lsstcorp.org/browse/DM-13990\" title=\"Add support for different SkyPix systems to Registry DataUnit schema\" class=\"issue-link\" data-issue-key=\"DM-13990\">DM-13990</a>, I\\'ll use HTM at depth 7 for everything, because that\\'s what the reference catalog in ci_hsc uses.</p><p>This will include updating daf_butler to\\xc2\\xa0work with the master version of skymap, which has slightly different APIs for sphgeom interoperability than the gen3-middleware branch.</p>\n",
            "<p>Make up the characterization report for the v15 release.  This will be done on the master branch of <a href=\"https://github.com/lsst-dm/dmtr-62\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/dmtr-62</a>.</p>\n",
            "<p>Re-run the data that <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ebellm\" class=\"user-hover\" rel=\"ebellm\">Eric Bellm</a> processed for the late-2017 LDM-503-3 milestone using a current (May 2018) version of ap_pipe.</p>\n",
            "<p>In the Developer Guide, documentation for LICENSE and COPYRIGHT were originally documented in <a href=\"https://developer.lsst.io/stack/package-docs.html\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/stack/package-docs.html</a>. That page will be rewritten to document the new documentation system for packages and pipelines.lsst.io.</p><p>This ticket is to move the LICENSE and COPYRIGHT discussion out of that page before it is rewritten, and to also add additional context around copyright management in DM.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_24. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_15. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p><p>(Starting this week, the reprocessing actually has RC2 only, and no longer include the two WIDE tracts of RC1.)</p>\n",
            "<p>Propose plan for handling DM tech notes in docushare.</p><p>There are a number of issues:</p><ul>\\t<li>Generating a PDF from rst tech note</li>\\t<li>Allocating numbers in docushare.</li></ul>\n",
            "<p>Camera tilts and decenters impart offsets to low-order Zernikes (how low?) that are affine in field position.  So to combine Zernikes from different exposures, we should first \"flatten\" the maps by subtracting the best-fit plane (in unrotated focal plane coords) to the fits.  So do that.  And then see how successful this is by comparing the residuals from different exposures.  If it worked, then these residuals should more-or-less line up.</p>\n",
            "<p>Develop a plan for combining multiple full focal plane out-of-focus images into a single reference wavefront.  This isn\\'t completely trivial, as the aberrations in different exposures will be somewhat different, so some strategy needs to be used to account for the differences.  <a href=\"http://adsabs.harvard.edu/abs/2014SPIE.9145E..16R\" class=\"external-link\" rel=\"nofollow\">This article</a> may illustrate how Aaron Roodman accomplished this for DECam.</p>\n",
            "<p>Become familiar with Bo Xin\\'s cwfs (curvature wavefront sensing) package (<a href=\"https://github.com/bxin/cwfs\" class=\"external-link\" rel=\"nofollow\">https://github.com/bxin/cwfs</a>).  Get it running, go through examples, fit some toy wavefronts....</p>\n",
            "<p>Harvard team and CNRS-LAL team have been independently performing and reducing observations for telescope throughput calibration from airmass regression.</p><p>Here is the (quite satisfaying) result shown at the LSST/DESC Calibration Workshop (May 25th 2018):</p><p><a href=\"https://indico.in2p3.fr/event/17361/contributions/62542/attachments/48385/61105/2018-05-25-atmspectra-final.pdf\" class=\"external-link\" rel=\"nofollow\">https://indico.in2p3.fr/event/17361/contributions/62542/attachments/48385/61105/2018-05-25-atmspectra-final.pdf</a></p><p><span class=\"image-wrap\" style=\"\"><img src=\"https://jira.lsstcorp.org/secure/attachment/32936/32936_Capture+d%E2%80%99e%CC%81cran+2018-05-28+a%CC%80+16.55.55.png\" style=\"border: 0px solid black\" /></span></p>\n",
            "<p>I wrote and ran some systematic tests in pyprofit to compare the accuracy and speed of galaxy profile integration and convolution using pyprofit/libprofit and GalSim. When evaluating the profile and convolving with an analytic PSF, GalSim is considerably faster for n&lt;4 and more accurate in most cases, especially for small axis ratios. However, ProFit can be faster for large Sersic indices (n&gt;4) and supports an essentially infinite range, whereas GalSim is limited to 0.3&lt;n&lt;6.2. Furthermore, the tests I ran used 3x oversampling in libprofit, which has further room for optimization - as does libprofit\\'s profile integration scheme. Thus, it\\'s worth keeping support for libprofit in the future.</p><p>pyprofit code: <a href=\"https://github.com/lsst-dm/pyprofit\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/pyprofit</a></p><p>pyprofit arguments to generate a table of benchmarks (in pycharm run configuration format, which is human-readable xml): <a href=\"https://github.com/lsst-dm/pyprofit/blob/master/.idea/runConfigurations/pyprofit_bench_integ_long.xml\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/pyprofit/blob/master/.idea/runConfigurations/pyprofit_bench_integ_long.xml</a></p><p>benchmarking notebook: <a href=\"https://github.com/lsst-dm/modelling_research/blob/master/jupyternotebooks/pyprofit_benchmarks_plot.ipynb\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/modelling_research/blob/master/jupyternotebooks/pyprofit_benchmarks_plot.ipynb</a></p><p>The plots should render better in a browser now, but I attached some copies anyway.</p>\n",
            "<p>Create a package for <tt>treecorr</tt>  to allow for calculation of correlation functions in a fast, robust, and tested code.</p><p>This will not add dependencies to <tt>lsst_apps</tt> or <tt>lsst_distrib</tt>. </p><p>Implementation is likely<br/>1. Create wrapper install packages for <tt>treecorr</tt>.<br/>2. Figure out how to avoid adding the FITS reader dependency in <tt>treecorr</tt>.<br/>3. Add treecorr dependence to <tt>validate_drp</tt> table file.</p><p>TreeCorr is a  \"<span class=\"error\">&#91;c&#93;</span>ode for efficiently computing 2-point and 3-point correlation functions\" and is being proposed for use in <tt>validate_drp</tt> to calculate the correlation function of the PSF residual ellipticity (<a href=\"https://jira.lsstcorp.org/browse/DM-8951\" title=\"Add TE1 and TE2 KPMs to validate_drp using code developed in DM-3040\" class=\"issue-link\" data-issue-key=\"DM-8951\"><del>DM-8951</del></a>).  The GitHub repo is here:</p><p><a href=\"https://github.com/rmjarvis/TreeCorr\" class=\"external-link\" rel=\"nofollow\">https://github.com/rmjarvis/TreeCorr</a></p><p>TreeCorr depends on the following Python packages.</p><p>numpy<br/>future<br/>fitsio<br/>pandas<br/>pyyaml<br/>cffi</p>\n",
            "<p>Take the JSON output of a <tt>validate_drp</tt> run and produce a report suitable for a Characterization Metrics Report.</p><p>See, e.g., </p><p><a href=\"https://pipelines.lsst.io/metrics/v13_0.html#metrics-v13-0\" class=\"external-link\" rel=\"nofollow\">https://pipelines.lsst.io/metrics/v13_0.html#metrics-v13-0</a></p><p><a href=\"https://github.com/lsst/pipelines_lsst_io/blob/master/metrics/v13_0.rst\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/pipelines_lsst_io/blob/master/metrics/v13_0.rst</a></p><p>and the attachment for an example to how to format things.</p>\n",
            "<p>Multiband driver can run detection on a coadd, but this code path is rarely exercised. The method signature to detect coadd sources in pipe_tasks has changed, but was not updated in pipe_drivers. This ticket should fix the call to runDetection in detectCoaddSources</p>\n",
            "\"<p>In order to implement forced photometry in AP pipe, we're going to need to understand how the forced photometry tasks in meas_base works. Take a look at <tt>ForcedPhotCcdTask</tt> (and the rest of its class hierarchy) and figure out how it all fits together.</p>\"\n",
            "nan\n",
            "<p>Write command line script to run mini production.  The scripts should be able to be handed directly to the orca layer.</p>\n",
            "<p>Assuming that the data needed for mini-production are to be simulated, the input files need to be created and simulated.  The input data then need to be put in a repo with appropriate calibrations.</p>\n",
            "\"<p>The run of a mini production will produce an output repository.  It's likely that we will not want to save all output data.  A script to clean up and potentially save parts of the repo is needed.</p>\"\n",
            "<p><font color=\"#000000\">Write the milestone test verification report.</font></p>\n",
            "<p>The <tt>ap_verify</tt> dataset framework is currently documented in the Sphinx documentation for <tt>ap_verify</tt>. This documentation assumes that individual datasets will at least have documentation of their GitHub repository, so that the pages can be linked from lists of known datasets or from examples. However, no such documentation has been written yet.</p><p>This issue adds a documentation placeholder to <tt>ap_verify_dataset_template</tt>, and standardized package documentation to <tt>ap_verify_hits2015</tt>, <tt>ap_verify_testdata</tt>, and any other datasets existing at the time of work. It will <b>not</b> move the documentation of the dataset framework from its current location in <tt>ap_verify</tt>.</p>\n",
            "<p>Ivezi\\xc4\\x87 et al. 2004 (2004AN....325..583I) define a \"Principle Color\" analysis\\xc2\\xa0to estimate the accuracy of the photometric zeropoint calibration.  The principle colors are defined by linear combinations of magnitudes in the SDSS bands.  The coefficients in that paper are for the SDSS filters.  To enable direct comparison with those results, derive the associated values of these coefficients for the HSC filters.  The calibration here will start with just the RC2 dataset.  A later ticket will use the full PDR1 to calibrate these coefficients.</p>\n",
            "<p>SNFactory has been collecting spectra of standards stars since 2006.</p><p>We compared the atmospheric parameters that they extracted with the ones interpolated from NASA MERRA-2 tables.</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p>Add a <tt>transaction</tt> context manager to enable multiple <tt>put</tt> calls to be handled as a single transaction (either all working or not at all).</p>\n",
            "<p>Merge configmaps and init containers definitions in master and worker pods</p>\n",
            "<p>Create reStructuredText directives\\xc2\\xa0that build the module and package toctrees for pipelines.lsst.io.</p><p>Building these toctrees automatically will make the pipelines_lsst_io repo more robust to a changing composition of stack packages.</p><p>The list of modules and packages available for the documentation should generally be known from eups setups and the presence of manifest.yaml files.</p><p>The directives should allow for packages to be explicitly ignored even if they are automatically detected. This feature should be easy to implement and will provide a safety valve for automatic package detection.</p><p>The directives will be implemented in <a href=\"https://github.com/lsst-sqre/documenteer\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/documenteer</a>.</p>\n",
            "<p>Minor tweaks to the SuperTask base class interface, prior to starting the work of adapting concrete CmdLineTasks to that interface.\\xc2\\xa0 Includes:</p><p>\\xc2\\xa0- Making sure coding conventions are used consistently.</p><p>\\xc2\\xa0- Making sure config/schema writing is handled appropriately.</p><p>\\xc2\\xa0- Adding introspection and other interface for input/output datasets used/created in Task initialization (will be used only for schemas).</p><p>\\xc2\\xa0</p>\n",
            "<p>Remove chart code supporting unused pre-multitrace architecture and server-side expressions.<br/>Update the documentation for showChart parameters.</p>\n",
            "<p>Update dmtn-060 with broader survey of data management / file transfer systems and tools.</p>\n",
            "<p>Update the code that generates the gaussian mixture model, which is to be used as the prior in the regularized moments code, so that all of the parameters are measured in sky tangent plane coordinates. This ticket should also convert the code in the regularized moments algorithm that uses this code to also operate in sky tangent plane coordinates.</p>\n",
            "<p>Modify <tt>pipe_tasks.multiBand</tt> to detect, merge, and measure sources across multiple DCR subfilter coadds. The documentation will also need to be updated, and a new unit test should probably be added.</p>\n",
            "<p>Test system/database performance using a known astronomical pipeline framework.</p>\n",
            "<p>Run Oracle tests and benchmarking, e.g., SLOB. Resolve issues.</p>\n",
            "\"<p>Create landing page that's better than the default 404</p>\"\n",
            "<p>Implement an initial basic (non-composite) version of:</p><ul>\\t<li><tt>Registry.find</tt></li>\\t<li><tt>Registry.associate</tt></li>\\t<li><tt>Registry.disassociate</tt></li>\\t<li><tt>Butler.get</tt>.</li></ul>\n",
            "<p>Change <tt>DataUnit</tt> (and its derived classes) in the Butler prototype to be a hierarchy of classes whose instances represent\\xc2\\xa0<tt>DataUnit</tt> <em>tables</em> rather than the rows of those tables. We will instead typically use plain <tt>dict</tt> objects (called <tt>DataID</tt> by analogy with the Gen. 2 Butler concept) to represent the rows of <tt>DataUnit</tt> tables.</p>\n",
            "<p>Implement:</p><ul>\\t<li><tt>Execution</tt></li>\\t<li><tt>Run</tt></li>\\t<li><tt>Quantum</tt><br/>and their associated <tt>Registry</tt> functionality.</li></ul>\n",
            "<p>The <tt>pytest-cov</tt> plugin should be enabled to write coverage reports from unit testing. This ticket covers the work to enable per-product coverage testing solely from the unittests associated with that product. This can be enabled as part of normal test execution. It is possible to write coverage results to html, the terminal and XML. XML is needed for Jenkins support &#8211; it may be desirable to default to HTML and terminal reporting but allow Jenkins to enable XML output via an environment variable.</p>\n",
            "<p>Calculate the ellipticity, and the residual ellipticity (moments - PSF).</p><p>Add to calculated SRD statistics.</p><p>This will involve thinking about things on an image-by-image basis, which is the natural and largely SRD-specified way for considering ellipticity.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_22. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Write simple script to compare each of the segments (HDU) for two FITS files (i.e. Truth FITS file vs new FITS file)</p>\n",
            "<p>I measured more diagnostics for differences in cModel performance with 2 vs 3 (default) vs 6 components in the initial fit. Performance-wise in HSC-deep r-band coadds, 2 components takes 6% less time than 3, while 6 takes 60% longer. Some galaxies have large differences in the quality of the initial fit, with slightly better fits on average with more components. However, the differences in the final fits are very modest, so there is little justification for using 6 components, and 2 might even be fine.</p><p>A large number of relevant plots/tables can be generated by the notebook created in <a href=\"https://jira.lsstcorp.org/browse/DM-14118\" title=\"Create Jupyter notebook summarizing cModel config results\" class=\"issue-link\" data-issue-key=\"DM-14118\"><del>DM-14118</del></a> (lsst-dev:/home/dtaranu/src/mine/taranu_lsst/cModelConfigs.ipynb).</p>\n",
            "<p>Rerun multiBandDriver.py with w_2018_14 on tract=9813 patch=3,4, varying cModel parameters like:</p><p>config.measureCoaddSources.measurement.plugins<span class=\"error\">&#91;&quot;modelfit_CModel&quot;&#93;</span>.initial.nComponents=2</p><p>This is to test whether changing the number of initial components can reduce the total running time without reducing the quality of the final cModel fit.</p><p>This includes going over slurm, lsst-dev file paths and miscellaneous pipeline info with Yusra.</p><p>An example command is:</p><p>multiBandDriver.py /datasets/hsc/repo --calib /datasets/hsc/repo/CALIB/ --rerun RC/w_2018_14/<a href=\"https://jira.lsstcorp.org/browse/DM-13890\" title=\"Reprocess RC2 with w_2018_14\" class=\"issue-link\" data-issue-key=\"DM-13890\"><del>DM-13890</del></a>:private/dtaranu/cmodelconfigs/w_2018_14_gradthresh_1e-3 --id tract=9813 patch=3,4 filter=HSC-G^HSC-R^HSC-I^HSC-Z^HSC-Y^NB0921 --configfile /project/dtaranu/cmodelconfigs/w_2018_14_gradthresh_1e-3/logs/config.py --batch-type=slurm --mpiexec=\\'-bind-to socket\\' --job gthreshp1 --cores 6 --time 180000</p><p>where /project/dtaranu/cmodelconfigs/w_2018_14_gradthresh_1e-3/logs/config.py contains:</p><p>config.measureCoaddSources.measurement.plugins<span class=\"error\">&#91;&#39;modelfit_CModel&#39;&#93;</span>.initial.optimizer.gradientThreshold=0.001</p>\n",
            "<p>Assess the performance of the classifier on data with different depths and seeings.</p>\n",
            "\"<p>In preparation for integrating the Forward Global Calibration Module code with LSST, we'd like to get a feeling for the abstractions and data structures it uses which can be replaced with (perhaps extended versions of) LSST equivalents. Please identify likely candidates, so we can discuss/demo the LSST equivalents. Examples might include filters, camera geometry, etc.</p>\"\n",
            "<p>The current polynomial fits in the color analysis use <em>numpy.polyfit</em>, which performs a regression on the vertical offsets from the polynomial. \\xc2\\xa0A regression on the orthogonal distance to the fit is preferable (and required for nearly-vertical distributions). \\xc2\\xa0This ticket is to implement an\\xc2\\xa0Orthogonal Distance Regression\\xc2\\xa0using \\xe2\\x80\\x9codr\\xe2\\x80\\x9d uses the <em>scipy.odr</em> module (the <em>numpy.polyfit</em>\\xc2\\xa0fit will be retained as it serves as an initial guess for the \"odr\" fit).</p><p>\\xc2\\xa0</p><p>The work here will likely be done as part of the <a href=\"https://jira.lsstcorp.org/browse/DM-13154\" title=\"Refine limits and labeling for color analysis plots\" class=\"issue-link\" data-issue-key=\"DM-13154\"><del>DM-13154</del></a> ticket (as plotting limits and refinements may require adjustments as a result of this work).</p>\n",
            "<p>While Oracle RAC at NCSA is getting ready for testing I could spend some time to\\xc2\\xa0try running my prototype against Oracle in some other non-production setup. ap_proto uses sqlalchemy but it also has\\xc2\\xa0dialect-specific SQL\\xc2\\xa0handling for optimization purpose. I need to extend that backend-specific code to support Oracle as well.\\xc2\\xa0</p><p>I can think of few potential\\xc2\\xa0things that need different implementation for Oracle:</p><ul>\\t<li>multi-row INSERT, Oracle does not support syntax that is supported by other backends (<tt>INSERT INTO TABLE (columns) VALUES (data), (data), (data), ...</tt>) so I\\'ll have to find some other mechanism for bulk row insert</li>\\t<li>\"UPSERT\" functionality should also be implemented differently in Oracle</li>\\t<li>Case-sensitivity issue (probably minor)</li>\\t<li>Usual DATETIME stuff is not very portable</li>\\t<li>Anything else...</li></ul>\n",
            "<p>This is to record the\\xc2\\xa0effort of SUIT team supporting the NB access to Firefly server, QAs, and debugging.</p><p>The issues and bugs\\xc2\\xa0need to be addressed are recorded in different tickets.\\xc2\\xa0</p>\n",
            "<p>In this case \"production\" means passed very friendly early user testing and the system is ready for integration and testing at the service level.</p>\n",
            "nan\n",
            "<p>The <tt>ImageSelector</tt> subclass imported in <a href=\"https://jira.lsstcorp.org/browse/DM-10977\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/DM-10977</a> requires manually specifying minimum and maximum FWHMs for constructing a \"best seeing\" coadd.  This is limiting for several reasons and requires manual offline analysis to determine those numbers.</p><p>This ticket is to change the algorithm to automatically determine the N best-seeing images in a patch for coaddition.</p>\n",
            "\"<p>As we think of more things to pass down to the spawned Lab container, and more knobs that need to be added to the deployment (for instance, selecting between CILogon and GitHub), then our deployment tool needs to be modified to accommodate these additional settings and generate configuration and deployment instructions for them.</p><p>Same goes for bug fixes in the deployment tool as we find corner cases where it doesn't currently work but should.</p>\"\n",
            "<p>Implement as described in DMTN-056.</p><p>Will require an expand-and-topological-sort algorithm (evaluate the one used on <a href=\"https://jira.lsstcorp.org/browse/DM-12371\" title=\"Implement minimal butler Registry prototype with sqlalchemy core\" class=\"issue-link\" data-issue-key=\"DM-12371\"><del>DM-12371</del></a>).</p>\n",
            "<p>Implement as described in DMTN-056.</p><p>Needs to be comparable/hashable on name.</p><p>May want to consider a global cache of all instances, with a construction mechanism that returns existing objects when possible (and verifies consistent DataUnit types).</p>\n",
            "nan\n",
            "nan\n",
            "<ol>\\t<li>Allow different projects, with different names, to use <tt>lsst-sphinx-bootstrap-theme</tt> (make the name templated)</li>\\t<li>Fix LSST logo branding (don\\'t use the inverted version)</li>\\t<li>Further improve colours and typography.</li></ol><p>This will allow the theme to be used with the nb.lsst.io site ( <a href=\"https://jira.lsstcorp.org/browse/DM-14406\" title=\"MVP user documentation site for the notebook aspect of the LSST Science Platform\" class=\"issue-link\" data-issue-key=\"DM-14406\"><del>DM-14406</del></a>)</p>\n",
            "<p>Separate the cluster provisioning (terraform) from k8s setup</p>\n",
            "<p>Unify the k8s definition of the proxy container for worker and master pods.</p>\n",
            "<p>multiBandDriver.py of the entire HSC PDR1 dataset with w_2018_15</p>\n",
            "<p>coaddDriver.py of the entire HSC PDR1 dataset with w_2018_15</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_20. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>This will involve standard testing as well as setting up a clone VM to test future changes locally before changing the remote system.</p>\n",
            "<p>Create Requirements Matrix for HeaderService in the form of a spreadsheet</p>\n",
            "\"<p>In <tt>Butler.put</tt> on concrete composite datasets, the Registry is informed of all component Datasets, but the Datastore is not (and PosixDatastore, at least, does not loop over them itself).</p><p>I think the right fix is to add a call to <tt>Datastore.ingest</tt> in <tt>Butler.put</tt> for each component.\\xc2\\xa0 That will cause <tt>PosixDatastore</tt> to look up the formatter for each component based on its StorageClass (which will generally not yield the right formatter, because it'll yield one appropriate for writing standalone objects of that type) and DatasetType (which could work, but only if we configure Formatters explicitly for every component of a composite DatasetType).\\xc2\\xa0 To fix that, I think we'll want want to also support Formatter lookup on strings that look like <tt>&lt;StorageClass&gt;.&lt;component&gt;</tt>.</p>\"\n",
            "nan\n",
            "<p>Trey, et. al.</p><p>Qualys reports that the SSL certificate for <a href=\"https://lsst-demo.ncsa.illinois.edu\" class=\"external-link\" rel=\"nofollow\">https://lsst-demo.ncsa.illinois.edu</a> expires on November 26th. Looks like this is a Let\\'s Encrypt cert so it should auto-renew, but we believe that should have already happened by now and it has not so probably a good idea to look into why it has not renewed yet.</p><p>This is the SSL certificate used by the <tt>proxy</tt> Docker container installed by SUI, and not something general to the server.</p><p>Similarly, the SSL certificate for <a href=\"https://lsst-demo2.ncsa.illinois.edu\" class=\"external-link\" rel=\"nofollow\">https://lsst-demo2.ncsa.illinois.edu</a> has already expired.</p>\n",
            "<p>Develop a ConOps document that can be included as appropriate sections of LDM-230 describing the Data Access Processing System that manages L3 computing in and interfaces to the Data Access Center, specifying automated operations sequences, how human intervention can occur, and processes to handle changes and updates.</p><p>(Story points are for KTL drafting and initial contributions)</p>\n",
            "<p>Develop a ConOps document that can be included as appropriate sections of LDM-230 describing the Data Backbone that contains, manages, and provides access to the Science Data Archive, specifying automated operations sequences, how human intervention can occur, and processes to handle changes and updates.</p><p>(Story points are for KTL drafting and initial contributions)</p>\n",
            "<p>Write sections that can be incorporated into LDM-148 describing the functional breakdown of the Observation Processing System, including, for each major element:</p><ul>\\t<li>overall function</li>\\t<li>inputs, outputs, and control interfaces</li>\\t<li>components used</li>\\t<li>descriptions of functions to be performed</li></ul><p>(Story points are for KTL drafting and initial contributions)</p>\n",
            "<p>Develop a ConOps document that can be included as appropriate sections of LDM-230 describing the batch processing environment, specifying automated operations sequences, how human intervention can occur, and processes to handle changes and updates.</p><p>(Story points are for KTL drafting and initial contributions)</p>\n",
            "<p>Define and publish\\xc2\\xa0interface to monitoring system for use by external applications</p>\n",
            "<p>Server side now handles the expressions and passes 14 significant digits, which the client can handle.</p><p>This ticket addresses the following issues:</p><ul class=\"alternate\" type=\"square\">\\t<li>Flexible histogram tooltip precision based on the bin width. You should not see bin ranges like \"0.000000 to 0.000000\" for when the boundaries are small numbers.</li>\\t<li>Histogram and heatmap now handle quoted column names and expressions. (Can be tested with NED.)</li>\\t<li>Histogram options will show range for quoted and unquoted columns.</li>\\t<li>Expressions for all charts are now handled by database. (There will be a separate ticket for cleanup.)</li></ul><p>Original description (Nov.16):</p><p>Histogram display is incorrect for large long values. There are several aspects contributing to this issue:</p><p>1. The data from the server should be passed at the full precision the client can handle.</p><p>To solve this issue, we can either set the format string or avoid formatting table data when passing them in JSON (which would be a separate ticket).</p><p>2. For large long numbers we are loosing precision twice:<br/>  First, when converting log to double on server side:<br/>    new Long(69327485392650247l)).doubleValue()<br/>    result: 6.9327485392650248E16<br/>  Second, in Javascript: <br/>    parseFloat(\"6.9327485392650248E16\")<br/>    result: 69327485392650250</p><p>To solve these issues, the server side code constructing bins should be using the same precision the client side can handle.</p>\n",
            "<p>After discussion among <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=xiuqin\" class=\"user-hover\" rel=\"xiuqin\">Xiuqin Wu</a>,\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=gpdf\" class=\"user-hover\" rel=\"gpdf\">Gregory Dubois-Felsmann</a> and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=roby\" class=\"user-hover\" rel=\"roby\">Trey Roby</a>. Here is the list of changes to be made regarding HiPS image zoom and HEALPix grid level control:</p><ol>\\t<li>When user click \"+\" icon to zoom in on a HiPS image, we should try to do our best to\\xc2\\xa0honor the depth of order of the original HiPS. For example HST-NICMOS has order of 16, current Firefly stops zooming in at order level 13.\\xc2\\xa0</li>\\t<li>Grid level: JavaScript integer support a large number. (Number.MAX_SAFE_INTEGER =\\xc2\\xa02^53^-1, or <tt>9,007,199,254,740,991</tt>). We should set the max grid level at 16 for now.\\xc2\\xa0</li>\\t<li>According to HiPS standard, the grid is HEALPix Grid. We should name it as such in the layer control dialog.\\xc2\\xa0</li></ol><p>Please reference IRSA tickets <a href=\"https://jira.ipac.caltech.edu/browse/IRSA-1657,\" class=\"external-link\" rel=\"nofollow\">https://jira.ipac.caltech.edu/browse/IRSA-1657,</a> <a href=\"https://jira.ipac.caltech.edu/browse/IRSA-1658\" class=\"external-link\" rel=\"nofollow\">https://jira.ipac.caltech.edu/browse/IRSA-1658</a>\\xc2\\xa0 for more background explanation</p>\n",
            "nan\n",
            "<p>Image qserv/qserv:dev image will be used for mariadb, so that depencies versions consistency will be ensured at build time.</p>\n",
            "nan\n",
            "<p>Deliver a 404 page via Fastly if the underlying object does not exist in the S3 bucket. This good UX, and also prevents S3\\'s error pages from being cached.</p><p>This tutorial provides a good start:\\xc2\\xa0<a href=\"https://docs.fastly.com/guides/basic-configuration/creating-error-pages-with-custom-responses.html\" class=\"external-link\" rel=\"nofollow\">https://docs.fastly.com/guides/basic-configuration/creating-error-pages-with-custom-responses.html</a></p>\n",
            "\"<p>Using the NumPy C API requires some ugly boilerplate in every wrapper file that uses the ndarray type_casters.  pybind11 provides its own low-level numpy interface, and it'd be better to use that instead.  I imagine this will uncover some functionality we'd want to add to upstream pybind11, but I imagine we'd at least have the option of doing that locally if that isn't a possibility.</p>\"\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_18. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Document the notional development workflow in the JupyterLab environment.</p>\n",
            "<p>Apply final polish and submit.</p>\n",
            "<p>We would like to allow arbitrary tags and a choice of container sizes.  See how feasible this is.</p>\n",
            "<p>Prepare slides on HSC PSF wavefront model to deliver at weekly DRP meeting.</p><p>\\xc2\\xa0</p>\n",
            "<p>This ticket applies to the usual Firefly image pixel coordinate readouts in the upper right of the display window, when the currently displayed image is a HiPS image map.</p><ol>\\t<li>Display as \"pixel size\" the \"tile pixel angular size\" from column 4 of the table in the screenshot linked to this ticket (which is also Figure 5, on page 11, of the HiPS standard), for the\\xc2\\xa0<em>currently displayed level</em>\\xc2\\xa0(\"order\") of the selected HiPS map.  This display, therefore, should change as the zoom level is changed.</li>\\t<li>By default, display galactic coordinates on the second line of the readout (instead of the usual default of image pixel coordinates).</li>\\t<li>Remove the option to display the \"image pixel\" coordinates (\"FITS Image Pixel\" in the selection dialog) for HiPS image.  (See <a href=\"https://jira.lsstcorp.org/browse/DM-13981\" title=\"Image pixel readout for HiPS images\" class=\"issue-link\" data-issue-key=\"DM-13981\">DM-13981</a> for a future ticket to restore this capability in an appropriate way.)</li></ol>\n",
            "nan\n",
            "<p>Until obscore/SIA_v2 is ready for use, imgserv is staying put to get the necessary metadata for images directly from the db. The work is done here to streamline that db access in imgserv today.\\xc2\\xa0\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>Was:</p><p>The scope of work for this feature is much larger than initial projection after investigation.\\xc2\\xa0 metaserv_v1 needs to add facility to convert query results into a JSON response.\\xc2\\xa0 imgserv_v1 will then need to convert the JSON response into a Python object suitable for input into afw functions for FITS metadata handling.</p><hr /><p>In dax_imgserv_v1, a module metaservGet is currently containing a SQL call to retrieve metadata for nearest image based on RaDec. This functionality should<br/> be provided by dax_metaserv API as a basic use case.</p><p>This ticket is for investigating the scope of this work.</p><p>------------------------------------------------------------------------------------------------------------------------</p>\n",
            "nan\n",
            "<p>To facilitate cleaning up the StarSelector API, we want to remove the <tt>makePsfCandidates</tt> step from <tt>starSelector.run()</tt>, and turn it into its own Task. As far as we can tell, only one existing Task (<tt>pipe_tasks.measurePsf</tt>) uses that feature of StarSelector, so this should be easy to manage.</p><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=swinbank\" class=\"user-hover\" rel=\"swinbank\">John Swinbank</a> suggested a future RFC for merging this: we\\'ll try a quick implementation first, and file a short RFC if it seems disruptive.</p>\n",
            "<p>Per discussion with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=fritzm\" class=\"user-hover\" rel=\"fritzm\">Fritz Mueller</a> yesterday, the following action items are needed in the short term meet dax\\'s CI needs:</p><ul>\\t<li>rename jenkins <tt>qserv/</tt> folders -&gt; <tt>dax/</tt></li>\\t<li>setup new dax equiv of <tt>stack-os-matrix</tt> that;<p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    - does not include osx</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    - does not include centos 6</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    - includes a clang/linux config</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/></li>\\t<li>new dax release pipeline that publishes eupspkg and moves only <tt>qserv-dev</tt><br/>  forward</li>\\t<li>stop applying <tt>w_201X_XX</tt> format tags to dax packages (unused) &#8211; this means splitting dax out of the nightly,weekly science-pipeline releases</li>\\t<li>stop updating <tt>qserv_latest</tt> tag (dead)</li>\\t<li>support TBD jenkins integration builds triggered by github push</li></ul>\n",
            "<p>We need to have a set of realistic footprint sizes to study how these may be affected by coadding.  This could include data from HSC or perhaps from simulations such as <a href=\"https://github.com/LSSTDESC/WeakLensingDeblending\" class=\"external-link\" rel=\"nofollow\">https://github.com/LSSTDESC/WeakLensingDeblending</a>.</p>\n",
            "<p>Make more reruns of COSMOS to different depths, one with 3 visits, one with 5 visits, one with 10 and one with 20. Some of the bands do not have 20 visits and will include the maximum number if it is less than the desired number.</p><p>\\xc2\\xa0</p>\n",
            "<p>In the spirit of disentangling computations from visualizations in the interactive QA framework of <tt>qa_explorer</tt>, write a task to compute columns of all quantities desired for <tt>pipe_analysis</tt>-style plots.\\xc2\\xa0 This should use the new object table parquet files (<tt>deepCoadd_obj</tt> dataset) generated by <tt>writeObjectTable.py</tt> to do computations on whole tracts of data at a time.  </p>\n",
            "<p>Create a short document or community post which outlines the steps necessary for using synpipe to add fake sources to to real data.</p>\n",
            "<p>PosixDatastore currently just holds its internal database in memory, rather than on-disk.</p><p>\\xc2\\xa0</p><p>My current idea for how to implement this is:</p><p>\\xc2\\xa0- Add an API for getting a SQLAlchemy engine from SqlRegistry.</p><p>\\xc2\\xa0- Add a\\xc2\\xa0\"datastore.db\" config entry that can take the same kinds of values as \"registry.db\", as well as a special value that tells it to get its database from the Registry.</p><p>\\xc2\\xa0- Make <tt>StoredFileInfo</tt> a subclass of something Datastore-generic or otherwise make sure it\\'s introspectable enough to map to a database without hard coding its fields in whatever is doing the mapping.</p><p>\\xc2\\xa0- Make a really simple ABC that just knows how to dump and retrieve generalized\\xc2\\xa0<tt>StoredFileInfo</tt>\\xc2\\xa0from\\xc2\\xa0some kind of database, with subclasses\\xc2\\xa0instantiated based on the value of \"datastore.db\".</p><p>\\xc2\\xa0- Implement a SQL-based\\xc2\\xa0subclass of that ABC.</p><p>\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_17. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Change usage.py so that the user can configure which slurm job names correspond to which code (ie, allow the user to specify that all jobs starting with \"p1-mo\", \"p2-mo\", \"p5-mo\" correspond to jobs that were run with mosaic.py instead of the accepted job names being hard-coded). Push the modified code to github.\\xc2\\xa0</p>\n",
            "<p>Do a column wise comparison of test catalogues to assess effects of quantisastion.</p>\n",
            "<p>An outcome of the 2018 JTM hack day on documentation (<a href=\"https://community.lsst.org/t/package-documentation-hack-session-at-jtm-2018/2760?u=jsick\" class=\"external-link\" rel=\"nofollow\">https://community.lsst.org/t/package-documentation-hack-session-at-jtm-2018/2760?u=jsick</a>) was the need for tooling to clean up documentation build artifacts. The current builds (for both single packages and multiple packages) leave behind multiple directories and need to be cleaned up to reset the build state.</p><p>This provides an opportunity to actually design a unified command line interface for building our stack documentation. In this ticket, I propose that we create two command line apps from the <a href=\"https://github.com/lsst-sqre/documenteer\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/documenteer</a> package.</p><p>One for the stack:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">stack-docs build</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">stack-docs clean</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>And for single-package builds:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">package-docs build</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">package-docs clean</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>There could even be use for other subcommands, like link check, lint, prepare release notes, and so on.</p><p>This command line app will be created with <a href=\"http://click.pocoo.org/6\" class=\"external-link\" rel=\"nofollow\">Click</a>.</p>\n",
            "<p>Overall we want to deprecate the use of LTD Mason since we\\'re no longer using LTD Mason to build packages. LTD Conveyor is a centralized library for S3/LTD Keeper clients, and I\\'ve used it to build clients into LTD Dasher and Lander projects. However, we still need a generic CLI build uploader to use in CI for general documentation builds. This would specifically replace the ltd-mason-travis CLI.</p><p>The goals are:</p><ul class=\"alternate\" type=\"square\">\\t<li>Have CLI arguments that are easy to use for ad hoc builds.</li>\\t<li>Also have an <tt>--env=travis</tt> argument to make Travis-based builds easy (taking advantage of travis environment variables).</li></ul>\n",
            "<p>Modernize the packaging of <a href=\"https://github.com/lsst-sqre/ltd-conveyor\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/ltd-conveyor</a> in prep for the new CLI in <a href=\"https://jira.lsstcorp.org/browse/DM-11638\" title=\"Create a general LSST the Docs build upload CLI in LTD Conveyor\" class=\"issue-link\" data-issue-key=\"DM-11638\"><del>DM-11638</del></a>:</p><ul class=\"alternate\" type=\"square\">\\t<li><tt>setuptools_scm</tt> support</li>\\t<li>Add a change log</li>\\t<li>robust PyPI deploy from Travis</li>\\t<li>pytest usage modernization</li>\\t<li>Remove Python 2.7 support (remove future)</li>\\t<li>Update Sphinx pipeline.</li></ul>\n",
            "<p>Implement a version of the progressive ACK timer that checks strictly for the one ATS forwarder response; these must be blocking ACKs, so proper ACKs should be identified quickly if received.</p>\n",
            "<p>Implement new starSelector baseClass</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "\"<p>Make it possible to run a <tt>CmdLineTask</tt>\\xc2\\xa0against a Gen3 Butler repository via a options in <tt>pipe.base.ArgumentParser/CmdLineTask.parseAndRun.</tt></p><p>Code may or may not be merged to master; if it does, it'll be via an <b>optional</b> dependency on daf_butler.</p><p>For now, we will expect all data IDs to be passed explicitly; there will be no expansion or wildcard support.</p>\"\n",
            "<p>Translate the setup scripts to terraform config files for the OpenStack setup</p>\n",
            "<p>The python api needs to support HiPS like the JavaScript API</p>\n",
            "<p>Discuss requirements for reformatted EFD schema with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ktl\" class=\"user-hover\" rel=\"ktl\">Kian-Tat Lim</a>.</p>\n",
            "<p>Make optional plots of things that are done along the way:</p><ul>\\t<li>PTC curve and its fit</li>\\t<li>Write out the diff images and ISR images as an option</li>\\t<li>Add afwDisplay debug options<br/> Maybe also add warnings here for things that might be out of range</li></ul>\n",
            "nan\n",
            "<p>Overlapping bad amps eat up the temporalThreshold budget.\\xc2\\xa0</p><p>For example if a local region has 10 visits, and 3 of those visits are not included because of bad amps, then no candidates are clipped.\\xc2\\xa0\\xc2\\xa0<br/>CLIPPED mask for <tt>/datasets/hsc/repo/rerun/private/yusra/RC/<a href=\"https://jira.lsstcorp.org/browse/DM-13553\" title=\"Deal with large blends\" class=\"issue-link\" data-issue-key=\"DM-13553\"><del>DM-13553</del></a>+DM-134110</tt>: 9813, HSC-Z<br/> <span class=\"image-wrap\" style=\"\"><a id=\"32139_thumb\" href=\"https://jira.lsstcorp.org/secure/attachment/32139/32139_mask_DM-13553%2BDM-134110_9813HSC-Z.png\" title=\"mask_DM-13553+DM-134110_9813HSC-Z.png\" file-preview-type=\"image\" file-preview-id=\"32139\" file-preview-title=\"mask_DM-13553+DM-134110_9813HSC-Z.png\"><img src=\"https://jira.lsstcorp.org/secure/thumbnail/32139/_thumb_32139.png\" style=\"border: 0px solid black\" /></a></span> </p><p>Seen since\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-12692\" title=\"Improve  temporal threshold for CompareWarp\" class=\"issue-link\" data-issue-key=\"DM-12692\"><del>DM-12692</del></a>: Bad amps can be seen in this epochCountImage: <br/> <span class=\"image-wrap\" style=\"\"><a id=\"32138_thumb\" href=\"https://jira.lsstcorp.org/secure/attachment/32138/32138_Screen+Shot+2018-01-25+at+12.20.55+PM.png\" title=\"Screen Shot 2018-01-25 at 12.20.55 PM.png\" file-preview-type=\"image\" file-preview-id=\"32138\" file-preview-title=\"Screen Shot 2018-01-25 at 12.20.55 PM.png\"><img src=\"https://jira.lsstcorp.org/secure/thumbnail/32138/_thumb_32138.png\" style=\"border: 0px solid black\" /></a></span> </p><p>If any detections the warpDiffs are entirely covered with the badPixelMask, then don\\'t contribute to the rolling epochCountImage or clip. </p>\n",
            "\"<p>This is currently the repo scanner, the prepuller components that use the repo scanner, and whatever client libraries we find convenient (e.g. a bokeh display widget wrapper method).\\xc2\\xa0 It's much more convenient for them to be an installable library than to have to scatter them around various Docker build directories.</p>\"\n",
            "<p>Felipe attends the Telescope &amp; Site Subsystem Meeting in Tucson.</p><p><a href=\"https://project.lsst.org/meetings/mini-jtm2018/ts\" class=\"external-link\" rel=\"nofollow\">https://project.lsst.org/meetings/mini-jtm2018/ts</a></p>\n",
            "<p>Once the Flask based API is deployed and jointcal data is flowing to SQuaSH we can finally enable jointcal visualization in the SQuaSH Monitor app.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_14. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>After <a href=\"https://jira.lsstcorp.org/browse/DM-9584\" title=\"Profile and optimize NMF deblender code\" class=\"issue-link\" data-issue-key=\"DM-9584\"><del>DM-9584</del></a>, the current bottleneck in the deblender is the translation and PSF operators, where (when PSF convolution is used) nearly all of the processing time is spent in a single function:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">def</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> apply_filter(X, weights, slices, inv_slices):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"\"\"Apply a filter to a 2D image X</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    Parameters</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    ----------</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    X: 2D numpy array</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        The image to apply the filter to</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    weights: 1D array</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        Weights corresponding to each slice in `slices`</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    slices: list of `slice` objects</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        Slices in the new `X` to store the filtered X</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    inv_slices: list of `slice` objects</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        Slices of `X` to apply each weight</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    Returns</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    -------</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    new_X: 2D numpy array</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        The result of applying the filter to `X`</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    \"\"\"</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    result </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> np.zeros(X.shape, dtype</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">X.dtype)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> n, weight </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">in</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">enumerate</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">(weights):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        result[slices[n]] </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">+</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> weight </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">*</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> X[inv_slices[n]]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> result</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Moving this to C++ and using the Eigen package is likely to improve the performance, and is the last tall pole remaining in optimizing the deblender. After this any performance increases will have to come from more clever implementations of certain algorithms and small optimizations throughout the code.</p>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/DM-10086\" title=\"Replace existing usage of XYTransform with the AST backed version\" class=\"issue-link\" data-issue-key=\"DM-10086\"><del>DM-10086</del></a>, we should replace all uses of <tt>XYTransform</tt> with the new AST-backed (<a href=\"https://jira.lsstcorp.org/browse/DM-6164\" title=\"Implement the API replacing XYTransform\" class=\"issue-link\" data-issue-key=\"DM-6164\"><del>DM-6164</del></a>) version. However, we don\\'t have a good list of what work needs doing or how much effort is involved. Audit the stack, uncover uses of old-school <tt>XYTransform</tt>, and file tickets to have them all replaced.</p>\n",
            "\"<p>Running <tt>ap_verify</tt> on a dataset of any reasonable size requires parallelization on the verification cluster via SLURM.  We also may wish <tt>ap_pipe</tt> to support <tt>-j</tt> parallization in the future.  However, the existing code writes all metrics to the same filename before moving them away, so parallel runs clobber each others' metrics.</p><p>This ticket is to implement an alternate scheme for persisting metrics that is threadsafe.</p>\"\n",
            "<p>Prepare &amp; install Header Service for Integration Activity.</p>\n",
            "<p>When Stack v14.0 is available in the shared stack in <tt>/software</tt>, reprocess the HSC RC dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack v14.0.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>,, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p>\n",
            "<p>cloudmanager.py must use the openstack python client shade, instead of low-level python clients (nova, cinder, ...)</p>\n",
            "<p>Remove the HiPS grid\\xc2\\xa0icon from the toolbar.\\xc2\\xa0 Then when a HiPS is added always add the HiPS grid layer with the checkbox turned off so that it is hidden by default.\\xc2\\xa0 This way a user has access to it without it being on the toolbar.</p><p>Add support for calling the IRSA hipslist.</p><p>this involves:<br/>\\xc2\\xa0 \\xc2\\xa0- app.config &amp; app.prop<br/>\\xc2\\xa0 \\xc2\\xa0- uniq creator_did<br/>\\xc2\\xa0 \\xc2\\xa0- if title is blank use creator_did, last parts<br/>\\xc2\\xa0 \\xc2\\xa0- irsa.hips.method and irsa.hips.url</p><p>\\xc2\\xa0</p><p>See also:</p><p><a href=\"https://caltech-ipac.atlassian.net/browse/IRSA-1556#add-comment\" class=\"external-link\" rel=\"nofollow\">https://caltech-ipac.atlassian.net/browse/IRSA-1556#add-comment</a></p>\n",
            "<p>Jim attends the Telescope &amp; Site Subsystem Meeting in Tucson.</p><p><a href=\"https://project.lsst.org/meetings/mini-jtm2018/ts\" class=\"external-link\" rel=\"nofollow\">https://project.lsst.org/meetings/mini-jtm2018/ts</a></p>\n",
            "<p>Attends the EPO all hands, participate in and contribute to the discussion of Science platform, Jupyter NB/lab, and visualization.\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>At the top left corner of HiPS images, we display the HiPS name. Currently the property label is used for this. Since label is no longer in the HiPS standard v1, we should not rely on it. The decision process should be:</p><ol>\\t<li>user obs_title</li>\\t<li>use label if obs_title not available. (only possible with older HiPS images since obs_title is required keyword)</li></ol><p>Test case: HST-I image (<a href=\"http://alasky.u-strasbg.fr/HST-hips/filter_I_hips/\" class=\"external-link\" rel=\"nofollow\">http://alasky.u-strasbg.fr/HST-hips/filter_I_hips/</a>)</p><p>the obs_title is \"HLA-I : F814W, F791W, F785LP and F775W\", label is only \"I\"</p><p>We may need to have a limit in the title length here. (This is already in place currently, limited by the space available)</p><p>\\xc2\\xa0</p><p><b>Improvement on using the initial value hips_initial_fov:</b></p><blockquote><p>if (<tt>hips_initial_fov</tt>\\xc2\\xa0&lt;1.0/3600) set the FOV to 180 degree;</p><p>else if (<tt>hips_initial_fov</tt>\\xc2\\xa0&lt;9.0/3600) set the FOV to 9.0/3600 degree</p><p>else set the FOV to\\xc2\\xa0hips_initial_fov</p></blockquote><p>More details in\\xc2\\xa0 <a href=\"https://jira.ipac.caltech.edu/browse/IRSA-1664\" class=\"external-link\" rel=\"nofollow\">https://jira.ipac.caltech.edu/browse/IRSA-1664</a></p><p><b>Improvement on using the initial values\\xc2\\xa0hips_initial_ra,</b> <b>hips_initial_dec:</b>**</p><blockquote><p>after user input a position at the image search panel, then clear it to empty, the HiPS display still uses it as the center position.</p><p>it should use the initial ra and dec if supplied by the HiPS image.\\xc2\\xa0</p></blockquote><p><b>IVO Reference:</b></p><p>Allow the API user to give a IVO reference to the HiPS data instead of a URL. Resolve it to a URL</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "<p>Contribute content to DM\\xe2\\x80\\x99s process paper for SPIE 2018. Repo is <a href=\"https://github.com/lsst-dm/spie-2018-dm-practices\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-dm/spie-2018-dm-practices</a></p><p>Expected content includes:</p><ul class=\"alternate\" type=\"square\">\\t<li>DM documentation (what we document)</li>\\t<li>Documentation engineering (systems for creating and publishing documentation)</li>\\t<li>community.lsst.org</li></ul>\n",
            "<p>Create a CLI for <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/templates</a>. This CLI should provide an interface for discovering templates, and then rendering templates. (We can\\xe2\\x80\\x99t reasonably use Cookiecutter alone because the Cookiecutter CLI doesn\\xe2\\x80\\x99t understand our single-file Jinja2 templates).</p><p>The CLI will be created with the <a href=\"http://click.pocoo.org/\" class=\"external-link\" rel=\"nofollow\">Click library</a>.</p>\n",
            "<p>Convert ap_association to new LSST DM documentation formats, including clearing up numpydoc style docstrings.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_12. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>The monitor app tells a concise story: the impact of code changes on KPMs. My the attempt to expand it to display multiple metrics at once id not work. It does not scale well with the number of metrics (both re loading time and space in the screen). A dashboard-like interface with summary information for the KPMs is be better suited for that.</p><p>In this ticket I simplified the monitor implementation and put back the code changes feature.</p>\n",
            "nan\n",
            "<p>Refine thesholds on monitoring parameters to reduce false positives and catch missed events on systems that cause service issues.</p>\n",
            "<p>After updating and changing the chart framework in PR <a href=\"https://github.com/Caltech-IPAC/firefly/pull/568\" class=\"external-link\" rel=\"nofollow\">https://github.com/Caltech-IPAC/firefly/pull/568</a>\\xc2\\xa0the API and in particular the function call addXYplot used in Gator need to be updated. The chart now resulting in calling this function doesn\\'t show\\xc2\\xa0the latest changes with single trace UI discussed\\xc2\\xa0in IRSA-1522.</p><p>IRSA/Gator\\xc2\\xa0html code shouldn\\'t change. Instead, the exposed API should be updated\\xc2\\xa0to use the\\xc2\\xa0latest API underneath and\\xc2\\xa0return a similar\\xc2\\xa0chart object as the one displayed in other apps such as FinderChart and IRSAViewer/Time Series tool.\\xc2\\xa0</p>\n",
            "<p>Prepare L1 Integration system for Integration Activity. Make sure accounts, software, networking, etc. are set up to prepare for the on-site activity.</p>\n",
            "<p>The DCR correction code needs to know the range of wavelengths permitted through a filter, not just the effective wavelength of the full band. I will add additional properties to `Filter` and define those properties for `obs_lsstSim` and `obs_decam`. Other packages should continue working as normal without being modified.</p>\n",
            "<p>Add algorithms to compute the <b>Jacobian</b> correction for each object (calculable from the Wcs, but sometimes convenient)  and record the <b>focal plane</b> coordinates (instead of CCD coordinates) for sources (useful for plotting).</p><p>The standalone HSC commits to be cherry-picked are:</p><p><b>Jacobian</b><br/><tt>meas_algorithms</tt><br/>May 3, 2013<br/><a href=\"https://github.com/HyperSuprime-Cam/meas_algorithms/commit/88d3bd3f32cf4d0138b80148e57bc275fc8c3454\" class=\"external-link\" rel=\"nofollow\">Jacobian: add Algorithm to compute the Jacobian.</a><br/>May 24, 2013<br/><a href=\"https://github.com/HyperSuprime-Cam/meas_algorithms/commit/ecad0d2559bb9815fc5560234f4502f35f50db73\" class=\"external-link\" rel=\"nofollow\">Jacobian: fix up some cut/paste oversights.</a><br/>May 28, 2013<br/><a href=\"https://github.com/HyperSuprime-Cam/meas_algorithms/commit/7f3db53b56279929b9e416173ed09cf00dc81406\" class=\"external-link\" rel=\"nofollow\">Jacobian: fix calculation</a></p><p><tt>obs_subaru</tt><br/>May 3, 2013<br/><a href=\"https://github.com/HyperSuprime-Cam/obs_subaru/commit/d0969911ee1a655fd82998f0b936fa90f443d2fd\" class=\"external-link\" rel=\"nofollow\">config: enable jacobian calculation in processCcd</a><br/>May 6, 2013<br/><a href=\"https://github.com/HyperSuprime-Cam/obs_subaru/commit/e36bd1b4410812ca314f50c01f899d92acc0e7a5\" class=\"external-link\" rel=\"nofollow\">config: set pixelScale for jacobian correction</a></p><p><b>focalplane</b><br/><tt>meas_algorithms</tt><br/>May 24, 2013<br/><a href=\"https://github.com/HyperSuprime-Cam/meas_algorithms/commit/dda3086f411d647e1a3e15451d7f093cd461873a\" class=\"external-link\" rel=\"nofollow\">add algorithm to calculate position on the focal plane</a><br/>May 25, 2013<br/><a href=\"https://github.com/HyperSuprime-Cam/meas_algorithms/commit/57d718bf51b255adf5789e389dfb776ecaa062d1\" class=\"external-link\" rel=\"nofollow\">fix up building of focalplane algorithm</a><br/>Nov 21, 2014<br/><a href=\"https://github.com/HyperSuprime-Cam/meas_algorithms/commit/95627d55cb7d64718a42027954474df5c3661a65\" class=\"external-link\" rel=\"nofollow\">Adapt to removal of Point&lt;float&gt; from afw::table.</a></p><p><tt>obs_subaru</tt><br/>May 24, 2013<br/><a href=\"https://github.com/HyperSuprime-Cam/obs_subaru/commit/d999a32e7e10b25cceccc94b61890486f96c0bfd\" class=\"external-link\" rel=\"nofollow\">config: activate focalplane algorithm</a></p>\n",
            "<p>When using images not convolved with the PSF, we\\'ve long known that \"snowflakes\" or spiky fractal-like structures are created due to the monotonicity operator. It is likely that a smoothness operator, which is used in compressive sensing applications, will be able to fix (or at least suppress) this problem.</p>\n",
            "\"<p>astshim currently follows AST's handling of the <tt>Id</tt> attribute: an arbitrary string that is not copied when the object is deep-copied. However astshim almost always makes deep copies, where AST does not. In particular, when adding a <tt>Mapping</tt> to a <tt>FrameSet</tt> AST will use a shallow copy (preserving <tt>Id</tt>) but astshim will make a deep copy (nulling <tt>Id</tt>), and indeed it is probably impossible to set the <tt>Id</tt> of a <tt>Mapping</tt> in a <tt>FrameSet</tt>.</p><p>I suggest we break AST's rule and copy <tt>Id</tt> when making a deep copy. One could imagine providing a flag, but I think it is simpler not to do so. The user can manually set or clear <tt>Id</tt> in the copy if necessary.</p>\"\n",
            "<p>Write up technical notes on current status and findings related to consolidated systems management.</p>\n",
            "<p>Write up the findings of\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-12426\" title=\"Catagorize the ways in which shape determination fails\" class=\"issue-link\" data-issue-key=\"DM-12426\"><del>DM-12426</del></a>\\xc2\\xa0into a short document with examples.</p>\n",
            "\"<p>Do following:</p><ul>\\t<li>for webpack/babel to use env for pollyfills</li>\\t<li>add webpack-visualizer-plugin:\\xc2\\xa0Visualize and analyze\\xc2\\xa0the Webpack bundle to see which modules are taking up space and which might be duplicates.</li>\\t<li>experiment with using\\xc2\\xa0babel-plugin-lodash to treeshake lodash (<em>experiment failed, we can't use it</em>)</li>\\t<li>remove fftools (we not longer us it)</li></ul><p>\\xc2\\xa0</p>\"\n",
            "\"<p>Prepare slides describing LSST's astrometric calibration and measurements for the Project Science Team / Science Collaboration Chair series talk on March 27.</p>\"\n",
            "<p>Now that the <a href=\"https://squash-restful-api-demo.lsst.codes/\" class=\"external-link\" rel=\"nofollow\">new API is alive</a>\\xc2\\xa0we need the <tt>code_changes</tt> resources that are consumed by the SQuaSH monitor apps</p><p>NOTE: the performance on retrieving the data from the new implementation will be evaluate only after <a href=\"https://jira.lsstcorp.org/browse/DM-12604\" title=\"Migrate SQuaSH data from the current production database to the new database schema\" class=\"issue-link\" data-issue-key=\"DM-12604\"><del>DM-12604</del></a> is done</p>\n",
            "<p>Contribute to the  \"development model\" section of the SPIE 2018 paper, as discussed on <tt>#dm-spie-2018-process</tt>.</p>\n",
            "\"<p>Building on <tt>validate_drp/reportPerformance.py</tt>, we need some code to take the JSON output of validate_drp on all of the tracts+filter combinations and produce some kind of summary table to compare the 115 tract+filter combinations across the three runs (singleFrame/jointcal/meas_mosaic) in photometry and astrometry. There's already some pretty-printing code in validate_drp that we can probably steal.</p>\"\n",
            "<p>These are things such as md5sum, object-size, etc. Would be nice if it could be generic. I could imagine something generic like <tt>Datastore.getInfo(uri) -&gt; BlobInfo</tt>, or something more specific such as <tt>Datastore.getSize(uri) -&gt; int</tt>.</p><p>Where should they live? Perhaps in SQL table for <tt>Datastore</tt> configuration. Possibly living in the same database as <tt>Registry</tt>? Or in some (YAML) config file.</p>\n",
            "<p>ipyAladin because EPO uses it, RISE for writing my JupyterCon presentation.</p>\n",
            "<p>Add summary and conclusions regarding suitability of Kafka to alert distribution system needs to DMTN-028.</p>\n",
            "<p>After some work (particularly <a href=\"https://jira.lsstcorp.org/browse/DM-8441\" title=\"Update DM Developer Onboarding Checklist\" class=\"issue-link\" data-issue-key=\"DM-8441\"><del>DM-8441</del></a> from SQuaRE and the DM Admin, and commit <a href=\"https://github.com/lsst-dm/dm_dev_guide/commit/e4de50d85cf7bd355aaf2646cfc646f491dd968b\" class=\"external-link\" rel=\"nofollow\">e4de50d</a> from NCSA), it seems that we aren\\'t converging as a project on what happens in onboarding. I think the root of the issue is that there hasn\\'t been sufficient communication between the key stakeholders. The purpose of this ticket is to:</p><ol>\\t<li>Host an initial discussion between all the stakeholders in the implementation of DM onboarding, namely T/CAMs, the DM admin, Project IT, and NCSA. The aim of this discussion is to eliminate all ambiguities in the expectations and responsibilities of each stakeholder in the onboarding process. I\\'m explicitly diverting this discussion from email because I think we need a permanent and citable record to sustain a multilateral understanding.</li>\\t<li>Capture that discussion in a final resolution to the (new hire-oriented) <a href=\"https://developer.lsst.io/getting-started/onboarding.html#\" class=\"external-link\" rel=\"nofollow\">onboarding process described in the Developer Guide</a>.</li>\\t<li>Serve as a reference for other JIRA tickets that implement work beyond new hire-oriented documentation.</li></ol><hr /><p>To start the discussion, here are issues with onboarding that I\\'ve observed from recent changes to the DM onboarding page, and in other discussions.</p><h3><a name=\"NCSAaccounts%28lsstdev%2Clsstdb%2CNebula%29.\"></a>NCSA accounts (lsst-dev, lsst-db, Nebula).</h3><p>My understanding while researching <a href=\"https://jira.lsstcorp.org/browse/DM-8441\" title=\"Update DM Developer Onboarding Checklist\" class=\"issue-link\" data-issue-key=\"DM-8441\"><del>DM-8441</del></a> was that the <a href=\"https://project.lsst.org/onboarding/form\" class=\"external-link\" rel=\"nofollow\">Project onboarding form</a> triggered coordination between Project IT and NCSA to automatically provision a lsst-dev account for DM hires (and that this was a new process).</p><p>The <a href=\"https://confluence.lsstcorp.org/display/IT/Account+Management\" class=\"external-link\" rel=\"nofollow\">Project IT account management page</a> confirms this in the documented process for giving a hire LSST credentials after the onboarding form is submitted:</p><blockquote><p>DM Users: In the email supplying their new user with credentials, direct them to The Team and add to dm-staff@lists.lsst.org (hidden list). Also notify lsst-account@ncsa.illinois.edu of DM hires. Point new user to <a href=\"https://lsstc.slack.com/\" class=\"external-link\" rel=\"nofollow\">https://lsstc.slack.com/</a> for Slack account.</p></blockquote><p>Commit  <a href=\"https://github.com/lsst-dm/dm_dev_guide/commit/e4de50d85cf7bd355aaf2646cfc646f491dd968b\" class=\"external-link\" rel=\"nofollow\">e4de50d</a>), from the NCSA perspective, contradicts this, effectively re-asserting that it is the <b>responsibility of the new hire</b> to email lsst-account@ncsa asking for credentials.</p><p>What is the actual process here?</p><p>If the Project IT instructions are correct, then we shouldn\\'t keep the NCSA version of the new hire instructions that now cause both the new hire and project IT to duplicate effort in getting NCSA credentials.</p><p>If the point of mentioning the lsst-account@ncsa email for obtaining credentials on the onboarding page is to help existing staff who do not yet have NCSA accounts, I think it\\'d be good to have:</p><ul class=\"alternate\" type=\"square\">\\t<li>A sentence at the top of the Developing Infrastructure pages giving this email address where they can obtain credentials and other assistance. Or,</li>\\t<li>Change the language in <a href=\"https://developer.lsst.io/getting-started/onboarding.html#ncsa-resources\" class=\"external-link\" rel=\"nofollow\">the section on NCSA infrastructure in the Developer Guide</a> to say that credentials are being created for you; but that you can email that address if there are problems.</li></ul><h3><a name=\"CoordinationbetweenLSSTITandNCSAonusernames\"></a>Coordination between LSST IT and NCSA on usernames</h3><p>It seems that there\\'s disagreement as to whether this process actually exists. I think this further suggests that we\\'d benefit from a better documented internal workflow between Project onboarding and NCSA onboarding.</p><h3><a name=\"DocuShareaccountcreation\"></a>DocuShare account creation</h3><p>It seems that DocuShare accounts are not automatically given to LSST DM staff. If this is the case, then we should change the <a href=\"https://developer.lsst.io/getting-started/onboarding.html#lsst-account\" class=\"external-link\" rel=\"nofollow\">LSST Account</a> section to break out DocuShare from the list of core Project platforms, stating that you\\'ll get an account if applicable. Possibly this should be a call that the T/CAM makes while going through <a href=\"https://developer.lsst.io/getting-started/onboarding.html#checklist-for-t-cams\" class=\"external-link\" rel=\"nofollow\">their checklist</a>. Better yet, there could be a checkbox on the Project on-boarding form that indicate whether the hire needs a DocuShare account or not.</p><h3><a name=\"DMcalendars\"></a>DM calendars</h3><p>The current instructions for new hires say:</p><blockquote><p>send your Google username to #dm-admin-support to access DM calendars.</p></blockquote><p>I think a better instruction is to point them to <a href=\"https://project.lsst.org/content/dm-team-calendar\" class=\"external-link\" rel=\"nofollow\">https://project.lsst.org/content/dm-team-calendar</a> and indicate that they can add the DM calendar from there to their own Google calendar.</p><hr /><p>Overall, I would advocate that the internal onboarding workflows reduce the burden on the new hire, and be more rigorously triggered by the submission of the Project onboarding form. Not only can NCSA onboarding be streamlined, but we should also have a process where submission of the onboarding form triggers a Slack invite.</p><hr /><p>There is also the issue of catching up new hires that haven\\'t been properly onboarded. (Don\\'t have an lsst-db credential, for example). My recommendation is each account provider should compare their account list to the DM staff roster and initiate the account creation process for staff that are lacking an account. I think an active approach to correcting onboarding issues is better than a passive one.</p>\n",
            "<p>Jenkins jobs that use docker are frequently hanging and <tt>dockerd</tt> / <tt>xfs</tt> errors are appearing in the <tt>dmesg</tt>:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.166094</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">] INFO: task dockerd:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">902</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> blocked </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> more than </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">120</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> seconds.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.169742</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">] </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> disables </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">this</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> message.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.173508</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">] dockerd         D ffff8800a188e010     </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">   </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">902</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">      </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x00000080</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.176932</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  ffff880033883d78 </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0000000000000086</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ffff8803bb2e8fd0 ffff880033883fd8</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.180601</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  ffff880033883fd8 ffff880033883fd8 ffff8803bb2e8fd0 ffff8800a188e000</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.184682</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  ffff8800a188e040 ffff88036f27c140 ffff8800a188e068 ffff8800a188e010</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.188403</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">] Call Trace:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.190270</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff816a94e9&gt;] schedule+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x29</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x70</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.193155</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffffc01732ea&gt;] xfs_ail_push_all_sync+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0xba</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x110</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> [xfs]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.196618</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff810b1910&gt;] ? wake_up_atomic_t+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x30</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x30</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.199554</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffffc015c2e1&gt;] xfs_unmountfs+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x71</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x1c0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> [xfs]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.202526</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffffc015cded&gt;] ? xfs_mru_cache_destroy+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x6d</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0xa0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> [xfs]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.205747</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffffc015ee92&gt;] xfs_fs_put_super+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x32</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x90</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> [xfs]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.209261</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff81203722&gt;] generic_shutdown_super+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x72</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x100</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.212640</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff81203b67&gt;] kill_block_super+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x27</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x70</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.215738</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff81203ea9&gt;] deactivate_locked_super+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x49</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x60</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.218801</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff81204616&gt;] deactivate_super+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x46</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x60</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.221628</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff8122184f&gt;] cleanup_mnt+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x3f</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x80</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.224301</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff812218e2&gt;] __cleanup_mnt+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x12</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x20</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.227135</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff810ad247&gt;] task_work_run+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0xa7</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0xf0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.230449</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff8102ab62&gt;] do_notify_resume+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x92</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0xb0</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">279961.233768</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]  [&lt;ffffffff816b52bd&gt;] int_signal+</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x12</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0x17</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>These problems seem to go away, at least for awhile, after the node is restarted (they will not soft reboot).  It isn\\'t yet known if this is a kernel bug or some of random EBS I/O timeouts.  As it seems to be only <img class=\"emoticon\" src=\"https://jira.lsstcorp.org/images/icons/emoticons/help_16.png\" height=\"16\" width=\"16\" align=\"absmiddle\" alt=\"\" border=\"0\"/> triggered by dockerd, it seems much more likely to be a kernel issue.  What is unusual is that this doesn\\'t seem to have been an issue until ~ a week ago and this doesn\\'t correlate with a kernel or dockerd version change.</p>\n",
            "<p>Set up a Kafka MirrorMaker service that is capable of making a copy of\\xc2\\xa0all or a subset of data and topics in another Kafka cluster.\\xc2\\xa0 This is useful for\\xc2\\xa0copying a\\xc2\\xa0Kafka service to external downstream brokers and potentially for our mini-broker if we have multiple Kafka clusters.</p>\n",
            "<p>The classifier is occasionally failing on bright objects where it should have the best inputs, look into what these objects are and how to mitigate this.<br/>This has been extended into looking into all failures more.</p>\n",
            "<p>In order to restrict the jenkins aws credentials to only being able to create new snaphots, a mechanism is needed to handle purging old snapshots that is external to jenkins.</p>\n",
            "<p>Support quoted non alpha-numeric column names in column expressions.</p><p>Currently, we only support column expressions for the columns that contain letters, digits, and underscore. </p><p>NED tables contain column names that are not alpha-numeric (\"RA(deg)\", \"Redshift Points\"). Expressions will fail on these columns. </p><p>Since we have no control on how columns are named in non IPACTable tables, we should be able to support any kind of column name or produce a warning if we can not support it.</p>\n",
            "<p>Document the flowdown of Level 3-related requirements from SRD, LSR, OSS, and DMSR.</p>\n",
            "\"<p>sqrbot has been disabled for excessive login attempts.</p><p>Working with GH support to determine where it's spamming so we can fix it.</p>\"\n",
            "nan\n",
            "<p>Implement a <tt>MultiBandCatalog</tt> in qa_explorer, in order to enable color-color plotting and exploration.  It should take a dictionary of coadd catalogs, keyed by filter name, and a <tt>QADataset</tt> initialized with such a catalog should calculate colors, and be able to plot color-color plots.</p>\n",
            "<p>To lower the barrier to getting started with interactive QA notebooks, make a script that automatically generates useful template notebooks.</p>\n",
            "<p>Currently, <tt>ap_pipe</tt> assumes that each dataId passed to it contains exactly one visit (e.g., in <tt>doProcessCcd</tt>). <tt>ap_pipe</tt> should be extended to support ranges and other combinations of visits.</p><p>This ticket may be partially or entirely superseded by <a href=\"https://jira.lsstcorp.org/browse/DM-11372\" title=\"Create CommandLineTask utility in `ap_pipe`\" class=\"issue-link\" data-issue-key=\"DM-11372\"><del>DM-11372</del></a>.</p>\n",
            "<p>The buildbot scripts have an explicit dependency on the <tt>datarel</tt> package, which we\\'d like to remove from the stack.  It uses <tt>datarel</tt> as the top-level product when building the cross-linked HTML documentation; <tt>lsstDoxygen</tt>\\'s <tt>makeDocs</tt> script takes a single package, and generates the list of packages to include in the Doxygen build by finding all dependencies of that package.</p><p>So, to remove the explicit dependency on <tt>datarel</tt>, we need to either:</p><ul class=\"alternate\" type=\"square\">\\t<li>find a new top-level product with a Doxygen build to pass to <tt>makeDocs</tt> (e.g. by adding a trivial Doxygen build to <tt>lsst_distrib</tt>)</li>\\t<li>modify the argument parsing in <tt>lsstDoxygen</tt> to take a list of multiple products (it <b>looks</b> like the limitation to one package is only in the argument parsing), and pass it a list of top-level products in the buildbot scripts.</li></ul><p>This is currently a blocker for <a href=\"https://jira.lsstcorp.org/browse/DM-2928\" title=\"move old ingest scripts into and retire old packages\" class=\"issue-link\" data-issue-key=\"DM-2928\"><del>DM-2928</del></a>, which itself a blocker for <a href=\"https://jira.lsstcorp.org/browse/DM-1766\" title=\"Remove in-memory support of old-version afw::table objects\" class=\"issue-link\" data-issue-key=\"DM-1766\"><del>DM-1766</del></a>, which has now been lingering for a few weeks now.  I\\'m going to look for other ways to remove the block on the latter, but I don\\'t have a solution yet.</p>\n",
            "<p>The current documentation for <tt>ap_verify</tt> consists of a readme file and some unpublished API documentation. The readme has basic usage instructions, but assumes the user will run <tt>ap_verify -h</tt> to learn the details of each command line argument.</p><p>We should move documentation out of the readme and into well-organized user-facing documents. This work may need to wait until <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jsick\" class=\"user-hover\" rel=\"jsick\">Jonathan Sick</a>\\'s documentation upgrades roll out.</p>\n",
            "<p>Do the following:</p><ul class=\"alternate\" type=\"square\">\\t<li>removed the GWT code</li>\\t<li>remove GWT annotation</li>\\t<li>remove unused methods that where used on the client</li>\\t<li>Move constants around there were in GWT code</li></ul>\n",
            "<p>Implement <a href=\"https://jira.lsstcorp.org/browse/RFC-453\" title=\"Reorganization of the DM Developer\\xc2\\xa0Guide\" class=\"issue-link\" data-issue-key=\"RFC-453\"><del>RFC-453</del></a>. by reorganizing the topics in the Developer Guide. Redirection pages will also be implemented.</p><p>The basic structure proposed in <a href=\"https://jira.lsstcorp.org/browse/RFC-453\" title=\"Reorganization of the DM Developer\\xc2\\xa0Guide\" class=\"issue-link\" data-issue-key=\"RFC-453\"><del>RFC-453</del></a> (and given in attached map) is acceptable. There is some concern about the \\xe2\\x80\\x9cworkflow\\xe2\\x80\\x9d topics, and where JIRA and GitHub fit. We\\xe2\\x80\\x99ll have to continue thinking about this as the reorganization shakes out.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "\"<p>Now that the constrainedPolyModel is selectable, we should improve it to bring it closer in line with what we expect the LSST Frames model will be. This would entail switching the TwoTransfoMapping to have T1 be an affine gtransfo constrained per chip (chips don't wiggle much), and T2 be an unconstrained polynomial (to nominally take out the variable sky component plus the optics, which we'll constrain later).</p><p>This may be as simple as swapping the models and where the constraint is defined. It would be very useful to have better plotting tools available to inspect the resulting models, and also possibly to have AST persistence available so we aren't having to squash the result into a TAN-SIP.</p>\"\n",
            "<p>Jointcal\\'s current astrometry model fixes one visit to be the identity, to break the sensor/visit model degeneracy. This leaves one visit unable to correct for focal plane/sky distortions. We should instead fix one sensor, fitting the rest of the sensors to that one.</p><p>This may mean making one sensor\\'s transform be the identity, or it may mean taking canonical values for one sensor but not letting them vary during the fit.</p><p>Because I\\'m digging into the astrometry code now, I\\'m going to try to do this as part of <a href=\"https://jira.lsstcorp.org/browse/DM-13272\" title=\"Confirm jointcal&#39;s astrometry output\" class=\"issue-link\" data-issue-key=\"DM-13272\"><del>DM-13272</del></a>.</p>\n",
            "<p>Conversations at the JTM made me realize I should be using a proper SourceSelector to select sources in FGCM.  This includes comparing the speed of the current ad-hoc column based approach with the SourceSelector tasks.  </p>\n",
            "<p>Use overlay instead of devicemapper for storage.</p>\n",
            "<p>Implement and unit-test StorageClass base/meta class.</p><p>Involves implementing <tt>StorageClass::assemble</tt> (when needed), but not actual persistence.</p>\n",
            "\"<p>Generating concrete classes from authoritative docs (if machine readable) is okay, but not necessary, and should not degrade code readability or documentation.</p><p>Machine-verifying concrete classes against authoritative docs (if we don't generate them) is also nice, but also not necessary.  Might be a good way to write unit tests.</p><p>Should use SP estimate to strictly time-box effort spent generating/machine-verification.</p>\"\n",
            "<p>Use the prototype Registry from either <a href=\"https://jira.lsstcorp.org/browse/DM-12613\" title=\"Implement minimal butler Registry prototype with sqlalchemy orm\" class=\"issue-link\" data-issue-key=\"DM-12613\"><del>DM-12613</del></a> or <a href=\"https://jira.lsstcorp.org/browse/DM-12371\" title=\"Implement minimal butler Registry prototype with sqlalchemy core\" class=\"issue-link\" data-issue-key=\"DM-12371\"><del>DM-12371</del></a> and the prototype Datastore from <a href=\"https://jira.lsstcorp.org/browse/DM-12667\" title=\"Implement minimal Butler POSIX Datastore prototype\" class=\"issue-link\" data-issue-key=\"DM-12667\"><del>DM-12667</del></a> to implement a prototype Butler (as described in DMTN-056).<br/>The only supported operations are <tt>Butler::get</tt>, <tt>Butler::put</tt> and <tt>Butler::unlink</tt> with a <tt>DatasetLabel</tt> (e.g. no querying, data-graphs or transfers).</p><p>The intent of this prototype is to inform design decisions for the final version. It should not be throw-away code but is allowed to be rough around the edges.</p>\n",
            "<p>It is desirable to have the authoritative Registry schema definition in a machine readable (YAML) format.<br/>This document should contain all information needed to initialize the Registry database with sqlalchemy.</p>\n",
            "<p>Reprocess the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_10. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>As it has been many years since I have worked through this branch of optimization, spend some time reading literature on optimization and more specifically optimization using prior probabilities.</p>\n",
            "<p>At the level that will enable a non-<a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=erykoff\" class=\"user-hover\" rel=\"erykoff\">Eli Rykoff</a> user to run FCGM on <tt>lsst-dev01</tt>.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a> has reproduced some strange data features at Princeton that had been reported by\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=masayuki.tanaka\" class=\"user-hover\" rel=\"masayuki.tanaka\">Masayuki Tanaka</a>.\\xc2\\xa0 Poke at this data with the interactive QA tools I have been developing to see if they can help diagnose what is going on, or at least to reproduce/match the topcat-style workflow that\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=price\" class=\"user-hover\" rel=\"price\">Paul Price</a> has heretofore used to investigate questions like this.</p><p>This involves setting up a QA environment equivalent on <tt>tigressdata</tt>\\xc2\\xa0to what I\\'ve been using on <tt>lsst-dev</tt>, running the pipe_analysis scripts (in parquet-only mode) on the data (<tt>/tigress/HSC/HSC --calib /tigress/HSC/HSC/CALIB-LSST-20170105 --rerun hscPipe-6.0-beta4/20180116/sxds</tt>), and putting together an investigatory notebook.</p>\n",
            "<p>The existing donut analysis plotting tools were created before our understanding that both intra and extra focal fits would be required to predict an in-focus PSF.  Several of these tools therefore incorrectly attempt to make plots of the optics PSF given only an intra or extra focal fit.  These should be reworked to make accurate optical PSF plots.</p>\n",
            "<p>I will review the paper:</p><p>\"SCARLET: Source separation in multi-band images by Constrained Matrix Factorization\"</p><p>for PUB-56.</p><p>\\xc2\\xa0</p>\n",
            "<p>Read and review PUB-58: A study of the Point Spread Function in SDSS images.</p>\n",
            "nan\n",
            "<p>Reprocess the two WIDE tracts of the HSC RC1 dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, and the three tracts of the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_08. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>From <a href=\"https://jira.lsstcorp.org/browse/DM-13203\" title=\"Behavior of Firefly on errors in column filtering\" class=\"issue-link\" data-issue-key=\"DM-13203\">DM-13203</a> item 1, 4, 5.</p><ol>\\t<li>Generate a meaningful error message when a column filter expression applied to a table is invalid.\\xc2\\xa0 This may not require any extra parsing effort for the filter expressions - the system knows the name of the column and the text typed in the filter field, and can just wrap the underlying error message with something like \"The filter expression \\'xyzzy\\' applied to column \\'foobar\\' is invalid.\".\\xc2\\xa0 For the purposes of debugging it may be useful to provide a UI action (e.g., a disclosure triangle) that makes it possible to see the full underlying exception text.</li>\\t<li></li>\\t<li></li>\\t<li>Ensure that, when an invalid filter expression is entered, after dismissing the error message the user is returned to the\\xc2\\xa0<em>same state of their data and previously-specified filters as before the failed attempt to construct a filter</em>.\\xc2\\xa0 This does not require arbitrary undos, but only that the displayed state of the table is not changed before the filter has been determined to be valid.</li>\\t<li>Do not use the word \"Reload\" for the button that dismisses the error dialog.\\xc2\\xa0 \"Back\", \"Close\", \"Cancel\" would all be better choices.\\xc2\\xa0 Consider asking for feedback from others, e.g., Vandana, for this choice.\\xc2\\xa0 \"Reload\"\\xc2\\xa0<em>strongly</em>\\xc2\\xa0suggests - to me - that the underlying data retrieval operation would be repeated rather than just abandoning the filter attempt.</li></ol>\n",
            "<p>In the snippet:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> os</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    dataPath </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> os.path.join(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/datasets\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"hsc\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"repo\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"rerun\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">,</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">                            </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"private\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"hchiang2\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"RC\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"DM-10084-mosaic\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    butler </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> dafPersist.Butler(dataPath)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    dataId </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">dict</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">(tract</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">8766</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, patch</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'2,1\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">filter</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'HSC-I\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    coadd </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> butler.get(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"deepCoadd_calexp\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, dataId)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    ci </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> coadd.getInfo().getCoaddInputs()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ccd </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">in</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ci.ccds:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        fn </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> butler.get(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"calexp_filename\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, dataId, visit</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ccd[</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"visit\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">], ccd</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ccd[</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"ccd\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">])[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        </span><span style=\"color: #ff1493; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">print</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> ccd[</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"visit\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">], ccd[</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"ccd\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">], fn, os.path.exists(fn), butler.get(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"calexp\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, dataId, visit</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ccd[</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"visit\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">], ccd</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">=</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">ccd[</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"ccd\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]).getDimensions()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">        </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">break</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Returns:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    7304 8 /datasets/hsc/repo/rerun/private/hchiang2/RC/DM-10084-mosaic/00995/HSC-I/corr/CORR-0007304-008.fits False (2048, 4176)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>In the case of a <tt>get</tt> (where <tt>write=False</tt>) the Butler should not be returning a path to a file that does not exist, it should look in parent repositories until an existing file is found, or return something meaning \"file not found\".</p><p>This seems to be an issue related to how bypass functions work. I think it\\xe2\\x80\\x99s because there\\xe2\\x80\\x99s no consideration for <tt>write=True</tt> or <tt>False</tt> in the filename bypass function (as there normally is for `map`ping), and so the <tt>map_xyz_filename</tt> function returns the first location its able to map (which would be appropriate for a `put` where <tt>write=True</tt> but is not appropriate for a <tt>get</tt> where <tt>write=False</tt>).</p>\n",
            "<p>metaserv v1 work needs to be started to support more information about the catalogs loaded into it. This work should be informed by IVOA standards, specifically RegTap. </p>\n",
            "<p>Move all Grafana instances to v5</p><p>Move all InfluxDB instances to v1.4 to support the Prometheus write API</p><p>Normal Telegraf Updates to latest version</p>\n",
            "<p>As the top level CI driver script <tt>jenkins_wrapper.sh</tt> is now checking compiler strings, these first line CI jobs need to always run on nodes with either the <tt>osx-10.11</tt> or <tt>osx-10.12</tt> label so an exact compiler string can be specified.  Prior to this, the more generic <tt>osx</tt> label was being used which includes all <tt>osx-10.1<span class=\"error\">&#91;12&#93;</span></tt> nodes.  This cuts the effective number of available OSX nodes in half.  Multiple compiler strings, wildcard matching, or both should be implemented.</p>\n",
            "<p>Add application-level monitoring for the Batch Scheduler.</p>\n",
            "nan\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/DM-11513\" title=\"Prototype system for publishing templates of package documentation\" class=\"issue-link\" data-issue-key=\"DM-11513\"><del>DM-11513</del></a> (and <a href=\"https://jira.lsstcorp.org/browse/RFC-376\" title=\"New organization for the templates repository\" class=\"issue-link\" data-issue-key=\"RFC-376\"><del>RFC-376</del></a>) we developed a new <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">lsst/templates</a> repository model that takes advantage of Jinja2 and cookiecutter to let us be more precise and deliberate with our templates. The design calls for examples that show rendered files and projects as built by Jinja2/cookiecutter. These examples are committed directly to the templates repo. We need to ensure that the examples stay in sync with the templates, however.</p><p>We can implement that with a build system that renders the templates into the lsst/templates repo. Developers of templates can run the build system to refresh examples, and a CI system can also run the build system to ensure that the committed examples are up-to-date.</p><p>The build system should be a very simple harness for Jinja2/cookiecutter. Scons might fit the bill, or even Makefiles.</p><p>This ticket will implement that system, hook it up to CI for checking, and document how to use it.</p>\n",
            "<p>This is a retroactive ticket to capture work already done: writing up</p><p><a href=\"https://confluence.lsstcorp.org/display/DM/Gen3+Butler+Composites+Design\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Gen3+Butler+Composites+Design</a></p><p>to guide a discussion on 2018-02-28.</p><p>\\xc2\\xa0</p>\n",
            "<p>Reprocess the HSC RC1 dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2018_03. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<del><a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a></del>/<del><a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a></del>).</p><p>Summarize the total node-hours needed. </p>\n",
            "<p>After prototype installation and configuration, work with PDAC team to specify required software versions. Update software as required.</p>\n",
            "<p>hipsSurveysId has some issues:</p><ul>\\t<li>It does not work when you load a HiPS with a URL via API</li>\\t<li>I am not sure it should be in WebPlotRequest at all.</li></ul><p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=cwang\" class=\"user-hover\" rel=\"cwang\">Cindy Wang</a> and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=roby\" class=\"user-hover\" rel=\"roby\">Trey Roby</a> need to review what it is doing and discuss the best way to implement it.</p><p>After the discussion implements the changes and fix any bugs.</p>\n",
            "<p>Removes the score and match methods from DIAObjectCollection and puts them, for now, into AssociationTask. Once AssociationTask moves into lsst-distrib we can move the further into meas_algorithms.</p>\n",
            "<p>Attend DAQ tutorial/workshop and related activities in Tucson.</p><p><a href=\"https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73568441\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/pages/viewpage.action?pageId=73568441</a></p>\n",
            "<p>For forward-compatibility with <a href=\"https://jira.lsstcorp.org/browse/DM-13163\" title=\"Refactor ap_pipe to use CmdLineTask primitives\" class=\"issue-link\" data-issue-key=\"DM-13163\"><del>DM-13163</del></a>, <tt>ap_verify</tt> should create separate repositories for ingestion and calibration. In effect, the current \"output repository\" should be a convenient \"workspace\" directory but not a repository.</p><p>In addition, the interface module <tt>pipeline_driver</tt> should make a distinction between input and output repositories, choosing the location of the latter instead of deferring the choice to <tt>ap_pipe</tt>. Neither <tt>CmdLineTasks</tt>, nor in the future <tt>Pipelines</tt>, are responsible for output paths.</p><p>Because the API will change again as part of <a href=\"https://jira.lsstcorp.org/browse/DM-13163\" title=\"Refactor ap_pipe to use CmdLineTask primitives\" class=\"issue-link\" data-issue-key=\"DM-13163\"><del>DM-13163</del></a>, changes to the interface between <tt>ap_pipe</tt> and <tt>ap_verify</tt> should be kept minimal; most likely, this will entail removing the ill-advised wrappers added in <a href=\"https://jira.lsstcorp.org/browse/DM-12257\" title=\"Implement association step in ap_verify\" class=\"issue-link\" data-issue-key=\"DM-12257\"><del>DM-12257</del></a> and calling the existing functions from <tt>pipeline_driver</tt> again.</p>\n",
            "nan\n",
            "<p>WarpCompare has no temporal information for the pixels that are outside the boundary of the psfMatched Warps. These pixels are marked NO_DATA. The BBoxes in the CoaddInputRecorder should be shrunk so that we can have an exact CoaddPsf for sources that fall in the border of calexp.\\xc2\\xa0</p>\n",
            "<p>Non regression on Qserv performances</p>\n",
            "<p>The metaserv should be able to support databases for which we don\\'t have the ascii schema with descriptions and special tokens (ucd, units etc). This story involves implementing it. In practice, the metaserv/bin/metaBackend will need to be extended to implement \"ADD DB\"</p>\n",
            "<p>Create a full example of a Python module documented in our Numpydoc style and add it to <a href=\"https://developer.lsst.io/docs/py_docs.html\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/docs/py_docs.html</a></p><p>See <a href=\"http://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html#example-numpy\" class=\"external-link\" rel=\"nofollow\">http://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html#example-numpy</a> for an example of this.</p><p>Also address the example in <a href=\"https://developer.lsst.io/docs/py_docs.html#examples-of-constant-and-class-attribute-docstrings\" class=\"external-link\" rel=\"nofollow\">https://developer.lsst.io/docs/py_docs.html#examples-of-constant-and-class-attribute-docstrings</a> to show that class attributes are documented separately for init parameters. See <a href=\"https://lsstc.slack.com/archives/C2B6DQBAL/p1518125199000564\" class=\"external-link\" rel=\"nofollow\">https://lsstc.slack.com/archives/C2B6DQBAL/p1518125199000564</a></p>\n",
            "<p>SUI software needs to know which tables support spatial queries. This story involves exposing this information via Metaserv (the information is available via CSS) </p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>We occasionally observe a \"wave\" of github fetch/clone failures from <tt>lsstsw / lsst_build</tt> in the jenkins env. Where a wave is several random failures over the course of a day or two and then there are no failures for weeks.  I am convinced that these are on the github end as I have experienced clone failures when running <tt>lsstsw</tt> outside the the jenkins env.</p><p>I am loath to retry the entire jenkins build upon any failure as this might result in a legitimate build failure unnecessarily tying up build slaves.  There are two  solutions that occur to me:</p><p>1) propagate errors up from <tt>lsst_build</tt> in such a way that the CI driver can determine the reason of failure and retry a set of failure modes</p><p>2) add git fetch/clone retrying support into <tt>lsst_build</tt></p><p>I am leaning towards #2 as the implementation is straight forward and contained within a single component.</p>\n",
            "<p>Reprocess the two WIDE tracts of the HSC RC1 dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, and the three tracts of the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_06. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>skyCorrection.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt>.\\xc2\\xa0</p>\n",
            "<p>Add documentation to DMTN-071 for the Kubernetes Dashboard.</p>\n",
            "\"<p>See Description (it's currently called PsfMatch)</p>\"\n",
            "\"<p>These are the major (interrelated) issues we want to have under control before the in-person meeting; we expect in-person meeting attendees to have input in the final resolution, but we want to go into the meeting with a non-empty set of approaches we think everyone will agree to. The current approach to preflight makes a lot of people nervous even if we haven't actually invalidated it yet.</p>\"\n",
            "\"<p>These are the major (interrelated) issues we want to have under control before the in-person meeting; we expect in-person meeting attendees to have input in the final resolution, but we want to go into the meeting with a non-empty set of approaches we think everyone will agree to.  The current approach to preflight makes a lot of people nervous even if we haven't actually invalidated it yet.</p>\"\n",
            "<p>When Lander fails to upload a PDF at the end of a build, the build is still marked as a success (see, e.g., <a href=\"https://travis-ci.org/lsst/LDM-534/builds/318277471\" class=\"external-link\" rel=\"nofollow\">https://travis-ci.org/lsst/LDM-534/builds/318277471</a>). That\\'s confusing \\xe2\\x80\\x94 please can we change this so the failure is acknowledged?</p>\n",
            "<p>The auxiliary telescope is coming online surprisingly soon. We also now know for sure which sensor it will be using. It is therefore prudent to create the obs_package for this now, so that we can start looking at lab data taken with this sensor in order to become intimately acquainted with it before it goes on sky.</p><p>This work can either be done by stripping down obs_comCam, or rebooting the somewhat-abandoned obs_ts3 work.</p>\n",
            "<p>Follow-on to <a href=\"https://jira.lsstcorp.org/browse/DM-13271\" title=\"Create and ingest JSON-LD metadata for LaTeX/Lander documents\" class=\"issue-link\" data-issue-key=\"DM-13271\"><del>DM-13271</del></a> to clean up data ingest issues now that lsst-projectmeta-kit 0.3.0 is emitting metadata.jsonld on Lander pages in the wild.</p><p>This ticket also covers re-building LaTeX document landing pages so that they include <tt>metadata.jsonld</tt> files.</p>\n",
            "nan\n",
            "<p>Review storage input numbers to increase accuracy of tech predictions. For example, current model states 24 drives per tray when current technology supports 60 drives per tray and soon will be 84</p>\n",
            "<p>Verify what inputs are generating the rack counts for floorspace costs, wanting to validate that what size the racks are and verify that they are at the capacity needed. Rack and PDU costs were also not currently reflected in the model and those costs have been added. </p>\n",
            "<p>Discussed costing of networking (Ethernet, Infiniband, and WAN) to correct costing to current technologies and project needs. Looking into WAN costs to determine accurate split of costs that will be incurred Getting updated quotes for the Ethernet costs, and removed the Infiniband costs</p>\n",
            "<p>I will read the manuscript:<br/> \\xc2\\xa0<br/> \"SCARLET: Source separation in multi-band images by Constrained Matrix Factorization\"<br/> Peter Melchior, Fred Moolekamp, Maximilian Jerdee, Robert Armstrong, Ai-Lei Sun, James Bosch, Robert Lupton</p><p>in its entirety and provide any feedback I have, but I have been asked to pay particular attention to <b>Section 3: Applications</b>.</p><p>\\xc2\\xa0</p><p>Note that this review is considered a \"Science Pipelines\" internal review (and is separate from the LSST-internal reviews being carried out\\xc2\\xa0and tracked on PUB-56).</p>\n",
            "<p>SsiSession is currently deleted by a call to Finished, and this can happen before tasks using the object are all done with it, causing a segfault and worker crash. Moving the the UnBindRequest call to the destructor and using a shared pointer for the SsiSesion object should make it safe. Also, it looks like eliminating the SsiSession::ReplyChannel class will make the code simpler, but some changes need to be made to expose the functions ReplyChannel calls in xrdssi.</p>\n",
            "\"<p>Currently a drawback of WarpCompare is any epochs where a source doesn't look like the other epochs gets clipped. This leads to some loss of signal in bright sources. While future work on the image comparison will improve this (background matching, image-to-image psf matching, etc....) for now, we probably want a nuclear option config:</p><p>If an artifact candidate fits entirely within a template coadd source, then don't clip it. This means that unfortunate CRs or supernovae won't be clipped, but will improve the photometry. For the HSC release,  coadd photometry seems to be a higher priority. </p>\"\n",
            "<p>Reprocess the two WIDE tracts of the HSC RC1 dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, and the three tracts of the HSC RC2 dataset, as defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11345\" title=\"Redefine HSC &quot;RC&quot; dataset for bi-weeklies processing\" class=\"issue-link\" data-issue-key=\"DM-11345\"><del>DM-11345</del></a>, using Stack w_2018_04. Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (-<del><a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a></del><del>/</del><del><a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a></del>-).</p>\n",
            "<p>Work on <tt>ap_verify</tt> documentation for -<del><a href=\"https://jira.lsstcorp.org/browse/DM-11592\" title=\"Better documentation for ap_verify\" class=\"issue-link\" data-issue-key=\"DM-11592\"><del>DM-11592</del></a></del>- has exposed a number of difficult-to-explain behaviors in <tt>ap_verify</tt>. Those with an obvious solution have been ticketed separately, but a number are UI/roadmap decisions that need to be agreed on before the \"correct\" behavior can be documented.</p><p>This ticket is to set aside time for discussing the following questions, and updating the documentation accordingly (TODOs tagged with this issue ID):</p><ul>\\t<li><del>How do we foresee installing datasets? Will they be automatically provided as part of <tt>lsst_distrib</tt> or another metapackage (<tt>ap_verify_hits2015</tt> is owned by the <tt>lsst</tt> GitHub group, but as far as I know it\\'s not distributed by any of the Stack installers)? If users will be installing them manually, how will they be versioned?</del> <font color=\"#707070\"><span class=\"error\">&#91;To be determined later; no updates to documentation for now&#93;</span></font></li>\\t<li>What is the rationale for giving datasets a command-line name distinct from their repository or EUPS name (see the \"HiTS\" : \"hits_data\" example in -<del><a href=\"https://jira.lsstcorp.org/browse/DM-11118\" title=\"Build stubbed out verify_ap\" class=\"issue-link\" data-issue-key=\"DM-11118\"><del>DM-11118</del></a></del>-)? Now that this feature is implemented and documented, it seems to only add user friction (e.g., it is difficult to work out where to download a dataset from its command-line name). <font color=\"#707070\"><span class=\"error\">&#91;Document that it&#39;s a placeholder for a future versioning system&#93;</span></font></li>\\t<li>Following -<del><a href=\"https://jira.lsstcorp.org/browse/DM-11118\" title=\"Build stubbed out verify_ap\" class=\"issue-link\" data-issue-key=\"DM-11118\"><del>DM-11118</del></a></del><del>, we added a <tt></del><del>rerun</del></tt> parameter that superficially resembles the <tt>-rerun</tt> parameter for <tt>CmdLineTask</tt>, but places results in the dataset directory. Its behavior is so unlike <a href=\"https://pipelines.lsst.io/v/DM-11253/modules/lsst.pipe.base/command-line-task-data-repo-howto.html#using-reruns-to-organize-outputs-in-a-single-data-repository\" class=\"external-link\" rel=\"nofollow\">repository chaining</a> that it is likely to confuse rather than help veteran Stack users, it requires users to know where a dataset is installed (something the rest of the design tries to hide), and it potentially makes changes to otherwise read-only datasets. I would like to revisit the question of whether this argument is desirable and, if so, what its behavior should be. <font color=\"#707070\"><span class=\"error\">&#91;To be modified as suggested by KSK; deferred to DM-13492 due to implementation constraints.&#93;</span></font></li>\\t<li>Why does <tt>ap_verify</tt> take a parameter called <tt>&#45;&#45;dataIdString</tt> rather than <tt>&#45;&#45;dataId</tt> or, as command-line tasks do it, <tt>&#45;&#45;id</tt>? <font color=\"#707070\"><span class=\"error\">&#91;Change parameter to {{--id}}&#93;</span></font></li>\\t<li><del><tt>ap_verify</tt> currently returns 0 if the pipeline ran to completion, and an interpreter-dependent value otherwise. Should we impose more specific guarantees? (Making <tt>ap_verify</tt> count failed dataIds the way command-line tasks do may have implications for its error-handling policy.)</del> <font color=\"#707070\"><span class=\"error\">&#91;To be determined later; no updates to documentation for now&#93;</span></font></li></ul>\n",
            "<p>REmoving ReplyChannel would simplify the code.</p>\n",
            "nan\n",
            "<p>We need a mechanism to retrieve the status of the job creation for the bulk insertion of jobs as part of the ETL task, see <a href=\"https://jira.lsstcorp.org/browse/DM-12604\" title=\"Migrate SQuaSH data from the current production database to the new database schema\" class=\"issue-link\" data-issue-key=\"DM-12604\"><del>DM-12604</del></a>.</p><p>Also need a SQUASH_ELT_MODE configuration parameter to handle some operations during the ETL such as preserving the original timestamp of jobs instead of using auto <tt>now()</tt>.</p>\n",
            "<p>6Document the current monitoring for the LSST infrastructure machines in NPCF and in NCSA.   Document the current dashboard for what is currently available, and how a current incident is resolved that was found in monitoring.   </p>\n",
            "<p>Develop and instantiate a monitoring view for NCSA TMG operations staff use.</p>\n",
            "<p>Add dashboards for use cases:</p><ul>\\t<li>Subsystem general status (casual user view)</li>\\t<li>Operators health/ping monitor</li>\\t<li>Operators view (TMG)</li></ul>\n",
            "<p>Add monitor tools and dashboard to check cluster and nodes health</p>\n",
            "<p>Now that the <a href=\"https://squash-restful-api-demo.lsst.codes/\" class=\"external-link\" rel=\"nofollow\">new API is alive</a>\\xc2\\xa0we need the following resources that are consumed by the SQuaSH bokeh apps:</p><ul>\\t<li>measurements -&gt;  monitor app</li>\\t<li>code changes -&gt; monitor app</li>\\t<li>stats -&gt; dashboard initial page</li>\\t<li>blobs &gt; AM1, PA1, etc apps</li></ul><p>NOTE: the performance on retrieving the data from the new implementation will be evaluate only after <a href=\"https://jira.lsstcorp.org/browse/DM-12604\" title=\"Migrate SQuaSH data from the current production database to the new database schema\" class=\"issue-link\" data-issue-key=\"DM-12604\"><del>DM-12604</del></a> is done</p>\n",
            "nan\n",
            "<p><a href=\"https://jira.lsstcorp.org/browse/DM-10729\" title=\"Near-term jointcal acceptance: make validate_drp use meas_mosaic outputs\" class=\"issue-link\" data-issue-key=\"DM-10729\"><del>DM-10729</del></a> added incomplete support for using meas_mosaic (and soon, jointcal) results in to calibrate the catalogs used by validate_drp.  This feature has only been tested in a one-off sense, because we currently don\\'t have any CI processing of a dataset large enough to run meas_mosaic/jointcal.  Once that\\'s addressed, we should finish making it possible to utilize jointcal results in the main driver scripts used by SQuaSH and enable these tests in CI.</p><p>If anyone knows of a ticket for adding larger datasets to CI, please add it as a blocker.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Create a framework and objective function used to run an MCMC algorithm on the library of objects which failed shape modeling as determined in <a href=\"https://jira.lsstcorp.org/browse/DM-12423\" class=\"external-link\" rel=\"nofollow\">DM-12423</a>.</p>\n",
            "<p>The NCSA foreman code currently differs from the message glossary documentation.</p>\n",
            "\"<p>This will allow 'Complete Night' testing wherein astronomical files are produced by the forwarders while the Header Service is being completed.</p>\"\n",
            "<p>Reprocess the HSC RC dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2017_52.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p><p>(Due to the holiday season, w_2017_52 may not be available, in which case we\\'ll make this ticket \"Won\\'t Fix\" and move on to 2018.) </p>\n",
            "<p>For catalog search, in case the searched catalog is with no position information, what should be rendered on the triview in addition to the table containing no position columns? </p><p>The content of the coverage will be blank. However, the chart content is various based on the table content, <br/>a default chart of the first two numeric columns? a blank chart with no numeric columns? a chart with only one numeric column? </p><p> The triview layout needs some update in case a catalog with no position information is searched and displayed. </p><p>----------<br/>TG 02/01/18</p><ul class=\"alternate\" type=\"square\">\\t<li>If the table with no positional info is the first rendered in firefly, no coverage or chart area will show.</li>\\t<li>If other tables are added, the coverage and chart areas will not disappear, when changing the active table. This is intentional behavior to avoid confusing layout changes.</li></ul><p>An example of a table with no position info WISE -&gt; AllWISE Inventory Table</p><p>Other bugs fixed:</p><ul class=\"alternate\" type=\"square\">\\t<li>non-returning search</li>\\t<li>removed chart hanging in the store</li>\\t<li>empty result area with no drop down, when all tables are deleted</li>\\t<li>missing layout updates (on table update or removed chart)</li>\\t<li>no axis labels in the default histogram chart</li></ul>\n",
            "<p>Build and install all of the SAL software on the new dedicated machine on the LSST L1 TestStand (lsst-l1-us-fault)</p><p>for\\xc2\\xa0 the DM HeaderService.</p><p>Build and install the DM HeaderService on this new machine.</p><p>Successfully run the DM HeaderService tests as done in the last Pathfinder Integration activity 4b.</p>\n",
            "<p>Capture NOAO Mosaic geometry FITS keyword definition for CCD Amplifiers as described in LCA-13501. The NOAO Mosaic keywords are used for assembling images from multi-CCD cameras and are widely used.\\xc2\\xa0</p>\n",
            "<p>Currently StorageClass subclasses (e.g. <tt>Exposure</tt>) are defined in code. Move these to YAML configuration (e.g. as done for <tt>Formatter</tt>).</p>\n",
            "nan\n",
            "<p>In addition to the existing Python docstring documentation in <tt>firefly_client</tt>, it would be desirable to have \"user guide\"-type documentation, including examples, available.</p>\n",
            "nan\n",
            "nan\n",
            "<p>The new `dcrAssembleCoaddTask` iterates over the outputs of its `assemble` method, which requires overriding the `run` method of the base `assembleCoaddTask`. This ticket and branch of `pipe_tasks` is to explore modifying the base `run` method to always iterate over the outputs of `assemble`. If that works cleanly, we will consider merging the branch, but it is possible it will instead be discarded.</p>\n",
            "nan\n",
            "<p>This ticket captures the SPs used during tests of the SQuaSH RESTful API to make sure it works with the datasets and verification jobs currently created in CI. It includes revision of <tt>nginx</tt> and <tt>uwsgi</tt> configuration and the dimensioning of the cluster node in GKE during the tests. </p><p>The first part of the tests was done after <a href=\"https://jira.lsstcorp.org/browse/DM-12603\" title=\"Deployment of the squash-restful-api service\" class=\"issue-link\" data-issue-key=\"DM-12603\"><del>DM-12603</del></a> and the second part after <a href=\"https://jira.lsstcorp.org/browse/DM-13275\" title=\"Upload verification job and data blobs to an S3 bucket using Celery\" class=\"issue-link\" data-issue-key=\"DM-13275\"><del>DM-13275</del></a>.</p>\n",
            "<p>Run code attached to <a href=\"https://jira.lsstcorp.org/browse/DM-5082\" title=\"Implement code to generate kernel for brighter fatter correction.\" class=\"issue-link\" data-issue-key=\"DM-5082\"><del>DM-5082</del></a> as-is, reproduce results</p><ul>\\t<li>gather data on tiger</li>\\t<li>run with correct version of stack</li>\\t<li>check against Will\\'s results</li></ul>\n",
            "nan\n",
            "<p>We decided to change how SQUASH handles the data blobs produced by the verification jobs. This is motivated by the performance issues seen in\\xc2\\xa0<a href=\"https://jira.lsstcorp.org/browse/DM-13259\" title=\"Enable dispatch_verify in validate_drp Jenkins job \" class=\"issue-link\" data-issue-key=\"DM-13259\"><del>DM-13259</del></a>\\xc2\\xa0pushing the HSC test dataset to the new SQuaSH API.</p><p>In this implementation the full verification job will still be sent to the SQuaSH API, the measurements and metadata will be stored in the MySQL database while the data blobs will be uploaded to an S3 bucket and the corresponding reference (the S3 object URI) will be kept in the database. We are also uploading the whole job document to S3 to have the source of truth around in case it is needed for a future refactoring.</p><p>This change goes in the direction of the Data Butler composite datasets and is a shim while we don\\'t have that functionality in place.\\xc2\\xa0</p><p>It is also interesting from the point of view of data access an visualization in SQuaSH. We could transform and store these data blobs in a more appropriate format such as\\xc2\\xa0<tt>parquet</tt>\\xc2\\xa0instead of retrieving them in JSON from the REST API as we do now.</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p><p>\\xc2\\xa0</p>\n",
            "nan\n",
            "<p>Correct and re-organize catalog-data selection screen on PDAC Portal for WISE single-epoch source data.</p><p>Under the \"LSST Data\" button and the \"Search\" tab that appears beneath it, there will be a \"Select Project\" dropdown, as now. That dropdown should have three selections:</p><p>(1) \"SDSS Stripe 82, 2013 LSST Processing\"<br/>     (Note that currently there is a typo: \"SSDS\".)</p><p>    This should remain unchanged, except for the more descriptive title.<br/> In particular, we retain the \"Catalogs\" and \"Images\" radio buttons.</p><p>    If possible, we could add, lower down on this panel (i.e., below all the radio buttons), an \"open in new window\" link to <a href=\"https://confluence.lsstcorp.org/display/DM/Properties+of+the+2013+SDSS+Stripe+82+reprocessing\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Properties+of+the+2013+SDSS+Stripe+82+reprocessing</a> with the text \"Documentation on the Stripe 82 reprocessing dataset\".</p><p>(2) \"AllWISE Processing of WISE pre-hibernation (2010-2011)\"<br/>     Under \"Catalogs\" we would have three radio buttons:<br/>     o AllWISE Source Catalog (comparable to LSST Object)<br/>     o AllWISE Multiepoch Photometry Table (comparable to ForcedSource)<br/>     o AllWISE Reject Table (no LSST analog)</p><p>    Under \"Images\" we would have exactly what is there now in the version deployed on PDAC.</p><p>    Below all the selectors, add an \"open in new window\" link to <a href=\"http://wise2.ipac.caltech.edu/docs/release/allwise/expsup/\" class=\"external-link\" rel=\"nofollow\">http://wise2.ipac.caltech.edu/docs/release/allwise/expsup/</a> with the text \"Documentation on the AllWISE dataset\".</p><p>(3) \"WISE &amp; NEOWISE Single-Epoch Photometry (2010-2014)\"<br/>      Under \"Catalogs\", there should be four radio buttons:<br/>      o WISE All-Sky Single Exposure (L1b) Source Table<br/>      o WISE 3-Band Cryo Single Exposure (L1b) Source Table<br/>      o WISE Post-Cryo Single Exposure (L1b) Source Table<br/>      o NEOWISE-R Year 1 Single Exposure Source Database</p><p>    Under \"Images\" we should have what is currently there under \"wise_00\"\\'s Images section, except for removing the AllWISE Atlas Images radio button.</p><p>    When \"Images\" is selected, below the three available radio buttons, add the note \"(Single-epoch images for the NEOWISE Reactivation mission are not currently available on the PDAC.)\"</p><p>    Below all the selectors, add an \"open in new window\" link to <a href=\"http://wise2.ipac.caltech.edu/docs/release/neowise/expsup/\" class=\"external-link\" rel=\"nofollow\">http://wise2.ipac.caltech.edu/docs/release/neowise/expsup/</a> with the text \"Documentation on the NeoWISE data releases\"</p>\n",
            "<p>Python 3 is now the default for the stack, and in the future only Python 3 will be supported.\\xc2\\xa0 FGCM (both the LSST stack code and the third-party module) need to be updated for python 3 support.\\xc2\\xa0\\xc2\\xa0</p>\n",
            "<p>To date, the qa analysis scripts have only been run and tested on HSC data.  As such, it is almost certain some HSC-isms have been unwittingly been baked into the code.  This ticket involves running the scripts on DESC DS1 simulation output and making any adaptations required.  The testing will be done on the visit and coadd levels for the single band (r) of the DC1 run.  This will be a significant step towards generalizing the scripts to run on any LSST-stack processed dataset.</p>\n",
            "nan\n",
            "\"<p>We want to run different branches of <tt>validate_drp</tt>.  We don't need to reduce the data twice, so we need to split the processing from the validation.</p>\"\n",
            "<p>Currently qana uses database-global \"ovelap\" value as a match table \"separation\" parameter which is wrong. Database-global \"ovelap\" is supposed to be a default overlap value for tables that don\\'t define their own overlap. Match table separation is not really related to overlap, so to reduce confusion we need to add new parameter to match table configuration in CSS and use is to set qana parameters.</p>\n",
            "\"<p>The current interface for the deblender takes constraints and components as arguments but doesn't utilize that information when building the constraints for each object (for example having default constraints for different component types). It also doesn't pass those parameters to the main NMF algorithm without being explicitly given as function arguments, so improving this interface would make constraints and components easier to use and more robust against inconsistencies (for example this weekend I had forgotten to pass the constraints to the function to build the monotonicity operator, causing half of the components to not have monotonicity applied).</p>\"\n",
            "<p>Before updating the stack API (<a href=\"https://jira.lsstcorp.org/browse/DM-12404\" title=\"Update stack with new deblender API\" class=\"issue-link\" data-issue-key=\"DM-12404\"><del>DM-12404</del></a>) and testing the deblender on HSC data (<a href=\"https://jira.lsstcorp.org/browse/DM-11330\" title=\"Test NMF deblender on example patches\" class=\"issue-link\" data-issue-key=\"DM-11330\">DM-11330</a>), we should make sure that the new version works on the same simulated data as well or better than the previous version.</p>\n",
            "<p>This ticket is to use the projectmeta MongoDB dataset created in <a href=\"https://jira.lsstcorp.org/browse/DM-13188\" title=\"Build extract-transform-load workflow for reStructuredText technote metadata\" class=\"issue-link\" data-issue-key=\"DM-13188\"><del>DM-13188</del></a> and use it to populate the <a href=\"https://www.lsst.io\" class=\"external-link\" rel=\"nofollow\">https://www.lsst.io</a> landing page.</p><p>The projectmeta DB currently only includes reStructuredText-based technotes.</p><p>This data will be presented on a single page, likely, so I don\\'t have to settle on a more general info architecture for the site.</p>\n",
            "<p>DAX already provided the ImgServ v1, SUIT needs to be modified to use the new version.\\xc2\\xa0</p><p>\\xc2\\xa0</p><p><a href=\"https://github.com/Caltech-IPAC/firefly/pull/528\" class=\"external-link\" rel=\"nofollow\">https://github.com/Caltech-IPAC/firefly/pull/528</a></p><p>The purpose of this PR is to convert from\\xc2\\xa0<a href=\"https://confluence.lsstcorp.org/display/DM/Update+for+ImageServ+API+-+v0\" class=\"external-link\" rel=\"nofollow\">DAX ImageServ v0</a>\\xc2\\xa0to\\xc2\\xa0<a href=\"https://confluence.lsstcorp.org/display/DM/ImageServ+API+-+v1\" class=\"external-link\" rel=\"nofollow\">DAX ImageServ v1</a></p><ul>\\t<li>converted URLs to work with ImageServ v1</li>\\t<li>added unit tests to check for successful HTTP status when retrieving table and images from DAX (when DAX services are available)</li>\\t<li>bug fix: applications with no workspace, should not initialize it</li>\\t<li>bug fix: catalog watcher should not throw exception when center cols are missing and only corner cols are present</li>\\t<li>bug fix: filter syntax should be\\xc2\\xa0<tt>\"filterName\" LIKE \\'u\\'</tt></li>\\t<li>avoid unnecessary wrapping of DataAccessException</li></ul><p>To run tests:<br/>gradle -Dtest.single=LSSTDbServ :firefly:test<br/>gradle -Dtest.single=LSSTImgServ :firefly:test</p>\n",
            "<p>Reprocess the HSC RC1 dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2018_02.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p>\n",
            "<p>When a calexp overlaps a patch by &lt; 1%, the PSF-matching is bad. <br/><span class=\"image-wrap\" style=\"\"><a id=\"30242_thumb\" href=\"https://jira.lsstcorp.org/secure/attachment/30242/30242_Screen+Shot+2017-11-15+at+5.59.58+PM.png\" title=\"Screen Shot 2017-11-15 at 5.59.58 PM.png\" file-preview-type=\"image\" file-preview-id=\"30242\" file-preview-title=\"Screen Shot 2017-11-15 at 5.59.58 PM.png\"><img src=\"https://jira.lsstcorp.org/secure/thumbnail/30242/_thumb_30242.png\" style=\"border: 0px solid black\" /></a></span><br/>This is especially problematic now that we\\'re requiring the PSF-matched pixels to agree with a template PSF-matched coadd before the the DIRECT warp\\'s pixels (which are probably fine) in a coadd.</p><p>Make it less bad or require that a calexp overlap by a minimum number of pixels before plopping it down. </p>\n",
            "<p>Run meas_mosaic on the acceptance data, and produce catalogs that are ready to be validated via validate_drp.</p>\n",
            "<p>Create a notebook that enables convenient browsing of the static QA plots generated by the <tt>pipe_analysis</tt> scripts, in support of the QA analysis milestone.</p>\n",
            "<p>www.lsst.io (DocHub) will be a portal for LSST project documentation, software projects, and other forms of information. This ticket is to create the Flask project for building out the www.lsst.io site, and outputting the Flask site as a static site deployed through LSST the Docs.</p>\n",
            "\"<p>Create a flexible tile-based grid layout for www.lsst.io (LSST's documentation hub). Each tile corresponds to a different product (a document or software project). These tile grids will be used on index pages and let people browse different products in a category.</p>\"\n",
            "<p>Write up the results of the test documented in LDM-533.</p>\n",
            "nan\n",
            "nan\n",
            "<p>The original implementation of the SQuaSH REST API used Django REST Framework. We decided to reimplement in Flask to be aligned with the technology stack being used in DAX and other projects in SQuaRE.</p><p>For the Flask implementation these are the main resources I am using:</p><ul>\\t<li>REST APIs with Flask and Python: <a href=\"https://www.safaribooksonline.com/library/view/rest-apis-with/9781788621526/\" class=\"external-link\" rel=\"nofollow\">https://www.safaribooksonline.com/library/view/rest-apis-with/9781788621526/</a></li></ul><ul>\\t<li>Developing RESTful APIs with Python and Flask: <a href=\"https://auth0.com/blog/developing-restful-apis-with-python-and-flask/\" class=\"external-link\" rel=\"nofollow\">https://auth0.com/blog/developing-restful-apis-with-python-and-flask/</a></li></ul><ul>\\t<li>Building RESTful Python Web Services: <a href=\"https://www.safaribooksonline.com/library/view/building-restful-python/9781786462251/ch06s06.html\" class=\"external-link\" rel=\"nofollow\">https://www.safaribooksonline.com/library/view/building-restful-python/9781786462251/ch06s06.html</a></li></ul><p>Still Keep here the Django references in case they are useful in the future/for anyone:</p><ul>\\t<li>Building RESTful Python Web Services with Django: <a href=\"https://www.safaribooksonline.com/library/view/building-restful-python/9781788620154/\" class=\"external-link\" rel=\"nofollow\">https://www.safaribooksonline.com/library/view/building-restful-python/9781788620154/</a></li></ul><ul>\\t<li>Django Projects: E-Learning Portal: <a href=\"https://www.safaribooksonline.com/library/view/django-projects-e-learning/9781788395175/video4_1.html\" class=\"external-link\" rel=\"nofollow\">https://www.safaribooksonline.com/library/view/django-projects-e-learning/9781788395175/video4_1.html</a></li></ul><ul>\\t<li>Mastering Django Web Development: <a href=\"https://www.safaribooksonline.com/library/view/mastering-django-web/9781783989805/\" class=\"external-link\" rel=\"nofollow\">https://www.safaribooksonline.com/library/view/mastering-django-web/9781783989805/</a></li></ul>\n",
            "<p>Currently, one needs a modtran installation to build the atmosphere model for FGCM and compute the look-up-tables (that depend on the atmosphere + instrument).  A recent conversation made me realize that I can compactly pre-compute sets of atmospheres for various sites/elevations that can be distributed with FGCM.  This will make the code more portable and flexible for use with LSST to swap out different instrument models.</p>\n",
            "nan\n",
            "<p>Review synpipe instructions set provided by <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=nlust\" class=\"user-hover\" rel=\"nlust\">Nate Lust</a>.  This is the first step in the project to put fake objects into the biweekly HSC continuous integration. </p>\n",
            "<p>Document Base AA monitoring system, including how-to for adding monitored resources.</p>\n",
            "<p>Configure low-level monitoring applications and initial dashboard-- nagios setup, triggers, etc.</p>\n",
            "<p>Deployment of the SQuaSH RESTful API, this includes the api, nginx and cloud sql containers and kubernetes configuration.</p><p>The production URL: <a href=\"https://squash-restful-api.lsst.codes\" class=\"external-link\" rel=\"nofollow\">https://squash-restful-api.lsst.codes</a></p><p>The demo URL: <a href=\"https://squash-restful-api-demo.lsst.codes\" class=\"external-link\" rel=\"nofollow\">https://squash-restful-api-demo.lsst.codes</a></p>\n",
            "<p>SQuaSH QC Tier 0 database must be generic to allow measurements from different <tt>lsst.verify</tt> packages such as <tt>jointcal</tt>. The work related to reimplement the SQuaSH API is covered in a separate epic <a href=\"https://jira.lsstcorp.org/browse/DM-12787\" title=\"Science Quality Monitoring and Testing\" class=\"issue-link\" data-issue-key=\"DM-12787\"><del>DM-12787</del></a></p>\n",
            "<p>We need a squash API acceptance test suite that can be run against the SQuaSH test client implemented on <a href=\"https://jira.lsstcorp.org/browse/DM-9741\" title=\"Implement a minimal viable REST API in Flask with a test client \" class=\"issue-link\" data-issue-key=\"DM-9741\"><del>DM-9741</del></a> that exercises the the entire REST API.</p><p>It should use for example \"real world\" fixture data include the large (&gt;50MiB) HSC measurement data set. </p>\n",
            "<p>this local installer could be used for running integration tests on travis-ci.</p>\n",
            "<p>The new change-controlled document release workflow uses the <tt>master</tt> branch as the integration branch, and <tt>v&lt;major&gt;.&lt;minor&gt;</tt> tags as releases. We\\'d like to have the latest release for documents featured as the primary version shown on a document\\'s <tt>handle.lsst.io</tt> landing page. This will require some new functionality in <a href=\"https://github.com/lsst-sqre/ltd-keeper\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/ltd-keeper</a> and possibly <a href=\"https://github.com/lsst-sqre/ltd-dasher\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/ltd-dasher</a>.</p><p>See also the document branch and tag API newly defined in <a href=\"https://jira.lsstcorp.org/browse/DM-11952\" title=\"Create an RFC for change-controlled DM document Git branch and release policy\" class=\"issue-link\" data-issue-key=\"DM-11952\"><del>DM-11952</del></a> and <a href=\"https://jira.lsstcorp.org/browse/RFC-401\" title=\"Revised DM change-controlled document release workflow\" class=\"issue-link\" data-issue-key=\"RFC-401\"><del>RFC-401</del></a>.</p>\n",
            "<p>Prepare the Base AA system with users, applications, and configuration necessary for running low-level monitoring.</p>\n",
            "<p>Research and if possible add initial application level monitoring with API creation.</p>\n",
            "<p>Update the <a href=\"https://developer.lsst.io/docs/py_docs.html\" class=\"external-link\" rel=\"nofollow\">Documenting Python APIs</a> page in the DM         Developer Guide to clarify and document issues that have come up in real-world application of Numpydoc-based docstrings in the last few months. This ticket encompasses the issues <a href=\"https://jira.lsstcorp.org/browse/DM-12926\" title=\"Clarify return value documentation for Python\" class=\"issue-link\" data-issue-key=\"DM-12926\">DM-12926</a> and <a href=\"https://jira.lsstcorp.org/browse/DM-12936\" title=\"Clarify formatting for parameters\" class=\"issue-link\" data-issue-key=\"DM-12936\">DM-12936</a>.</p>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>Set up a more flexible environment to use the development DESDM software and a newer stack version</li>\\t<li>Try the mini tests in lsst-dm/prod_wcl/wcl with stack <tt>w_2017_50</tt> and DESDM post-<a href=\"https://jira.lsstcorp.org/browse/DM-12983\" title=\"QCFramework error: descriptor &#39;write&#39; requires a &#39;file&#39; object but received a &#39;str&#39;\" class=\"issue-link\" data-issue-key=\"DM-12983\"><del>DM-12983</del></a>,<a href=\"https://jira.lsstcorp.org/browse/DM-12966\" title=\"SVN version no longer useful? \" class=\"issue-link\" data-issue-key=\"DM-12966\"><del>DM-12966</del></a> fixes.</li>\\t<li>Make new configs, schemas, skymaps for w_2017_50 needed for the mini tests.</li>\\t<li>Don\\'t merge anything to <tt>prod_wcl</tt> as python 3 and other tests continue to be rely on the w_2017_33 version</li></ul>\n",
            "<p>write the draft requirement for Level 3, and its relationship with data space and JupyterHub. </p>\n",
            "nan\n",
            "<p>This epic is started with an examination/test of the FTS3 service, which serves to consolidate<br/>the work with Rucio and GFAL2  of <a href=\"https://jira.lsstcorp.org/browse/DM-10707\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/DM-10707</a> and<br/><a href=\"https://jira.lsstcorp.org/browse/DM-11844\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/DM-11844</a> , and transition to initial work to support the spectrograph.</p><p>FTS3 (main site <a href=\"http://fts3-service.web.cern.ch\" class=\"external-link\" rel=\"nofollow\">http://fts3-service.web.cern.ch</a> , docs <a href=\"http://fts3-docs.web.cern.ch/fts3-docs/\" class=\"external-link\" rel=\"nofollow\">http://fts3-docs.web.cern.ch/fts3-docs/</a> )<br/>is the reliable file transfer service that is used by experiments at CERN (ATLAS, CMS, etc) to<br/>transfer data globally for processing. As such it is a mature, tested service that provides monitoring and summaries of transfers that have been submitted for management.<br/>FTS3 utilizes GFAL2 (<a href=\"https://dmc.web.cern.ch/projects/gfal-2/home\" class=\"external-link\" rel=\"nofollow\">https://dmc.web.cern.ch/projects/gfal-2/home</a>) to implement transfers for numerous commonly used protocols with a single API.  Here we show the submission of some test transfers to an FTS3 instance at NCSA using fts3-client commands and the monitoring interfaces that, for example, could enable multiple sites within a collaboration to follow the progress &amp; status of intersite transfers.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=astier\" class=\"user-hover\" rel=\"astier\">Pierre Astier</a> added work in <tt>u/fix_outliers</tt> to better manage photometry errors and outlier rejection. This ticket is to review that work and see if it fixes the problems with HSC processing on the constrained model.</p>\n",
            "<p>Reprocess the HSC RC dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2017_50.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p>\n",
            "<p>This ticket is to create a test plan in LDM-533 for the LDM-503-3 milestone occurring this cycle.</p>\n",
            "<p>The updated deblender does not have useful docstrings, so to assist with <a href=\"https://jira.lsstcorp.org/browse/DM-12404\" title=\"Update stack with new deblender API\" class=\"issue-link\" data-issue-key=\"DM-12404\"><del>DM-12404</del></a> (and make sure that I understand the new API) I am writing docstrings for all of the new classes and methods.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Add logging to LSST the Docs Keeper to enable basic monitoring of the service. Use structlog (<a href=\"http://www.structlog.org/en/stable/\" class=\"external-link\" rel=\"nofollow\">http://www.structlog.org/en/stable/</a>) to get JSON-formatted log messages that can be easily parsed by ELK or Stackdriver. Logs will go to stdout so that any log shipper can get them.</p>\n",
            "\"<p>Reduce technical debt in how we create Docker releases and versions for LSST the Docs applications.</p><ol>\\t<li>Use <tt>setuptools_scm</tt> to create semantic versions for the LTD Keeper and Dasher applications based on the repo's Git tag state.</li>\\t<li>Convert Keeper and Dasher to setuptools projects to use <tt>setuptools_scm</tt>.</li>\\t<li>Create a Makefile to create a Docker image that automatically inserts the version information.</li>\\t<li>Create a Travis CD pipeline that uploads to Docker Hub when a new tag or branch is available.</li>\\t<li>Create an API route that exposes the Keeper API version.</li></ol>\"\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>With <a href=\"https://jira.lsstcorp.org/browse/DM-12356\" title=\"Support document release workflow with LSST the Docs\" class=\"issue-link\" data-issue-key=\"DM-12356\"><del>DM-12356</del></a> I found it hard to fully deploy the LTD Keeper app in a staging namespace from scratch, indicating that some technical debt has crept into the deployment process. This ticket is to systematically go through the deployment and resolve documentation and deployment processes.</p>\n",
            "<p>QA drill-down using the interactive QA tools requires viewing image data; ideally attached to some callback, such as clicking on a point in a scatter plot or sky plot.  Do some preliminary investigation of how this might work.</p>\n",
            "<p>For interactive QA drill-down, especially when investigating repeatability metrics, enable a simple plot to quickly scroll through the individual visit-level sky plots of the visits that went into a particular coadd region.  </p>\n",
            "\"<p>auth_data isn't getting refreshed on login, so we never get a list of new containers.</p>\"\n",
            "<p>backup file lists are occasionally empty. Find and fix issue.</p>\n",
            "\"<p>Thus far I've been clipping any any region for which we don't have information from the PSF-matched warp. This includes more area than direct warp because of  matching kernel smears out the bad pixels and edges of calexps.  Test allowing saturated pixels through. Merge if it works. </p>\"\n",
            "<p>AssociationTask currently passes a circle on the sky to load DIAObject/Source from the database wrapper rather than the precise CCD BoundingBox. This means that the metric \"Fraction of known previously-known DiaObjects that have detections in a new difference image.\" in <a href=\"https://jira.lsstcorp.org/browse/DM-11155\" title=\"Implement object count metrics\" class=\"issue-link\" data-issue-key=\"DM-11155\"><del>DM-11155</del></a> will difficult to interpret as the DIAObjects loaded represent a larger area than the CCD of the current exposure.</p><p>This ticket will implement this cut to the CCD BoundingBox by parroting the _trimToBBox method of LoadReferenceObjectsTask.</p>\n",
            "<p>To be discussed at DMLT of 2017-11-20. Not the final plan: will still need to be refined in conjunction with science leadership &amp; developers.</p>\n",
            "<p>Reprocess the HSC RC dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2017_48.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p>\n",
            "<p>Currently <tt>ap_pipe</tt> processes one CCD visit at a time.  For  <a href=\"https://jira.lsstcorp.org/browse/DM-12534\" title=\"Write test report for LDM-503-3\" class=\"issue-link\" data-issue-key=\"DM-12534\"><del>DM-12534</del></a> we need to run over the full MVS HITS repository.  This may involve writing a temporary loop or wrapper until we complete <a href=\"https://jira.lsstcorp.org/browse/DM-11372\" title=\"Create CommandLineTask utility in `ap_pipe`\" class=\"issue-link\" data-issue-key=\"DM-11372\"><del>DM-11372</del></a>, which would allow <tt>ap_pipe</tt> to process multiple visits at once.</p>\n",
            "<p>Given the outliers from <a href=\"https://jira.lsstcorp.org/browse/DM-12422\" class=\"external-link\" rel=\"nofollow\">DM-12422</a>, create code which generates a library of postage stamps and a measurement catalog of objects which fail shape measurement in some way.</p><p>These failures may be related to:</p><ul class=\"alternate\" type=\"square\">\\t<li>size vs. magnitude</li>\\t<li>shapes smaller than the PSF</li>\\t<li>Objects which are flagged</li></ul>\n",
            "<p>Reprocess the HSC RC dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2017_46.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<ul>\\t<li>Document Data Distribution</li>\\t<li>Create structure for DAX doc</li>\\t<li>Bring over Provenance documentation from prov_prototype</li>\\t<li>Update LDM-135 to reflect the updates to the storage/IO model</li>\\t<li>Update LDM-152</li>\\t<li>Fix LDM-135: 3.3.6.4 and 3.3.6.5 should be 3rd level, so 3.3.7 and 3.3.8</li></ul>\n",
            "<p>The specification for the data model of imageREST_v1 is based on the standard JSON schema specification: <a href=\"http://json-schema.org\" class=\"external-link\" rel=\"nofollow\">http://json-schema.org</a>.</p><p>The schema validator package for JSON-based queries is available on Github: <a href=\"https://github.com/Julian/jsonschema\" class=\"external-link\" rel=\"nofollow\">https://github.com/Julian/jsonschema</a>.</p>\n",
            "<p>Add documentation in reStructuredText format to the display_firefly package, in a doc/ subdirectory. The documentation will include setup of the afw.display interface, including the host, port, etc. parameters that are specific to display_firefly. Other points (like known issues) unique to display_firefly will be covered.</p><p>display_firefly is not yet included with lsst_apps or lsst_distrib. Initially, an Installation section will be included. It is expected to replace the contents with links to centralized pages on how to install additional packages against a core stack installation.</p><p>Copied for pull request  <a href=\"https://github.com/lsst/display_firefly/pull/7\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst/display_firefly/pull/7</a></p><ul>\\t<li>Add doc/_static placeholder README</li>\\t<li>setup initial files following validate_base as template</li>\\t<li>add installation, start tutorial</li>\\t<li>ignore eupspkg directory</li>\\t<li>add setup of display_firefly for Python API ref</li>\\t<li>add introduction, installation content</li>\\t<li>fill out rest of Using... section</li>\\t<li>Pin Sphinx&lt;1.6.0</li>\\t<li>Various reStructuredText formatting fixes</li>\\t<li>reformat Makefile</li>\\t<li>Merge branch \\'tickets/<a href=\"https://jira.lsstcorp.org/browse/DM-11017\" title=\"Create temporary documentation deployment for display_firefly\" class=\"issue-link\" data-issue-key=\"DM-11017\"><del>DM-11017</del></a>\\' into tickets/<a href=\"https://jira.lsstcorp.org/browse/DM-10601\" title=\"Add reStructuredText documentation to display_firefly\" class=\"issue-link\" data-issue-key=\"DM-10601\"><del>DM-10601</del></a></li></ul>\n",
            "<p>Process the 3 tracts of the HSC RC data with</p><ul class=\"alternate\" type=\"square\">\\t<li>DESDM framework packages, plugins and integration codes <tt>BPSstack</tt> tag <tt>lsstv14-desdmv1.01</tt>. This version is based on Stack v14.0</li>\\t<li>wcl as of <a href=\"https://jira.lsstcorp.org/browse/DM-12590\" title=\"Minor improvements in prod_wcl\" class=\"issue-link\" data-issue-key=\"DM-12590\"><del>DM-12590</del></a> (<a href=\"https://github.com/lsst-dm/prod_wcl/commit/f6efaaabecfaee4a70c02aea0d5ae92823027340\" class=\"external-link\" rel=\"nofollow\">f6efaaa</a>)</li></ul>\n",
            "<p>Perform the \"basic data completeness and integrity checks\" following the procedues in  <a href=\"https://jira.lsstcorp.org/browse/DM-12605\" title=\"Draft an initial version of the test case specification DRP-00-05 in LDM-534 \" class=\"issue-link\" data-issue-key=\"DM-12605\"><del>DM-12605</del></a>\\'s LDM-534 test case DRP-00-05 (sect. 4.2.8.3)</p>\n",
            "<p>Diagram the architectural overview of monitoring for all physical ocations.</p>\n",
            "nan\n",
            "<p><tt>despyastro</tt> is one of the packages DESDM framework consist of. The goal is to port it to Python 3.</p>\n",
            "<p><tt>DatabaseApps</tt> is one of the packages DESDM framework consist of. The goal is to port it to Python 3.</p>\n",
            "<p><tt>depydb</tt> is one of the packages DESDM framework consist of. The goal is to port it to Python 3.</p>\n",
            "<p><tt>IntegrationUtils</tt> is one of the packages DESDM framework consist of. The goal is to port it to Python 3.</p>\n",
            "nan\n",
            "nan\n",
            "<p>The info button show the FITS head for FITS,  it should show the properties for HiPS when HiPS image is displayed.</p>\n",
            "<p>Brief Jenkins job reference and stack-os-matrix how-to guides for ci.lsst.codes that will be published in developer.lsst.io. An extension of <a href=\"https://jira.lsstcorp.org/browse/DM-12107\" title=\"add CI (jenkins) to developers docs\" class=\"issue-link\" data-issue-key=\"DM-12107\"><del>DM-12107</del></a>.</p>\n",
            "<p>Represent Alert Production in the Lossy Compression Working Group. This is mainly expected to involve communicating with other AP stakeholders regarding plans, requirements, and necessary tests to show that a compressed dataset is \"good enough\".</p>\n",
            "<p>Revise the DCR technote DMTN-037 based on feedback received on the initial full draft.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=krughoff\" class=\"user-hover\" rel=\"krughoff\">Simon Krughoff</a> has requested that in addition to the <tt>master</tt> branch, that the <tt>tickets/<a href=\"https://jira.lsstcorp.org/browse/DM-12253\" title=\"Port validate_drp to lsst.verify\" class=\"issue-link\" data-issue-key=\"DM-12253\"><del>DM-12253</del></a></tt> branch of <tt>lsst/validate_drp</tt> also be run.</p><p>As the output of this branch is not expected to be compatible with <tt>post-qa</tt>, and squash has no facility for tracking input from multiple branches, the output of the alternative branch should be archived and not submitted to squash.</p>\n",
            "<p>Make a deep training set for BFD with different noise properties than the main sample, and make it possible for BFD to run with this training set.</p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=astier\" class=\"user-hover\" rel=\"astier\">Pierre Astier</a> and <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=boutigny\" class=\"user-hover\" rel=\"boutigny\">Dominique Boutigny</a> found a few bugs in jointcal\\'s constrained models that were causing cholmod factorization failures and/or improper fits. I need to implement those changes before doing the meas_mosaic comparison.</p>\n",
            "<p>This includes understanding the plan as currently constituted and figuring how how to sensible extend it for another three months.</p>\n",
            "nan\n",
            "nan\n",
            "\"<p>There appears to be a problem with the interface between the stack and the deblender. In the attached images, stack_output shows the data and the footprints created from the stack results, while deblender_output shows the results when the deblender is run using the exact same settings. This shows that somehow the results aren't being persisted properly in the pipeline.</p><p>This ticket is to investigate includes work the last few days to diagnose the problem and upcoming work to find and fix the bug.</p>\"\n",
            "<p>Fork eotest package and port to py3, and then make PR to upstream</p>\n",
            "<p>We are now developing DM change-controlled documents using latex but we have no documented policy for this or a description of the process. The process is slightly different to code development and involves specific requirements for review and release.</p><p>Add a section to the developer guide.</p>\n",
            "<p>Wil, Frossie, Tim, and I have discussed a new change-controlled document Git repository workflow to replace the current policy (release on master, work on draft).</p><p>The basic features of the new workflow are:</p><ul class=\"alternate\" type=\"square\">\\t<li>Development on master in ticket branches. In general, document development should mirror code development workflows.</li>\\t<li>Release branches (named after the corresponding RFC or LCR) that are never merged back to master.</li>\\t<li>The release manager backports commits on the release branches (amendments requested by a CCB) to the master branch.</li>\\t<li>Tags for docushare upload number and document version.</li>\\t<li>A moving tag for the docushare preferred version.</li></ul><p>These tags are an API for LSST the Docs (lsst.io) and for future DocuShare automation.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>SQuaSH database backups required alpha features enabled to use CronJob resource (batch/v2alpha1)</p><p>This has been deprecated and cluster version 1.8 switchs to batch/v1beta1 which is enabled by default in the API server. </p><p>Also we need to fix the <tt>squash-dash.lsst.codes</tt> -&gt; <tt>squash.lsst.codes</tt> creation which is done manual currently.</p>\n",
            "<p>The current bandpass implementation leads to an inaccurate effective wavelength calculation for DCR. That implementation should change, and the way the bandpass is used throughout the prototype code should be updated</p>\n",
            "\"<p>Attend Michael Strauss and Jenny Greene's observational galactic astronomy class to better understand the scientific applications of the deblender.</p>\"\n",
            "<p>Once we have useable coadds from the HiTS 2014 fields matching our HiTS 2015 dataset, these should be used as templates for the AP prototype pipeline (soon to be <tt>ap_pipe</tt>). The pipeline will still accept another visit as a template, but the default will be to use the coadds from a specific location in the dataset repo.</p>\n",
            "\"<p>Until we have butler metrics persistence system, we can use a dedicated logger to output each product's metrics. Since jointcal is the testbed for the new metrics system, we'll use it as an example for how to produce those logs.</p>\"\n",
            "<p>We want to use CILogon as source of truth, but also do the GitHub magic.</p>\n",
            "<p>Similar to SwiftStorage, this allows existing LSST science code that uses the Butler for local filesystem repositories to send those objects to repositories in S3 containers.</p>\n",
            "<p>We need to be able to put a registry in a mysql database and access it via MySqlStorage. </p><p>TBD if this should be done by refactoring or duplicating the sqlite registry to work with mysql, or if there should be a formatter to write sqlite3 registries to mysql databases. Or, if it should be done another way.</p>\n",
            "<p>For evolvability, we need to track the serialization version of persisted datasets  with the datasets in the database.</p><p>This will be at least partly implemented by the daf_io afw_table database serializer &amp; deserializer. If there are any requirements imposed on <tt>daf_fmt_mysql</tt> or Butler this is the story to implement those.</p>\n",
            "<p>From the recent HSC data we know that the performance of the PSF modeling code, PSFEx, is poor when the seeing is &lt; ~0.45\".  Robert Lupton found that the single pixel basis functions of the PSF model were being Lanczos interpolated.  He updated the code to use the overlap of model basis with the original pixels.  This ticket implements his change.</p>\n",
            "<p>Set default configs for makeCoaddTempExp, assembleCoadd, and coaddDriver in pipe_tasks and obs_subaru based on testing results.</p><p>These include the usual obs_subaru defaults for AssembleTask and SafeClipAssembleTask and more.  For example, these will probably include these configs:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.makeCoaddTempExp.makePsfMatched=True</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.makeCoaddTempExp.warpAndPsfMatch.psfMatch.kernel[\\'AL\\'].kernelSize=29</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.makeCoaddTempExp.warpAndPsfMatch.psfMatch.kernel[\\'AL\\'].alardSigGauss=[1.0, 2.0, 4.5]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.makeCoaddTempExp.modelPsf.defaultFwhm=6.1</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">from lsst.pipe.tasks.assembleCoadd import CompareWarpAssembleCoaddTask</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.retarget(CompareWarpAssembleCoaddTask)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.badMaskPlanes = (\"BAD\", \"EDGE\", \"SAT\", \"INTRP\", \"NO_DATA\",)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.doSigmaClip = False</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.subregionSize = (10000, 200) # 200 rows (since patch width is typically &lt; 10k pixels)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.doMaskBrightObjects = True</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.sigmaClip = 1.5</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.clipIter = 3</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.assembleStaticSkyModel.sigmaClip = 1.5</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.assembleStaticSkyModel.clipIter = 3</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.assembleStaticSkyModel.statistic = \\'MEANCLIP\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.doNImage=True</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">config.assembleCoadd.doWrite=True</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>Recent improvements to the <tt>firefly_client</tt> package need to be gathered into a v1.2 release due to some API changes. At an appropriate point, tag this version, publish to PyPI (for <tt>pip install firefly_client</tt>, and synchronize the fork in the lsst Github org.</p>\n",
            "<p>Make one coadd patch both ways, subtract, verify that the residuals are negligible.</p>\n",
            "<p>Write up instructions on how to install Kubernetes 1.8.3 on Openstack for a master node and two worker nodes.   Also include instructions on how to install a local registry and how to verify the local registry is working.</p><p>This will later  be used by the admin create Puppet scripts to do this installation.</p>\n",
            "<p>With <a href=\"https://dmtn-030.lsst.io\" class=\"external-link\" rel=\"nofollow\">DMTN-030</a> we have a conceptual design for Science Pipelines package documentation design. I\\'ve realized part of that concept in <tt>pipe_base</tt> documentation (<a href=\"https://jira.lsstcorp.org/browse/DM-1253\" title=\"Requirements gathering for Metadata Store\" class=\"issue-link\" data-issue-key=\"DM-1253\"><del>DM-1253</del></a>). The next step is to document these content patterns and the Git repository layout more precisely so that the <tt>pipe_base</tt> documentation effort can be replicated by anyone in any other package.</p><p>I think we want to continue to use the <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">lsst/templates</a> repository for this type of package documentation. Two key issues with <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">lsst/templates</a> are:</p><ol>\\t<li>It\\'s filled with non-essential content (like a pybind11 example)</li>\\t<li>It\\'s hard in that example format to document libraries of repeatable content snippets, like Task documentation pages, for example, that aren\\'t essential parts of a package, but <em>are</em> nontheless standardized.</li></ol><p>This ticket is intended to prototype a new organization of the <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">lsst/templates</a> repository that allows more effective documentation of both package structure and documentation templates.</p><p>Some design goals are:</p><ul class=\"alternate\" type=\"square\">\\t<li>Eventual compatibility with <a href=\"http://cookiecutter.readthedocs.io\" class=\"external-link\" rel=\"nofollow\">cookiecutter</a>.</li>\\t<li>Ability to document repeating content fragments in a way where an original source of truth is clear, and that templated information is propagated throughout the template project.</li>\\t<li>Ability to have template documentation alongside the template itself.</li></ul><p>On a practical level, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=krughoff\" class=\"user-hover\" rel=\"krughoff\">Simon Krughoff</a> notes that <a href=\"https://github.com/lsst/obs_test\" class=\"external-link\" rel=\"nofollow\">obs_test</a> is probably a more up-to-date example of a package than the <a href=\"https://github.com/lsst/templates\" class=\"external-link\" rel=\"nofollow\">lsst/templates</a> repository is.</p>\n",
            "<p>Add the small support classes needed to prototype Registries: DatasetType, the DatasetRef hierarchy, DataUnits, StorageClass, Quantum, and Run.</p>\n",
            "\"<p>Create test data for a Registry database corresponding to what's in ci_hsc: tables for Datasets, DataUnits (including SkyMaps).</p><p>For now, this will make it much easier to write unit tests for Registry and is support classes.  In the long term, it should let us test conversion of CmdLineTasks to SuperTasks.</p>\"\n",
            "<p>Following review comments on <a href=\"https://jira.lsstcorp.org/browse/DM-12429\" title=\"Migrate obs_comCam .paf policy file to yaml format\" class=\"issue-link\" data-issue-key=\"DM-12429\"><del>DM-12429</del></a>, the policy for obs_comCam is not the minimal required to produce the same functionality, as a lot of things are redefined identically to how they are defined for the default in obs_base. This ticket is to make a best-effort at improving that situation, <em>and</em> to fix a number of places in the path templates that are not currently correct (this is a newish obs_package and they were born wrong).</p>\n",
            "\"<p>Prepare initial set of SysML diagrams of the SUIT's relationship to other system components.</p>\"\n",
            "<p>Firefly_client needs to be updated after <a href=\"https://jira.lsstcorp.org/browse/DM-11601\" title=\"Update plotting API and related dispatcher\" class=\"issue-link\" data-issue-key=\"DM-11601\"><del>DM-11601</del></a></p>\n",
            "<p>Rebuild spawner options form without needing to redeploy Hub.</p>\n",
            "<p>The GitHub extension is published.  I will be investigating to see how much work we have to do to make it work with our magic GH stuff we already have.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Implement a testbed for GraphQL using django-graphene and implement a  proof of concept GraphQL Schema to query the Metrics/Measurements</p>\n",
            "<p>This started back in the August 2016 AHM from discussions with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=ctslater\" class=\"user-hover\" rel=\"ctslater\">Colin Slater</a> when we explored ways of embedding SQuaSH bokeh apps in Jupyter.</p><p>Bokeh apps  are the building blocks of SQuaSH, and the SQuaSH architecture is such that the apps can run independently of each other (see <a href=\"https://github.com/lsst-sqre/squash-deployment\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/squash-deployment</a>)</p><p>Currently SQuaSH bokeh apps can be reached from:</p><p><a href=\"https://squash-bokeh.lsst.codes\" class=\"external-link\" rel=\"nofollow\">https://squash-bokeh.lsst.codes</a></p><p>1) One approach is to embed a bokeh app running elsewhere in the notebook. In this scenario the bokeh app is served by SQuaSH and used inside the notebook to help on the data analysis task.</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">from IPython.display </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> HTML, display</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">from bokeh.embed </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">import</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> server_document</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">script = server_document(url=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'https://squash-bokeh.lsst.codes/monitor\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">display(HTML(script))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>It works on a classical Jupyter notebook running locally if we add  `localhost:8888` to the bokeh server `--allow-websocket-origin` option.  </p><p>NOTE: Embeding a bokeh server app still doesn\\'t work on JupyterLab, see status at <a href=\"https://github.com/bokeh/bokeh/issues/6700\" class=\"external-link\" rel=\"nofollow\">https://github.com/bokeh/bokeh/issues/6700</a></p><p>2) Another approach is to run the bokeh server locally on the notebook. In doing so we can use the notebook environment to develop bokeh apps that later can be deployed to SQuaSH. That\\'s an interesting workflow. </p><p>See for instance: <a href=\"https://bokeh.github.io/blog/2017/6/29/simple_bokeh_server/\" class=\"external-link\" rel=\"nofollow\">https://bokeh.github.io/blog/2017/6/29/simple_bokeh_server/</a></p><p>Holoviews simplifies this workflow further <a href=\"http://holoviews.org/user_guide/Deploying_Bokeh_Apps.html\" class=\"external-link\" rel=\"nofollow\">http://holoviews.org/user_guide/Deploying_Bokeh_Apps.html</a></p><p>The goal of this ticket is to explore holoviews + bokeh for creating interactive visualizations and dashboards in the notebook environment. As a proof of concept we\\'ll reproduce one of the SQuaSH bokeh apps using holoviews + bokeh. </p>\n",
            "<p>The datashader solution that allows the plotting of millions of datapoints (<a href=\"https://jira.lsstcorp.org/browse/DM-11405\" title=\"Investigate using datashader for density plots of large datasets\" class=\"issue-link\" data-issue-key=\"DM-11405\"><del>DM-11405</del></a>) changes how linking the marginal histograms to the selection box must be implemented, and how dataIDs might be obtained from the figures.  That is, because it is now an image rather than a plot containing information about each points, the hover/select features that I had used for <a href=\"https://jira.lsstcorp.org/browse/DM-10619\" title=\"Build a prototype bokeh server implementation to demonstrate desired interactive QA plots\" class=\"issue-link\" data-issue-key=\"DM-10619\"><del>DM-10619</del></a> must be updated.  I propose to have a secondary \"zoom-in\" figure on the dashboard that <b>is</b> a bokeh scatter plot (thus allowing typical bokeh hover/selection), but would show the region selected in the primary datashader figure.  It will be capped at maybe ~5000 points, beyond which holoviews/bokeh will \"decimate\" the figure by random sampling.   The marginal histograms, though, should be able to remain the distributions of the full un-decimated dataset (or selection thereof).</p><p>In this ticket, implement the following alongside the datashader demo:</p><ul>\\t<li>Decimated bokeh plot corresponding to selection</li>\\t<li>Marginal histogram figures computed from the full dataset (or selection thereupon), corresponding to what was done for <a href=\"https://jira.lsstcorp.org/browse/DM-10619\" title=\"Build a prototype bokeh server implementation to demonstrate desired interactive QA plots\" class=\"issue-link\" data-issue-key=\"DM-10619\"><del>DM-10619</del></a>.</li>\\t<li>Some way for <b>all</b> the dataIDs in a region selected on the datashader image to be returned, for use in a callback</li></ul>\n",
            "<p>We observed in S15 tests that if we run too many queries, czar is running out of connections to mysql and as a result through exception that is uncaught (and dies). We triggered this by starting 110 queries. To \"fix\" this problem we increased the max_connections in etc/my.cnf from 256 to 512. So, most likely the easiest way to reproduce it would be to set the max_connections to a very small number. </p><p>This story involves handling the \"uncaught exception\" gracefully.</p>\n",
            "<p>When we are analyzing a query, sometimes there are situations where we need to know the schema of tables involved in a query. It will also be useful for checking if user is authorized to run query, and for queries like \"SHOW CREATE TABLE\". This story involves writing code that will provide access to schema.</p>\n",
            "nan\n",
            "<p>Webpack currently inserts such things MODULE_NAME, SCRIPT_NAME, help.base.url we want to change how we are doing build time global varibles so it inserts only one object such as `fireflyGlobals` then we have an accessor function.</p>\n",
            "<p>Reprocess the HSC RC dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2017_44.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p>\n",
            "<p>When running naively as command line tasks, the default of makeCoaddTempExp.py and assembleCoadd.py is to <a href=\"https://github.com/lsst/pipe_tasks/blob/w.2017.33/python/lsst/pipe/tasks/coaddBase.py#L59\" class=\"external-link\" rel=\"nofollow\">use WcsSelectImages</a> in the \"select\" subtask. No camera override in obs_subaru/config/(hsc/)makeCoaddTempExp.py or obs_subaru/config/safeClipAssembleCoadd.py so far either. </p><p>However, in coaddDriver, the select subtask is <a href=\"https://github.com/lsst/obs_subaru/blob/w.2017.33/config/coaddDriver.py#L14\" class=\"external-link\" rel=\"nofollow\">retargeted to PsfWcsSelectImagesTask</a> (select is done before makeCoaddTempExp and assembleCoadd subtasks in coaddDriver).</p><p>I\\'m not sure if it is intentional in the Science Pipelines  (e.g. difference between obs_subaru/config/assembleCoadd.py and obs_subaru/config/safeClipAssembleCoadd.py <a href=\"https://jira.lsstcorp.org/browse/DM-10634\" title=\"Check configs for coaddDriver\" class=\"issue-link\" data-issue-key=\"DM-10634\">DM-10634</a>). As the idea of <a href=\"https://jira.lsstcorp.org/browse/DM-12291\" title=\"Production Development for LDM-503-2\" class=\"issue-link\" data-issue-key=\"DM-12291\"><del>DM-12291</del></a> is to follow the pipe_drivers workflow as much as possible, I will override the configs to use   <br/>PsfWcsSelectImagesTask in both makeCoaddTempExp.py and assembleCoadd.py in the tests of <a href=\"https://jira.lsstcorp.org/browse/DM-12291\" title=\"Production Development for LDM-503-2\" class=\"issue-link\" data-issue-key=\"DM-12291\"><del>DM-12291</del></a>. </p>\n",
            "<p>After further work on jointcal, I\\'ve realized that the basic definition of <tt>PhotoCalib</tt> should be multiplicative-<tt>instFlux * zeroPoint(x,y</tt>, instead of the current division-<tt>instFlux * zeroPoint(x,y</tt>. Fortunately, PhotoCalib isn\\'t really used in the stack yet, so now is the time to fix it. Minor changes will also be required in jointcal and meas_mosaic creation of a PhotoCalib for persistence.</p><p>This shouldn\\'t have any impact on the existing API, just on the internal calculations and persistence.</p><p>Not RFCing this, as it was defined this way in the original RFC and we changed it during implementation, and all of the current stakeholders have agreed to the change (<a href=\"https://lsstc.slack.com/archives/C2JPL2DGD/p1505330578000322\" class=\"external-link\" rel=\"nofollow\">slack#dm</a>).</p>\n",
            "\"<p>The illuminated portions of off-axis pupils currently being generated for HSC are off-center in their arrays since the vignetting by the first HSC lens introduces obscuration at a particular azimuthal angle, but the center of the array corresponds to the center of the unvignetted primary mirror.  In Zemax, the pupil is recentered after taking into account this additional obscuration.  I suspect that this makes the Zernike polynomials on the centered pupil closer to orthogonal than the Zernike polynomials on the uncentered pupil.  I'm guessing that the effect on the PSF is just a shift in the image, but this needs to be checked.</p><p>This ticket is to a) investigate the orthogonality of the Zernike polynomials on centered/uncentered vignetted pupils and what effects centering has on the implied PSFs, and b) if it looks interesting, add (optional) pupil recentering to the afw pupil API.</p>\"\n",
            "<p>Define and implement how we\\'ll be making Synpipe available within the LSST stack. That may include treating it as a regular third party package, or tracking it via an LSST fork, or adopting the package entirely.</p><p>Although <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=nlust\" class=\"user-hover\" rel=\"nlust\">Nate Lust</a> will lead this work, <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a> will coordinate with the upstream maintainer (Song Huang) to figure out how we can best cooperate with him.</p><p>This ticket is to make SynPipe able to be installed through the LSST distribution system. Success will be marked when the repository is is put in place such that the fake object insertion tasks are usable be used in the course of LSST processing. Full functionality of all scripts in the repository is not necessary, as that work will be completed on other tickets.  </p>\n",
            "nan\n",
            "nan\n",
            "<p>With one tract of the HSC RC data, run the equivalent steps of singleFrameDriver + coaddDriver + multiBandDriver using DESDM framework as of <a href=\"https://jira.lsstcorp.org/browse/DM-12183\" title=\"Identify a small set of data to allow  a &quot;mini&quot; workflow that contains fringe correction\" class=\"issue-link\" data-issue-key=\"DM-12183\"><del>DM-12183</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-12240\" title=\"Can&#39;t retrieve calibration files because calibRegistry.sqlite3 is misplaced\" class=\"issue-link\" data-issue-key=\"DM-12240\"><del>DM-12240</del></a> (no newer features for now), based on Stack w_2017_33 + <a href=\"https://jira.lsstcorp.org/browse/DM-11857\" title=\"Prepare the stack packages without commas in patch IDs for DESDM test runs\" class=\"issue-link\" data-issue-key=\"DM-11857\"><del>DM-11857</del></a> installation in the /project/production/python2/ space.</p>\n",
            "<p>Davix is a library and tools developed at the IT-SDC-ID section at CERN (<a href=\"https://dmc.web.cern.ch/projects/davix/home\" class=\"external-link\" rel=\"nofollow\">https://dmc.web.cern.ch/projects/davix/home</a>) to \\'make (HTTP) a competitive alternative for high performance I/O and data analysis applications in a global computing grid.\\'  We perform initials test transfers with the \"davix-put\" client against nginx webdav endpoints.</p>\n",
            "<p>We setup webdav servers with nginx on lsst-ddb-fts1.ncsa.illinois.edu and lsst-ddb-fts2.ncsa.illinois.edu, and transient test instances on verification compute nodes for testing. These utilize the nginx-dav-ext-module to support PROPFIND OPTIONS (which are not supported by<br/>default with nginx) , and they use Basic authentication with access via username &amp; password,<br/>and also client x509 certificates.</p>\n",
            "<p>The current test hsc mini wcl does not include filters that need fringe correction, hence no fringe correction is run in that test.  This makes testing the fringe workflow difficult. </p><p>Pick images (visit/ccd IDs) for a new wcl with at least one filter with fringe correction  and at least one without fringe correction. This input data set should be as small as possible. </p>\n",
            "<p>In running makeCoaddTempExp, sometimes warp files would not be created because <tt>directWarp has 0 good pixels (0.0%)</tt> (<a href=\"https://confluence.lsstcorp.org/display/~hchiang2/Collection+of+edge+cases\" class=\"external-link\" rel=\"nofollow\">one example here</a>). If the framework/workflow expects the files, missing the files can be considered as a failure.</p><p>One way to get around this is to blacklist those specific visit/CCDs so to ignore those inputs, then this case never happens.  But figuring out all CCDs to blacklist can be very time consuming (unless with help of new tools). In this ticket, solve the problem by making <tt>deepcoadd_directwarp</tt> an optional output of <tt>make_coadd_temp_exp</tt> (p.s. Part was mistakenly <a href=\"https://github.com/lsst-dm/prod_wcl/commit/0b5d33e9ca6351a5c53aceed1ff3739e9d20b168\" class=\"external-link\" rel=\"nofollow\">merged previously</a>.  The existing tiny tests do not have such cases.)</p><p>This implies splitting the \"drp-patch\" block into two. The first one has only <tt>make_coadd_temp_exp</tt> and allows optional warp outputs.  In the subsequent block a new query is done to use only the available warps from the previous block, rather than everything inferred by the overlap table.  </p>\n",
            "<p>Providing misc. help with pipeline integration into DESDM.</p>\n",
            "<p>Took previous query code and added the capability to query the following tables:</p><ul>\\t<li>ops_calibration_lookup</li>\\t<li>visit_tag</li>\\t<li>blacklist</li></ul><p>(These \"LSST plugins for DESDM\" codes are not yet in LSST-DM git.)</p>\n",
            "<p>The idea is that our current integration test is using \"mono\" configuration which is only useful for integration test but it\\'s not used anywhere else. It would be more useful to have an integration test which is close to real setup, e.g. used more than one worker. It should still be possible to run the whole shebang on a single node though to keep it usable for regular development tasks.</p>\n",
            "<p>We need to constraint the query that loads the measurenents in the monitor, right now we are reading all measurements and it is slow, the ideia is to add a filter called <tt>window</tt> and a select widget place right above the plot showing:</p><ul>\\t<li>Last 3 months</li>\\t<li>Last 6 months</li>\\t<li>Last year</li>\\t<li>All</li></ul>\n",
            "<p>Identify existing project documents that need to be revised to reflect new procedures. e.g., developer documentation on confluence and developer.lsst.io.</p>\n",
            "<p>Create &amp; vet incident response process</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "\"<p>Nearly all many-visit HSC datasets that I've tried to process fail to fit photometry because the chi2 starts out as NaN, resulting in all stars being rejected as outliers and (after a long time) Eigen blowing up. We can't proceed with the photometric part of the meas_mosaic comparison until I can produce a fit.</p><p>Some steps to try:</p><ol>\\t<li>make jointcal fail immediately if chi2 is NaN (write a testcase for this)</li>\\t<li>fit the SimplePhotometryModel instead, to see if that doesn't produce NaN</li>\\t<li>print various input values to look for NaNs</li>\\t<li>Is it worth writing the astrometry output before starting the photometry fit, so we at least have it in case of failure?</li></ol>\"\n",
            "<p>Review with internal science users.</p>\n",
            "nan\n",
            "<p>Receive &amp; unpack hardware. Plan for setup and testing, and ready work area.</p>\n",
            "<p>Post-installation cleanup and decommissioning.</p>\n",
            "nan\n",
            "<p>Recreate characteristic CModel test plots described in <a href=\"https://github.com/dr-guangtou/synpipe/blob/master/draft/synpipe_submit.pdf\" class=\"external-link\" rel=\"nofollow\">https://github.com/dr-guangtou/synpipe/blob/master/draft/synpipe_submit.pdf</a> based on the LSST stack.</p><p>Input data is the latest HSC RC dataset at time of carrying out this work: see <a href=\"https://confluence.lsstcorp.org/display/DM/Reprocessing+of+the+HSC+RC+dataset\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/DM/Reprocessing+of+the+HSC+RC+dataset</a> for details.</p>\n",
            "\"<p>The base DCR algorithm assumes that there is negligible DCR across each DCR model plane's bandwidth. That is typically a good assumption, but very high airmass observations may have DCR with an amplitude of a pixel or more across model planes in g-band. This ticket is to test for and write an approximate correction for those cases. One solution is to increase the number of model planes to reduce the bandwidth of each, but that may not always be possible from lack of data.</p>\"\n",
            "<p><a href=\"https://ci.lsst.codes/job/sqre/job/infrastructure/job/build-jupyterlabdemo/67/consoleFull\" class=\"external-link\" rel=\"nofollow\">https://ci.lsst.codes/job/sqre/job/infrastructure/job/build-jupyterlabdemo/67/consoleFull</a></p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt; npm pack /usr/share/git/jupyterlab-hub</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">npm WARN lifecycle </span><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">@jupyterlab</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/hub-extension</span><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">@0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.4.</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">~prepublish: cannot run in wd %s %s (wd=%s) </span><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">@jupyterlab</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/hub-extension</span><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">@0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.4.</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> npm run build /usr/share/git/jupyterlab-hub</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">jupyterlab-hub-extension-</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0.4</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.tgz</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt; node node-version-check.js</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Uninstalling </span><span style=\"color: gray; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">@jupyterlab</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/hub-extension from /usr/share/jupyter/lab/extensions</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/bin/jupyter-labextension\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">11</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    load_entry_point(</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'jupyterlab==0.28.0.dev0\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'console_scripts\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'jupyter-labextension\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib/python3.4/site-packages/jupyter_core/application.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">267</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in launch_instance</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">super</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">(JupyterApp, cls).launch_instance(argv=argv, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib/python3.4/site-packages/traitlets/config/application.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">658</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in launch_instance</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    app.start()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib/python3.4/site-packages/jupyterlab/labextensions.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">168</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in start</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">super</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">(LabExtensionApp, self).start()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib/python3.4/site-packages/jupyter_core/application.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">256</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in start</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    self.subapp.start()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib/python3.4/site-packages/jupyterlab/labextensions.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">90</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in start</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    raise e</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib/python3.4/site-packages/jupyterlab/labextensions.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">86</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in start</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    build(self.app_dir, logger=self.log)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib/python3.4/site-packages/jupyterlab/commands.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">525</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in build</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> IOLoop.instance().run_sync(func)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib64/python3.4/site-packages/tornado/ioloop.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">458</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in run_sync</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> future_cell[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">].result()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib64/python3.4/site-packages/tornado/concurrent.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">238</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in result</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    raise_exc_info(self._exc_info)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"&lt;string&gt;\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">4</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in raise_exc_info</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib64/python3.4/site-packages/tornado/gen.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1069</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in run</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    yielded = self.gen.send(value)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib/python3.4/site-packages/jupyterlab/commands.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">541</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in build_async</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    _ensure_package(app_dir, name=name, version=version, logger=logger)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib/python3.4/site-packages/jupyterlab/commands.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">823</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in _ensure_package</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    shutil.copy(src, dest)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib64/python3.4/shutil.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">229</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in copy</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    copyfile(src, dst, follow_symlinks=follow_symlinks)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/usr/lib64/python3.4/shutil.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">108</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in copyfile</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    with open(src, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'rb\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">) as fsrc:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">FileNotFoundError: [Errno </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">] No such file or directory: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'/usr/lib/python3.4/site-packages/packages/shortcuts-extension/schema/plugin.json\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">/bin/sh: line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: cd: jupyterlab-savequit: No such file or directory</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">The command </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'/bin/sh -c mkdir -p /usr/share/git &amp;&amp;      cd /usr/share/git &amp;&amp;      npm install -g webpack &amp;&amp;      git clone https://github.com/jupyterhub/jupyterlab-hub.git &amp;&amp;      git clone https://github.com/lsst-sqre/jupyterlab-savequit &amp;&amp;      for i in hub savequit; do      \\t cd jupyterlab-${i} &amp;&amp;          npm install --unsafe-perm &amp;&amp;          python3 /usr/bin/jupyter labextension link . &amp;&amp;          npm run build &amp;&amp;          cd .. ;     done\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> returned a non-zero code: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Docker build failed.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>The <tt>w_2017_38</tt> weekly-release is still in progress. In appears that there may have been some sort of network lurch over the weekend that interrupted the ssh connections between the master and the osx build nodes.  Jenkins reconnected via ssh and was displaying the tarball build pipeline script fragment as running on an osx node, but not progress was being made.  The tarball builds needed to be manually aborted so the <tt>weekly-release</tt> pipeline would retry.</p><p>I suspect that setting timeouts on the tarball builds would avoid this. Also, splitting the tarball builds up into one build per python major version/os/conda env, would make retrying vastly more efficient.</p>\n",
            "<p>As part of the overall shift to use py3 as the default, instead of py2, the \"canonical\" <tt>lsstsw</tt> based build env used for publishing <tt>eupspkg</tt> should also be switched to py3.  This inherently requires removing local state to prevent py2 / py3 linkage problems with previously installed eups products.  Removing the installed eups products would cause the eups <tt>&lt;version&gt;+&lt;build&gt;</tt> sequences to reset.  This can be mitigated by doing an eups distrib install of the most recent nightly release when starting from a clean workspace.</p><p>Additionally, there has long been a desire to migrate the \"canonical\" build off of <tt>lsst-dev</tt>, primarily motivated by performance issues with the filesystem <tt>~lsstsw</tt> resides on.  As this would also inherently involve a loss of state, it is nature to combine these tasks.</p>\n",
            "\"<p>Attend Michael Strauss and Jenny Greene's observational galactic astronomy class to better understand the scientific applications of the deblender.</p>\"\n",
            "\"<p>Attend Michael Strauss and Jenny Greene's observational galactic astronomy class to better understand the scientific applications of the deblender.</p>\"\n",
            "<p>Reprocess the HSC RC dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2017_42.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p>\n",
            "<p>Part two of the v14 release installation instructions update. This ticket follows on <a href=\"https://jira.lsstcorp.org/browse/DM-10636\" title=\"v14 pipelines.lsst.io installation guide update\" class=\"issue-link\" data-issue-key=\"DM-10636\"><del>DM-10636</del></a>, which is already merged to the v14 integration branch. The goals of this ticket are:</p><ul class=\"alternate\" type=\"square\">\\t<li>Copy edit new content from <a href=\"https://jira.lsstcorp.org/browse/DM-10636\" title=\"v14 pipelines.lsst.io installation guide update\" class=\"issue-link\" data-issue-key=\"DM-10636\"><del>DM-10636</del></a>.</li>\\t<li>Improve installation instructions based on early user feedback (particularly around binaries).</li></ul><p>See also <a href=\"https://jira.lsstcorp.org/browse/DM-11936\" title=\"Document Science Pipelines Platforms in Prerequisites\" class=\"issue-link\" data-issue-key=\"DM-11936\"><del>DM-11936</del></a> for an update to how supported platforms are documented.</p>\n",
            "<p>The DCR matched template code has dependencies on sims packages that might be replaced with functionality from core software. Once <a href=\"https://jira.lsstcorp.org/browse/DM-9615\" title=\"Convert DCR code to use Tasks\" class=\"issue-link\" data-issue-key=\"DM-9615\"><del>DM-9615</del></a> is completed, some of these (such as the bandpass) may be obtained from the relevant obs package.</p>\n",
            "<p>When the DM OCS Bridge sends a Next Visit event, or an event published within the exposure sequence, the DMCS must catch this message and react accordingly. This behavior is only started in this story; one event is wired into DM Component code permanently, but the other exposure events are, for now, being caught and logged for the Pathfinder activity.</p>\n",
            "<p>Investigate the memory usage with one example of coaddDriver.  Consider one fixed small set of input data.</p>\n",
            "<p>Reprocess the HSC RC dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2017_40.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p>\n",
            "nan\n",
            "nan\n",
            "<p>Based on the plans in <a href=\"https://jira.lsstcorp.org/browse/DM-7846\" title=\"Redraft and revise straw-man DRP plan\" class=\"issue-link\" data-issue-key=\"DM-7846\"><del>DM-7846</del></a> and <a href=\"https://jira.lsstcorp.org/browse/DM-7860\" title=\"Produce straw-man plan for Calibration Products Pipeline \" class=\"issue-link\" data-issue-key=\"DM-7860\"><del>DM-7860</del></a>, develop a new set of planning packages for DRP and CPP in Excel sheet form.</p>\n",
            "<p>Meet with Jim &amp; Simon. Discuss the Software Primitives section of LDM-151: clarify any ambiguities and perform an initial resource loading estimate.</p>\n",
            "<p>Meet with Jim &amp; Simon. Discuss the Algorithmic Components section of LDM-151: clarify any ambiguities and perform an initial resource loading estimate</p>\n",
            "<p>While several updates have been made to the visit and coadd scripts, the run comparison and color analysis scripts have suffered some bitrot.  Please update the visit and coadd run comparison scripts and the coadd color analysis script to current APIs.</p>\n",
            "<p>There is existing comment inside imageREST_v1.py mentioning the desirability of writing Image object to data object in memory instead of to a temporary FITS file, then reading it into memory, to improve image response performance and avoidance of using temp files in the local file system. </p><p>Since afw.Image does not provide an existing/ready method to do so, some investigation of alternative ways of doing this is warranted.</p>\n",
            "<p>The good-seeing ImageSelector ported in <a href=\"https://jira.lsstcorp.org/browse/DM-10977\" title=\"Share ImageSelector from Twinkles\" class=\"issue-link\" data-issue-key=\"DM-10977\"><del>DM-10977</del></a> seems to be extremely slow compared to passing the visit ids directly to selectID.  This ticket is to investigate the cause of the slowness and see if it can be mitigated.</p>\n",
            "<p>For running a <tt>ctrl_pool</tt>/<tt>pipe_driver</tt> task such as <tt>singleFrameDriver</tt>/<tt>coaddDriver</tt>/<tt>multiBandDriver</tt>, the memory usage reported by <tt>sacct</tt> on <tt>lsst-dev</tt> seems too small to be true. Research other methods and estimate memory usage of a <tt>ctrl_pool</tt>/<tt>pipe_driver</tt> job. </p>\n",
            "<p>Issues found during the end-to-end test of the <tt>squash-deployment</tt></p>\n",
            "\"<p>For PDF landing pages (Lander project), determine the revision date metadata for an lsstdoc-based LaTeX document through these methods, in priority:</p><p>1. Date provided in <tt>\\\\date</tt> command<br/>2. Git timestamp for the most recent commit that affected document content.<br/>3. Run time</p><p>This will make the revision dates posted on the document landing pages more consistent with the dates printed in the PDF. It will also prevent the post revision date from changing for administrative commits to a document's repo.</p>\"\n",
            "\"<p>This effort includes component use for each machine, subnet location, initial software installation, security key schema, 'Nobody' user accounts for each task on each machine, connection schema for DAQ crate, and sudoers entries for specific capabilities where necessary. </p>\"\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Where ever possible, missing dep information and patches from conda-lsst should be upstreamed.  The patches have already been observed to cause builds to fail due to upstream changes.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Starting with the min test wcl file from <a href=\"https://jira.lsstcorp.org/browse/DM-10474\" title=\"Report prototype file management using DESDM framework\" class=\"issue-link\" data-issue-key=\"DM-10474\"><del>DM-10474</del></a>, go through the junk tar balls and add new filetypes as needed.  Ignore those that were renamed to allow Butler to locate the files. </p><p>Files needed to be taken care of are: </p><ul class=\"alternate\" type=\"square\">\\t<li>SRCMATCH</li>\\t<li>SRCMATCHFULL</li>\\t<li>ICSRC</li>\\t<li>BKGD</li>\\t<li>metadata boost files</li>\\t<li>thumbs pngs<br/>If possible, also do:</li>\\t<li>(output) schema files</li>\\t<li>(output) config files</li>\\t<li>package version pickes</li></ul>\n",
            "nan\n",
            "nan\n",
            "<p>Details:</p><ul>\\t<li>tbl_id in data</li>\\t<li>syntax- \"table::column\" or \"table::expression\"</li></ul>\n",
            "<p>Following <a href=\"https://jira.lsstcorp.org/browse/DM-11924\" title=\"Create tests for obs_ctio0m9\" class=\"issue-link\" data-issue-key=\"DM-11924\">DM-11924</a>, get ci_ctio0m9 up and running, create a JIRA component for it, and get it run as part of the standard CI tests.</p>\n",
            "<p>Submit plan and estimate to project. Address concerns and feedback.</p>\n",
            "<p>After resolution of <a href=\"https://jira.lsstcorp.org/browse/DM-11410\" title=\"validate_drp incorrectly outputs filenames as &#39;_&lt;filter&gt;.json&#39;\" class=\"issue-link\" data-issue-key=\"DM-11410\"><del>DM-11410</del></a>, the <tt>hsc</tt> dataset has a new failure mode:</p><p><a href=\"https://ci.lsst.codes/job/sqre/job/validate_drp/1018/dataset=hsc,label=centos-7,python=py2/console\" class=\"external-link\" rel=\"nofollow\">https://ci.lsst.codes/job/sqre/job/validate_drp/1018/dataset=hsc,label=centos-7,python=py2/console</a></p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">root INFO: Loading config overrride file u</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/obs_subaru/13.0-41-g9300a79+5/config/hsc/makeDiscreteSkyMap.py\\'</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/pipe_tasks/13.0-50-gf3eeffc+5/bin/makeDiscreteSkyMap.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">25</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in &lt;module&gt;</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    MakeDiscreteSkyMapTask.parseAndRun()</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/pipe_base/13.0-11-gdf6a56c+9/python/lsst/pipe/base/cmdLineTask.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">526</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in parseAndRun</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    parsedCmd = argumentParser.parse_args(config=config, args=args, log=log, override=cls.applyOverrides)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/pipe_base/13.0-11-gdf6a56c+9/python/lsst/pipe/base/argumentParser.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">514</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in parse_args</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    namespace.butler = dafPersist.Butler(inputs=inputs, outputs=outputs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/daf_persistence/13.0-29-g32a3f02/python/lsst/daf/persistence/butler.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">531</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in __init__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    self._setAndVerifyParentsLists(repoDataList)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/lsstsw/stack/Linux64/daf_persistence/13.0-29-g32a3f02/python/lsst/daf/persistence/butler.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">914</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in _setAndVerifyParentsLists</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    parents, repoData.cfg.parents, e))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">RuntimeError: Inputs of </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">this</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> Butler:[RepositoryCfg(root=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'../..\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, mapper=&lt;</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'lsst.obs.hsc.hscMapper.HscMapper\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;, mapperArgs={</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'calibRoot\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/validation_data_hsc/CALIB\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}, parents=[], policy=None), RepositoryCfg(root=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'../..\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, mapper=&lt;</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'lsst.obs.hsc.hscMapper.HscMapper\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;, mapperArgs={}, parents=[], policy=None)] </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">do</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> not match parents of existing writable cfg:[RepositoryCfg(root=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/validate_drp/data_hsc\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, mapper=&lt;</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'lsst.obs.hsc.hscMapper.HscMapper\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;, mapperArgs={</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'calibRoot\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/validation_data_hsc/CALIB\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}, parents=[], policy=None)] (ParentMismatch exception: The beginning of the passed-in parents list: [RepositoryCfg(root=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'../..\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, mapper=&lt;</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'lsst.obs.hsc.hscMapper.HscMapper\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;, mapperArgs={</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'calibRoot\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/validation_data_hsc/CALIB\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}, parents=[], policy=None), RepositoryCfg(root=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'../..\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, mapper=&lt;</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'lsst.obs.hsc.hscMapper.HscMapper\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;, mapperArgs={}, parents=[], policy=None)] does not match the existing parents list in </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">this</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> RepositoryCfg: [RepositoryCfg(root=</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/validate_drp/data_hsc\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, mapper=&lt;</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">class</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'lsst.obs.hsc.hscMapper.HscMapper\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">&gt;, mapperArgs={</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'calibRoot\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'/home/jenkins-slave/workspace/sqre/validate_drp/dataset/hsc/label/centos-7/python/py2/validation_data_hsc/CALIB\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}, parents=[], policy=None)]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "nan\n",
            "<p>obs_ctio0m9 may or may not be py3 compliant. If it\\'s not, \"make it so\" \\xe2\\x84\\xa2</p>\n",
            "<p>Configure the server for external use. Includes general configuration, networking, account creation and communication with user(s), etc.</p>\n",
            "<p>Files generated on instances of the Nebula openstack  should be managed with some commensurate  level of data replication/backups.     We investigate services that might serve this task within the cloud context.</p>\n",
            "nan\n",
            "<p>We run and study a \"single slow worker\" HTCondor ClassAds Scenario. The scenario is a perturbation of the baseline HTCondor ClassAds Scenario. In the baseline, Jobs for a given CCD  are consistently pinned to a slot/node that advertises the presence of associated data files/calibration files for that CCD.  A baseline run may proceed, for example,  with jobs for 4 CCDs repeating executing within same HTCondor slot on a node (even when spare processing slots are readily available.). The baseline is observed to be quite stable, as the pool is empty each time a wave of jobs is submitted. In the \"single slow worker\" scenario, we cause one of the jobs for a chosen CCD to stall (mocking up a slow file transfer, lengthy computation in an algorithm, etc), such that the pool is not empty at the the submission time for a wave of jobs.  We seek to observe how Rank places jobs in this scenario, and work to assign Rank (especially for spare slots) in an optimal way so as to minimize file transfers. </p>\n",
            "<p>Review procedures with NCSA Security to assure compliance with accepted practices.</p>\n",
            "<p>Rack and configure network hardware.</p>\n",
            "<p>Before testing in other environments (bare metal) we will try to install Kubernetes directly on top of Nebula OpenStack using current infrastructure and Openstack plugins.</p>\n",
            "<p>Incorporate concerns, solutions and agreements into ConOps and any draft design notes.</p>\n",
            "<p>Add Archive DMCS</p><p>Demonstrate:</p><p>Receiving information from duplicator (visit id, exposure sequence number, raft id, and network address).</p>\n",
            "<p>We install a globus-gridftp-server from the Open Science Grid yum repositories<br/>as a service to provide access to a Rucio Storage Element on a remote system.</p>\n",
            "nan\n",
            "<p>A DM tech note DMTN-060 is written to summarize the work done in epic <a href=\"https://jira.lsstcorp.org/browse/DM-10707\" title=\"File distribution and management framework\" class=\"issue-link\" data-issue-key=\"DM-10707\"><del>DM-10707</del></a>. </p>\n",
            "<p>Various issues arose due to unexpected data volume needs as well as differing storage characteristics. Investigate and propose solution(s). May impact data management policy.</p>\n",
            "<p>How to load data and perform queries.<br/>Investigate DAX interface to qserv.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Review of user migration plan with admins, communicate of plan to users via slack and clo, handling of user inquires.</p>\n",
            "nan\n",
            "\"<p>The APIs for the storage brokers we're looking into are similar, but don't have a 1-1 correspondence.  Write up the features offered by the APIs, and see where there is overlap.</p>\"\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Create an initial model of the Data Backbone enclave</p>\n",
            "<p>Spent some time shepherding setting of GPFS immutability attributes, setting file ownership &amp; group settings, etc for datasets of significant size, e.g,, the results of the HSC PDR1 reprocessing<br/>on the Verification Cluster. </p>\n",
            "nan\n",
            "nan\n",
            "<p>Process refinement and improvement: automating backup processes. Processes are currently run with sysadmin involvement. Manual processes will be replaced with scripts, cron jobs, etc.</p>\n",
            "<p>Draft and submit addendum to contract to cover transfer of NCSA inventory to Aura/Chile.</p>\n",
            "<p>Review of capability by site security team</p>\n",
            "nan\n",
            "<p>Design disaster recovery plan for science datasets.</p>\n",
            "<p>Contribute to Concept of Operations sections about Chilean, NCSA, and CC-IN2P3 facilities. Describing the \"nuts and bolts\" basics and summarize each facility\\'s role in the LSST operational system.</p>\n",
            "<p> Dividing F16 Service Management  ~ monthly.</p>\n",
            "<p>Based on review of existing policies, draft a proposed policy document.</p>\n",
            "<p>Kubernetes installation has some trouble setting a DNS server for the internal network to resolve names especially when connecting remotely. Might need to create a separate DNS server for it</p>\n",
            "<p>Can we use IPMI in place of a KVM?  Can we reliably do the following across our various server vendors?</p><ul class=\"alternate\" type=\"square\">\\t<li>power cycle hung systems</li>\\t<li>view and use text console</li>\\t<li>view and use remote gui console</li>\\t<li>boot from a remote ISO</li></ul>\n",
            "<p>Work with camera personnel to facilitate installation of the simulation hardware.</p>\n",
            "<p>Kubernetes made an auto-discovery process to create a build a Kubernetes cluster on top of a pre-defined cluster. This is an improvement on previous installation methods</p>\n",
            "<p>Make sure actual full archive copy transfers without error. Correct invalid design assumptions.</p>\n",
            "<p>We build the recent Version 10.1 stack release in a Centos 6.6 docker container. As we do so, we also gather strace logs for candidate packages<br/>(for example, afw) for analysis within an effort to create load simulators for file system testing/profiling.   As another product of the effort,  I will make a docker image of the latest release installed on Centos 6.6 and push to  docker hub.</p>\n",
            "<p>pro data system scaling tests on cray system were limited by the number of outgoing ports on a cray node. The limitation had been  ~20 ports, participated in Tests of new system software,limit relaxed to at least ~2000 in tests. Likely greater.</p>\n",
            "nan\n",
            "nan\n",
            "\"<p>Project started to categorize documents on docushare as per LSST's information categorization policy.</p>\"\n",
            "nan\n",
            "<p>Configure WebDAV for Kerberos authentication and LDAP authorization. Create example subdirectories where LDAP groups determine access (using .htaccess files):</p><ul>\\t<li>lsst: anyone in lsst group can read/write to this directory</li>\\t<li>ncsa: anyone in all_ncsa_employe can write, anyone in lsst can read</li></ul>\n",
            "nan\n",
            "<p>Reworking LDM-144 tape &amp; tape requirements tabs for initial feedback on redesign.</p>\n",
            "<p>Install and configure monitoring platform and client based on investigation of various solutions.</p>\n",
            "<p>Configure and test performance thresholds and incorporate them into the prototype dashboard.</p>\n",
            "<p>In instances where the files the worker expected to get never arrive, there should be a way of the worker to recognize this (say, a timeout after waiting for the Archive DMCS for some time), and exit.</p>\n",
            "nan\n",
            "<p>Refine initial lsst-db plans based on review of initial plan. Work with vendors to get necessary quotes.</p>\n",
            "<p>Prototype methodology for dependency mapping in the service catalog, whereby one can decompose top-level services down to the component level.</p>\n",
            "<p>This issue captures emergent work to support for example <a href=\"https://jira.lsstcorp.org/browse/DM-6905\" title=\"Locate the test dataset for PDAC\" class=\"issue-link\" data-issue-key=\"DM-6905\"><del>DM-6905</del></a> , for which I spent some cycles locating datasets of the 2013  SDRP, staging some files off of BW tape through globus online and unpacking to /nfs/scratch,  etc.    This effort may not fit exactly as \\'emergent middleware\\',  but it was roughly the best fit at this time. </p>\n",
            "<p>Extract Data Management requirements from Enterprise Architect and catalog as the basis for Service Level Targets (SLT)</p>\n",
            "<p>Review FY17 plan; get updated vendor quotes as needed. This is for the temporary loaner system as well as the follow-on ful (40+) system.</p>\n",
            "nan\n",
            "<p>We prepare and debug/test HTCondor configurations for use on head node lsst-dev01 and for glide ins for Verification Cluster worker nodes.   Firewall settings for lsst-dev01 and Verification nodes are also tested in this program of activity. </p>\n",
            "<p>Gather schemas for all databases within the consolidated database</p>\n",
            "<p>Discussions and planning for allocating the 1PB storage increase within Nebula between object storage and block storage. Further discussions with LSST DM interested stakeholders about this feature. Policy development for use and monitoring of use of this feature.</p>\n",
            "<p>The set of packages that will enable us to write against the native Python APIs of the OpenStack services is</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">python-keystoneclient</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">python-glanceclient</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">python-novaclient</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">python-quantumclient</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">python-cinderclient</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">python-swiftclient</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>We begin testing these in <a href=\"https://jira.lsstcorp.org/browse/DM-1787\" title=\"OpenStack automation via Python scripts : Launch an Instance\" class=\"issue-link\" data-issue-key=\"DM-1787\"><del>DM-1787</del></a>  on the NCSA OpenStack head node, but eventual use within LSST orchestrating workflow would entail these being installed on LSST nodes in the LSST stack.</p><p>In this issue we perform a basic installation of these packages into the system space on an LSST node/VM for testing.</p><p>These are managed in github, and we install these via \\'pip install\\' onto an LSST VM for initial tests.</p>\n",
            "<p>Setup up one master node and one worker node.</p>\n",
            "<p>This story captures service management / emergent work  for December actives related to the LSST development servers and Nebula OpenStack. This include issues and project communications related to the Home Directory transition to NFS to GPFS, network settings maintenance in NPCF,  tuning of HTCondor settings &amp; installation on lsst-dev01,  Nebula instance shutdowns / migrations to help support live migration functionality, and similar issues. </p>\n",
            "<p>Create a deploy a Kubernetes cluster automatically on Nebula, with its own private Network, CNI, and dashboard in a automatic manner. </p>\n",
            "<p>Review of services (compute, storage, networking) by LSST project before considering work final.</p>\n",
            "nan\n",
            "nan\n",
            "<p>Attending NSF Cyber Security Summit in my capacity as LSST ISO.</p>\n",
            "<p>Write a raw draft of the concept of operations for service monitoring. In this iteration the document is developed in Google docs following the ConOps template.</p>\n",
            "<p>Attend OCS Middleware workshop.</p><p>This will probably have be done remotely because I have a personal conflict with that time that will prevent me from attending in person.</p>\n",
            "<p>Provide access to developer-specified GPFS directories for datasets, home directories, and scratch directories.</p>\n",
            "<p>Define additional metrics to collect based on initial user feedback</p>\n",
            "<p>Gave input on IAM design for FY16 Integration Environment.<br/>Discussed IAM replication requirements with stakeholders.<br/>Attended local NCSA LSST coordination meeting.</p>\n",
            "<p>Started studying LSST coding policies and best practices via confluence.<br/>Colloquium.<br/>Small meetings with other LSST team members throughout day.<br/>Rebuilt PhoSim/LSST-Stack to take advantage of multiple cores when rendering portion of sky to a file. Built these commands into Stack code. They would have to be custom #defined by ./configure at build time depending on computer arch. which is too much to do when just gaining familiarity so stuck to MacBook<br/>multi-core specs, where I was working.<br/>Logged into JIRA and studied how tasks were proposed, realized, and checked as done.<br/>Extensive talk about BBQ in group area of NCSA/LSST.<br/>Close reading and note taking of LDM-230 and related docs.</p>\n",
            "<p>Research BeeGFS as possible networked filesystem for LSST usage to replace parts of NFS. Estimate spending 10 hours of work with result being a wiki page of suggestions, limitations, etc. (Any implementation will be a different task, presuming we want to implement.)</p><p><a href=\"http://www.beegfs.com/content/\" class=\"external-link\" rel=\"nofollow\">http://www.beegfs.com/content/</a></p><p>BeeGFS (formerly FhGFS) is a parallel cluster file system, developed with a strong focus on performance and designed for very easy installation and management. If I/O intensive workloads are your problem, BeeGFS is the solution.</p><p>Likely not good replacement for formal/managed data, but perhaps great option for shared scratch file systems.</p>\n",
            "<p>A initial investigation on using Kubernetes as resource manager </p>\n",
            "nan\n",
            "<p>Dividing F16 Service Management  ~ monthly.</p>\n",
            "nan\n",
            "<p>Create file list for full backup.</p>\n",
            "nan\n",
            "<p>Security vetting of the DAQ system revealed issues with iptables, etc., that also exist on the lsst-dev systems. This story covers the discovery and followup activities to remedy the issues.</p>\n",
            "nan\n",
            "<p>Configure log collection, storage, and forwarding.</p>\n",
            "<p>We create the first Rucio Storage Element (RSE)  to be managed by the NCSA Rucio installation and begin to upload data and test things out.   For simplicity the first RSE is  a local  storage element accessed through file protocol (rather than a remote RSE behind a gridftp/SRM/xrootd service). </p>\n",
            "<p>Write a raw draft of the concept of operations for data backbone services. In this iteration the document is developed in Google docs following the ConOps template.</p>\n",
            "\"<p>Accommodated Ron Lambert's input on networking equipment.<br/>Assigned tier-2 and tier-3 levels to processing systems. </p>\"\n",
            "nan\n",
            "nan\n",
            "<p>First draft of data backbone services conops.</p>\n",
            "<p>Define architecture/schema for Service Level Targets in Enterprise Architect</p>\n",
            "<p>Prototype LSST system monitoring dashboard.</p>\n",
            "<p>Configure <a href=\"https://fedorahosted.org/sssd/\" class=\"external-link\" rel=\"nofollow\">sssd</a> with NCSA LDAP for accounts in test IAM VM using instructions from Doug Fein.</p>\n",
            "<p>Configure sshd in our test IAM VM to use pam_krb5 so the user gets a Kerberos ticket when logging in as discussed in our design doc. Document the configuration steps.</p>\n",
            "<p> Dividing F16 Service Management  ~ monthly.  </p>\n",
            "<p>Collate responses from database needs questionnaire.</p>\n",
            "<p>Create read only OpenStack volume and execute processing scenario</p>\n",
            "<p>Evaluate the TICK stack considering monitoring system requirements and interface needs</p>\n",
            "nan\n",
            "<p>There emergent request for comment emerged in June. </p><p>1) The interim project manager,  directed that the project begin an investigation into Amazon Wen Service due to contacts he developed at a Data base orient workshop he sponsors.  Formulating  a response required a review of the service offered by AWS, and inquiring about the validity of pursing an evaluation of just one vendor in a marketplace that has many vendors, and a deciding that an appropriate amount of work was to send additional NCSA staff to an AWS workshop to gain a similar appreciation of AWS as was gained at the database meeting at SLAC.  (Authority of interim project manager to insist on immediate action was also sorted out)</p><p>2) Request to understand computing capabilities at alternate site from the Deputy director.  Support for for alternate site capabilities are documented in the  the emerging L2 Batch concept of operations a copy of which was shared (though draft status noted) </p><p>3) Processed a summary of the Camera meeting which occurred at SLAC. Did not find  conclusions that related to a concept of operations.    IN particular we could not understand it there was a call for computing and a summit data service to support disconnected operations,  or if this was a mere optimization in the system to relocate the acquisition and forwarding infrstructure to the summit, with no other changes.</p>\n",
            "nan\n",
            "<p>The initial series of tests with HTCondor ClassAds work with jobs for individual ccds with a single file representing the data dependency  for the job. In this issue we consider the management of multiple types of data dependencies that may have to be cached for jobs (calibrations, templates, catalogs of sources/objects, etc). </p>\n",
            "nan\n",
            "<p>Perform assessment of SQL Server and Oracle for suitability given known requirements.</p>\n",
            "<p>A test plan draft was written and some short meetings were held regarding the use of the WAN Emulator. The manuals for the Apposite Netropy 40G emulator were retrieved and read. The test plan draft for three test projects is attached.</p>\n",
            "<p>In our introductory work with OpenStack we have been utilizing the Horizon<br/>GUI interface for first steps, followed by the use of command line tools (the \\'CLI\\') (e.g., nova, cinder, etc) as shown in <a href=\"https://jira.lsstcorp.org/browse/DM-1334\" title=\"Test the creation of basic OpenStack instances on the new ISL testbed [IceHouse]\" class=\"issue-link\" data-issue-key=\"DM-1334\"><del>DM-1334</del></a>  <a href=\"https://jira.lsstcorp.org/browse/DM-1700\" title=\"Create read only OpenStack volume and execute processing scenario\" class=\"issue-link\" data-issue-key=\"DM-1700\"><del>DM-1700</del></a> , <a href=\"https://jira.lsstcorp.org/browse/DM-1701\" title=\"Clone OpenStack volume for use against multiple instances\" class=\"issue-link\" data-issue-key=\"DM-1701\"><del>DM-1701</del></a>.<br/>While it is possible to write automation scripts that utilize the CLI, an approach<br/>based on \\'pure\\' Python scripting would fit more seamlessly into the LSST software development process. Enabling OpenStack automation via Python offers the opportunity to integrate provisioning of resources into the overall flow of LSST workflow &amp; processing (e.g., DRP.)</p><p>The OpenStack services expose native Python APIs that expose the same<br/>feature set as the command-line tools.</p><p>The required python packages (python-keystoneclient, python-novaclient, ..)<br/>are installed on the head node \\'vlad-mgmt\\' of the NCSA ISL OpenStack, and<br/>so initial Python scripting can be executed/tested there.  A first Python<br/>script will perform required authentication and launch an instance.</p>\n",
            "<p>Install GPFS on LSSTdev servers to prepare for data migration.</p>\n",
            "<p>Build transfer mechanism into DR tool.</p>\n",
            "<p>Formulate and send questionnaire to identified project collaborators to assess individual database needs. </p>\n",
            "<p>Document each component sufficient enough for transfer of knowledge and system recovery as needed.</p>\n",
            "nan\n",
            "<ul>\\t<li>Request 10G BaseT networking drops for node from NetEng (Corey Eichelberger or Matthew Kollross)</li>\\t<li>Assign and setup IPMI networking and cables for each node</li>\\t<li>Connect to network</li></ul>\n",
            "<p>Evaluate time series enterprise monitoring platforms. These include Graphite, TICK/InfluxDB, and Prometheus.</p>\n",
            "<p>Write a raw draft of the concept of operations for batch processing services. In this iteration the document is developed in Google docs following the ConOps template.</p>\n",
            "<p>Put together a draft plan including rough dates, functionality, products, other information as necessary for discussions and planning.</p>\n",
            "nan\n",
            "<p>In <a href=\"https://jira.lsstcorp.org/browse/DM-1431\" title=\"Process sample sdss data with LSST Stack in a Docker container in OpenStack\" class=\"issue-link\" data-issue-key=\"DM-1431\"><del>DM-1431</del></a> we demonstrated processing of sample data within Docker containers within an OpenStack instance.  Data was processed for containers based on CentOS6.5, Ubuntu 13.10, Ubuntu 14.10.</p><p>We consider a multi-platform \"testing\" scenario, where we process the sample data in numerous containers based on various platforms/OSs all simultaneously on an OpenStack instance. </p><p>This scenario entails starting up and managing multiple Docker containers.  Fig (<a href=\"http://www.fig.sh\" class=\"external-link\" rel=\"nofollow\">http://www.fig.sh</a>) is a new tool for starting up and managing services via Docker containers.   It is a common use case with Docker to have individual components of an application each run separately in a container (resulting in numerous  containers running on a node or cloud env, i.e., a \\'Docker stack\\'), with the containers having linkages/dependencies to be managed. Fig may be used to encode the relationship between the containers in the Docker stack, and to start up such a set of containers.  We install and examine Fig, and apply Fig to our multi-platform \"testing\" scenario. </p>\n",
            "<p>Upgrade LSSTdev Puppet to version 4.x  to prepare for GPFS migration.</p>\n",
            "nan\n",
            "<p>Replicator jobs that receive no data specifically for the visit, raft, and exposure sequence ID within a certain amount of time should self expire to prevent future jobs from running.  If this is not done, jobs will back up in the HTCondor queue.</p>\n",
            "<p>The tests for this package predate the unit test framework that other package use.  Update the tests to uses the unit test framework and get rid of any duplicate  or obsolete tests.</p>\n",
            "<p>F16 Service Management ~ monthly.</p>\n",
            "nan\n",
            "<p>Write a raw draft of the concept of operations for authentication and authorization services. In this iteration the document is developed in Google docs following the ConOps template.</p>\n",
            "<p>Get SSL certificate and configure httpd for mod_auth_krb5 authentication in IAM test VM. Document the setup.</p>\n",
            "<p>Exercise the service model using representative use cases </p>\n",
            "<p>Renewal of the LSST security plan.  Starts with DM.</p>\n",
            "<p>Use an OpenStack instance to run an HTCondor Central manager</p>\n",
            "<p>Report on how to modify the current infrastructure to make use of a container cluster manager.</p>\n",
            "<p>Run planning process with local staff to appreciate amount of effort needed.</p>\n",
            "<p>Create new WBS structure for use with new planning packages.</p>\n",
            "\"<p>Draft a brief description of life of the data backbone as if implemented today using OpenStack Swift with it's features and shortcomings. This document is not to be base-lined; it is a conversation and discovery piece. </p>\"\n",
            "nan\n",
            "<p>Produce raw draft of conops for review by steering committee. Includes operational components and connectivity for the system monitoring services that will monitor devices from the summit to NCSA.</p>\n",
            "<p>To understand the effectiveness with which we are mapping Jobs to Data, it is vital to monitor/record what data has been processed on a given Node, or within a given Slot on a Node.   Under this issue we examine HTCondor monitoring standards like STARTD_HISTORY,  as well as more custom implementation of blackboard type records via  Job Update hooks to be <br/>executed on the execute node (along the lines of OWL.) </p>\n",
            "<p>In order to be come more familiar with how to use the log.git package, write some tests to see how existing configurations and appenders are used by the log.git package.</p>\n",
            "<p>Notify users, plan for process, and remove access to NFS disks.</p>\n",
            "<p>Based on the batch services conops, develop a list of engineering considerations for making a BOE for the batch services planning package.</p>\n",
            "<p>We write up some introductory guides for Nebula usage to enable new users to get started.<br/>These are located on Confluence under :</p><p><a href=\"https://confluence.lsstcorp.org/display/LDMDG/NCSA+Nebula+OpenStack+User+Guide\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/LDMDG/NCSA+Nebula+OpenStack+User+Guide</a></p>\n",
            "<p>Test data exchange between System Engineering tool (MagicDraw) and existing planning tools. </p>\n",
            "<p>Run initial HTCondor ClassAds Scenarios to verify that the implementation for utilizing Rank to place Jobs near data is operating as anticipated.  The main test of the baseline scenarios is to verify that, e.g., a job for a CCD that has calibrations advertised for a particular slot/node  will consistency be executed within that location for appropriate Rank expression. This is to occur even when other open slots are always available (e.g., 4 CCDs, 5 slots). </p>\n",
            "nan\n",
            "<p>Write some example programs to get familiar with the OCS middleware software. The OCS middleware will later be integrated with the AP, in the base dmcs and replicator jobs.</p>\n",
            "nan\n",
            "<p>Given directions from interim project management, participation consisted of direct conversations with Kevin and Jacek plus background work talking to staff related to assembling a plan.</p>\n",
            "<p>Need to collect all configuration files, Dockefiles, kubernetes files and instructions to deploy jupyterhub with NFS mounted volume on Kubernetes</p>\n",
            "<p>Emergent and System work for supporting the Chilean ITC Tiger Team.</p>\n",
            "<p>install and configure OS</p>\n",
            "<p>The Cyber security center has provided a risk template consistent with their templates,  The Center attempted to populate their templates with material from LSE 99  to the templates,   The impedance mis match was too large, The way forward is seem as  attempting a high level decomposition of risk into the templates.</p>\n",
            "<p>Examine fqdn/hostname assignment for OpenStack instance</p>\n",
            "<p>Discuss database needs with data management architect, database owners, and local experts. Document known project databases. </p>\n",
            "<p>Turn criteria into tabular comparison chart and respect test implementation constraints.</p>\n",
            "<p>The nature of the process is to have additional monitoring and interaction with staff to review and observe how well plans are followed, tickets are recorded in a timely fashion, and deviations from plans are also recorded and available for analysis and process improvements. </p>\n",
            "<p>Provide high-level context for service-level monitoring with respect to components and business needs. Create diagram. Provide one worked out case of high-level requirements in the context of the Level 1 system.</p>\n",
            "<p>Based on the L3 Hosting services conops, develop a list of engineering considerations for making a BOE for the L3 Hosting planning package.</p>\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "<p>Produce a scorecard document cataloging features and concerns.</p>\n",
            "<p>Convert prototype schema(s) for selected database(s).</p>\n",
            "<p>Prepare for JTM session with a working title of \\xe2\\x80\\x9cHow Authentication/Authorization technology can be used to implement and enforce data access rights and operational processes for LSST\".  Prepare a final title and agenda for the session. Tuesday from 3:30pm - 5:00pm.</p>\n",
            "<p>researched the docushare traversing the plans for materials to be embedded in the OCS and similar systems, as well as extant operational plans. The goal was to understand how to separate the the security responsibilities of development, what security constraints ought to be but on items that are delivered, and what to tell the camera and telecscope teams  to mender ea smooth integration with IT security systems upon delivey and integration of their sub systems in Chile.</p>\n",
            "<p>Systems Engineering and Chilean ITC Tiger Team (September work):</p><ul>\\t<li>Addressed concerns relating to quick-look capabilities on the Summit and operational needs during disconnected operations</li>\\t<li>IT Security, definition of SCADA enclave boundary</li>\\t<li>Interface of DPP services to other logical components in Chile</li></ul>\n",
            "<p>Arrange for, order, and receive small-scale Dell loaner systems for initial testing.</p>\n",
            "<p>Setup an independent HTCondor central manager outside of the Kubernetes cluster to direct worker nodes inside of Kubernetes.</p>\n",
            "<p>Configure mod_auth_oidc on lsst-auth1 with CILogon and Globus.</p>\n",
            "<p>Draft logical design of the monitoring system:<br/>Requirements of the Enterprise Service Monitoring Software Needs:</p><ul class=\"alternate\" type=\"square\">\\t<li>Integrate ITC monitoring \\xc2\\xad how do we get info out of RRDBs sufficient for service monitoring?</li>\\t<li>Ability to mirror for disconnected operations &#8211; how to run 2 copies and synchronize?</li>\\t<li>Ability to get info out \\xc2\\xad can data be exported to Pandas/R/similar analytical environment?</li>\\t<li>Python API for programs/applications to inject data</li>\\t<li>Ability to produce Go plugins \\xc2\\xad if monitoring agent that is not ITC</li>\\t<li>Generate displays for well-known customers using 1 of 2 display generators that database supports</li>\\t<li>Conquerer tool \\xc2\\xad generates events by monitoring scripts, back-end displays<br/>o   Integrate with paging infrastructure, but paging should be separate<br/>Ability to inflate independent test instances of monitoring infrastructure and bring in tools from production infrastructure to run tests and retaining test records.<br/>Admin of databases itself:</li>\\t<li>State data retention policies</li>\\t<li>State data summaries and their own retention policies</li>\\t<li>Using namespace in the database \\xc2\\xad schema development and maintenance, how to use namespace so there is not chaos<br/>It would look like we need something akin to a \"Swiss Army Knife on the back-end which will be able to do the following</li></ul><ul>\\t<li>integrate someone else\\xc2\\xb9s software</li>\\t<li>communicate directly with software we write</li>\\t<li>work with agent</li></ul><p>One of the tools which seems to satisfy the aforementioned requirements was the TICK stack which includes a InfluxDB </p>\n",
            "nan\n",
            "<p>Seeking out developer use cases of incoming data sets. Need to determine if datasets will be accessed for verification only or by developers and QA in general. Determine access methods. </p>\n",
            "nan\n",
            "<p>Account cleanup process for existing infrastructure (Identify accounts, assign sponsors)</p><p>Reconcile inventory between NCSA and Aura (on going). Mock request was generated by Aura for dry run audit. Several machines have been found not included in inventory. Task to be completed in February.</p>\n",
            "nan\n",
            "<p>Videos from the <a href=\"https://community.lsst.org/t/dm-boot-camp-announcement/249\" class=\"external-link\" rel=\"nofollow\">DM Boot Camp</a> cover a lot of topics a newbie like me is interested in.</p>\n",
            "<p>Pixels near the edges of the DECam CCDs are bigger/brighter and correcting them is not trivial. One way to move forward is to mask them out.  </p><p>DESDM and CP mask 15 pixels on each edge.  The cut was later raised to 25 pixels, with the inner 10 pixels flagged as SUSPECT.</p>\n",
            "nan\n",
            "<p>Investigate the footprint of L1 Prompt processing in terms of files sizes for input and outputs.</p>\n",
            "<p>Document policy regarding action to take when various components are found to be unhealthy. This can vary depending when 1 component type (Forwarder) is offline versus 21 Forwarders offline. In addition, plans must be formulated for addressing the point in the exposure cycle when the health failure occurs.</p>\n",
            "<p>Work on use cases from the Operations viewpoint (L1 Alert Processing, Offline Batch Production Service, etc)</p>\n",
            "nan\n",
            "<p>iRODS can support access to a tape archive with the use of a \"tiered resource\" where one resource has the role of the cache, and a second has the role of archive.    Use of such a tiered resource construct could be valuable to data management.   Because a iRODS plugin for HPSS is readily available, we examine the set up and use of the tiered resource testing against NERSC HPSS.</p>\n",
            "<p>As an exercise, run the single frame processing code (as-in from pipe_drivers) with the HSC COSMOS dataset on the Verification Cluster.  If appropriate, develop scripts to facilitate the process. </p>\n",
            "<p>Learn the concept behind the previous API changes (<a href=\"https://jira.lsstcorp.org/browse/RFC-26\" title=\"API Change for IsrTask (Backwards-compatible)\" class=\"issue-link\" data-issue-key=\"RFC-26\"><del>RFC-26</del></a>) in the tasks of ISR processing, and data storage/retrieval involved. </p>\n",
            "<p>Based on the slurm statistics collected during the processing or anything post-mortem, summarize the computing resource used in <a href=\"https://jira.lsstcorp.org/browse/DM-10404\" title=\"S17B \\xc2\\xa0full HSC reprocessing with the SSP PDR1 data\" class=\"issue-link\" data-issue-key=\"DM-10404\"><del>DM-10404</del></a>. </p>\n",
            "\"<p>Remove the dependency on CAT databases (this functionality has been deprecated and hasn't been in use for a long time).  Also make database setup optional.</p>\"\n",
            "\"<p>Audit format of existing messaging and adjust according to 'wants' not task 'needs'...that is, msg body format that exists now is sufficient to fulfill tasks, but destination components must receive a broader description of overall system state. This will allow all components to log a more comprehensive snapshot of current state and is needed for troubleshooting. These additions to the message dictionary will be configurable like a logging priority levels function, and additions to message payload can be turned off for typical nightly operation.</p>\"\n",
            "<p>recruiting for open positions<br/>Work on accounting infrastrucutre.<br/>\"hardware\" contact - - <br/> outline to Jeff over the phone what is coming<br/> work through  inventory infrastructure for materials for La Sereba<br/> review budget and effort projections.<br/> hear file system invesitigations meeting. </p>\n",
            "<p>Near term goals are to save raw files into a custodial store and interact with the Batch Processing Service.   </p><p>Try using DESDM framework that already has the concepts: file catalog, metadata table, file provenance, file transfers to/from compute jobs, etc.</p><p>Goal:   Save HSC raw files into a DESDM \"home archive\" along with enough metadata that can run pipeline steps inside the DESDM framework (<a href=\"https://jira.lsstcorp.org/browse/DM-10468\" class=\"external-link\" rel=\"nofollow\">https://jira.lsstcorp.org/browse/DM-10468</a>).</p><p>A report will be tracked via a separate story.</p>\n",
            "<p>We start with initial tests of Shifter, with the first goal to  submit PBS jobs on the Blue Waters test system utilizing Shifter that start HTCondor master/startd daemons on compute nodes.  These daemons will communicate to a remote HTCondor central manager (e.g., running on the Nebula OpenStack) and glide-in to join a working pool.  The setup will then be tested with simple payload jobs (these  submitted from a Nebula instance running the schedd)  that verify access to the LSST stack within the UDI (User Defined Image).</p>\n",
            "<p>Outline of data flow between Chile-&gt;NCSA and NCSA-&gt;Chile.</p>\n",
            "nan\n",
            "<p>Sometimes DECam-specific bugs only reveal in or affect the processed data. For example the bug of <a href=\"https://jira.lsstcorp.org/browse/DM-4859\" title=\"DECam postISRCCD products of south CCDs have shifted wcs\" class=\"issue-link\" data-issue-key=\"DM-4859\"><del>DM-4859</del></a> reveals in the <tt>postISRCCD</tt> products.  If the bugs are DECam-specific, some changes in <tt>obs_decam</tt> are likely needed.  It would be useful to have a more convenient way to test those changes. In this ticket I modify <tt>testdata_decam</tt> so that those data can be processed, and then allow wider options in the <tt>obs_decam</tt> unit tests.</p><p>I add <tt>testProcessCcd.py</tt> in <tt>obs_decam</tt> that runs <tt>processCcd.py</tt> with raw and calibration data in <tt>testdata_decam</tt>.  Besides a short sanity check, I add a test (testWcsPostIsr) that tests <a href=\"https://jira.lsstcorp.org/browse/DM-4859\" title=\"DECam postISRCCD products of south CCDs have shifted wcs\" class=\"issue-link\" data-issue-key=\"DM-4859\"><del>DM-4859</del></a>. <tt>testWcsPostIsr</tt> fails without the <a href=\"https://jira.lsstcorp.org/browse/DM-4859\" title=\"DECam postISRCCD products of south CCDs have shifted wcs\" class=\"issue-link\" data-issue-key=\"DM-4859\"><del>DM-4859</del></a> fix, and passes with it.</p>\n",
            "nan\n",
            "<p>Analyze the bug described in <a href=\"https://jira.lsstcorp.org/browse/DM-6462\" title=\"Emergent middleware work (F16, part 1)\" class=\"issue-link\" data-issue-key=\"DM-6462\"><del>DM-6462</del></a></p>\n",
            "<p>Compare the technical evaluation materials and the batch production services conops.</p>\n",
            "<p>Connect all of the parts together.</p>\n",
            "<p>The exampleCmdLine task worked fine, need to show demo for other tasks from pipe_tasks</p>\n",
            "nan\n",
            "<p>Reprocess the HSC RC dataset using w_2017_32 following the same steps as in <a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a></p>\n",
            "<p>Not all known ISR corrections are applied or implemented to DECam data yet. For example, no cross-talk, edge-bleed, non-linearity, sky pattern removal, satellite trail masking, brighter-fatter, or illumination correction.</p><p>But we have most of the basic ISR already. With what we already have, identify issues that would severely affect the quality of post-ISR processing.</p>\n",
            "<p>I was asked for a revision of <a href=\"https://jira.lsstcorp.org/browse/DM-2983\" title=\"Backport HSC parallelization code\" class=\"issue-link\" data-issue-key=\"DM-2983\"><del>DM-2983</del></a> which is part of the Backport HSC parallelization code</p>\n",
            "nan\n",
            "<p>Curate documentation defining terms used in swim lanes diagram. Publish in appropriate location.</p>\n",
            "nan\n",
            "<p>Updated processor projections based upon Haswell and Skylake expectations. Added Shipping rates, Chilean and US power and cooling rates, updated memory pricing projections. Working with Spectra Logic on updating and improving tape predictions, library space and power requirements, upgrade options and mapping of bandwidth and capacity requirements to hardware (need to figure in fudge factors for latency of mounting tapes, latency of seeks times, maybe space for tape migrations, replace replacement tapes with updating pricing that includes tape replacement). Inclusion of that into the document will be in the next story.</p>\n",
            "nan\n",
            "<p>Internal and external recruiting. <br/>Input on NCSA re-organizaiton to ensure proper placement of LSST activities in the NCSA organization.<br/>Meetings.</p>\n",
            "<p>Create file transfer API so we can easily test different types of file transfer mechanisms to/from the AP.</p>\n",
            "<p>Prepare new system diagram for DM system architect.</p>\n",
            "nan\n",
            "<p>Investigated invoicing fro storage condo &#8211; appears to be annual fee, OK by Jeff.<br/>Investigated attaching  effort breakdown to invoke &#8211; this seems hard as U of I invoicing occurs at quite a distance (procedural) distance from the NCSA business office.  Decided to look at improvements in recording effort in Jira so as to be able to generate report. &#8211; Capture all actuals. <br/>Business office transition  support is transitioning from Matt S. to new person. <br/>Review AMCL sides,  kept tradition generating exponentially more comments, but reduced the exponent. <br/>Process to bill out effort applied to project, but not in standing assignments in the staffing plan. <br/>Internal strategy meeting about agenda items w.r.t VAO given Rap Plante is leaving NCSA.<br/>Prep for DM leadership meeting &#8211;  synergies at NCSA.</p>\n",
            "<p>Build testing mechanism to inject faults into into health framework and stub code to address health check failures</p>\n",
            "nan\n",
            "<p>Digest and parse headers from fits files provided by the camera. These will be use to augment the templates that will produce telemetry to mock meta-data to be captured by the new header client.</p>\n",
            "<p>Addition of <a href=\"https://confluence.lsstcorp.org/display/~petravick/Products+of+Image+Ingest+and+Processing\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/~petravick/Products+of+Image+Ingest+and+Processing</a> to understand more of the requirements necessary for the functional design</p>\n",
            "<p>Recent API changes in <a href=\"https://jira.lsstcorp.org/browse/DM-8686\" title=\"Change Child Repo Access to Parent Registries\" class=\"issue-link\" data-issue-key=\"DM-8686\"><del>DM-8686</del></a> broke the Pegasus DAX-generating scripts. Recover from the changes and make it work again. </p><p>First error: </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"ciHsc/generateDax.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">179</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in generateDax</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    mapper = HscMapper(root=inputRepo, outputRoot=outPath)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">  File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/home/hchiang2/lsstsw/stack/Linux64/obs_subaru/13.0-14-gb43a883+1/python/lsst/obs/hsc/hscMapper.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">31</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in __init__</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">    </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">super</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">(HscMapper, self).__init__(policy, policyFile.getRepositoryPath(), **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">TypeError: __init__() got an unexpected keyword argument </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'outputRoot\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>Also, <a href=\"https://jira.lsstcorp.org/browse/DM-9438\" title=\"Switch default reference catalog for HSC to PS1 in LSST format\" class=\"issue-link\" data-issue-key=\"DM-9438\"><del>DM-9438</del></a> switched the reference catalog to use the LSST HTM format. Do the necessary changes to make the dax run again. </p>\n",
            "<p>Add doc directory and fix doxygen warnings.</p>\n",
            "nan\n",
            "<p>Transfer Feb2013 COSMOS data to /datasets/decam/ and butlerize it.  </p><p>Run some processing to verify the butler repo is useable.  </p>\n",
            "nan\n",
            "<p>Hiring &#8211; make offer to candidate, and also review candidates and strategy.<br/>Review proposal for FY 2015 spend<br/>Management meetings.<br/>Openstack meeting.</p>\n",
            "<p>Preliminary work to extend the Process Execution Framework to accomodate changes needed by SUI and others.</p><p>This story captures work done in June, prior to incorporating the activity into the baseline plan. Work will be logged under <a href=\"https://jira.lsstcorp.org/browse/DM-3003\" title=\"Extend the Process Execution Framework to accomodate changes needed by SUI and others\" class=\"issue-link\" data-issue-key=\"DM-3003\"><del>DM-3003</del></a> starting July 1st.</p>\n",
            "<p>Read Gartner materials related to ITIL, devops  IT organization in preparation for more detailed thinking about Data Operations.    One major category of thought is \"Mode 1 and Mode 2\" type organizations. Mode ! is the current typical controlled environment the strength is when something precious needs to be managed.  For LSST this might be the data release production, which is baselined to be 9 months on a unique resource that the project procured.<br/>Mode 2 is \"doves\" which is best used for nimble, fall fast software.  An example e testing algorithms.</p>\n",
            "<p>Update the data product diagram of top-level Pipelines on <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=jbosch\" class=\"user-hover\" rel=\"jbosch\">Jim Bosch</a>\\'s <a href=\"https://confluence.lsstcorp.org/display/~jbosch/Data+Release+Production+Top-Level+Overview\" class=\"external-link\" rel=\"nofollow\">Data Release Production Top-Level Overview page</a> to reflect the new changes and follow the terminology in <a href=\"https://ldm-151.lsst.io/v/draft/LDM-151.pdf\" class=\"external-link\" rel=\"nofollow\">LDM-151</a>. </p>\n",
            "nan\n",
            "<p>More pricing iterations with several companies and incorporating that information into our final decision. More Q&amp;A with storage companies re: comparable features. Compiled all storage option quotes into a spread sheet which now forms as a good comparison and helps LDM-144  forecasting. </p><p>Awaiting quotes for racks and PDUs. Now that rack size is known for the Chilean DC, this will serve us well for LDM-144 costs. </p><p>Power issues for FY16 hardware are settled and we are ready to schedule installation as soon as the hardware purchase contract is complete.</p><p>Tagging issues for FY15 hardware complete. Looking into pre FY15 tagging. Requested that LSST/Aura perform an inventory request to complete the circle and prove the process.</p><p>Working with Spectra / NetSource to create a sustainable tape condo that can serve LSST through 2030.</p>\n",
            "<p>Meetings &#8211; Monday CAM meeting, Friday standup and infrastructure.  Internal NCSA group meeting,  Internal NCSA \"comp pol\" technical coordination meeting.  Screen existing candidate pool for likely people to fill opening,  Interviewed one person checked references + Misc.</p>\n",
            "\"<p>(Actual assignee: Samuel Piehl) </p><p>Have a script to show what visits are in what tracts/patches. This is especially useful for running coadd making and processing (e.g. makeCoaddTempExp, assembleCoadd) with runOrca and HTCondor, as the dataId of the jobs need to be specified. So this script's output will be in the format of a runOrca input file. </p>\"\n",
            "<p>Describe the current orchestration software architecture, and post it to the Orchestration confluence page.</p>\n",
            "<p>Under the assumption that the RAW files will be created as <tt>Int18</tt> files, we need to mock the creation of <tt>Int18</tt> RAW files inside a <tt>Int32</tt> container. We need to test how well this mocked <tt>Int18</tt> files will compress.</p>\n",
            "<p>The EventAppender needs to add host identification (host/process/id) information to the log message it transmits.   This was inadvertently left out.</p>\n",
            "\"<p>I'll add a way to specify on the command line the path or the package to discover for CmdLineTask or SuperTasks</p>\"\n",
            "<p>Two day JCC activity at NCSA, including extended JCC meeting with HEP centers likely to <br/>host people exploiting LSST Data.  </p><p>writeup of extended meeting is here: <a href=\"https://confluence.lsstcorp.org/display/JCC/Extended+JCC+meeting+--+2015-11-23\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/JCC/Extended+JCC+meeting+--+2015-11-23</a> <br/>in the JCC section. </p><p>organize, coordinate, and write up meeting notes. </p>\n",
            "<p>Support for lsst-dev cluster, OpenStack, and accounts<br/>for week ending February 28, 2016.</p>\n",
            "\"<ul>\\t<li>Three Dell R730's:\\t<ul>\\t\\t<li>Mount in A row racks</li>\\t\\t<li>Complete Bios updates</li>\\t</ul>\\t</li>\\t<li>Moved ~25 VMs over to new lsst-vsphere infrastructure</li>\\t<li>Setup lsst-condor[1-6] VMs</li>\\t<li>Setup lsst-esxmac1 with networking</li>\\t<li>Fixed networking issues on new lsst-esx1 server (an undocumented host was squatting on the IP address)</li></ul>\"\n",
            "<p>Read up on current IRODS usage and development track. </p>\n",
            "<p>Work with <a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=mgower\" class=\"user-hover\" rel=\"mgower\">Michelle Gower</a> on data product inputs/outputs; use JointCal as an example use case of composite datasets; summarize in a data flow diagram. </p>\n",
            "<p>On boarded Mattais Carrasco-Kind to work in the process execution in the context of Level 3 processing. <br/>Misc.</p>\n",
            "<p>Read over the revised LSE-209 and LSE-70 documents</p>\n",
            "nan\n",
            "<p>Reprocess the HSC RC dataset using the pipe_drivers tasks. </p><p>The processed results should go to <tt>/project/hsc_rc/w_2017_27/<a href=\"https://jira.lsstcorp.org/browse/DM-11273\" title=\"Reprocess RC with w_2017_27\" class=\"issue-link\" data-issue-key=\"DM-11273\"><del>DM-11273</del></a></tt> as a Butler repo. </p>\n",
            "\"<p>Di progress on understanding the possibility of using websocket locally to communicate with JS9 instances on local server. In this case we wouldn't need an external server and communication can be bi-directional. Now is only in one direction (mostly) when running Js9 locally </p>\"\n",
            "nan\n",
            "<p>After updating some latest changes, need to update documentation to explain the extend of this supertask and activator initial implementation.</p>\n",
            "<p>Currently, the default overscan correction from IsrTask is used for processing DECam raw data. Overscan subtraction is done one amplifier at a time. </p><p>However, a bias jump occurs due to the simultaneous readout of the smaller ancillary CCDs on DECam, some images show discontinuity in the y direction across one amplifier, as in the example screen shot. </p><p>This ticket is to improve overscan correction for DECam data so to mitigate this discontinuity in the ISR processing.</p><p>Arrangement of CCDs on DECam: <a href=\"http://www.ctio.noao.edu/noao/sites/default/files/DECam/DECamPixelOrientation.png\" class=\"external-link\" rel=\"nofollow\">http://www.ctio.noao.edu/noao/sites/default/files/DECam/DECamPixelOrientation.png</a></p><h3><a name=\"Moredetails%3A\"></a>More details:</h3><p>There are 6 backplanes in the readout system, shown by the colors in DECamPixelOrientation.png. In raw data files, the CCD\\'s backplane is noted in the header keyword \"FPA\".  Examination of some images suggests that science CCDs on orange and yellow backplanes show bias jump at 2098 pixels from the y readout. That is the y size of the focus CCDs. </p><h3><a name=\"Actions%3A\"></a>Actions:</h3><p>For CCDs on the affected backplanes, divide the array into two pieces at the jump location, and do overscan correction on the upper and lower pieces separately.</p>\n",
            "<p>Discuss implementation of Header client during  Integration Activity #3</p>\n",
            "nan\n",
            "<ul>\\t<li>Set up new lsst-dev7 as CentOS 7 server</li>\\t<li>Continuing to set up IPMI on new test servers (working with Dell on issue with iDRAC license upgrade)</li></ul>\n",
            "nan\n",
            "<p>Reprocess the HSC RC dataset using w_2017_36 following the same steps as in <a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a></p>\n",
            "<p>Create a new package <tt>pipe_supertask</tt> and move all supertask code and activator there. Will soon create a poll to pick a better name.</p>\n",
            "<p>Xiuqin\\'s \\'short term\\' version:<br/>1 VM - SUI build server<br/>4GB memory and 200GB hard disk should be good enough.<br/>1 VM - Apache server as a proxy and web front end<br/>4GB memory and 100GB hard disk should be enough<br/>port 80 accessible from outside<br/>2 VMs - Tomcat servers<br/>each has 16GB memory, access to 1TB of shared hard disk<br/>Port 8080 should be open for Apache server to access<br/>Port 8009 should be open to each other so they can replicate cache.<br/>(First 2 VMs are not absolutely needed. We can always use one of the hosts in number 3 to do build and host Apache server.)</p><p>The 2 Tomcat servers are larger than we can currently support as VMs.   We\\'ve discussed repurposing 2 of the older LSST \"cluster/condor\" nodes (e.g. lsst14 &amp; lsst15) for this purpose.</p><p>But, ideally these could be implemented with the new vSphere hardware if the timeframe works.</p>\n",
            "<p>Per request from project management, make a Test Report from the HSC full reprocessing analysis. </p>\n",
            "<p>Switch the logging/tracing in C++ from lsst.pex.logging to lsst.log in meas_algorithms</p>\n",
            "<p>Review of multiple quotes from multiple vendors across full year of purchases. Derived power requirements and rack layouts for placement, networking, electrical work discussions to begin.</p>\n",
            "<p>Sahand progress on storage objects to be used in OpenStack</p>\n",
            "<p>Data backbone first edit : 1pt (week 1)<br/>Data backbone second edit : 1 pt (week 2)<br/>Third edition : 1 pt week 3&amp;4</p>\n",
            "<p>Hiring,  Internal relationships within the NCSA organization. LSST meetings, general management</p>\n",
            "<p>Weeks 1&amp;2 - Interviews, Team mtgs, uptime institute tier discussions: 1.5 pts<br/>Weeks 3&amp;4 - Team mtgs, ICI meetings, set/prioritize IT goals 4 pts</p>\n",
            "<p>Support for lsst-dev cluster, OpenStack, and accounts<br/>for week ending October 30, 2015.</p>\n",
            "<p>review document  with Kantor, KT, Hobblit, and Lambert,  including prep time </p>\n",
            "<p>Di progress in writing a wrapper to interact between JS9 within Jupyter</p>\n",
            "<p>Support for lsst-dev cluster, OpenStack, and accounts<br/>for week ending October 17, 2015.</p>\n",
            "<p>Robert McKercher</p>\n",
            "<ul>\\t<li>Moved spare rack to Row C</li>\\t<li>Documented setup of new LSST vSphere setup (<a href=\"https://wiki.ncsa.illinois.edu/display/LSST/LSST+vSphere\" class=\"external-link\" rel=\"nofollow\">https://wiki.ncsa.illinois.edu/display/LSST/LSST+vSphere</a>)</li>\\t<li>Debugging networking issues on new lsst-esxi1 server - testing with new/alternate hardware</li>\\t<li>Installed 6 new drives for historical log storage on lsst10 MySQL server</li></ul>\n",
            "<p>Day 1 : Facility Coordination Day with Argonne, CC-IN2P3, NERSC, and NCSA<br/>Day 2: Extended JCC meeting</p><p>Notes posted on Confluence: <a href=\"https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=JCC&amp;title=Extended+JCC+meeting+--+2015-11-23\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/pages/viewpage.action?spaceKey=JCC&amp;title=Extended+JCC+meeting+--+2015-11-23</a> </p>\n",
            "<p>Sahand progress on learning about Openstack</p>\n",
            "<p>provide switch quantities, weight, power and budgetary costs</p>\n",
            "nan\n",
            "<p>Starting with raw DECam data, perform single frame processing and then try image coaddition with a few visits of images. </p>\n",
            "<p>Need to finish documentation, implementation and comments on the code</p>\n",
            "<p>Di progress on Communication technologies for the web</p>\n",
            "<p><em>Executor</em> can work in two modes. It can either use existing input repository or create one from scratch in a specified location. Currently, when in latter mode, by default, it deletes any directory in that location before starting building a new one. The mode is selected automatically based on presence certain fields in job description. It may lead to accidental removal of an existing dataset repository if a malformed job description file is used. The goal is to make <em>Executor</em> much more careful when dealing with existing dataset repositories and  remove anything only if explicitly asked.</p>\n",
            "\"<p>I'll make sure I explored other alternatives before creating a RFC for adding networkx which by itself require other packages. This is needed for the pipe_flow_x work. I tried one stand-alone package before pygraphviz but then decided to migrate to networkx as it is more complete and allow other possible future features</p>\"\n",
            "nan\n",
            "<p>Reprocess the HSC RC dataset, as defined in <a href=\"https://docushare.lsst.org/docushare/dsweb/Get/DMTR-31\" class=\"external-link\" rel=\"nofollow\">DMTR-31 Sect. 4.1 </a>, using Stack w_2017_38.  Steps include <tt>makeSkyMap.py</tt>, <tt>singleFrameDriver.py</tt>, <tt>mosaic.py</tt>, <tt>coaddDriver.py</tt>, and <tt>multiBandDriver.py</tt> (<a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a>).</p>\n",
            "<p>weekly LSST local grouop meetings, NCSA meetings (All-hands, software, etc), code review, other local meetings, postdoc meetings and tasks</p>\n",
            "<p>Reprocess the HSC RC dataset using w_2017_26 following the same steps as in <a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a></p>\n",
            "<p>A RUNID needs to be added as an option to EventAppender to allow event logging selectors to receive only events for a particular run.</p>\n",
            "<p>Document in the wiki how the test and development systems are connected and configured.</p>\n",
            "<p>2 days of design discussions and refining functional diagrams of the Alert Productions and Image Ingest system.</p>\n",
            "<p>Message types for system bookkeeping acknowledgements as well as report messages were added to the existing dictionary and the means for acting upon these message types are being added to component prototype code.<br/>In addition, needed changes were made to the existing dictionary so all reporting entities write more complete details to their report message queues.</p>\n",
            "<p>Support for lsst-dev cluster, OpenStack, and accounts<br/>for week ending September 5, 2015.</p>\n",
            "<p>Will deploy a new version of kubernetes cluster (v1.7) with Cinder volume attached and NFS server</p>\n",
            "<p>Remove pex_logging dependency on pipe_tasks.</p>\n",
            "<p>Review of design documents, correspondence with the design team regarding Data Center details and floor space, and conferences via web links.</p>\n",
            "<p>With the transition of Tasks\\' logs from lsst.pex.logging to lsst.log (<a href=\"https://jira.lsstcorp.org/browse/DM-6999\" title=\"Use lsst::log in pipe_base and pipe_tasks\" class=\"issue-link\" data-issue-key=\"DM-6999\"><del>DM-6999</del></a>), suggest changesets using lsst::log instead of pex::logging in meas packages that has dependency on Tasks\\' logging framework. </p>\n",
            "<p>Run the HSC RC reprocessing using a Python 3 stack. </p>\n",
            "nan\n",
            "<p>Support for lsst-dev cluster, OpenStack, and accounts<br/>for week ending October 10, 2015.</p>\n",
            "<p>There are a couple references to EventLog in ctrl_orca, which is an object that no longer exists.</p>\n",
            "<p>Activities this month include: IT sys admin meetings, LSST internal project meetings, conducting, coordinating, discussing interviews. Meeting with candidates. ICI coordination meeting (Randy). Discussion of work-to-be-done with onboarded teammates. Relaying task prioritization to IT for LSST-related activities. </p>\n",
            "<p>Sahand progress on learning Docker containers and potential automatic deploy in OpenStack</p>\n",
            "<p>Add remaining components: power estimates, vSphere annual licensing, networking, PDUs, login nodes</p><p>review: misc expense fund, decommissioned services, financial targets</p>\n",
            "<p>Work though recruiting for software effort.  Investigated and filled the \"kenton\" recruiting pattern at NCSA &#8211; (few explicit requirements, many desirable)</p><p>Began discussion to break down hires for \"2nd\" floor  work &#8211; to be in the LSST group v.s support groups &#8211; ADS and Doug\\'s group</p>\n",
            "<p>Reprocess the HSC RC dataset using <tt>w_2017_25</tt> following the same steps as in <a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a> </p>\n",
            "<p><a href=\"https://jira.lsstcorp.org/secure/ViewProfile.jspa?name=aritter\" class=\"user-hover\" rel=\"aritter\">Andreas Ritter</a> got this error when running <tt>constructBias.py</tt>. It seems <tt>pipe_drivers</tt> needs changes following the logging framework transition in <tt>pipe_base</tt>. </p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">bias WARN: Unable to process DataId(initialdata={</span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'category\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'A\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'taiObs\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'2015-12-04\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'visit\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">6301</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'dateObs\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'2015-12-04\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'site\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'S\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'filter\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'r\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'field\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'BIAS\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'spectrograph\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">2</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'ccd\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">5</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'arm\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">: </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'r\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">}, tag=set([])): Wrong number or type of arguments </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> overloaded function </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'Log_log\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82Possible C/C++ prototypes are:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82lsst::log::Log::log(lsst::log::Log,log4cxx::LevelPtr,log4cxx::spi::LocationInfo </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> &amp;,</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">char</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> *,...)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82lsst::log::Log::log(log4cxx::LevelPtr,log4cxx::spi::LocationInfo </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> &amp;,</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">char</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> *,...)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">NotImplementedError on tiger1:</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">27163</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> in map: Wrong number or type of arguments </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> overloaded function </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'Log_log\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82Possible C/C++ prototypes are:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82lsst::log::Log::log(lsst::log::Log,log4cxx::LevelPtr,log4cxx::spi::LocationInfo </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> &amp;,</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">char</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> *,...)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82lsst::log::Log::log(log4cxx::LevelPtr,log4cxx::spi::LocationInfo </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> &amp;,</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">char</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> *,...)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Traceback (most recent call last):</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/ctrl_pool/12.0+45/python/lsst/ctrl/pool/pool.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">89</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> func(*args, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/ctrl_pool/12.0+45/python/lsst/ctrl/pool/pool.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">207</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in wrapper</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> func(*args, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/ctrl_pool/12.0+45/python/lsst/ctrl/pool/pool.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">524</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in map</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> self._processQueue(context, func, zip(range(num), dataList), *args, **kwargs)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/ctrl_pool/12.0+45/python/lsst/ctrl/pool/pool.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">421</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in _processQueue</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> [func(self._getCache(context, i), data, *args, **kwargs) </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> i, data in queue]</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/pipe_drivers/12.0-3-g33a9219+35/python/lsst/pipe/drivers/constructCalibs.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">459</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in process</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82exposure = self.processSingle(sensorRef)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/pipe_drivers/12.0-3-g33a9219+35/python/lsst/pipe/drivers/constructCalibs.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">477</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in processSingle</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> self.isr.runDataRef(dataRef).exposure</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/obs_subaru/12.0-18-gb01a726+1/python/lsst/obs/subaru/isr.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">268</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in runDataRef</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82ccdExposure = self.assembleCcd.assembleCcd(ccdExposure)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/ip_isr/12.0-7-ga6ffce9+2/python/lsst/ip/isr/assembleCcdTask.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">229</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in assembleCcd</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82self.postprocessExposure(outExposure=outExposure, inExposure=getNextExposure(ccd[</span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">]))</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/ip_isr/12.0-7-ga6ffce9+2/python/lsst/ip/isr/assembleCcdTask.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">243</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in postprocessExposure</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82self.setWcs(outExposure = outExposure, inExposure = inExposure)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/ip_isr/12.0-7-ga6ffce9+2/python/lsst/ip/isr/assembleCcdTask.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">280</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in setWcs</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82self.log.log(self.log.WARN, </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"No WCS found in input exposure\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82File </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\"/tigress/HSC/LSST/stack/Linux64/log/12.0-5-g1df3bbf/python/lsst/log/logLib.py\"</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, line </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">249</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">, in log</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">return</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> _logLib.Log_log(self, *args)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">NotImplementedError: Wrong number or type of arguments </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">for</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> overloaded function </span><span style=\"color: blue; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\'Log_log\\'</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82Possible C/C++ prototypes are:</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82lsst::log::Log::log(lsst::log::Log,log4cxx::LevelPtr,log4cxx::spi::LocationInfo </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> &amp;,</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">char</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> *,...)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82\\xe2\\x80\\x82lsst::log::Log::log(log4cxx::LevelPtr,log4cxx::spi::LocationInfo </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> &amp;,</span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">char</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> </span><span style=\"color: #006699; font-weight: bold; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">const</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"> *,...)</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   width: auto; padding: 0;\">&nbsp;</pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">application called MPI_Abort(MPI_COMM_WORLD, </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">1</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">) - process </span><span style=\"color: #009900; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">0</span><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\"></span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/>\n",
            "<p>The Linux build for ctrl_stats succeeds, but the mac OS X build for ctrl_stats fails in the tests/testYearWrap.py.</p><p>Additionally, a change in Python 3.6:</p><p/><div id=\"syntaxplugin\" class=\"syntaxplugin\" style=\"border: 1px dashed #bbb; border-radius: 5px !important; overflow: auto; max-height: 30em;\"><table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"font-size: 1em; line-height: 1.4em !important; font-weight: normal; font-style: normal; color: black;\">\\t\\t<tbody >\\t\\t\\t\\t<tr id=\"syntaxplugin_code_and_gutter\">\\t\\t\\t\\t\\t\\t<td  style=\" line-height: 1.4em !important; padding: 0em; vertical-align: top;\">\\t\\t\\t\\t\\t<pre style=\"font-size: 1em; margin: 0 10px;  margin-top: 10px;   margin-bottom: 10px;  width: auto; padding: 0;\"><span style=\"color: black; font-family: \\'Consolas\\', \\'Bitstream Vera Sans Mono\\', \\'Courier New\\', Courier, monospace !important;\">Unknown escapes consisting of \\'/\\' and an ASCII letter in regular expressions will now cause an error.</span></pre>\\t\\t\\t</td>\\t\\t</tr>\\t\\t\\t</tbody></table></div><p/><p>now makes some code in terminated.py fail (and possibly in other places).</p>\n",
            "<p>Sahand progress on getting the interface to access the Openstack interface using Nova Client</p>\n",
            "<p>Learn more about orchestration, task execution, and logging.  </p>\n",
            "nan\n",
            "<ul>\\t<li>Updated lsst-dev7 with few missing pieces after initial user testing</li>\\t<li>Setup 3 of 8 lsst-test servers</li>\\t<li>Confirmed IPMI setup on new test servers (working with Dell on issue with 1 iDRAC license upgrade)\\t<ul>\\t\\t<li>Completed and verified IPMI setups\\t\\t<ul>\\t\\t\\t<li>Installed licenses for lsst-test1 - lsst-test6</li>\\t\\t\\t<li>re-associated IPMI lsst-test1m last-tsst6m with the correct systems.</li>\\t\\t\\t<li>Installed CentOS7 on lsst-test1 - lsst-test6. (in progress)</li>\\t\\t</ul>\\t\\t</li>\\t</ul>\\t</li>\\t<li>UPS setup\\t<ul>\\t\\t<li>Setup table with location of systems in 3003 racks</li>\\t\\t<li>Setup apcusbd on lsst-stor141, lsst-stor142, lsst-stor143, lsst-stor144, lsst20, lsst13</li>\\t</ul>\\t</li></ul>\n",
            "<p>Read proposed  \"Hardware\" contract amendment, sent marked up comments to Julie Robinson, U of I contract negotiator.  Major points are that Hardware is not descriptive of all purchases  needed to fulfill SOW.  The procurement approval process needs spelling out. Detailed guidance in comments inserted into contract.</p><p>Along with M. Gelman met with the NCSA business people to fully understand the U  of I invoicing process, and the information in the existing business processes. prior to inventing processes for the  supplementing the U of I invoice with the more detailed annotations (hours by WBS) agreed to in the LSST contract.  Obtained help from the NSCS IT group. Documented in tow page note. </p><p>Met concerning seemingly large amount of effort to respond to hip chat take about slowness in the NCSA development system.   </p><p>Miscellaneous and meetings. </p>\n",
            "<p>Reprocess the HSC RC dataset using w_2017_28 following the same steps as in <a href=\"https://jira.lsstcorp.org/browse/DM-10129\" title=\"Process HSC RC dataset using Stack version chosen for the full S17B reprocessing\" class=\"issue-link\" data-issue-key=\"DM-10129\"><del>DM-10129</del></a>/<a href=\"https://jira.lsstcorp.org/browse/DM-11020\" title=\"Reprocess RC with w_2017_25\" class=\"issue-link\" data-issue-key=\"DM-11020\"><del>DM-11020</del></a></p>\n",
            "<p>Add accounts and install software necessary to begin benchmarking the L1 system on the phase 1 test platform. Formulate test plan.</p>\n",
            "nan\n",
            "<p>Drafted documentation for Web SSO capabilities: <a href=\"https://confluence.lsstcorp.org/display/LAAIM/Web+SSO\" class=\"external-link\" rel=\"nofollow\">https://confluence.lsstcorp.org/display/LAAIM/Web+SSO</a><br/>Began testing new NCSA IAM capabilities (group management, user self-registration).<br/>Registered NCSA with InCommon as a sub-org of UIUC to ease future IdP/SP registrations.<br/>Attended local NCSA LSST coordination meetings.</p>\n",
            "<p>If we choose Kubernetes to manage the clusters and container microservices, we can then manage Jupyterhub as well. This story might be pushed for next cycle</p>\n",
            "nan\n",
            "nan\n",
            "\"<ul>\\t<li>Received Dell iDrac license upgrades for new Dell R730 servers</li>\\t<li>Received and configured VMware vSphere licenses from CDW-G &amp; AURA</li>\\t<li>Converted three physical systems to VM's:\\t<ul>\\t\\t<li>lsst-nagios\\t\\t<ul>\\t\\t\\t<li>Problems with software mirror raids.\\t\\t\\t<ul>\\t\\t\\t\\t<li>VMware converter does not see software raided drives.</li>\\t\\t\\t\\t<li>Split the raid 1 into discrete drives.</li>\\t\\t\\t\\t<li>Chose sda to modify - failed as sad was faulty.</li>\\t\\t\\t</ul>\\t\\t\\t</li>\\t\\t\\t<li>Built new Centos 6.6 VM\\t\\t\\t<ul>\\t\\t\\t\\t<li>Used CrashPlan to rebuild.</li>\\t\\t\\t</ul>\\t\\t\\t</li>\\t\\t</ul>\\t\\t</li>\\t\\t<li>lsst7 - converted after learning how to convert system to a fixed IP subnet</li>\\t\\t<li>lsst8 - converted\\t\\t<ul>\\t\\t\\t<li>Debugged lsst8 system migration to vmware. \\xc2\\xa0Partition table was invalid and was preventing move</li>\\t\\t</ul>\\t\\t</li>\\t</ul>\\t</li>\\t<li>Finished moving all VMs to new lsst-vsphere infrastructure</li></ul>\"\n",
            "nan\n",
            "nan\n",
            "<p>Moving back to the LSST VM Cluster is not trivial. It is terrific for testing up to 11 forwarder and distributor pairings, bit when it was first used for the testing of prompt processing, it was functional but crude in that it did not have the more sophisticated configuration capabilities recently added to the base part of the system. Now development efforts on Nebula have been terminated except for a small, turnkey demo configured for archiving with one forwarder.</p><p>The VM Cluster components had to be reassigned, the proper software installed via git and scripts on all 40 nodes, and outside software reinstalled/updated. This story tracks the effort.</p>\n",
            "<p>Use <tt>runOrca</tt> to launch jobs through <tt>lsst-dev</tt> and do some single frame processing with it. Also learn a little about process execution. </p>\n",
            "<p>Di progress on learning these web technologies</p>\n",
            "<p>Support for lsst-dev cluster, OpenStack, and accounts<br/>for week ending February 14, 2016.</p>\n",
            "nan\n",
            "<p>Support for lsst-dev cluster, OpenStack, and accounts<br/>for week ending November 21, 2015.</p>\n",
            "<p>New entries in message dictionary must be added and tested with the existing messaging code base.</p>\n",
            "\"<p>Prepared two longer con accompanied by (hand drawn activity diagrams).  </p><p>One conops /activity  diagram describe the work at the archive center to provide and support the L1 services used by telescope operations.</p><p>the second activity diagram and conops respdes to Chuck Clavers' request to have materials that explain the relationship of the stiletto computing center at CCIN2P3 to Archive Center at NCSA.</p><p>Both are DRAFT; and coops seem to be systems engineering documents, and where to deliver a blessed version and who is responsible for this is unclear to me. </p>\""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "nan\n",
            "nan\n",
            "<p>This issue is the implementation for <a href=\"https://jira.lsstcorp.org/browse/DM-1126\" title=\"design new Footprint API\" class=\"issue-link\" data-issue-key=\"DM-1126\"><del>DM-1126</del></a>, including fixing code broken by the API changes.  This issue should be given subtasks for discrete pieces of work as part <a href=\"https://jira.lsstcorp.org/browse/DM-1126\" title=\"design new Footprint API\" class=\"issue-link\" data-issue-key=\"DM-1126\"><del>DM-1126</del></a>, as it has a lot of story points.  Because it\\'s likely all of this needs to be merged at the same time, it should probably be done on a single branch, unless some of the earlier work can be done in a backwards-compatible way..</p>\n",
            "nan\n",
            "nan\n",
            "<p>We have a working plan of putting the buildbot-scripts under jenkins demo into usage as a production CI system as an intermediate step towards a fully decomposed build.</p>\n",
            "nan\n",
            "<p>Using the PSF simulations generated in <a href=\"https://jira.lsstcorp.org/browse/DM-1131\" title=\"create PSF simulations for shapelet approximation test\" class=\"issue-link\" data-issue-key=\"DM-1131\"><del>DM-1131</del></a> and the GalSim package, generate ~20k galaxies for each of 3 shear values for each input PSF.</p><p>Will need to be divided into subtasks - figure out what the outputs should look like, write the code to generate the simulations, estimate the time need to run the simulations, run the simulations at scale, etc.</p>\n",
            "<p>Come up with an architecture for detecting failure or non-nominal conditions (e.g. under replication). The core question to resolve is whether we go with a distributed approach, or with centralized control.</p>\n",
            "<p>(Cf. <a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1024\" class=\"external-link\" rel=\"nofollow\">HSC-1024</a>)</p><p>One poor-man\\'s approach to deblending multiple bands and visits is</p><ul class=\"alternate\" type=\"square\">\\t<li>Deblend in one band (or a combination, e.g. chi^2 band)</li>\\t<li>Fit models in that band</li>\\t<li>In all bands separately fit those models simultaneously to all object in the blend, allowing only a minimum of coefficients to float (ideally only amplitudes, but given the realities of real galaxies the bulge and disk will need to both be fit, or the Sloan Swindle components, or the Lensfit Swindle, or ...).  The correct PSF for each image would be used.</li></ul><p>It will probably be necessary to include undetected objects in this fit (cf. <a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1023\" class=\"external-link\" rel=\"nofollow\">HSC-1023</a>), using point-source models.</p><p>It is not clear how much of a poor-man\\'s solution this actually is, or whether it will work quite well.</p>\n",
            "<p>(See also <a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1025\" class=\"external-link\" rel=\"nofollow\">HSC-1025</a>)</p><p>One poor-man\\'s approach to deblending multiple bands and visits is</p><ul class=\"alternate\" type=\"square\">\\t<li>Deblend in one band (or a combination, e.g. chi^2 band) using an SDSS-like algorithm that produces templates for each child</li>\\t<li>Take the templates (or possible model fits to those templates) and use them to deblend the objects in all other bands</li></ul><p>It will probably be necessary to include undetected objects in this fit (cf. <a href=\"https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1023\" class=\"external-link\" rel=\"nofollow\">HSC-1023</a>), using point-source models.</p><p>Note that this does not allow for the different seeing in each band.  This is not obviously catastrophic for reasonably wide blends as the total flux in each pixel is conserved, and if only one template is important near an object\\'s centre the exact form of the template is unimportant.</p>\n",
            "nan\n",
            "<p>Prototype an environment that allows automatic </p><ul class=\"alternate\" type=\"square\">\\t<li>Provisioning of a VM for a certain OS</li>\\t<li>Install the Stack prerequisites for that OS</li>\\t<li>Build the stack via newinstall.sh from the production server</li>\\t<li>Run integration tests (in the curent case the sdss test</li></ul><p><a href=\"https://github.com/lsst-sqre/sandbox-stackbuild\" class=\"external-link\" rel=\"nofollow\">https://github.com/lsst-sqre/sandbox-stackbuild</a></p>\n",
            "<p>Master-branch doxygen documentation should be rebuild on every full master build.</p>\n",
            "<p>Currently we are using a generic 2-d binning algorithm, that is finding minimum and maximum values of the two columns to be visualized and bins the values into 2-d grid with the specified number of grid cells.</p><p>This algorithm distorts data in the pole regions and whenever data are on both sides of ra=0. More smart binning based on a spatial index is necessary when reducing the number of (ra,dec) entries intended for visualization.</p>\n",
            "nan\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>FITS reader class refactoring, improve readability</li>\\t<li>validation of the new code against the old one</li>\\t<li>unit test</li>\\t<li>performance improvement recording if possible</li></ul>\n",
            "<ul class=\"alternate\" type=\"square\">\\t<li>checkout the classes</li>\\t<li>understand the FITS standard and current implementation</li></ul>\n",
            "<p>Attend the annual  ADASS conference to keep up with the software development in the astronomy community. <br/>Trey Roby, Tatiana Goldina, Xiuqin Wu plan to attend the ADASS 24.</p>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptJ8hWbL8VB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60e709e9-1628-44cb-e56e-7f834feb361e"
      },
      "source": [
        "for _ in titles:\n",
        "  print(_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " configuration\n",
            " rc2 with w_2018_38\n",
            " rc2 with w_2018_42\n",
            " hits 2014, build template coadds\n",
            " sphinx-based task documentation for packages\n",
            " draft of task documentation topic-type\n",
            " user visible error reporting in qserv with antlr4 parser\n",
            " lsst30 dataset to cloud\n",
            " k8s and deployment documentation for test deployment in the cloud\n",
            " rc2 with w_2018_41\n",
            " end users to cancel builds\n",
            " pod policies within k8s commons\n",
            " using file headers for overscan region definition\n",
            " gain measurement from eotest's ptc task with bftask.estimategains()\"\n",
            " to comparison scripts in pipe_analysis\n",
            " message mod\n",
            " telemetry queues and proper callbacks for the queues in l1 dm system\n",
            " initial telemetry stream to ocs_bridge\n",
            "  command for dmcs\n",
            " rfc-534: update naming of base_blendedness fields\n",
            " management of gke persistentdisks\n",
            " potential issue with setting of not_deblended mask\n",
            " adass butler poster\n",
            " machine generating/verifying butler storageclass\n",
            " butler quantumgraph\n",
            " test cases for makedatagraph and dataunitmap\n",
            " -supertask executor for conversion testing\n",
            " functionality for metadata stripping in afw\n",
            " squash metrics into honeycom\n",
            " to prometheus\n",
            " dm pipelines tutorial\n",
            " dcrcoadd subfilter order\n",
            " the bf simulation code so that the biascorr parameter can be measured\n",
            " shapelet documentation to numpydoc and remove python 2 compatibility\n",
            " and test headerservice to use feature-ignore-empty\n",
            " install for tpc/https with oauth2/scitokens - tests with demo issuer\n",
            " transfer of data on 3 nfs filesystems\n",
            " mask transparency and color  in display_firefly\n",
            " jl 0.34-compatible extensions\n",
            " for tomcat version 9\n",
            " lsst firefly deployment to java 10\n",
            " ap documentation into pipelines.lsst.io\n",
            " quote(s)\n",
            " output of the test specification generation script\n",
            " camera round-trip persistable via afw::table::io\n",
            " up authentication for influxdb on monitor01\n",
            " community post about new star galaxy classifier\n",
            " testing\n",
            " ap_verify to lsst_distri\n",
            " tasks/task configuration and prototype documentation architectures\n",
            " daf_butler put handle all identifier types\n",
            " full description of the current state of the mini-broker art\n",
            " variable names in multibanddriver\n",
            " proof of concept dask notebook\n",
            " jenkins workspace cleanup\n",
            " jenkinns core to >= 2.121.3 + plugins to resolve security warnings\n",
            " jointcal config defaults to at least obs_subaru\n",
            " support for activities at lsst2018\n",
            " quotes\n",
            " new lse-61 performance metrics through lcr process\n",
            " utility code/scripts to clean/purge sal messages for csc\n",
            " adm01 backups pushed to gpfs location\n",
            " of current dr backup system\n",
            " how to run pipeline tasks from command line\n",
            " ack timer for auxdevice wait for xfer_params ack\n",
            " data transfer with gcs\n",
            " summaries of tasks' python apis for task documentation topics\"\n",
            " _bridge/dmcs should deny 'same state' transition\"\n",
            " dpdd to specify contents of diaforcedsources and include them in alerts\n",
            " prototype of json for afwdetect footprints\n",
            " changes to pep8 version of headerservice and salpytools\n",
            " textangle in ds9 text regions in firefly\n",
            " pybind11 version to upstream v2.2.0\n",
            " pybind11 build size\n",
            " talk for brazil\n",
            " gpfs health mount check\n",
            " on laptop\n",
            " rc2 with w_2018_36\n",
            " in the t&s ocs scripting workshop\n",
            " code for calculating bias correction factor to brighter-fatter code\n",
            " options for integrating ap with ci\n",
            " limitedregistry concept\n",
            " non-qserv pods from qserv nodes in pdac\n",
            " ha for non-telegraf inputs\n",
            " composite disassembly at butler level\n",
            " public datastore information and datastore internal information\n",
            " storageclasses to define an inheritance tree\n",
            " composites/formatter/template access to use datasettype\n",
            " parameters robustly for get()\n",
            " should issue summary state event when entering fault state\n",
            " of oracle data guard for replication\n",
            " of oracle goldengate for replication\n",
            " through database backups to filesystems\n",
            " drp group's qa procedures\"\n",
            " stack demo to be regular eups product\n",
            " network enforcement configuration for k8s\n",
            " local firefly work area from shared work area\n",
            " up number of filters per node\n",
            " of possible solutions in firefly for ast adoption by lsst pipeline\n",
            " reference catalogs of dcr simulations to new style\n",
            " work on jl environment deployment tool\n",
            " jointcal astrometry of pdr1 hsc-y tract 15832\n",
            " comparison of jointcal/meas_mosaic in validate_drp\n",
            " : do not send row_idx and row_num columns when not requested\n",
            " rc2 with w_2018_34\n",
            " rc2 with w_2018_32\n",
            " __str__ for butler\n",
            "  everywhere\n",
            " pipe_analysis to rfc-498 implementation\n",
            " documentation\n",
            " /publicize new procedures\n",
            " 8 security network architecture: initial planning\n",
            " support for multiple filters per dataset\n",
            " quality control software technote\n",
            " network policies within k8s commons\n",
            " mpi cluster in kubernetes environment\n",
            " continuous delivery for squash docker images\n",
            " configuration\n",
            " requirements\n",
            " pyprofit example scripts into package\n",
            " sip fitter for writing approximations to general wcss\n",
            " rc2 with w_2018_30\n",
            " 8s dashboard and pod monitoring\n",
            " chair/contributor at lsst18\n",
            " tutorials at all-hands\n",
            " metrics to yearly ramp specs\n",
            " dataset planning for ci, small, medium, and large in dmtn\n",
            " specification thresholds back to the code_changes app\n",
            " lsst allhands\n",
            " to use the test management in jira\n",
            " new tags for validate_drp metric definition and specifications\n",
            " antlr4 the main parser & ir generator in master\n",
            " technote on design of notebook-based reports\n",
            " tutorial for the deblending workshop\n",
            " jupyter summary notebook based on hits reprocessing\n",
            " header service uses summarystate enumeration for event information\n",
            " te1, te2 plots to show expected range of 10^-5\n",
            " square demo notebooks\n",
            " timescales and systems for ccob integration to dm\n",
            " uservice_nbreport project for publishing notebook-based reports\n",
            " nbreport issue and other core commands that interact with api.lsst.codes/nbreport\n",
            " scarlet as 3rd party package to the stack\n",
            " characterization report for v16\n",
            " measurements made on different bands in squash\n",
            " the bokeh models api to create new charts\n",
            " flasgger for the squash rest api documentation\n",
            " up handling of extra data id information in supertask.run\n",
            " noexcept specifiers to applicable methods in afw\n",
            " storage requirements\n",
            " work for xrootd install for third party copy/https with oauth2/scitokens\n",
            " input from operators\n",
            " work on kubernetes cluster\n",
            " k8s resource management tools\n",
            " and run initial time test\n",
            " quotes\n",
            " and prepare procurement activity\n",
            " and prepare procurement activity\n",
            " cases\n",
            " the deblender to use multiband classes\n",
            " optimization 1\n",
            " position errors in scarlet blends\n",
            " findings regarding data management in pegasus into technote\n",
            " table display: enable display of data type for each column\n",
            " there useful informations about aerosols in merra-2 ?\n",
            " nbreport test command\n",
            " scipy meeting\n",
            " investigation of using the stack from singularity containers\n",
            " -write internal dcr template wcs-matching\n",
            " dcr code an eups package\n",
            " logging in dcr code\n",
            " dcr command line task\n",
            " comparing angles in matchpessimisticb, make sure all vectors are plane projected\n",
            " per-object galactic extinction correction in color analysis qa plots\n",
            " blending presentation for sc chairs\n",
            " overnight variation of merra-2 ozone level above lsst site statistically significant ?\n",
            " package and module documentation directories exclusive\n",
            " hsc data\n",
            " rfc-483: fix image bbox slicing origin\n",
            " lsst the docs tracking mode for eups tags (major, weekly, daily)\n",
            " consistency\n",
            " design\n",
            " resource limiting in current mini-broker setup\n",
            " table parsing and memory usage\n",
            " should also support no paging option\n",
            " up environment for alert processing testing.\n",
            " integrate cluster into lsst infrastructure\n",
            " instructions for ats turnkey system operation\n",
            " improvements\n",
            " heapster integration with ldf monitoring\n",
            " away from \n",
            " patch consistency and automation during (re-)deployment process\n",
            " earthquake activity for system issue correlation\n",
            " improvements for sims / pst projects\n",
            " local volumes kubernetes api for qserv data\n",
            " rc2 with w_2018_26\n",
            " into production\n",
            " testing\n",
            " configuration\n",
            " federation across different kubernetes clusters\n",
            " to sphinx-automodapi package\n",
            " more bands optional with fgcmcal\n",
            " -alone function to test assembly of header files and daq pixels using python\n",
            " configuration testing\n",
            " legacy auth scheme for https access for xrootd\n",
            " technote describing job clustering in pegasus wms\n",
            " current design of the supertask\n",
            " skypix and spatial relationships to gen2->gen3 conversion\n",
            " characterization report for v15\n",
            " -run hits data processing with current ap_pipe\n",
            " license/copyright docs out of  documentation\n",
            " rc2 with w_2018_24\n",
            " rc2 with w_2018_15\n",
            " dmtn upload to docushare\n",
            " reference wavefront\n",
            " plan to measure reference wavefront from out-of-focus images.\n",
            " familiar with cwfs\n",
            " two independent on-sky calibrations of 0.9-m telescope\n",
            " profit and galsim galaxy modelling speed and accuracy\n",
            " treecorr to validate_drp and lsst_ci dependencies\n",
            " script to produce release performance table\n",
            " driver uses wrong method signature in rundetection\n",
            " how forced photometry works\n",
            " data set for miniproduction\n",
            " scripts to run miniproduction\n",
            " data for miniproduction\n",
            " script to clean up after miniproduction run\n",
            " verification test report\n",
            " package docs to datasets\n",
            "  coeffecients \\xc3\\xa0 la ivezi\\xc4\\x87 et al. 2004 for the hsc filters\n",
            "10 years of atmospheric parameters above mauna kea from the snfactory vs nasa merra\n",
            " datastore optionally transactional\n",
            " master and worker configmaps\n",
            " rst directives that build the module and package toctrees for pipelines.lsst.io\n",
            " base class api tweaks\n",
            " pre-multitrace chart code and server-side expressions\n",
            " dmtn-060 with broader survey of data management / file transfer\n",
            " regularized moments code use sky tangent plane coordinates\n",
            " multiband to work on dcr subfilter coadds\n",
            " framework testing\n",
            " oracle benchmarking/testing\n",
            " landing page for lsp-demo\n",
            " basic registry.find and related functionality\n",
            " dataunit class (and children) in butler prototype\n",
            " butler provenance primitives\n",
            " coverage testing of unittest\n",
            " ellipticity measurement to validate_drp\n",
            " rc2 with w_2018_22\n",
            " files comparison script for pixels only\n",
            " behaviour of cmodel initial fits with varying numbers of components\n",
            " multibanddriver on hsc tract with varying cmodel initial components\n",
            " at how the classifier performs on data with different depth to the training data\n",
            " utility structures needed for forward global calibration module\n",
            " orthogonal distance regression fits to the color analysis\n",
            " oracle dialect in ap prototype script\n",
            " lsp nb access to firefly in kubernetes commons\n",
            " into production\n",
            " testing\n",
            " maxpsfwcsselectimagestask\n",
            " work on deployment tool\n",
            " butler dataunitset\n",
            " butler datasettype\n",
            " fitting in-focus psf optical model with wavefront model.\n",
            " meas_modelfit/s13starselector to new baseclass\n",
            " lsst-sphinx-bootstrap-theme for multiple projects\n",
            " cluster provisioning and k8s setup\n",
            " k8s proxy manifest for worker and master pods\n",
            " of the hsc pdr1 dataset\n",
            " of the hsc pdr1 dataset\n",
            " rc2 with w_2018_20\n",
            " testing at ncsa\n",
            " requirements matrix for headerservice\n",
            " implementing concrete composite component-writing\n",
            " meas_algorithms/objectsizestarselector to new baseclass\n",
            " -demo.ncsa.illinois.edu ssl cert expires 2017-11-26\n",
            " operations concept for data access processing system\n",
            " operations concept for data backbone\n",
            " functional breakdown for observation processing system\n",
            " operations concept for batch processing system\n",
            " interface for application monitoring\n",
            " display and expression improvements\n",
            " image zoom and healpix grid level control\n",
            " ip_diffim/diacatalogsourceselector to new baseclass\n",
            " mariadb in k8s\n",
            " , verify items received, place items in rack\n",
            " an mvp 404 page for lsst the docs\n",
            " ndarray pybind11 type_casters to avoid numpy api\n",
            " rc2 with w_2018_18\n",
            " up development workflow for jellybean\n",
            " lsp design document ldm-542 to dm-ccb for approval\n",
            " expanding options form\n",
            " slides for drp meeting\n",
            " for hips image - pixel size and image pixel\n",
            " matchersourceselector to new baseclass\n",
            " improvements in dax_imgserv\n",
            " astrometrysourceselector to new baseclass\n",
            " makepsfcandidates into its own task\n",
            " dax specific ci environment\n",
            " realistic footprint sizes for use in coadd studies\n",
            " more cosmos reruns\n",
            " task that computes single consolidated qa table for whole tract\n",
            " up short how to for using synpipe\n",
            " posixdatastore's internal records persistent\"\n",
            " dbserv async\n",
            " rc2 with w_2018_17\n",
            " usage.py to allow the user to specify slurm job names.\n",
            " comparison for cwg\n",
            " sphinx front-end for building stack documentation\n",
            " general lsst the docs build upload cli in ltd conveyor\n",
            " ltd-conveyor packaging\n",
            " tune auxdev ack consumption and make more efficient.\n",
            " new starselector baseclass\n",
            " meas_algorithms/flaggedstarselector to new baseclass\n",
            " of purchase order from university of illinois\n",
            " meas_algorithms/secondmomentstarselector to new baseclass\n",
            " gen3 butler support to cmdlinetask\n",
            " terraform config for openstack setup\n",
            " hips image to python api\n",
            " requirements for reformatted efd schema\n",
            " debug functionality to bf kernel measurement code\n",
            " up new production instance and synchronize databases\n",
            " : bad amps eat up temporal budget\n",
            " libraries for jh/jl\n",
            " telescope & site subsystem meeting\n",
            " bokeh apps for accessing data from the flask rest api and from s3\n",
            " rc2 with w_2018_14\n",
            " transformation filters to c++\n",
            " the stack for uses of xytransform which need replacing\n",
            " ap_verify to run under slurm\n",
            " & install header service software for integration activity\n",
            " rc with stack version 14.0\n",
            " cloudmanager script to use shade client\n",
            " the hips grid icon, always add the hips grid layer with checkbox off\n",
            " telescope & site subsystem meeting\n",
            " the epo all hands\n",
            " k8s on cc-in2p3 upper half cluster\n",
            " image name display and improvement on using hips initial values\n",
            " to dm\\xe2\\x80\\x99s 2018 spie dm process paper\n",
            " cli (templatekit) to use the lsst/templates repository\n",
            " conversion for ap_association\n",
            " rc2 with w_2018_12\n",
            " code changes back to the monitor app\n",
            " approval from project\n",
            " of alert thresholds for ldf monitoring stack\n",
            " level api need to be updated to use the latest chart single trace options\n",
            " l1 integration system for integration activity\n",
            " minimum and maximum lambda to filter properties\n",
            " backport: jacobian and focalplane algorithms\n",
            " smoothness constraint\n",
            " should be copied\n",
            " current status and findings\n",
            " short write up on the findings of shape model failures\n",
            " webpack/babel to use env for pollyfills and add webpack-visualizer-plugin\n",
            " astrometry talk for pst/scc\n",
            " the /code_changes resource in the flask rest api to feed the monitor app\n",
            " to spie paper\n",
            " summary tables for jointcal/meas_mosaic comparison\n",
            " out api and where to store blob metadata for datastore\n",
            " ipyaladin and rise to lab container\n",
            " final conclusions to dmtn-028\n",
            " dm on-boarding process with coordination between project it, ncsa, dm t/cams and admin\n",
            " jenkins dockerd/xfs errors\n",
            " kafka mirrormaker service\n",
            " into bright classification failures\n",
            " jenkins snapshot purging\n",
            " column expressions for column names that are not alpha-numeric\n",
            " 3 requirements flowdown\n",
            " gh account disabled\n",
            " configuration\n",
            " color-color plotting in interactive qa framework\n",
            " script to automatically generate template notebooks for interactive qa\n",
            " ap_pipe to multiple visits\n",
            " explicit buildbot dependency on datarel\n",
            " documentation for ap_verify\n",
            " old gwt from firefly\n",
            " developer guide topic reorganization\n",
            " procurement activity\n",
            " configuration\n",
            " quote(s)\n",
            " constrainedpolymodel to use constrained affine chip and unconstrained polynomial visit models\n",
            " model should fix one sensor instead of one visit\n",
            " fgcm to use proper sourceselectors to select sources\n",
            " /etc/sysconfig/docker at cc-in2p3\n",
            " butler storageclass\n",
            " machine generating/verifying butler dataunits\n",
            " minimal butler prototype\n",
            " butler registry schema definition in yaml\n",
            " rc2 with w_2018_10\n",
            " knowledge on greedy fitting with priors\n",
            " introductory docs on running fgcm\n",
            " hsc data tract 8524 strangeness with qa tools\n",
            " donut analysis optics psf plotting tools\n",
            " pub-56\n",
            " pub-58\n",
            " dmtn describing qa efforts in advance of march ahm\n",
            " rc with w_2018_08\n",
            " message handling for failed table filtering\n",
            "_filename functions return first mappable repository even when file does not exist\n",
            " on prototyping dax_metaserv v1 based on ivoa standards\n",
            " to software stack\n",
            " multiple compiler strings and/or wildcard matching in lsst_compiler\n",
            " monitoring for the batch scheduler\n",
            " jupytercon 2018 cfp\n",
            " example auto-build system for the templates repository\n",
            " up design proposal for butler composites\n",
            " rc1 with w_2018_03\n",
            " & configure specified software versions\n",
            " in webplotrequest needs some work and review\n",
            " association math from diaobjectcollection into associationtask\n",
            " daq workshop\n",
            " repositories more idiomatically\n",
            " testing\n",
            " input bboxes in inputrecorder per psfmatched warp in warpcompare\n",
            " s15 large scale test @ cc-in2p3\n",
            " metadata for databases without description\n",
            " full example of numpydoc'd module\"\n",
            " flag to metaserv showing if qserv_area_spec is available\n",
            " of purchase order from university of illinois\n",
            " of purchase order from university of illinois\n",
            " of purchase order from university of illinois\n",
            " _build git fetch/clone retrying\n",
            " rc with w_2018_06\n",
            " for kubernetes dashboard installation\n",
            " task documentation for psfmatchtask\n",
            " design issues with datasetref hierarchy and preflight (p)\n",
            " design issues with datasetref hierarchy and preflight (j)\n",
            " failures should cause travis build to fail\n",
            " obs_auxtel\n",
            " lander metadata.jsonld ingest\n",
            " mgmt: refinement\n",
            " and update storage input numbers\n",
            " and update rack counts and costs\n",
            " estimates and costs of items in ldm-144 with networking\n",
            " an internal review for melchior et at. 2018 (deblender paper)\n",
            " ssisession to be deleted by shared pointer.\n",
            " config to make warpcompare very conservative\n",
            " rc with w_2018_04\n",
            " design questions in ap_verify\n",
            " ssirequest::replychannel\n",
            " ncsa cilogon group membership tester\n",
            " status of job creation from the api\n",
            " as-is monitoring and dashboards\n",
            " operations view(s) for 24/7 base aa system\n",
            " dashboards (january)\n",
            " monitor tools and dashboard to cluster\n",
            " the /monitor resource in the flask rest api to feed the monitor app\n",
            " approval from project\n",
            " and test use of jointcal results in validate_drp\n",
            " procurement activity\n",
            " quote(s)\n",
            " framework to run mcmc on object which fail shape determination\n",
            " message types in ncsa foreman\n",
            " out simulated file annex to act as temporary efd.\n",
            " rc with w_2017_52\n",
            " and chart rendering on tri-view when catalog without position information is searched\n",
            " and run the header service on the ncsa l1 teststand\n",
            " noao mosaic geometry fits keyword for ccd amplifiers\n",
            " storageclass configurable in butler datastore\n",
            " approval from project\n",
            "  documentation for firefly_client\n",
            " & configure docker and kubernetes modules\n",
            " qserv in docker\n",
            " -write run method of assemblecoaddtask to iterate over outputs\n",
            " procurement activity\n",
            " of squash-restful-api with current test datasets used in ci\n",
            " will coulton's hsc bf coefficients\"\n",
            " approval from project\n",
            " verification job and data blobs to an s3 bucket using celery\n",
            " mapper for gh <-> slack userids\n",
            " pdac portal for wise single-epoch source data\n",
            " fgcm for python 3 compatibility\n",
            " qa analysis scripts to run on desc dc1 simulations output\n",
            " , verify items received, place items in rack\n",
            " processing and validation\n",
            " needs new parameter for match table separation.\n",
            " interface for multiple components\n",
            " new deblender on simulated data\n",
            " projectmeta mongodb dataset to populate www.lsst.io (mvp)\n",
            " dax v1 image search service in suit\n",
            " rc1 with w_2018_02\n",
            " slivers of calexps are worthless\n",
            " meas_mosaic on acceptance data\n",
            " notebook-based tools to easily browse static qa plots\n",
            " www.lsst.io static site generation\n",
            " .lsst.io project tile design & implementation\n",
            " test report for ldm-503-3\n",
            " procurement activity\n",
            " quote(s)\n",
            " of the flask extensions to be used in the squash rest api\n",
            " fgcm atmospheres for easy distribution\n",
            " git-lfs-s3-server\n",
            " synpipe instruction set\n",
            " base aa monitoring system\n",
            " monitoring applications and dashboard for base aa system\n",
            " of the squash-restful-api service\n",
            " squash qc tier 0 database to allow measurements from different lsst.verify packages\n",
            " tests for the squash rest api\n",
            " test and study local k8s installer\n",
            " document release workflow with lsst the docs\n",
            " base aa system for monitoring installation\n",
            " application-level monitoring\n",
            " numpydoc documentation in developer guide\n",
            " running mini-tests in desdm with newer software\n",
            " requirement of level 3 and data space\n",
            " quote(s)\n",
            " and test the fts3 service of the rucio ecosystem\n",
            " and merge u/fix_outliers\n",
            " rc with w_2017_50\n",
            " test plan for milestone ldm-503-3\n",
            " docstrings for updated deblender\n",
            " procurement activity\n",
            " of purchase order from university of illinois\n",
            " environment and verify ready for production\n",
            " structlog-based logging in ltd keeper\n",
            " versioned docker image continuous delivery pipeline for ltd lander and dasher\n",
            " testing & roll into production\n",
            " configuration\n",
            " configuration\n",
            " , verify items received, place items in rack\n",
            " ltd keeper deployment\n",
            " image data viewing within interactive qa framework\n",
            " scroll-through-visit sky plots for interative qa\n",
            " auth_data at each jupyterhub login\n",
            " and fix empty file list issue\n",
            " hollowed out cores of saturated stars in comparewarp\n",
            " loading of diaobjects to the ccd boundingbox area in ap_assocation\n",
            " out s18 plan for science piplines\n",
            " rc with w_2017_48\n",
            " ap_verify and run it over hits dataset\n",
            " library of shape measurement failures\n",
            " rc with w_2017_46\n",
            " generic utility to emulate ocs commands\n",
            " new sal version with updated xml with proper entercotrol\n",
            " bfd simulations with final parameters in wcs\n",
            " wcs jacobian values from hsc\n",
            " & db docs (fritz)\n",
            " json schema validation package for imageserv\n",
            " restructuredtext documentation to display_firefly\n",
            " hsc rc with desdm version 1.01\n",
            " basic data completeness and integrity checks\n",
            " architectural overview\n",
            " the power/power down sequence for sal device\n",
            " despyastro to python 3\n",
            " databaseapps to python 3\n",
            " despydb to python 3\n",
            " integrationutils to python 3\n",
            " debug tools and use miniconda in dev image generated by ci\n",
            " splitted k8s pods at cc-in2p3\n",
            " : info toolbar button should show the properties info\n",
            " docs for ci.lsst.codes jenkins jobs\n",
            " compression wg -- krzysztof\n",
            " dcr technote\n",
            " additional branch to jenkins validate_drp jo\n",
            " bfd to run with different training set\n",
            " jointcal constrained model fixes to reduce failing factorizations\n",
            " ap plan for f17b\n",
            " into production\n",
            " of purchase order from university of illinois\n",
            " problem in deblender interface with the stack\n",
            " eotest package and port to py3\n",
            " ldm latex documentation development process\n",
            " an rfc for change-controlled dm document git branch and release policy\n",
            " of purchase order from university of illinois\n",
            " approval from project\n",
            " of purchase order from university of illinois\n",
            " squash to kubernetes 1.8\n",
            " -write bandpass class and usage in prototype dcr code\n",
            " galaxy and cosmology class in nov\n",
            " prototype pipeline to use coadds as templates\n",
            " jointcal metrics via metrics logger\n",
            " jupyterhub authenticator mixing cilogon and githu\n",
            " /serialize objects via posixstorage and pull/push using s3 connection\n",
            " support for registry in mysql databases\n",
            " serialization version in butler with datasets in database\n",
            " psfex in good seeing\n",
            " appropriate default configs for comparewarp coadds\n",
            " v1.2 of firefly_client for pypi and sync the lsst fork\n",
            " add fakes to coadds vs. visit images\n",
            " up instructions for kubernetes 1.8.x install on nebula\n",
            " system for publishing templates of package documentation\n",
            " support classes for registry prototype\n",
            " test dataset for butler prototyping\n",
            " obs_comcam policy file\n",
            " design diagramming\n",
            " _client update\n",
            " generation of spawner form\n",
            " jupyterlab github extension\n",
            " approval from project\n",
            " procurement activity\n",
            " approval from project\n",
            " procurement activity\n",
            " quote(s)\n",
            " approval from project\n",
            " procurement activity\n",
            " graphql as an alternative to django rest framework for the squash-api microservice\n",
            " bokeh apps in jupyter/jupyterlab notebooks\n",
            " way to get dataids and statistics from selection in datashader figure\n",
            " problems with connecting to mysql in czar\n",
            " support for accessing schema from querycontext\n",
            " working group (oct)\n",
            " webpack to insert only one global object instead of many global variables\n",
            " rc with w_2017_44\n",
            " makecoaddtempexp.py and assemblecoadd.py config to use psfwcsselect\n",
            " photocalib defintion to use multiplication\n",
            " centering for vignetted pupils\n",
            " synpipe into the stack\n",
            " quote(s)\n",
            " backups for squash-d\n",
            " one tract of hsc rc using desdm framework as of dm-12183\n",
            " tests with davix clients against webdav servers\n",
            " nginx webdav servers as test endpoints\n",
            " small set of data to allow  workflow that contains fringe correction\n",
            " the  into its own block\n",
            " misc desdm support\n",
            " specialized query code for the pipeline\n",
            " /simplify multi-worker tests\n",
            " pagination in the measurements api endpoint to constraint queries\n",
            " documentation to be revised\n",
            " & vet incident response process\n",
            " mgmt: workflow implementation\n",
            " mgmt: consolidation\n",
            " quote(s)\n",
            " out why most hsc datasets start with photometry chi2==nan\n",
            " with science users\n",
            " demo setup for xldb 2017\n",
            " , unpack, and stage hardware\n",
            "3003 clean up\n",
            " butler wg calls\n",
            " some plots from huang et al figures 10, 11, & 12\n",
            " finite bandwidth of dcr planes\n",
            " -jupyterlabdemo failing\n",
            " release w_2017_38 delayed/required manual intervention\n",
            "  stack env to py3 / migrate away from lsst-dev\n",
            " galaxy and cosmology class in oct\n",
            " galaxy and cosmology class in sept\n",
            " rc with w_2017_42\n",
            " 14 pipelines.lsst.io installation instructions part 2\n",
            " package dependencies of template generation\n",
            " event awareness within dm component code\n",
            " the memory usage of one coadddriver jo\n",
            " rc with w_2017_40\n",
            " pipelines release notes for v14\n",
            " job ads for tucson dm positions\n",
            " planning packages for drp & cpp\n",
            " resource requirements for software primitives\n",
            " resource requirements for algorithmic components\n",
            " run comparison and color qa scripts to current apis\n",
            " imagerest_v1 _file_response(): investigate writing lsst.afw.image straight to data vs temp fits file first\n",
            " performance of maxpsfwcsselectimagestask\n",
            " the memory usage of ctrl_pool/pipe_driver task\n",
            " during end-to-end testing with validate_drp and post-qa\n",
            " lsstdoc date for lander from \\\\date command or git\n",
            " initial deployment of l1 test stand machines.\n",
            " data rate calculation\n",
            " views and roles for grafana dashboard as needed\n",
            " to do prediction analysis with available gpfs file system usage data\n",
            " rules for alerting and notification for monitoring systems\n",
            " ipmi metrics for nodes\n",
            " patches/deps from conda-lsst\n",
            " configuration\n",
            " and rack in machine room\n",
            " more filetypes to wcl so to clean up  in the previous mini hsc test\n",
            " and power equipment\n",
            " working group (aug)\n",
            " syntax for table column data identification\n",
            " ci_ctio0m9 up and running and included\n",
            " fy18 acquisition plan\n",
            " _drp hsc dataset butler failure\n",
            " in september 2017 astropy coordination meeting\n",
            " obs_ctio0m9, obs_comcam and ci_ctio0m9 py3 compliant\n",
            " system\n",
            " services for backups/data replication on nebula openstack\n",
            " and placement\n",
            "  htcondor classads scenario\n",
            " vetting of dr procedure\n",
            " switch setup and programming\n",
            " kubernetes on nebula for development investigation\n",
            " into conops and any draft design notes\n",
            " archive dmcs to simulator - v3\n",
            " globus-gridftp-server from osg and configure an associated rucio storage element\n",
            " ldm-143\n",
            " dmtn-060 to summarize the work done in dm-10707\n",
            " and resolve disk space/quota issues\n",
            " mononode test environment for initial learning about installations\n",
            " acceptance\n",
            " mgmt: refinement\n",
            " announcement and follow up nagging\n",
            " plan renewal\n",
            " description of features in storage apis\n",
            " mgmt: process design\n",
            " configuration\n",
            " ipmi bastion hosts\n",
            " initial model of data backbone enclave\n",
            " /datasets in s17b for hsc reprocessing and others\n",
            " ldm-135 (lsst database design)\n",
            " estimates\n",
            " automation\n",
            " contract addendum\n",
            " vetting\n",
            " related emergent work in august\n",
            " recovery design for datasets\n",
            " sections for concept of operations\n",
            " management for f16 august\n",
            " proposed policy\n",
            " dns server issues with nebula and kubernetes\n",
            " if ipmi can replace kvm\n",
            " installation of the daq simulation hardware\n",
            " on new kubeadm process for kubernetes\n",
            " file transfer for dr tool\n",
            " the recent 10.1 release & gather strace logs for file system testing\n",
            " outgoing port issues on blue waters/cray systems\n",
            " gatewaying conops through stage 4\n",
            " configuration\n",
            " categorization for docushare\n",
            " \n",
            " webdav with kerberos/ldap on lsst-auth1\n",
            " vetting\n",
            " tape tabs for feedback\n",
            " and configure monitoring platform and client\n",
            " and test performance thresholds\n",
            " workers that receive no files\n",
            " validation\n",
            " lsst-db refresh plan\n",
            " methodology for dependency mapping in the service catalog\n",
            " work related to pdac effort\n",
            " data management requirements from the model and catalog\n",
            " and refresh vendor quotes\n",
            " abstract api\n",
            " htcondor configurations for use in verification cluster\n",
            " gather schemas\n",
            " storage installation\n",
            " automation via python scripts : software installation/test on an lsst node\n",
            " multinode test environment for initial learning about installations\n",
            " management & emergent work (december)\n",
            " and create kube clusters on nebula\n",
            " by stakeholders\n",
            " swift command line tool for objects greater than 5gb\n",
            " plan renewal\n",
            " cyber security summit\n",
            " monitoring conops iteration 1: create raw draft (internal)\n",
            " middleware workshop\n",
            " access to external mount points\n",
            " additional metrics\n",
            " 2016 laaim work\n",
            " of confluence data into learning curve\n",
            " beegfs file system\n",
            " on kubernetes as resource manager\n",
            " swift command line tool for objects less than 5gb\n",
            " management for f16 june\n",
            " and publish\n",
            " file list for full bakup\n",
            " distribution conops (l1) through stage 4\n",
            " vetting and followup for lsst-dev\n",
            " \n",
            " log collection, storage, and forwarding\n",
            " first rucio storage element (rse) of posix/file protocol\n",
            " backbone conops level 1 service considerations (internal)\n",
            " to assigning tier-2 and tier-3 reliability levels\n",
            " mgmt: consolidation\n",
            " into baseline\n",
            " backbone conops interation 1: create raw draft (internal)\n",
            " archictecture/schema for slts in ea\n",
            " lsst system monitoring dashboard\n",
            " sssd with ncsa ldap for accounts in test iam vm\n",
            " sshd with pam_krb5 and document\n",
            " management for f16 july\n",
            " database needs responses\n",
            " read only openstack volume and execute processing scenario\n",
            " the tick stack\n",
            " planning document\n",
            " with emergent related requests affecting operations planning in june\n",
            " and troubleshoot installation\n",
            " htcondor classads scenarios with heterogeneous data cache\n",
            " gathering\n",
            " assessment of sql server and oracle\n",
            " development issues by testing using wan emulator\n",
            " automation via python scripts : launch an instance\n",
            " gpfs on lsstdev servers\n",
            " transfer mechanism for dr tool.\n",
            " project database operational needs\n",
            " \n",
            " /propose storage implementation\n",
            " to physical network\n",
            " time series enterprise monitoring platforms\n",
            " processing conops iteration 1: create raw draft (internal)\n",
            " plan for poc\n",
            " results and write report\n",
            " multi-platform lsst_dm_stack_demo test with fig orchestration\n",
            " puppet\n",
            " swift custom tool for objects less than 5gb\n",
            " expiration of replicator jobs\n",
            " tests to use unit test framework\n",
            " management for f16 (october)\n",
            " validation\n",
            " & authorization conops iteration 1: create raw draft (internal)\n",
            " httpd with ssl and mod_krb5 in iam test vm\n",
            " the service model using representative use cases\n",
            " plan renewal\n",
            " an openstack instance to run an htcondor central manager\n",
            " report\n",
            " amount of effort needed to run preliminary planning exercise\n",
            " new structure\n",
            " data backbone scenario: openstack swift\n",
            " swift custom tool for objects greater than 5gb\n",
            " draft of system monitor and comfort display\n",
            " monitoring for identifying data processed on node/in slot\n",
            " /configure tests with existing configurations and appenders\n",
            " write access to nfs user volume\n",
            " processing conops: develop engineering considerations for boe for work package\n",
            " up some introductory guides for nebula usage\n",
            " data exchange\n",
            " baseline htcondor classads scenarios\n",
            " recovery implementation\n",
            " example programs for ocs middleware\n",
            " mgmt: workflow implementation\n",
            " according to direction from interim project management\n",
            " configuration files and instructions for jupyterhub deployment\n",
            " engineering and chilean itc tiger team (november)\n",
            " configuration of nfs servers\n",
            " security risks into the center's template\"\n",
            " fqdn/hostname assignment for openstack instance\n",
            " and discuss project database needs\n",
            " evaluation plan from evaluation criteria\n",
            " improved processes for timely reporting into jira\n",
            " monitoring conops iteration 1 prep\n",
            " processing for commissioning conops: develop engineering considerations for boe for work package\n",
            " up netem server with dell pe 1950\n",
            " with puppet\n",
            " mgmt: process design\n",
            " scorecard document cataloging features and concerns\n",
            " convert lsst & hsc schema\n",
            " for auth session at jtm\n",
            " historical written docushare materials dealing with the operational security environment.\n",
            " engineering and chilean itc tiger team\n",
            " limited test system\n",
            " htcondor central manager outside of kubernetes cluster\n",
            " web authentication using cilogon and globus\n",
            " logical design of the monitoring system\n",
            " results and write report\n",
            " use cases for verification data sets\n",
            " lanes for l1 system mock\n",
            " operation support related tasks\n",
            " - week ending 8/21/15\n",
            " boot camp materials\n",
            " out the glowing edges of decam ccds\n",
            " swim lane diagram for ap mock\n",
            " file sizes for inputs and outputs for l1using mock.\n",
            " policy for health check failure\n",
            " wg august homework\n",
            " components, inputs, outputs and considerations for the system\n",
            " irods tiered resource with nersc hpss\n",
            " singleframedriver with the hsc cosmos dataset on verification cluster\n",
            " about the task design in isr processing\n",
            " and summarize computing resource used in s17b full hsc reprocessing\n",
            " dependency on cat package and make database setup optional\n",
            " dictionary adjustment.\n",
            " for balance of april\n",
            " file management using desdm framework\n",
            " tests running htcondor jobs utilizing shifter\n",
            " of data flow\n",
            " ingesting couple hsc catalogs using existing desdm software\n",
            " obs_decam with processed data\n",
            " - week ending 1/16/15\n",
            " segmentation fault in eventappendertest\n",
            " analysis iteration 1\n",
            " data stream from socket to lsst-stack pipeline\n",
            " demo on other older tasks\n",
            " and documenting the l1 system\n",
            " rc with w_2017_32\n",
            " decam isr up to currently implemented\n",
            " of [dm-2983]\n",
            " activator to reflect recent changes in cmdlinetask\n",
            " documentation for swim lanes diagram\n",
            " rack, pdu specifications and obtain pricing quotes\n",
            " to the sizing model\n",
            " networking hardware into openstack and verify operation\n",
            " work for don in the week of june 22\n",
            " file transfer api\n",
            " new system diagram\n",
            " basic jupyterhub server in nebula\n",
            " for week march 30.\n",
            " injection in the form of unsuccessful health checks for components\n",
            " - week ending 5/15/15\n",
            " and parse new images and header from camera testing for headers\n",
            " data products description\n",
            " from the recent cameramapper changes and refcat changes\n",
            " doc directory, and fix doxygen warnings\n",
            " - week ending 6/12/15\n",
            " rfc-263: add decam cosmos data to /datasets/decam/\n",
            " conops for main camera archive services\n",
            " for aug 23-29\n",
            " process execution framework work\n",
            " gartner materials relating itil, devops and related topic\n",
            " the pipeline data product diagram\n",
            " network monitoring dashboard for nebula sys admins\n",
            " preparation for fy16 hardware\n",
            " \n",
            " script to summarize what visits are in what patches\n",
            " of current orchestration architecture\n",
            " integer 18 option to the creation of mocked raw images\n",
            " identification info needs to be part of log message\n",
            " task discovery on command line activator\n",
            " \n",
            " end 2/28/16\n",
            " equipment setup and configuration (week end 11/07/15)\n",
            " usage, devel survey\n",
            " the data flow of jointcal example\n",
            " for don for week of june 15\n",
            " revised lse-209 and lse-70\n",
            " ncsa lsst perfsonar host\n",
            " rc with w_2017_27\n",
            " the option to use websockets used by jupyter to explore bi-directional communication\n",
            " and configure gnu/linux on my office desktop.\n",
            " documentation and current issues of prototype\n",
            " overscan correction for decam raw data\n",
            " -data header client discussion during integration activity #3\n",
            " design concepts into mock api\n",
            " equipment setup and configuration (week end 1/30/16)\n",
            " , plan, procure development infrastructure (fy15)\n",
            " rc with w_2017_36\n",
            " supertask code our from pipe_base\n",
            " hosts for sui (2x tomcat, apache, and build)\n",
            " hsc reprocessing analysis into test report form\n",
            " to use lsst.log in meas_algorithms\n",
            " quotes, power requirements, rack layouts\n",
            " about swift and hdfs\n",
            " backbone conops\n",
            " management\n",
            " feb tasks\n",
            " end 10/30/15\n",
            " at dm leadership team meeting\n",
            " wrapper api for js9 and jupyter\n",
            " end 10/17/15\n",
            " isp documents into lsst standard format for control and delivery\n",
            " equipment setup and configuration (week end 10/30/15)\n",
            " coordination meeting and jcc meeting @ ncsa\n",
            " about openstack\n",
            " pricing estimates for networking infrastructure\n",
            " 4: final draft and convert to restructuredtext to produce tech note\n",
            " coadd processing with decam data with default config\n",
            " documentation and comments on supertask\n",
            " about socketio and html rest api\n",
            " not allow executor for silent removal of existing dataset repositories\n",
            " alternative for networkx before rfc\n",
            " the lsst stack on loaned laptop\n",
            " rc with w_2017_38\n",
            " loe -- dec 2015\n",
            " rc with w_2017_26\n",
            " runid option to eventappender\n",
            " existing test and development system\n",
            " 1 function and design mtgs\n",
            " dictionary additions\n",
            " end 09/05/15\n",
            " new kubernetes cluster in nebula for developers\n",
            " pex_logging dependency on pipe_tasks\n",
            " in november\n",
            " tasks' logging migration in meas packages\"\n",
            " ctrl_pool/pipe_driver tasks with hsc rc data with python 3 stack\n",
            " on system and network design\n",
            " end 10/10/15\n",
            " eventlog references in ctrl_orca\n",
            " january tasks\n",
            " about docker\n",
            " additions and review\n",
            " requisitions\n",
            " rc with w_2017_25\n",
            " .py crashes with errors about log\n",
            " _stats fails on mac os\n",
            " python interface to access openstack\n",
            " learning about middleware\n",
            " of ctrl_execute to python 3\n",
            " equipment setup and configuration (week end 2/07/16)\n",
            " activities for week of april 13\n",
            " rc with w_2017_28\n",
            " phase 1 test system\n",
            " network testbed\n",
            " 2016 laaim work\n",
            " jupyerhub using kubernetes\n",
            " processing on nersc cori shifter implementation\n",
            " report\n",
            " equipment setup and configuration (week end 11/14/15)\n",
            " interconnect for gpfs cluster prototype\n",
            " in december\n",
            " cluster machine reset\n",
            " basic middleware and orchestration tools\n",
            " about openstack and jupyter\n",
            " end 2/14/16\n",
            " network emulator operation\n",
            " end 11/21/15\n",
            " ack messages to existing code framework\n",
            " activity diagrams and backing conops for li provisioning and arp, including satellite computing centers.\n",
            " python multiprocessing into header writer\n",
            " basic jupyterhub dockerfile/image with py2/3\n",
            " thinking about governance aspects of dm operations\n",
            " diagram of drp data flow\n",
            " implementation demo\n",
            " of kubernetes for startup scaffolding\n",
            " , verify and test network equipment\n",
            " - week ending 8/28/15\n",
            " gathering input from dm representatives\n",
            " itil v3.0 as prep for input to it use case\n",
            " logger dependency and deprecated plugins from orchestration\n",
            " to lsst.log in coadd_utils and coadd_chisquared\n",
            " framework extension\n",
            " end 09/12/15\n",
            " -144 consistency update\n",
            " specifications for auditing system\n",
            " loe - nov 2015\n",
            " - week ending 6/19/15\n",
            " of ctrl_stats to python 3\n",
            " and install kubernetes\n",
            " 4 bare metal hosts for testing base to archive transfer implementation\n",
            " slide set for dm bootcamp\n",
            " irods zone on isl openstack\n",
            " meeting\n",
            " about spark\n",
            " irods installations/servers as docker images\n",
            " review\n",
            " tasks\n",
            " equipment setup (week end 10/10/15)\n",
            " rbac rules for testing authorization and authentication for all level users\n",
            " equipment setup and configuration (week end 12/05/15)\n",
            " htcondor configuration wrt dropping of nodes in backfill scenario\n",
            " changes to lse-209 and lse-70\n",
            " meetings - march\n",
            " mtg, review and discussions of l1 processing\n",
            " for new equipment setup (week end 10/03/15)\n",
            " end 09/26/15\n",
            " vms to provide additional slots for task switching\n",
            " rc with w_2017_34\n",
            " - week ending 6/5/15\n",
            "'ack' (acknowledgement) message formats\"\n",
            " activities for week of april 21\n",
            " lsst software stack from the source\n",
            " authentication plugin using lsst ldap\n",
            " stack-like installation requirements for pegasus\n",
            " end 11/14/15\n",
            " more features to js9 wrapper\n",
            " task switching between work job machines\n",
            " , institute events, or other loe, sep 2015\n",
            " health failure policy\n",
            " test server\n",
            " - week ending 5/22/15\n",
            " l1 refined specifications\n",
            " fy2015 hardware budget plan\n",
            " document for that specifications are clearer\n",
            " meeting\n",
            " and design workflow for archival model\n",
            " end 09/19/15\n",
            " to run meas_mosaic with hsc data\n",
            " end 2/07/16\n",
            " of swim lanes diagram\n",
            " data products and config in obs_decam for multi-band processing\n",
            " network infrastructure support to deployment of new nodes\n",
            " of xml descriptions of messages sent to ocs\n",
            " lsst wiki documentation for lhn effort\n",
            " rc with w_2017_30\n",
            " the development workflow and obs_decam status update\n",
            " in september\n",
            " activity summary for week of april 6\n",
            " - week ending 12/26/14\n",
            " butler wg calls\n",
            " to write note for the towg using itil as checklist\n",
            " obs_ctio0m9 to work following dm-5922\n",
            " the firefly readme file in githu\n",
            " the new architecture and deployment procedure\n",
            " the squash-dash microservice\n",
            " query does not kill the query with the id from show proceslist.\n",
            " safeclip and comparewarp in mockcoadd.py\n",
            " (losslessly) compress image hdus\n",
            " synpipe up and running with the current lsst stack\n",
            " up spanset operations\n",
            " fitdonuttask to cmdlinetask\n",
            " coadds in diffim within prototype mvs\n",
            " qa analysis scripts to plot  units for certain metrics\n",
            " qa analysis script to matplotlib versions on shared stacks\n",
            " pipelines monthly narratives for august 2017\n",
            " multiple components per peak\n",
            " dns for squash microservices\n",
            " simulated pinhole images to simulated pupil mask\n",
            " in2p3 scientist to load stack processed data inside qserv\n",
            " tests of squash-db, squash-api, squash-bokeh, squash-dash\n",
            " tutorial jupyterlab environment\n",
            " commissioning butler use cases\n",
            " square butler use cases\n",
            " flags for sources used in astrometric and photometric calibration\n",
            " : fix title parsing bug in dmtn-036\n",
            " container build in jenkins\n",
            " formatters & the plan for rollout and use in existing storages\n",
            " mvp alert production metrics\n",
            " mvp alert production metrics\n",
            " up on verify -- reiss\n",
            " dcr visualization tools\n",
            " with ncsa in deploying firefly app in lsst-dev or nebula\n",
            " hits datasets in /datasets\n",
            " keeper: use google cloud platform sql\n",
            " demo failure with devtoolset-6\n",
            " for ap verification metrics session at lsst 2017 meeting\n",
            " of squash k8s deployment\n",
            " query killing by query id.\n",
            " meas_mosaic with pybind11 instead of swig\n",
            " pybind11 remaining code\n",
            " packaging layout for ap_verify\n",
            " using datashader for density plots of large datasets\n",
            " lsst.verify to pipelines.lsst.io\n",
            " the squash-api microservice\n",
            " does not work in time series tool in pdac\n",
            " jupyterhub menu rebuild to ci\n",
            " qserv to pybind11\n",
            " hits 2015 data\n",
            " python firefly_client demo like ffapi-slate-test2.html and make sure python can create charts with plot.ly\n",
            " 3d bug fixes\n",
            " repos.yaml to dedicated repository\n",
            " familiar with outcomes from supertask wg\n",
            " with ncsa in deploying firefly app in lss-dev or nebula\n",
            " configuring more statistical options for assemblecoadds.py\n",
            " release w_2017_30 failed\n",
            " coadd objects with invalid coadd psfs\n",
            " to portal aspect writing in the science platform design doc\n",
            " vulnerability cve-2016-2107\n",
            " squash-db microservice\n",
            " sw.lsstcorp.org -> eups.lsst.codes\n",
            " method to load sql from file\n",
            " documenteer dependency for lsst-texmf, developer.lsst.io sites, and technotes\n",
            " in image access or ingest in hsc and decam examples\n",
            " dockerfile for squash (monolith application still)\n",
            " squash api to squash-api microservice repository\n",
            " donut zernikes into telescope frame\n",
            " hits 2014 data\n",
            " gradle tasks for docker related functions.\n",
            " interface between bfd and simulation code\n",
            " simple diaobject\n",
            " experimental framework for generating per-object coadds\n",
            " cause of new api inconsistencies\n",
            " testing for pdac and visualization functions\n",
            " writes many copies of identical entries _parents to repositorycfg.yaml\n",
            " deblender to use new proxmin api\n",
            " kernel menu creation\n",
            " getting started tutorial about multi-band forced photometry catalog analysis\n",
            " afw.display getting started tutorial\n",
            " pdac to make use of the newly added group info provided by cilogon\n",
            " sphinxcontrib-bibtex in technotes\n",
            " on docker techonology\n",
            " options for speeding up data ingestion into qserv \n",
            " scaling experiments for kpm scripts\n",
            " glmm convergence\n",
            " feature allowing assignment of x- or y-data to custom operations on columns to the qa dashboard prototype\n",
            " butler instantiation code in imgserv\n",
            " sources to use different constraints\n",
            " .lsst.io site build tool\n",
            " save/exit menu\n",
            " packaging layout\n",
            " to using jemalloc.\n",
            " breakout presentation on pipelines schedule & status for july 2017 nsf dm review\n",
            " plenary presentation on pipelines & alerts for july 2017 nsf dm review\n",
            " necessary metrics for verify_ap\n",
            " more detailed history in glmm\n",
            " diaobject api\n",
            " of ctio may-june run\n",
            " for updating metaserv database catalog information\n",
            " testing (june 2017)\n",
            " by job and metric when returning data from the api\n",
            " technote\n",
            " up on verify -- findeisen\n",
            " ap_association repository in lsst-dm\n",
            " and implement conversation with dax about l1 db\n",
            " skywcs transform to icrscoord instead of spherepoint\n",
            " l1 minimum viable system\n",
            " the work done on ap pipeline so far\n",
            " -varying a&l decorrelation option\n",
            " resized method to all psfs and enable psf-matching any type to any type psf\n",
            " metadata access for filter\n",
            " persistent session manager for jupyterhu\n",
            " new design for afw::math::statistics\n",
            " grid generation in imagemapreducetask\n",
            " for drp f17-1 sprint\n",
            " ellipticity residuals quiver plots\n",
            " hsc camera description paper\n",
            " planning spreadsheet to estimate cost per wbs element\n",
            " projmgmt wg long term planning conclusions in dmtn-020\n",
            " plan for updates to & maintenance of qa plotting scripts\n",
            " new sourceselector baseclass\n",
            " up to speed with new deblending algorithm.\n",
            " slac information on image cutout, reference irsa existing practice\n",
            " bootstrap for lsst-texmf projects\n",
            " test of tickets related to ui changes and bug fixes (may 2017)\n",
            " qhttp c++ http server library to qserv builds\n",
            " metricdeviation api url needs correction\n",
            " terraform deployment for rabbitmq\n",
            " zoom and pan to firefly widgets\n",
            " strict monotonicity\n",
            " current sizing model inputs\n",
            " object ids are strings and this is causing problem with qserv\n",
            " query execution with shared scans disabled for comparison with shared scans.\n",
            " to kubernetes/kubeadm v1.6.1 on openstack\n",
            " memory locking in containers\n",
            " kubernetes/docker on cc-in2p3 cluster\n",
            " user query when the result becomes too large.\n",
            " texlive docker image for lsst-texmf projects\n",
            " and understand how firefly would use docker\n",
            " reporting facility in lsst.verify framework\n",
            " dcrcoadds proper coadds\n",
            " -019 technote demonstrating the lsst.verify api\n",
            " astrometry distortion model configurable\n",
            " for python2/python3 stack\n",
            " with multiple series histogram display\n",
            " metadata store prototype\n",
            " store - design v1\n",
            " design for query metadata v2\n",
            " data access & db team s15 release docs\n",
            " rio - workshop report\n",
            " problems with near neighbor queries\n",
            " configuration - detailed design\n",
            " how to kill query in mysql\n",
            " qserv code to nullptr\n",
            " up with standard to handle c++ exceptions in qserv (and the rest of dm?)\n",
            " -partitioned table query returns duplicated rows\n",
            " 12 issues in testcppparser (related to switching to css)\n",
            " backup/restore for css\n",
            " structure for db/table metadata in css\n",
            " how to run multi-node tests\n",
            " store - design v2\n",
            " webserv to work with reworked db module\n",
            " exceptions in db module\n",
            " implementation of web form for collecting data about existing data sets\n",
            " boost:thread to std::thread\n",
            " namespaces in all qserv core modules\n",
            " release (12.04) - final build, testing and cutting release\n",
            " code cleanup and auto_ptr --> unique_ptr migration\n",
            " tostring() function\n",
            " css schema to support table deletion\n",
            " qserv performance / kpis\n",
            " serf and consul\n",
            " queries are broken\n",
            " and test 2015_09 qserv release\n",
            " - strategic positioning\n",
            " problem with timeout\n",
            " parse/analysis tests to detect missing css-kvmap early\n",
            " maxscale as mysql-proxy replacement\n",
            " how to integrate different image metadata stores with datacat\n",
            " errors in parsing or rendering nested expressions\n",
            " to the  name consistently\n",
            " times out\n",
            " all chunk-queries to primary copy of the chunk\n",
            " socket timeout problem in xrootd framework\n",
            " location of images more flexible\n",
            " how the proposed interfaces fit with qserv code\n",
            " support for configuring multi-node integration tests\n",
            " order by support\n",
            " json results for metaserv and dbserv\n",
            " for setting up new cluster at in2p3 for continuous integration/testing\n",
            " 16 data access and db release documentation\n",
            " qserv to external sphgeom\n",
            " to web form\n",
            " design for query metadata v1\n",
            " to mariadb\n",
            " off-the-shelf solutions for harvesting metadata\n",
            " error message (non-existing column referenced)\n",
            " apache mesos and google kubernetes\n",
            " performance of vertical-partition joins in mysql\n",
            " metadata store prototype v1 with cat and d\n",
            " python client\n",
            " -generate data for large scale tests at in2p3\n",
            " sqlite-based v0.1 unit testing for metaserv\n",
            " code made obsolete\n",
            " & db docs (andys)\n",
            " confusing error message\n",
            " pipelines with mysql and qserv\n",
            " error messages from czar to end user - design\n",
            " mysql-based test to multi-node integration test\n",
            " on c++ 11 flag for qserv\n",
            " json results for data access services\n",
            " human-friendly thread id in logging messages\n",
            " and document api versioning\n",
            " image response for imgserv\n",
            " interactions with xrdoss\n",
            " stitching multiple patches across tract boundaries in coadd\n",
            " code that initializes shared_ptrs\n",
            " short and long term plans for butler\n",
            " cleanup of query cancellation code\n",
            " and experiment with building form for capturing user input\n",
            " data distribution prototype (march)\n",
            " mysql connection to querycontext\n",
            " and test 2016_01 qserv release\n",
            " test server using new xrootd\n",
            " to using new partitioner, loader\n",
            " patterns for data store that supports data distribution\n",
            " flask dependencies\n",
            " multi-node testbed\n",
            " error handling\n",
            " and implement restful api for image stitching and rotation\n",
            " support for running unit tests in scons\n",
            " exchange between processes - research\n",
            " documentation for ssi interface\n",
            " setting up multi-node qserv and running integration test\n",
            " image cutout service interfaces with butler\n",
            " restful interfaces for database (get)\n",
            " - surviving mysql and zookeeper glitches\n",
            " for documenting \n",
            " kvinterface - add support for updates\n",
            " hits_ingest script to handle all steps from ingestion to diffim\n",
            " the issues rising out of suit but needs dm attention\n",
            " test for overlapping galaxies\n",
            " and load sdss pdac metadata\n",
            " cat package\n",
            " hub button (or something) for server stop/logout from la\n",
            " standard conventions and colors for ldm-151 diagrams\n",
            " python 3 - based jupyterlab lsst stack\n",
            " deblender with exact positions\n",
            " save image button for plotly charts\n",
            " fails memorytestcase\n",
            " gcc5 to ci matrix\n",
            " storage for jupyterlab containers\n",
            " qa plots\n",
            " test of tickets related to ui changes and bug fixes (apr. 2017)\n",
            " for drp s17-6 sprint\n",
            " framework metadata system\n",
            " post-qa into lsst.verify framework\n",
            " l1db without immediate diaobject indexing\n",
            " (and correct) conversion for nmf deblender\n",
            " using both monotonicity and symmetry\n",
            " jupyterlab shell environment\n",
            " _dm_stack_demo failing with new footprints\n",
            " measurement class integration in lsst.verify framework\n",
            " order of operations when using temporary local backgrounds in detection\n",
            " pseudocode implementation of coaddition supertasks\n",
            " all measurement exceptions at debug level\n",
            " tech note describing options for dm software releases\n",
            " inefficiencies in detection\n",
            " meas_mosaic's wcs/fcr output files to reflect lsst coordinate system\"\n",
            " access to squash rest api\n",
            " histogram on external viewer doesn't allow to interact with more charts\"\n",
            " gh group-based oauth authenticator for jupyterhu\n",
            " referer in the http request header by cookie\n",
            " apps should share the same default values\n",
            " 3.py branch protection api is out-of-date\n",
            " name class for semantic metric and specification name handling\n",
            " better symmetry operator\n",
            " validate_base to verify and validate_metrics to verify_metrics\n",
            " jupyterhub/lab environment atop container release.\n",
            " the convergence of admm, sdmm, and glm algorithms\n",
            " unit test for rotate class\n",
            " the resource loaded long term plan\n",
            " conda binaries for 0.13.0 (v13.0) release\n",
            " sims conda binary\n",
            " channel errors causing lsstsw/bin/deploy to fail\n",
            " dm\\xe2\\x80\\x99s communication / documentation / information architecture strategy\n",
            " squash change required by square bot\n",
            " github org snapshots to s3\n",
            " testing in squash prototype\n",
            " firefly search processor that retrieves image paths from the butler\n",
            " change: create plotly loading infrastructure and react wrapper\n",
            " meas_modelfit with pybind11\n",
            " in error nebula instance (lfr.lsst.codes)\n",
            " test for difference of overlap between objects\n",
            " new hsc calibs\n",
            " hsc  dataset through the lsst stack using hsc\\'s brighter-fatter implementation\n",
            " on robert and zeljko's requests for tweaks ldm-151 from yesterday's chat\"\n",
            " firefly_client to handle variations in base url\n",
            " for drp s17-5 sprint\n",
            " propagation of visit flags for certain patches in hsc rc processing\n",
            " the hsc rc dataset with the latest hscpipe 4.0.5\n",
            " stars to blending simulation script\n",
            " is set after dark subtraction\n",
            " transform to return matrix of derivatives\n",
            " whether differences in brighter-fatter implementations are contributing to the trace radii differences: lsst vs. hsc\n",
            " transform to return its inverse\n",
            " nmf with alternating least squares\n",
            "13.0 documentation\n",
            " mvp for dochubproto\n",
            " transition hsc team to lsst stack\n",
            " option to deblender to turn off smoothing.\n",
            " existing microservices to apikit 0.1.1 logger\n",
            " calibration  document\n",
            " square python logger\n",
            " nmf deblender presentation\n",
            " new eups_pkgroot(s) for osx/linux tarballs\n",
            " _drp hsc dataset broken due to http request size limit\n",
            " job (frequent) to sync travis ci <-> githu\n",
            " microservices to uwsgi\n",
            " __str__ and __repr__ copied from swig\n",
            " technote describing new metrics system\n",
            " release notes for pybind11 port\n",
            " lsst_sims on pybind11\n",
            " pybind11 code in afw\n",
            " pybind11 how-to technote to dev guide\n",
            " fgcm gray corrections with aperture effects\n",
            " update\n",
            " tests for order of flags to all measurment plugins\n",
            " pybind11 code in core meas and ip packages\n",
            " source of systematic difference of model psf trace radii: hsc vs. lsst\n",
            " high-stellar-density fields for deblender testing\n",
            " for s17-4 sprint\n",
            " in feb 2017\n",
            " gke ingress controller with nginx/haproxy\n",
            " many sky simulations through dcr correction to find edge cases\n",
            " test of tickets related to ui changes and bug fixes (feb. 2017)\n",
            " post_qa to shim blobs, measurement metadata and metric definitions to squash api\n",
            " existing tools for monitoring\n",
            " hsc rc data using pybind11 prototype\n",
            " getdimensions and/or getbbox method to all psfs\n",
            " procedures for package reorganization\n",
            " lsst-desc collaboration meeting at slac\n",
            " dax containers at ncsa\n",
            " hsc  dataset through the lsst stack\n",
            " covariance matrices from multiple visits into covariance matrix for the coadd\n",
            " support for parallel execution of supertask\n",
            " bimodal distribution of footprint sizes for \n",
            " effects of bounding box setting for adaptive moments\n",
            " -cycle replan\n",
            " python api for show_xyplot\n",
            " standard difference image for iterative dcr solution\n",
            " meas_mosiac's photometric model\"\n",
            " check lsst processing of rc dataset\n",
            " creation / installation of eups distrib 'tarball' packages #2\"\n",
            " region bugs\n",
            " sgs: plotsscript.py: makerachelplots work!\n",
            " & document s/g code\n",
            " afw::image with pybind11 (uw work)\n",
            " ci_hsc with pybind11\n",
            " pex_exceptions with pybind11\n",
            " shapelet with pybind11\n",
            " ip_diffim with pybind11\n",
            " chatops service to monitor qa metric values\n",
            " test for centralpoint.java\n",
            " jenkins osx build slave configuration\n",
            " search processor(s) to support all sky mode\n",
            " the git-lfs server protocol\n",
            " feature to overlay the searched position on the coverage image.\n",
            "  mode in lsst catalog and image search panels\n",
            " and configure esxi on lsst-dm-mac-2\n",
            " pybind11 holder type inheritance\n",
            " 2d monotonic operator for nmf deblender\n",
            " deblending techniques\n",
            " colorbar setting in firefly widgets\n",
            " `mysqldump`s of squash qad\n",
            " search mistakingly brings up an image ta\n",
            " new calib object and interface\n",
            " plot does not abort and over writes active plot\n",
            " fileinfo and filedata classes into one class\n",
            " master unstable\n",
            " for wrapped-template abcs and class extension decorators\n",
            " lsst calibration workshop at harvard\n",
            " covariance matrices from individual exposures into single covariance matrix for full visit\n",
            " display_ds9 with pybind11\n",
            " detail for drp background matching, coaddition, and diffim in ldm-151\n",
            " multiple-backgrounds concept into ldm-151\n",
            " round of updates to drp ldm-151 sections from reviews\n",
            " detail for drp object characterization in ldm-151\n",
            " calibration products pipeline section of ldm-151\n",
            " data release production section of ldm-151\n",
            " outlines to ldm-151 for ap\n",
            " up kafka alert producers\n",
            " qa-dashboard deployment to using python3\n",
            " test of tickets related to ui changes and bug fixes (jan. 2017)\n",
            " common s3 upload/interface python package for lsst the docs microservices and clients\n",
            " pybind11 port for outstanding technical debt\n",
            " line chart\n",
            " in january 2017\n",
            " for s17-3 sprint\n",
            " astshim using pybind11\n",
            " hits calibration products and test on raw images\n",
            " in the squash api to upload metrics definition\n",
            " jenkins to lsst-dev[-old] retirement\n",
            " the class cropandcenter\n",
            " test for image crop class\n",
            " related classes need to be refactored\n",
            " squash to store json as blob/text in mariadb 10.1+\n",
            " macos sierra vm for esxi.\n",
            " distribution of footprint sizes: hsc vs. lsst\n",
            " isotropic footprint growing/dilating behavior: hsc vs. lsst\n",
            " chatops service for cookiecutter microservice\n",
            " up multi-component footprints\n",
            " slave password exposed in process table\n",
            " some options to web app to support lsst preferences\n",
            " squash database model and json api with concepts from validate_drp measurement api\n",
            " jointcal photometry test for hsc\n",
            " user-friendly template customization\n",
            " priority of aprox/interp upgrades.\n",
            " download script dialog\n",
            " jointcal photometry test for decam\n",
            " api: external api and the api for histogram\n",
            " component to handle the algorithm(s) input parameters to compute \\xe2\\x80\\x98periodogram\\xe2\\x80\\x99 need to be adapted\n",
            " container networking in alert_stream to use non-host network\n",
            " link does not work when launched from  popup.\n",
            " cookiecutter template for api.lsst.codes microservices\n",
            " microservice creation for api.lsst.codes\n",
            " asterics demo\n",
            " dataset for prototype ap pipeline\n",
            " unused jenkins plugins / fully manage all plugins\n",
            " diffim tests code (simulations for algorithm testing)\n",
            " lsst the docs product monitoring\n",
            " deblender api\n",
            " fixes to build process\n",
            " sample alert with expected content without postage stamp\n",
            " slow avro encoding/decoding in alert_stream\n",
            " postage stamp transmission/collection to alert_stream\n",
            " issues related to tomcat8 and ipv6. also add firefly.war into firefly release page.\n",
            " all hsc calibration data to lsst camera geometry\n",
            " alternatives to ingest json blobs into the squash database\n",
            " leftover tests in afw with pybind11\n",
            " sphinx/breath/doxygen-generated api docs for daf_base\n",
            " sphinx configuration for pipelines documentation, including mvp html/css template\n",
            " wrapping of pickling with pybind11 in afw\n",
            " user guide for new validate_drp metric/measurement api\n",
            " slack-integrated dm-square bot\n",
            " codekit python3 compatible\n",
            " api.lsst.codes and metadata definitions\n",
            " afw::detection with pybind11\n",
            " hsc afterburner functionality\n",
            " obs_base (was daf_butlerutils) with pybind11\n",
            " caom\n",
            " materials about how to best write technical documentation\n",
            " production requirements to supertask\n",
            " unit tests to pipe_supertask\n",
            " pybind11 wrapper for coaddinputs segfaults\n",
            " optimistic pattern matcher failure modes\n",
            " the coverage map and the image panel without clicking the image itself\n",
            " up the server side visualization code\n",
            " qa analysis script for lsst vs. hsc coadd processing comparison\n",
            " performance of zogy when psfs are inaccurately measured\n",
            " scons eups package to work with python 3 builds\n",
            " non-survey-generic python in jointcal\n",
            " pdac v1\n",
            " application to  git files\n",
            " the sql expressions on lsstcatalogsearch's image searches\"\n",
            " to the database loading procedure to allow parallel loading of chunks\n",
            " api for new footprints class\n",
            " transition footprints class using spansets\n",
            " rfc documents for changes to mapper.paf files\n",
            " patch/tract and config mapping definitions to daf_butlerutils\n",
            " multiple bokeh apps\n",
            " spanset spatial union\n",
            " spanset overlap tests\n",
            " interface for spansets\n",
            " interface for spansets class\n",
            " spanset applyfunctor methods\n",
            " run-time performance of a&l and zogy\n",
            " up galsim opticalpsf class\n",
            " camera team visualization development\n",
            " aaron roodman's decam psf tools\"\n",
            " current supertask interface\n",
            " mvp\n",
            " lst into visitinfo\n",
            " modification to individual mapper.paf files for rfc-232-237\n",
            " pybind11 branch onto unit test and python 3 changes\n",
            " fails to fit gaussian psf\n",
            " constraints on reference band selection for multiband\n",
            " flaghandler to be used from python\n",
            " unit tests for the new colorterms code\n",
            " parent/child measurement from hsc\n",
            " changes requested in rfc-247\n",
            " for 'subset' keyword in composite datasets\"\n",
            " pipe_tasks to python 3\n",
            " skymap to python 3\n",
            " and test 2015_10 qserv release\n",
            " and test 2015_12 qserv release\n",
            " and test 2015_11 qserv release\n",
            " technote on how to rename package\n",
            " breaks with conda v12.1 binaries because of missing libexpat.so.0 file.\n",
            " lsst-mariadbclient recipe to conda-lsst\n",
            " docker image for conda binary creation\n",
            " conda-lsst problems using lsstsw\n",
            " different combinations of cmake and other lsstsw dependencies\n",
            " using conda forge's docker image\"\n",
            " and complete v12.1 conda binary packages\n",
            " irsaviewer to display images directly via url\n",
            " - load components individually\n",
            " needs to be refactored\n",
            " straw-man plan for calibration products pipeline\n",
            " and revise straw-man drp plan\n",
            " to build release git tag when 3rd party deps change\n",
            " select panel not yet working correctly with coverage\n",
            " options - reset to default\n",
            " technical note on galaxy shear experiments\n",
            " alert consumer with the kafka framework\n",
            " alert producer with the kafka framework\n",
            " obs_monocam tests into obs_base\n",
            " post-qa to submit new json from validate_drp measurement api\n",
            " footprint design\n",
            " coadd and differencing datasets\n",
            " dax containers\n",
            " adass python 3 paper\n",
            " sky data from usno monocam run\n",
            " dependency map for calibration products production\n",
            " in2p3 engineer in loading dc2013 data sample\n",
            " functionality of experimental jupyter widgets for firefly\n",
            " pybind11 wrapped functions with container arguments to accept any sequence type\n",
            " example command line task\n",
            "  procedure for new stack developers\n",
            " problem with mac os processccd output when compared to 'identical' dataset generated on rhel6\"\n",
            " daf_butlerutils to obs_base\n",
            " poster for adass xxvi conference\n",
            " monolithic subset of the stripe82 catalogs and image files for testing suit implementations\n",
            " with piff\n",
            " chunkresource for testability\n",
            " don't show up in png download\"\n",
            " and upgrade the javascript third party packages\n",
            " meas_extensions_convolved from hsc\n",
            " up more hsc data for validate_drp\n",
            " xrootd configuration\n",
            " restructure\n",
            " ui component to handle the algorithm(s) input parameters to compute \\xe2\\x80\\x98periodogram\\xe2\\x80\\x99\n",
            " 2d plotting package design discussion\n",
            " 2d plotting package design discussion\n",
            "2d plotting package design discussion\n",
            " the 2d plotting package design discussion\n",
            " pex_config and its use in tasks\n",
            " l1 prototype testing to qserv150\n",
            " box annotations to indicate missing jobs\n",
            " validate_base package\n",
            " display of metric thresholds\n",
            " identifying requirements and associating them with use case examples from jim & simon\n",
            " decorrelation expression in the case of science image preconvolution\n",
            " new search that will compute the periodogram via external api\n",
            " coverage of s13 databases found so far\n",
            " access policy for pdac\n",
            " vision document\n",
            " flux measurement is correct in decorrelated image differences\n",
            " hsc parallelization code\n",
            " dependency map for data release production\n",
            " of jsdoc usage\n",
            " python coding standard based on rfc-162\n",
            " squash bokeh driven views\n",
            " design work for composite datasets\n",
            " an experimental firefly widget\n",
            " mathematical formalism for propagating covariance in warping\n",
            " updated f16 drp plan for pmcs ingest\n",
            " light curve skeleton app\n",
            " the kafka quickstart running and dockerized with colin's mini-alert code\"\n",
            " policy class needs to search for policies similar to pex_policy\n",
            " object yaml dump needs pretty formatting\n",
            " shortlist of technologies and draft requirements\n",
            " shared stack on lsst-dev & other relevant systems\n",
            " mathematical formalism for warping in the stack\n",
            " result is wrong after apply filter on catalog from image\n",
            " in rebuild under lsstswbuild.sh may cause bogus log printing\n",
            " the htm based reference catalogs in tests\n",
            " some tests to support nose and/or py.test\n",
            " query generation performance with sqlalchemy\n",
            " panel issues\n",
            " with footprint redesign\n",
            " memman to be inline with the qserv worker scheduler.\n",
            " xrootd from upstream\n",
            " developer guide with pytest guidance\n",
            " sconsutils to query python on path for executable location\n",
            " api bugs 2\n",
            " the docs fastly courtesy redirects for directory paths\n",
            " miscellaneous table issues\n",
            " and experiment the process of creating jupyter widget\n",
            " dia simulation script with postgres\n",
            " / image vis issue\n",
            " standalone firefly build using ipac githu\n",
            " resource requirements for algorithmic components\n",
            " resource requirements for software primitives\n",
            " with memorytest ordering\n",
            " gwt from build\n",
            " editor on chart toolbar\n",
            " backport: include psf moments in the output tables\n",
            " validation regression issues\n",
            " out software primitives\n",
            " support for deriving from python exception types to pybind11\n",
            " refactoring\n",
            " cmodel results from lsst and hsc\n",
            " options display\n",
            " report on spie conference\n",
            " exception translators in upstream pybind11\n",
            " plan systems engineering status review\n",
            " cmodel issues with aperture corrections\n",
            " usage of header metadata\n",
            " load related chart data on table data update\n",
            " meas_mosaic-ed hsc and lsst coadds\n",
            "  scan\n",
            " transforms do we currently need?\n",
            " template dcr images\n",
            " & db docs (mike)\n",
            " qserv areas affected by secondary index\n",
            " with c-style arrays for secondary index\n",
            " up multi-host tests for secondary index technologies\n",
            " multi-host and bulk-update performance data for secondary index\n",
            " single-host performance data for secondary index\n",
            " candidate technology for secondary index\n",
            " vs. hsc stack comparison: psf estimation\n",
            " kron results from lsst and hsc\n",
            " segmentation fault in loggingevent destructor\n",
            " shared scan table information to css\n",
            " prep for sbag meeting, attend video telecon with heidi et al.\n",
            " materials related to sbag prep and attend telecon\n",
            " replacement for a.net index files\n",
            " for noise replacement differences between lsst and hsc\n",
            " : decimation options\n",
            " conversion: system notifications\n",
            " coaddition for aperture corrections\n",
            " hsc-1199 to lsst (unmaskednan mask propagates to all amplifiers)\n",
            " suspect pixel flags to meas_base\n",
            " approximation object for aperture corrections\n",
            " hsc-side functionality to allow showcamera to display real data via the butler\n",
            " backport: guarantee consistent handling of peaks in deblender\n",
            " coaddition code\n",
            " backport: low-level footprint merge code\n",
            " external viewer from popup blockers.\n",
            " note integration for 12_0 stack release\n",
            " draft of overview () document\n",
            " lsstsw to python 3\n",
            " astropy-compliant strings for units in afw.table\n",
            " hsc mpi driver for multi-band coadd processing\n",
            " hsc meas_extensions_simpleshape package to lsst\n",
            " backport: add functions to generate 'unpacked matches' in catalog\"\n",
            " new blendedness metric\n",
            " w16 cmodel improvements from hsc\n",
            " backport: include documentation strings for config parameters when they are dumped\n",
            " brighter-fatter correction\n",
            " sky objects\n",
            " hsc mpi driver for coaddition\n",
            " bright object masks to pipeline outputs\n",
            " detection task footprint growth changes from hsc\n",
            " hsc --rerun option for cmdlinetask\n",
            " hsc pipe_tasks changesets to lsst\n",
            " hsc hooks for simulated source injection\n",
            " backport: cleanup interpolation tasks and implement usefallbackvalueatedge\n",
            " stale obs_subaru dependencies\n",
            " readmatches back to meas_astrom\n",
            " hsc improvements to hsm moments code\n",
            " installation and operation instructions for conda\n",
            " ansible automation to run the conda build\n",
            " conda repository to s3\n",
            " and deploy beats for logstash and elasticsearch.\n",
            " and deploy elasticsearch and kibana ansible roles\n",
            " and deploy logstash, fluentd and riemann ansible roles\n",
            " with rhl calibration documentation\n",
            " style of catalog panel\n",
            " butler to ref loader\n",
            " layer improvement to handle mouse selection\n",
            " git-lfs documentation to work with git-lfs 1.1.0+\n",
            " work for butler storage & format factorization\n",
            " color stretch dialog box does not work properly\n",
            " the post_save mechanism to update bokeh sessions when new data is available\n",
            " git refs to jobs table of qa dashboard\n",
            " recommendation for how to manage wcs in lsst\n",
            " sqr-006 lsst the docs technote to reflect deployment in dm-5404\n",
            " json file for monitoring stack\n",
            " scipi wg f2f in tucson\n",
            " scipi wg phonecon\n",
            " out mops work\n",
            " mysql account for monitoring\n",
            " ingestion code for the qa results\n",
            " of django and bokeh server\n",
            " django project and initial dashboard app\n",
            " look at the overall performance of the application\n",
            " cloudbees-folder support to puppet-jenkins\n",
            " -arrange how qserv directories are installed\n",
            " sagas in place of side-effects in chart-related controllers\n",
            " keeper: more robust edition purges\n",
            " ltd mason for single-package doc builds on travis ci\n",
            " alert production database design\n",
            " dialog are not working well together\n",
            " multi image fits and controls\n",
            " hsc obs_subaru changesets to lsst\n",
            " fastly infrastructure for lsst the docs\n",
            " docker storage backend on redhat-like distributions\n",
            " kernel panic issue\n",
            " kernel on in2p3 cluster\n",
            " : tab titles need to shrink to accommodate large number of tabs.\n",
            " paging bar to imagemetadatatoolbarview\n",
            " imageselectpanel into dropdown\n",
            " needs way to keep it state between renders\n",
            " obs_lsstsim\n",
            " motivated model fits to validate_drp photometric and astrometric scatter/repeatability analysis and plots\n",
            " and deploy common ansible roles for elk\n",
            " meas_mosaic for compatibility with new single frame processing\n",
            " toy composite (ast/gwcs) model with supported components\n",
            " with ngmix codebase\n",
            " color stretch dialog to react/flux/javascript\n",
            " table client-side sorting\n",
            " qserv master in env variable for docker containers\n",
            " vertical partitioning tests\n",
            " classes of measurementerror\n",
            " and use  flag in slots and slot-like measurements\n",
            " fine-grained authorization to ltd-keeper users\n",
            " lmfit package to the stack\n",
            " visualizer porting: selecting points of catalog from image view, showing selected points\n",
            " documentation and examples for safeclipassemblecoadd\n",
            " discussions (nate, march)\n",
            " discussions (fritz, march)\n",
            " configured requirements parameters. pass/fail test.\n",
            " cluster deployment scripts more generic and enable ccqserv100...124\n",
            " discussions (john, march)\n",
            " discussions (andys, march)\n",
            " calibratetask to command line task\n",
            " characterizationtask to command line task\n",
            " isrtask to command line task.\n",
            " conversion: history and routing\n",
            " planning for x16\n",
            " exploratory tap implementation within dbserv\n",
            " reusable upload file component\n",
            " communication and publication platforms document and presentation\n",
            " communication and publication platforms document and presentation - clone\n",
            " (js): sorting\n",
            " visualizer porting: expanded single\n",
            " -going support to camera team in visualization (feb. 2016)\n",
            " (js): table options\n",
            " visualizer porting: statistics - part 1\n",
            " visualizer porting: expanded mode single - part 2\n",
            " auto play,select which dialog, close button working, to expanded mode\n",
            " visualizer porting: crop\n",
            " c++ code for experimenting with python binding\n",
            " usable repos in {{validation_data_*}} packages.\n",
            " conversion: dropdown container\n",
            " lcr-385\n",
            " current version of lse-78, prepare for lcr\n",
            " lcr-323 proposal for integration milestones\n",
            " of lse-70 and lse-209 drafts, september 2015\n",
            " in november 2015 ocs-subsystems teleconference (lse-70, lse-209)\n",
            " removal of response queuing on czar to see if this provides useful flow control\n",
            " hsc afw changesets to lsst\n",
            " hsc meas_algorithms changesets to lsst\n",
            " qserv into square release - part i\n",
            " presentation on verification datasets for aas\n",
            " script to print the names of all visits that overlap patch\n",
            " on script to test the astrometric matcher\n",
            " qserv multinodes integration tests inside travis\n",
            " decam/cbp data into lsst stack\n",
            " technote on the new technical note platform\n",
            " zenodio.harvest\n",
            " hsc psf sample for use in algorithm testing\n",
            " jenkins core + plugin versions\n",
            " to galaxy_shear_experiments python code\n",
            " basic tests of cmodel ellipticity measurements\n",
            " sdssshape changes from hsc meas_algorithms to lsst meas_base\n",
            " path gate to pachon\n",
            " detailing usage of wcs in the stack\n",
            " to collect current and future use cases of wcs\n",
            " the lsst and hsc codebases for differences\n",
            " proof-of-concept package documentation for lsst.afw\n",
            " calibration products for analysing decam data\n",
            " of alma and reuna/aura costs on national link\n",
            " america infinera rep to give presentation of equipment\n",
            " from tololo to pachon\n",
            " system layout to support expanded views\n",
            " dcr amplitudes using realistic distribution of stars\n",
            " github mirror of lsst repositories\n",
            " an ipython notebook visualization of the lsst demo data\n",
            " email should state if the build used master only or included other branches\n",
            " _sdss should use pydl.yanny instead of it's own copy thereof\"\n",
            " prototype docs into \\xe2\\x80\\x9cdeveloper guide\\xe2\\x80\\x9d and science pipelines doc projects\n",
            " understanding inheritability and reusability of dataset types\n",
            " prototype stack documentation with sphinx\n",
            " from xy plot table view (js)\n",
            " unique query-id generation\n",
            " visualizer porting: mouse readout: part 2: flux value\n",
            " configuration management for jenkins\n",
            " use of imageorigin argument\n",
            " task documentation for assembleccdtask\n",
            " task documentation for cmdlinetask\n",
            " code to use restored names for methods that return pixel iterators and locators\n",
            " ++ code changes required for --std=c++11\n",
            " kind of wcs that encapsulates tan wcs and distortion model\n",
            " task documentation for isrtask\n",
            " default image origin parent in all cases\n",
            " task documentation for repairtask\n",
            " naming convention\n",
            " to write your own command line task, including how-to-retarget sub-tasks\n",
            " the astrometry.net astrometry solver to use the new standard schema\n",
            " ntermediate plan for macosx builds\n",
            " evaluation (part 1)\n",
            " intelligence to `validate_drp` so it does  on an unknown output repo\n",
            " the bi-weekly meeting authentication and authorization discussion\n",
            " buildbot with jenkins job(s)\n",
            " flow of light curve visulizaiton\n",
            " support for 3 color\n",
            " problems in lsstsw, related to qserv offline install procedure\n",
            " s3/route53 project provisioning capabilities to ltd-keeper\n",
            " backport: set bad mask for dead amps instead of sat\n",
            " srd-based measurements of astrometric performance for validate_drp\n",
            " photometric repeatability and correctness of reported errors\n",
            " calculation for image stretch has infinite loop\n",
            " confluence dm developer guide to sphinx (hack day)\n",
            " the corrections that need to be imlemented\n",
            " development data\n",
            " simple reference index files\n",
            " and conduct conversation about dcr in the project\n",
            " simulation tools\n",
            " visualizer porting: expanded view\n",
            " button hide/show, delete button hide/show, display title options,\n",
            " values for photometric repeatability kpms in fy15\n",
            " popup\n",
            " for software documentation deployment service\n",
            " code style guidelines to new dm developer guide\n",
            " fits view decoration: context toolbar, title, expand button, etc\n",
            " -deploy lsstsw on jenkins\n",
            " using breathe for python & c++ api reference in new docs\n",
            " bug and add unit tests for psfshapeletapprox\n",
            " hsc background matching routines\n",
            " plot showing the number of process ccd failures in each visit as function of the density of sources.\n",
            " list of dm simulation needs for andy connolly\n",
            " reference catalog to use in bulge survey processing\n",
            " current dipole measurement examples and tests\n",
            " the matchoptimisticb astrometric matcher\n",
            " set of tests (or update the current ones) to facilitate refactoring of dipole measurement\n",
            " lsst/ci_hsc repo to git-lfs.lsst.codes\n",
            " plot view of the table (js): define state tree\n",
            " conversion: basic layout for results\n",
            " visualizer porting: thumbnail\n",
            " if mysqlproxy can be compatible with mariadb client\n",
            " scisql and mysqlproxy to mariad\n",
            " pushing firefly to githu\n",
            " visualizer porting: distance tools\n",
            " rfc/rfd/decision making page to new docs\n",
            " tickets for list of stack deficiencies and suggested upgrades\n",
            " developer workflow documentation\n",
            " visualizer porting: select area\n",
            " visualizer porting: drawing target center\n",
            " replicating eups published packages\n",
            " lfs remote support to lsstsw/lsst_build\n",
            " the design of firefly core system using react and flux\n",
            " assertxnearlyequal methods for image-like classes\n",
            " dm boot camp\n",
            " dm boot camp\n",
            " -implement packed keys in css\n",
            " for hsc integration test\n",
            " design meeting 1\n",
            " qserv_objectid restrictor\n",
            " ldm-135 to new design docs platform\n",
            " git lfs prototype and provide feedback\n",
            " conversion from gwt to react/flux design meeting\n",
            " and document multi-node test with docker\n",
            " overly bug\n",
            " build fails on gcc 4.8 with opt=3\n",
            " the design of firefly core system using react and flux\n",
            " the issues accessing the newly populated tables\n",
            " value for drp computational budget kpm in fy15\n",
            " region overlay on image function through javascript api\n",
            " requirements for pipeline developer visualization tools\n",
            " up and running phosim for psf library\n",
            " fits table catalog upload\n",
            " time tests running measurement algorithms against sample galaxies\n",
            " on lse-75 with telescope & site personnel\n",
            " current lse-75 status as intro for new t&s personnel\n",
            " bugs found in fitsread\n",
            " an adequate process platform for shape measurement tests\n",
            " risk register status\n",
            " for winter 2016 work on lse-68\n",
            " change request for lse-68, mid-phase-3 update\n",
            " and post docgen of lse-68\n",
            " functions discussion\n",
            " workspace functions discussion\n",
            " qserv dependencies build on os with clang\n",
            " for distortion in matchoptimisticb astrometry matcher\n",
            " scipy 2015 tutorials\n",
            " /deploy sui web application at ncsa\n",
            " up gitolite\n",
            " review with chris smith aura head\n",
            " usage of obsolete astrometry interfaces in processimagetask\n",
            " nightly/weekly release automatic distribution - part i\n",
            " use of compound fields in minimal schema\n",
            " python wrapper: make launch browser smarter.\n",
            " getxxxkey for slots with returning functorkeys similar to existing compound keys\n",
            " api for worker management service\n",
            " assertxnearlyequal to afw\n",
            " region support\n",
            " histogram in edu.caltech.ipac.visualize.plot package.\n",
            " test harness for testing measurement algorithms\n",
            " psf libraries from phosim images\n",
            " support for  for has-chunks query\n",
            " xrootd client debug messages in qserv czar\n",
            " data distribution/replication testing strategy\n",
            " support for bit columns\n",
            " dilation performance regression\n",
            " configuration tool main use cases\n",
            " down monster dm-1108 stories\n",
            " simulated psfs from library of on-disk files\n",
            " great3 sim code and integrate with lsst stack\n",
            " data directory at configuration\n",
            " authentication mechanism for worker management service\n",
            " parallel ssh to manage qserv on in2p3 cluster\n",
            " for qserv processes at configuration tool startup\n",
            " typemaps for numpy scalars\n",
            " and learn to use ipython notebook\n",
            " processfile to use new measurement framework\n",
            " faint source and minimum-radius problems in kron photometry\n",
            " meas_extensions_photometrykron to new measurement framework\n",
            " measurement code from meas_algorithms\n",
            " footprints from different bands/epochs\n",
            " master list of objects given detections in multiple bands/epochs\n",
            " -level processing for merged objects\n",
            " post-merge objects\n",
            "  flag in sdsscentroid\n",
            " querysession::_stmtparallel from query::selectstmtptrvector to query::selectstmtptr\n",
            " management service - design\n",
            " usage of measurement framework in star selectors\n",
            " table versions to schema\n",
            " measurement algorithms in meas_extensions_shapehsm\n",
            " measurement algorithms in ip_diffim\n",
            " standard aliases for frequently-used measurements\n",
            " doxygen doc for new meas_base classes\n",
            " transition: storage of large data files\n",
            " transition: stash-stored pull requests, extraction\n",
            " webdav capabilities and past experience using it\n",
            " should be caching and restoring plot metadata\n",
            " noisereplacer outputs reproduceable\n",
            " sui requirements, send list of questions to the group scientist\n",
            " work environment / test builds for refactored repositories\n",
            " and implement css structure for distributed qserv setup\n",
            " remote host access for management framework\n",
            " lse-130 review by ccb (mainly camera)\n",
            " initial content\n",
            " draft of lse-130 for camera and ccb review\n",
            " project for rfcs\n",
            " transition: naming conventions for repositories\n",
            " mechanism for periodic (nightly/weekly) build distribution\n",
            " -based shrink operations for footprint\n",
            " up multiple aperture photometry code\n",
            " looking at how python pandas can be used for lsst data analysis.\n",
            " the current sui requirement\n",
            " the current sui requirement\n",
            " an integration test case with gb-sized data\n",
            " sui data (dc_w13_stripe82_subset)\n",
            " porting meas_algorithms unit tests\n",
            " functorkeys to replace compound field functionality\n",
            " _base resultmappers should be functorkeys\n",
            " from '.' to '_' in afw::table fields\"\n",
            " basic functorkeys\n",
            " of four new measurement algorithms for processccd testing\n",
            " four algorithms for compatibility with original meas_algorithms\n",
            " slot support for meas_base-style outputs\n",
            " ++ redesign -- result definition for custom algorithms\n",
            " afw::camerageom::utils code\n",
            " test data and camera\n",
            " qserv mono-node instance in docker\n",
            " tune czar and worker database initialization\n",
            " meas_base python wrappers and plugin registration\n",
            " api without (or with optional) result objects\n",
            " winter 2014 binaries\n",
            " agreed-upon changes into word version of lse-69\n",
            " documentation and automatic install script w.r.t. qserv 2014_09.0 release\n",
            " scisql plugin (shared library) outside of eups stack.\n",
            " moving to c++11 for .cc files\n",
            " qserv-testdata.py to qserv_testdata package\n",
            " install/distribution procedures using lsst-sw\n",
            " test should optionally ignore column headers\n",
            " linux standard base - compliant init.d scripts\n",
            " rebuilds targets without changes\n",
            " antlr 2.7 in eups\n",
            " tests dataset should be packaged in eupspkg\n",
            " geom eups package for installing geometry\n",
            " returns error table instead of error code\n",
            " docs for scarlet v0.5\n",
            " calexp_fakes through skycorrection and coadddriver\n",
            " new wcs fitting for final tangent to sky projection\n",
            " management and migration preparation\n",
            " for jupyter community workshop 2019\n",
            " and reorder isr steps to support writing pre-interpolated pixels\n",
            " key numbers\n",
            " for alert production in year 1\n",
            " merge table (i.e. result_m) creation on czar side\n",
            " out camerageom+boresight+rotation approach to initial wcss\n",
            " technical report for may 2019\n",
            " initial task list\n",
            " parameter during observations with gemini telescope\n",
            " meas_extensions_scarlet\n",
            " into the data backbone\n",
            " offsets in backgrounds (aug 2018)\n",
            " unit tests for scarlet\n",
            " obs_lsst defects to new form\n",
            " obs_decam defects to new form\n",
            " obs_cfht defects to new form\n",
            " ingestindexreferenceobjectstask multiprocessing capable\n",
            " scarlet models more general\n",
            " one full raft of ccds successfully\n",
            " general functionality of archiver csc\n",
            " ap_association to use pandas data frames (rather than afw::table) as an interface\n",
            " down astrometry model\n",
            " higher order aberrations in hsc donuts\n",
            " functions for making and applying gain flats\n",
            " and validate fits files assembly from atarchiver\n",
            " storable mixin to exposureinfo components\n",
            " format for metadata file for the headerservice\n",
            " for and attend tma software workshop\n",
            " sssc june 2019 meeting\n",
            " plan for more sensitive metrics for weekly builds\n",
            " defect identifcation\n",
            " 2 quantumgraph generation\n",
            " queries sometimes never return\n",
            " imgserv with soda support to lsp-int on pdac\n",
            " first demo of dal and soda implementation for imgserv.\n",
            " kubernetes setup for replication framework in pdac\n",
            " c++ iteration to genericmap\n",
            " statement of work for the quansight qa dashboard development\n",
            " xrootd/cmsd containers\n",
            " initial planning data\n",
            " in operations rehearsal\n",
            " the performance issue of firefly in lsp-int\n",
            " research for firefly extension to jupyter la\n",
            " and deliver test dataset for qa dashboard project\n",
            " and install rpms for ts_sal v3.10 on the ncsa test stand\n",
            " _client needs to pass along the user's credential when in notebook environment\"\n",
            " widget design discussion and guideline\n",
            " ut1 in visitinfo from available information\n",
            " era into visitinfo\n",
            " up dcrmodel convergence\n",
            " diffim false detections as function of seeing range\n",
            " the psf for dcr coadds\n",
            " quantumgraph generation tests for trace and profiling info\n",
            " up with jupyter development\n",
            " fastparquet as read option for parquettable\n",
            " fgcmcal reference stars on s18a\n",
            " reference stars to fgcmcal fit as an option\n",
            " likelihood gradient evaluation in multiprofit\n",
            " duplication in deferred prelight follow-up queries\n",
            " user login and use the credential to do authentication\n",
            " task for identifying defects\n",
            " available ptg/mcs/spectrograph information into aths\n",
            " machine deployment of the dm-efd using k3s ()\n",
            " technical report for april 2019\n",
            " query progress through show processlist\n",
            " getting started notes on ip_diffim\n",
            " v0.1 exec config\n",
            " impact of pupil != pinhole for wavefront modeling\n",
            " logging directory and loading config file into base class for c++\n",
            " and possibly fix afw::table record allocation performance`\n",
            " coverage above gemini from merra-2\n",
            " aod from photometry, spectrometry and global assimilation model\n",
            " ivoa meeting in paris\n",
            " in operations rehearsal #1\n",
            " scarlet and sdss deblender cmodel\n",
            " and analyze new scarlet on coadds with fakes\n",
            " scarlet models with hst candels\n",
            " where deblending time is being spent in new scarlet\n",
            " exception rates from new scarlet\n",
            " variation versus regular modulation of atmospheric parameters : does this depend on their mean altitude?\n",
            " tests to ap_pipe\n",
            " adding backoff to dask jupyterlab extension\n",
            " on \n",
            " the \\xe2\\x80\\x9cwiggles\\xe2\\x80\\x9d observed when histogramming flats & darks from ts8 and auxtel\n",
            " in ops rehearsal as verification/validation scientist role\n",
            " solar system object observations per night\n",
            " of mpc data rates\n",
            " the 6th iaa planetary defense conference\n",
            " heterogenous map\n",
            " 2020 white papers\n",
            " in desc brokers workshop (as soc member and presenter)\n",
            " color-dependent offsets from ref cat in jointcal vs. meas_mosaic\n",
            " qserv monitoring services\n",
            " capture wcs requirements\n",
            " and define rfc to keep deployments in k8s organized\n",
            " up solar system infrastructure at ncsa\n",
            " and attend astronomical time series 2019 workshop\n",
            " multicast on gke\n",
            " metadata and chunklists for wise and kpm30\n",
            " data to qserv node disks from bucket storage\n",
            " latex technote template to lsst/templates repository\n",
            " an lsst-specific pre/post-hook microservice for templatebot\n",
            " test coverage of cmodel failure modes\n",
            " psf issues in deblending\n",
            " dmtn-006 & dmtn-021\n",
            " pre-computed values to parquet tables output by pipe_analysis scripts\n",
            " jointcal astrometry models with run2.1i data\n",
            " visit and coadd qa analysis scripts to run on desc dc2 outputs\n",
            " hits output to martinez 2018\n",
            " and begin to implement incident monitoring and response\n",
            " an implementation guide for dax web services\n",
            " technical report for march 2019\n",
            " for lsp review\n",
            " dax_ppdb to use pandas data frames (rather than afw::table) as an interface\n",
            " rfc-460: move afw.geom content to new geom package\n",
            " plan to address pybind11 build size issues\n",
            " and attend astronomical time series 2019 workshop\n",
            " and test linear fitters with cosmos data\n",
            " naming conventions in salpytools/salpylib.py\n",
            " side file system browsing\n",
            " the axis-symmetry hypothesis\n",
            " statistics apply to merra-2 data\n",
            " back l1 test stand back online by march 15\n",
            " filename template mechanisms in posixdatastore and butler\n",
            " astro_metadata_translator in daf_butler\n",
            " tool to validate datastore template configurations\n",
            " to normalize warps by jointcal's photocalib\"\n",
            " all uses of calib with photocali\n",
            " explicit registry close in the butler\n",
            " support for common shapes defined by vo-soda\n",
            " soda1.0 service registration in imgserv\n",
            " installation method for the headerservice\n",
            " results of cosmos galaxy fits\n",
            " -2 table floating altitude grid\n",
            " of optical depth from combination of 15 aerosol components.\n",
            " signal of aod annual modulation above maunakea: is this also the case above lsst site?\n",
            " image processing : the correct method to adjust the pixel-to-wavelength solution\n",
            " analysis of merra-2 aod 3-d tables\n",
            " process fit of the temporal modulation of merra-2 parameters\n",
            " 's up with mauna kea aod ?\"\n",
            " defect machinery working for the auxtel\n",
            " maximum record limit in tap query screens in firefly\n",
            " mapping of ip_diffim dipole fields to dpdd\n",
            " data loading\n",
            " cron job to pull validation data on regular basis\n",
            " reporting for february 2019\n",
            " and submit cycle plan\n",
            " up gaussian processes apllied to atmospheric parameter monitoring\n",
            " binaries of ts_xml, ts_sal and ts_opensplice for the ncsa l1 test stand\n",
            " backwards-compatibility with calib api\n",
            " loadreferenceobjectstask to output fluxes in nanojansky\n",
            " the results table in qserv\n",
            " (in-)accuracy of geometric approximation when fitting donuts.\n",
            " at header templates using information mapping -- part1\n",
            " software on ncsa side of auxtel image transfer\n",
            " sst activities for march 2019\n",
            " for database services at the base\n",
            " base services needing rdbms\n",
            " existing hardware and os for attachment of new storage\n",
            " and storage architecture modifications for gen3 butler integration\n",
            " integration of oracle builds/installs with puppet, for node rebuilds\n",
            " nodes into development/test and pre-production subsets\n",
            " on tools for bulk download march 2019\n",
            " privileged containers in test clusters\n",
            " kubectl access\n",
            " native gpfs on test cluster\n",
            " design for tap search\n",
            " uses of pex::exceptions\n",
            " for support of  for more efficient image passing to python\n",
            " winter desc meeting at berkeley (feb 2019)\n",
            " minimal rucio setup for first prototype features\n",
            " design proposal for results management\n",
            " impact of variable seeing on current dcr correction\n",
            " and attend pst-f2f\n",
            " initial subset of timeseries features for diaobject\n",
            " dc2 imsim one tract of data\n",
            " qserv data for gke/wise cluster\n",
            " 1m3 thermal fpga development part 1\n",
            " plotting scripts into reusable format\n",
            " scaling test in google cloud\n",
            " tables in vo format\n",
            " meeting\n",
            " butler working with oracle\n",
            " and verification of march pm\n",
            " for march pm\n",
            " visitanalysis to work on jointcal's output\"\n",
            " search processors calling dax api\n",
            " the portal code to use tap provided by dax team when avaialble\n",
            " fft convolutions in scarlet\n",
            " fft psf convolution algorithms\n",
            " regression tests for scarlet\n",
            " cosmos galaxies with pyprofit\n",
            " alert production prototype with new index type\n",
            " new vm compute nodes\n",
            " and test new vm infrastructure\n",
            " new mac mini to jenkins\n",
            " technical report for february 2019\n",
            " development to calculate lsst data rates for mpc\n",
            " qserv_deploy configuration\n",
            " search: target and spacial panel updates / next steps\n",
            " deployment of the influxdb + chronograf + kapacitor stack\n",
            " react to 16.8\n",
            " jwt authorization exploration\n",
            " proof of concept use of sdm system\n",
            " search: column constraints panel updates / next steps\n",
            " forced-photometry procedure with firefly in pdac v1\n",
            " antlr2 from qserv\n",
            " gliffy diagram of suit-camera architecture\n",
            " search: relayout tap ui\n",
            " all explicit imports of ds9\n",
            " of telefonica 4 fibers at aura gate\n",
            " day for rfp from equipment vendors\n",
            " switches and transceivers on pachon and tololo\n",
            " switches for aura tenants\n",
            " and implement rfp for dwdm devices\n",
            " progress feature for qserv\n",
            " meas_extensions_ngmix for better functionality and upstream collaboration\n",
            " openorb build system\n",
            " status of influxdb-sink kafka connector\n",
            " mock experiment\n",
            " sink connector does not support arrays in avro messages\n",
            " and chair dmlt virtual meeting\n",
            "  nomenclature from jellybean components\n",
            " trip to help with kubernetes deployment of firefly\n",
            " existing documentation left by jim parsons on the l1 test stand\n",
            " to initiate replication in rucio\n",
            " rpms for dm l1 system\n",
            " reporting for january 2019\n",
            " first ops rehearsal description\n",
            " search: improve the constraints table for tap search\n",
            " transfer test from chile to us google bucket\n",
            " notebook scale test on google cloud\n",
            " and test multi-band fitting with multiprofit on hsc/cosmos\n",
            " sketch of auxtel pipeline\n",
            " sst activities for february 2019\n",
            " search: temporal search box content\n",
            " up square events microservice for creating projects/files from templates\n",
            " trip\n",
            " on tools for bulk download february 2019\n",
            " and coordinate move of equipment out of noao closet\n",
            " search prototype\n",
            " obscore, recognize some ucds, do normal catalog overlay\n",
            " pv/pvc on qserv-cluster@gke\n",
            " generation hits sqlite join limit\n",
            " validation_data_* processing to use htm catalogs\n",
            " finished epics\n",
            " and verification of february pm\n",
            " ingest improvement requirements for qserv\n",
            " the dpddification (sdmization...) work and how it applies to ap_association\n",
            " of linked plots with holoviews and datashader\n",
            " memory usage in matchpessimisticb\n",
            " taxonomy/hierarchy\n",
            " functionality tests of imagedifferencetask\n",
            " non-subtask \\xe2\\x80\\x9csubtasks\\xe2\\x80\\x9d in ip_diffim\n",
            " with the ip_diffim codebase\n",
            " _lsst no longer supports ts3 test data\n",
            " in the daq 2.5 workshop\n",
            " search: create component to select tables and schema that is firefly/irsa viewer like\n",
            " user guide for display_firefly\n",
            " technical report for january 2019\n",
            " model development to calculate lsst data rates for mpc\n",
            " for daq 2.5 workshop at ncsa\n",
            " parameters for n=4 multi-gaussian sersic\n",
            " salpytools to add error cases and codes for the headerservice\n",
            " camerageom paf files\n",
            " loi for community broker call\n",
            " error cases and codes for the headerservice\n",
            " packaging of shared libraries in scons\n",
            " colorterm config support to jointcal\n",
            " time post-demo reviewing and preparing next stages\n",
            " aas poster on ap_pipe\n",
            " initial raw-data ingest system for gen3 butler\n",
            " packed integer versions of gen3 data ids\n",
            " pipelinetask to make warps (makecoaddtempexp conversion)\n",
            " selection on s/n in objectsizestarselector\n",
            " hsc  dataset for bi-weeklies processing\n",
            " _base plugin for sampling-based galaxy fitter\n",
            " table watching sagas so there is one \n",
            " filesystems\n",
            " current filesystem usage\n",
            " on tools for bulk download january 2019\n",
            " search: spatial and temporal specialized search boxes\n",
            " sst activities for january 2019\n",
            " search: advance adql query panel for\n",
            " and test pipelinetask systems and prepare demo presentation\n",
            " sure data ids are expanded when adding datasets and filling templates\n",
            " puppetlabs kubernetes module\n",
            " puppetlabs kubernetes module\n",
            " non-admin users access to k8s logs\n",
            " current kubernetes puppet module to kubernetes_old\n",
            " based replication example\n",
            " puppet port in iptables on puppet master\n",
            " firewall for puppet and gitlabs access in npcf\n",
            " configuration management db (ie: gitlab) to vm\n",
            " bastion01 as vm\n",
            " npcf puppet master to vm\n",
            " yum repo service as vm\n",
            " rsync arguments for data transfer\n",
            " relative dcrmodel option\n",
            " testing with gen3 butler in support of oods\n",
            " storage hardware for redundancy\n",
            " reporting for december 2018\n",
            " and verification of january pm\n",
            " doesn't push down source_id predicate, causing table scan\"\n",
            " confluent registry-enabled avro serializer plugin for aiokafka\n",
            " phosim 3.9 wavefront sensing chips work with obs_lsst\n",
            " metadata translators for obs_lsst cameras\n",
            " measuremergedcoaddsources to pipeline task\n",
            " problems in pipelinetasks uncovered by end to end tests\n",
            " assemblecoaddtasks to pipelinetasks with shims\n",
            " swug chapter on measurement\n",
            " simulated dcr test data with variable psfs\n",
            " calibratetask into pipelinetask\n",
            " display_firefly to working firefly_client changes\n",
            " collection integrity constraint inside the registry database\n",
            " test cases\n",
            " of cache cleaning task\n",
            " technical report for december 2018\n",
            " sal text-based kafka messages to avro\n",
            " tap service watchdog\n",
            " tables in other formats develop infrastructure and implement csv and tsv\n",
            " search: update the tap panel layout/infrastructure to allow for concurrent work\n",
            " and resource-load plan\n",
            " for january pm\n",
            " scans for drx-1 to the model\n",
            " loadreferenceobjectstask for supertask compatibility\n",
            " query class code\n",
            " pdac jellybean in ncsa k8s commons\n",
            " _config numpydoc conversion and package documentation configuration\n",
            " qserv_ functions to be called through tap\n",
            " fits image reading so the the specified index is the fits hdu index and not the image count index\n",
            " configurations for fitting dc2 u-band psfs\n",
            " sys_resource and ulimit\n",
            " deployment of new kafka-based square bot slack bot\n",
            " _base to numpydoc format\n",
            " up initial ci for pytrax\n",
            " /install and test new ts_sal and ts_xml\n",
            " cleanup of pytrax codebase\n",
            " njy in photocalib as the unit for calibrated fluxes\n",
            " classes for dataunit tuples/sets and data ids\n",
            " integration of l1 pipeline into daq\n",
            " deblendcoaddsourcestask to pipelinetask framework\n",
            " mergedetectionstask into pipelinetask\n",
            " sst activities for december 2018\n",
            " transfer tools tests from cc-in2p3 to ncsa\n",
            " out first ops rehearsal based on dmlt feedback\n",
            " the full 1.2i data using ctrl_pool/pipe_drivers\n",
            " test run drp pipelines with small set of imsim data\n",
            " reporting for november 2018\n",
            " auxiliary telescope integration activity in tucson\n",
            " bbox integrator for photometrytransform\n",
            " initial requirements document for the oods\n",
            " hits2015 based on dcr-corrected templates\n",
            " we have unit tests and add if needed for arithmetic operators, logical operators, bit operators, and comparison operators\n",
            " up framework to make firefly test easier\n",
            " diasource flags into ppdb\n",
            " obs_test to numpydoc\n",
            " preliminary task/epic list\n",
            " greedy optimizer from dm-13406 for elliptical gaussians\n",
            " metrics-handling task\n",
            " technical report for november 2018\n",
            " interactive qa system to spatially binned metrics\n",
            " bokeh server app to browse static qa plots\n",
            " user to attach custom callback to an action in the qa dashboard, possibly within jupyterla\n",
            " 'symlog' axis scale in bokeh, and allow for scale selection in qa dashboard\"\n",
            " visit outlines on interactive qa sky plots\n",
            " hierarchical qa sky-plots that are navigable by clicking on regions\n",
            " job metadata in verify_ap\n",
            " source catalog / footprint browser for firefly\n",
            " deployment for efd-kafka demo\n",
            " jenkins test env creation\n",
            " work for shear on coadds paper\n",
            " some afw types hashable\n",
            " existing storage model\n",
            " model fixes\n",
            " scans for drp-produced dia* tables to the model\n",
            " lifetime support for auxtel test stand ingestion service\n",
            " and create new fs for data backbone\n",
            " filesystem needs & procedures for raw data\n",
            " webserv for sui\n",
            " dbserv_1 xml output via topcat ivoa tool\n",
            " docker 17.06 and overlay2 at cc-in2p3\n",
            " minikube for travis-ci\n",
            " framework (http service)\n",
            " sst activities for november 2018\n",
            " czar for per-table overlap (facade, relationgraph)\n",
            " mock sal kafka producer\n",
            " and test headerservice against new version of sal and xml\n",
            " isr on phosim runs of wavefront sensor chips\n",
            " balloons vs. merra-2\n",
            " report describing plans for atmospheric characterization\n",
            " & discuss a.t. observation strategy at the october 2018 desc/lsst calibration workshop\n",
            " and the molecular scattering\n",
            " atmospheric transmission determination from global data vs local observations : decennial monitoring comparison.\n",
            " end-to-end assessment of the a.t. extraction method : the aod challenge.\n",
            " stack_package cookiecutter template\n",
            " stack demonstration\n",
            " test specification for ldm-503-5 milestone\n",
            " with diffimtests repository\n",
            " suit ui to include hsc data search\n",
            " support for xor\n",
            " the formatter for serializing diaobjects/sources through the butler\n",
            " tsv importer to handle nulls\n",
            " off of github master for 3d party packages\n",
            " how lsst sims system works\n",
            " efd demo producer/consumer load test\n",
            " of november pm\n",
            " of october pm\n",
            " the tap_schema to browse tables\n",
            " input for more detailed database/dax performance requirements\n",
            " home-brewed sqlite ppdb\n",
            " of november pm\n",
            " correction working group data challenge\n",
            " objects for source modelling code\n",
            " multi-gaussian free sersic profile in pyprofit\n",
            " kafka writer for efd environment\n",
            " quota support for jupyterlab users\n",
            " and preparation for november pm\n",
            " -out gitlab and puppet-master as vms at npcf\n",
            " for distributed deployment/management infrastructure to serve all sites/datacetners within ncsa-managed machines\n",
            " of satellite deployment/management infrastructure at ncsa 3003 as first  site\n",
            " design for remote deployment on commissioning cluster service\n",
            " necessary, adjustments to infrastructure at npcf to integrate with other sites/datacenters\n",
            " the ui to display data coverage region for different dataset\n",
            " transfer of data on 2 gpfs filesystems\n",
            " reporting for october 2018\n",
            " converting sal xml schemas to avro\n",
            " statefulset\n",
            " an existing task to be usable as supertask\n",
            " coordination of camera bootcamp at slac\n",
            " object inputcount qa plots to coaddanalysis\n",
            " ip_diffim outputs to cat schema\n",
            " diasource access in l1dbproto\n",
            " for commissioning boot camp\n",
            " user configurable cfg file options\n",
            " dmlt/ivoa/adass\n",
            " source table and footprints by id column\n",
            " and audit header template for the ats\n",
            " the literature on image differencing\n",
            " technical report for october 2018\n",
            " management implementation in jira\n",
            " processing\n",
            " pipeline testing for biweekly testing of software\n",
            " initial qa results\n",
            " an extensible task for metrics handling\n",
            " votable support when uploading table\n",
            " and sst\n",
            " science pipelines algorithms paper/talk for adass 2018\n",
            " experimental python-based kafka clients (prep for creating dm efd-specific producers/consumers)\n",
            " jacobian boundedfield accessor to skywcs\n",
            " seqnum from obs_lsst/ts8 and prepare obs_lsst for bootcamp\n",
            " celery task in the squash api to save time series data to influxdb\n",
            " stargalaxyprior with pybind\n",
            " to error/acknowledgement codes\n",
            " qsmysqllistener adapters handle or throw grammar possibilities\n",
            " functor.yaml file for dpdd object table\n",
            " -altitude determination of atmospheric parameters from merra-2 3-d tables\n",
            " mini-broker design documentation\n",
            " summary of alert distribution design\n",
            " survey of alert db technologies\n",
            " adql2.1 and sql-92 grammars\n",
            " pex_policy and persistable usage from daf_persistence, obs_*, and filter\n",
            " characteristics of existing oracle rac system\n",
            " preparation and planning for ffy19 contract september work\n",
            " to run hsc_test_hscmini.wcl with w_2018_36\n",
            " dcrcoadd variance plane bug\n",
            " sst activities for october 2018\n",
            " reporting for september 2018\n",
            " policy proposal\n",
            " and october work for ffy19 acquisition plan\n",
            " out cadc tap service\n",
            " configuration\n",
            " testing\n",
            " one-time krb keyta\n",
            " puppet configuration for kerberos\n",
            " kerberos entity\n",
            " schema for json output from albuquery\n",
            " database backed association into ap_verify\n",
            " good seeing coadds from 2014 hits\n",
            " , ingest and play with atmospec dev data\n",
            " photocalib returns negative calibrations\n",
            " filter throughput for dcrcoadds\n",
            " technical report for september 2018\n",
            " support for multi-task pipelines to command line framework\n",
            " end users to cancel builds\n",
            " elements needed for general archiver\n",
            " camerageom::camera round-trip persistable\n",
            " afw::camerageom::detector table-persistable\n",
            " daf_persistence hooks in propertyset, propertylist, and afw objects\n",
            " galaxy/psf model fitting performance\n",
            " undefined values to fits standards for headerservice\n",
            " qserv code for choice between antlr v2 parser and antlr4 parser.\n",
            " dask\n",
            " auxtel ingestion into data backbone from tucson\n",
            " support for composites to datastore prototype\n",
            " sql-yaml converters for butler registry schema\n",
            " dataunit inserts in registries\n",
            " concrete cmdlinetasks and gen3 butler as necessary to work together\n",
            " dataunitregistry from schema\n",
            " wg activities\n",
            " squash metrics into honeycom\n",
            " to prometheus\n",
            " -implement task execution in laptop activator\n",
            "  in sourcecatalogs\n",
            " -preserving 3-color image making dialog changes\n",
            " the write method for the headerservice\n",
            " brazil meetings and workshop\n",
            " pipeline conversion process for detectcoaddsources\n",
            " sourcedeblendtask out of measurecoaddsources\n",
            " the ability of detector to find the camera in which it lives\n",
            " bbcp command lines and performance in attempts to transfer slac data to ncsa\n",
            " investigation of slac data\n",
            " fgcmcal output stars to stack reference catalog format\n",
            " calibration repositories in gen2->gen3 conversion\n",
            " principal color axes to stellar color-color plots\n",
            " integration tests on gke\n",
            " feedback on dmtn-057\n",
            " shell script to serve as jenkins hook\n",
            " write-up of best practices for containers\n",
            " /index of task topics\n",
            " test to check the logic of the calib_psf_* flag setting\n",
            " astrometry and photometry visit calibration flags to coadds\n",
            " and staff epics\n",
            " framework for an async searchprocessor\n",
            " galaxy model integration/convolution and fitting tests\n",
            " summary of initial galaxy model comparisons\n",
            " task to train classifier\n",
            " -level monitoring refinement\n",
            " displays/views for monitoring services\n",
            " persistentvolume for /data directory\n",
            " parts of l1dbproto to the stack\n",
            " behavior of 2d-histogram (heatmap) fallback in firefly\n",
            " fgcm on hsc s18a\n",
            " ldf kubernetes section to ldm-542\n",
            " dcrcoadd frequency regularization\n",
            " dcr paper during december 2017\n",
            " salpytools pep8 compliant\n",
            " headerservice pep8 compliant\n",
            " report for august 2018\n",
            " progress report for august 2018\n",
            " preliminary epic list\n",
            " pst and do little prep\n",
            " forced photometry on pvis in ap pipe.\n",
            " and transfer wise dataset to cloud\n",
            " symbol visibility to hidden in pybind11 wrappers\n",
            " use case document\n",
            " report generation\n",
            " in-memory caching datastore\n",
            " chained datastore support to butler\n",
            " config separator in daf_butler\n",
            "  in pipeline/developer documentation\n",
            " fits header display to use local headers and update as the user switches the active image\n",
            " c++11 inheritance safeguards to afw\n",
            " proper motions in reference catalogs\n",
            " implementing yaml storage for propertylist/propertyset\n",
            " of spectrograph controller\n",
            " minimal shimbutler for v2 on top of v3\n",
            " auxtel data backbone setup\n",
            " zeroth-level draft (for one rehearsal)\n",
            " mocs from other sources\n",
            " work for ffy19 acquisition plan\n",
            " dmtn-080\n",
            " bucket for keeping up with jupyter evolution\n",
            " maintenance\n",
            " albuquery and webserv deploys to pdac from docker\n",
            " constrainedmagnitude model\n",
            " eigenvalues/eigenvectors of decam constrainedphotometrymodel\n",
            " option to filter existing output datasets\n",
            " vision document for dm-efd\n",
            " implement in jira and with it staff\n",
            " initial network policy configurations\n",
            " deblender defaults in in new deblendcoaddsourcestask\n",
            " report for july 2018\n",
            " migrate headerservice to python3\n",
            " fgcmcal on hsc pdr1\n",
            " statefulset\n",
            " jupytercon presentation\n",
            " case01/queries/1012_orderbyclause.sql.fixme\n",
            " are ignored in the where clause of qserv queries\n",
            " registry.getregion(dataid)\n",
            " tasks cannot assume that masks can fit in memory\n",
            " tutorial notebook for lsst@europe3\n",
            " fitsread part of image process\n",
            " lsst footprint overlay on image\n",
            " rfc-498: homogenize naming of calibration flags\n",
            " -of-concept for stack pipelines.lsst.io build\n",
            " using storageclasses to provide assemblers for composites\n",
            " lsst allhands\n",
            " lsst allhands\n",
            " progress report for july 2018\n",
            " resource in the squash-restful-api for the kpms dashboard\n",
            " lsst-themed ipynb to html conversion for notebook-based report system\n",
            " up pdac deployment\n",
            " and test sal code for ocs integration of spectrograph image creation components\n",
            " one-filter-per-container broker\n",
            " processccd outcomes using py2 and py3 stacks\n",
            " up and simplify build process for docker images\n",
            " squash rest api to make it complaint with lsst.verify\n",
            " centos7 sal docker container with python3\n",
            " and document running ap_pipe on the verification cluster with slurm\n",
            " dcr corrected templates in image differencing\n",
            " ap_pipe to non-hits data\n",
            " prototype to latest version of toolkits\n",
            " porting branch of validate_drp\n",
            " submenu in the menu list\n",
            " jointcal on acceptance data\n",
            " verification jobs produced by the hsc reprocessing to squash\n",
            " preparation and planning for ffy19 contract\n",
            " primary method names, run/rundataref, across pipetasks\n",
            " line search\n",
            " and types returned by metaserv should match d\n",
            " report telemetry design and implementation\n",
            " collaborate with slac to improve performance and stability of ap beta application.\n",
            " draft with use cases for batch processing service\n",
            " run/document ap_pipe\n",
            " /slurm test code\n",
            " final difference image\n",
            " prompt processing test field from des sn field\n",
            " prompt processing test field from des sn field\n",
            " in accs mcm/ocs bridge for spectrograph integration test\n",
            " information about the oods\n",
            " and test sal code for accs mcm/ocs bridge for spectrograph integration test\n",
            " and architecture meetings for kubernetes commons\n",
            " progress report for june 2018\n",
            " report for june 2018\n",
            " votable 1.3 to json schema for dbserv/albuquery\n",
            " gke deployments to rds or something, not sqlite\n",
            " how to write and build the integrated pipelines.lsst.io\n",
            " validate_drp to lsst.verify\n",
            " of suit using kubernetes in lsp\n",
            " magnitude-based photometric model\n",
            " the as-is process of hsc biweekly and pdr1 reprocessing\n",
            " quantumgraph implementation\n",
            " dcr matched template data type\n",
            " dcr code to use tasks\n",
            " crosstalk correction in decam\n",
            " one off-questions that arise while writing paper text\n",
            " noise correlations on coadd using visit information\n",
            " depth of simulated footprints using different cell sizes and dither strategies\n",
            " depth of coadds using different cell sizes and dither strategies\n",
            " bf code porting\n",
            " scope of restricted python environments\n",
            " blob quoting problem in result aggregation\n",
            " end testing of dm l1 ats system\n",
            " tpv projection\n",
            " brown bag on the state of the broker\n",
            " performance results and analysis\n",
            " handling\n",
            " archive device\n",
            " ocs bridge with header service\n",
            " forwarder code\n",
            " initial version\n",
            " implementing quantumgraph building\n",
            " -proxy issues with mariadb 10.2.14\n",
            " discussion for lsst data w.r.t null and fixed point fields\n",
            " with kpm30 tests.\n",
            " pegasus data management capabilities\n",
            " k8s issue with containers not starting\n",
            " security issues and tools\n",
            " disaster recovery methods and tools\n",
            " migration plan for migrating monitoring to vms\n",
            " /influxdb ssl implementation\n",
            " feasibility of using smb mounts on kubernetes\n",
            " plotly library\n",
            " puppet setup for ccqservproxy and ccqservbuild at cc-in2p3\n",
            " star galaxy classifier into task\n",
            " to drp team on measuring shear on coadds\n",
            " mini-broker prototype with kubernetes\n",
            " feedback to gen3 middleware designs and discussions (june)\n",
            " review of butler schema\n",
            " setup of r10k\n",
            " cmodel config parameters\n",
            " yaml configuration option to headerservice\n",
            " support for sub-workflows in pegasus wms\n",
            " pegasus job clustering abilities\n",
            " design for file portion of data backbone\n",
            " design for file portion of data backbone\n",
            " l1dbproto into associationtask\n",
            " design for multiple parallel filters\n",
            " out relationship between coordinate systems involved in fourier optics\n",
            " spie 2018 paper on dm processes\n",
            " up lsst europe cluster\n",
            " and write down the math for fitting in-focus psfs with optical model.\n",
            " of gemini-south gmos observations\n",
            " of atmospheric parameters from snif spectra\n",
            " psf/donut cutout images into exposure catalogs\n",
            " te1 and te2 kpms to validate_drp using code developed in dm-3040\n",
            " limits and labeling for color analysis plots\n",
            " alert distribution prototype\n",
            " scripts to assess and report miniproduction quality.\n",
            " test specification\n",
            " fits file assembly at ncsa\n",
            " server memory usage\n",
            " framework (integration with qserv)\n",
            " cache mechanism improvement for dockerized firefly deployment\n",
            " up end-to-end alert system\n",
            " webserv api to pass security tokens\n",
            " api document update\n",
            " dmtns for this epic\n",
            " validate_drp jenkins job to pipeline\n",
            " purging of daily eups distrib tags\n",
            " sqlregistry more transactional\n",
            " butler for composite work to begin\n",
            " level python api for firefly plotting\n",
            " up artifact rejection report\n",
            " for and attend lsst/desc calibration workshop\n",
            " qa_explorer and move to lsst-dm repo\n",
            " spatial exposure selection task\n",
            " covariance propagation code to study covariance properties\n",
            " on desc survey of survey geometry use cases\n",
            " documentation for ap_pipe\n",
            " single-sign-on authentication system for webserv\n",
            " meeting attendance\n",
            " meeting\n",
            " -level security work\n",
            " firewall settings for container access\n",
            " up test framework for antlr4 vs antlr2\n",
            " subchunk query generation to the worker.\n",
            " bucket for keeping up with jupyter upstream\n",
            " provenance methods in registries\n",
            " support for composite datasets in butler registry\n",
            " adddataset in registries\n",
            " butler datasetref\n",
            " fit all donut data with optics wavefront field-of-view model\n",
            " user documentation site for the notebook aspect of the lsst science platform\n",
            " firefly scaling\n",
            " configuration\n",
            " configuration\n",
            " into production\n",
            " configuration\n",
            " atmosphere transmission curves from fgcm\n",
            " initialization of display_firefly and firefly_client\n",
            " initial butler metadata schema proposal\n",
            " 9 region support document\n",
            " document for header clients\n",
            " with dax team on metaserv api v1\n",
            " with ldm-556 butler review comments\n",
            " and refactor yaml config usage in gen3 butler\n",
            " k8s setup for in2p3 cluster, after docker 1.18 upgrade.\n",
            " blue end enigma\n",
            " hips support down to level 20\n",
            " and implement fault state mechanism for auxtel machine.\n",
            " and implement automated start-up and restore for ats machine.\n",
            " storage of calibrated fluxes and computation of flux means to ap_assocation\n",
            " docker to 1.18 and switch to overlayfs2 on openstack setup\n",
            " obs_lsstsim\n",
            " parquet libraries/tools\n",
            " quantumgraph implementation\n",
            " of hips with fits & aitoff in catalog coverage maps\n",
            " headerservice to work with sal/dds tools as separate module\n",
            " old and deprecated versions of header service tests\n",
            " image metadata retrieval implementation in dax_metaserv\n",
            " morphology only sg classifier\n",
            " the sg classifier\n",
            " objective function for moment optimization\n",
            " decam running in lsst_ci and validate_drp again\n",
            " up parquet studies with lsst data\n",
            " xrootd/cmds as microservices\n",
            " restful api for async queries in webserv\n",
            " initial version of science platform test specification, ldm-540\n",
            " parquetstorage butler storage type\n",
            " of the hsc pdr1 dataset\n",
            " initial design for how dcr will fit in the stack\n",
            " rc with stack version 15.0 and compare to version 14.0 for the vvds tract\n",
            " narrative description of l3 conops\n",
            " stand-alone task to convert/consolidate source tables to parquet files for qa\n",
            " and grammar for user filter expression\n",
            " up sandbox instance for squash\n",
            " initial gen2->gen3 conversion script\n",
            " verification test to l1 plan\n",
            " verification feature to authentication & authorization conops\n",
            " verification feature to data backbone conops\n",
            " verification test to l1 design\n",
            " with systems engineering\n",
            " verification feature to l1 conops\n",
            " verification feature to l2 conops\n",
            " dbb verification tests\n",
            " to common psf\n",
            " dependency on qserv-run-dir\n",
            " outline design for the cbp coordinate transformation tool\n",
            " option to fgcm to remove large-scale variations from flat-field\n",
            " l1 database requirements (continuing)\n",
            " up qserv and replication cluster at in2p3\n",
            " associationdbsqlite to return and store afw tables containing diaobjects instead of the current diaobjectcollection. remove diaobjectcollection from the repository.\n",
            " obs_decam handle raw data\n",
            " bf kernel measurement code\n",
            " ingestion to non-hits data\n",
            " statistics for 30% dr1 dataset at in2p3\n",
            " hips selection go back to the popular / merged list style\n",
            " error handling for antlr4 parser\n",
            " antlr4 parser abilities\n",
            " equations for cbp coordinate conversions\n",
            " up development environment on ncsa openstack\n",
            " for emergent qa work in february\n",
            " work on deployment tool.\n",
            " documenteer (pipelines_lsst_io) job developer experience features\n",
            " usage.py and usageplot.py to allow for color-coded plots\n",
            " and conduct replication framework design review\n",
            " simple filter for sims alerts\n",
            " stack with new deblender api\n",
            " cloud provisionning scripts\n",
            " se/dm subsystem meeting\n",
            " exploratory plots from hits processing\n",
            " albuquery into production at pdac\n",
            " error messages for position input\n",
            " integration activity at ncsa\n",
            " notebook exploration\n",
            " code changes back to the monitor app\n",
            " probes to wmgr on k8s\n",
            " specification of test-ready dbb system\n",
            " & testing of service endpoints\n",
            " for service endpoints\n",
            " -ready version of ingestion of delivered raw files\n",
            " -ready version of saving raw files\n",
            " blocking dr task issue\n",
            " issues with daily summary reports\n",
            " and optimize nmf deblender code\n",
            " sparse matrices in the new deblender\n",
            " webpack version and babel presets\n",
            " an  plan for optimizing elliptical gaussian\n",
            " an up to date docker registry at cc-in2p3\n",
            " hips popular list configurable and update hips list content\n",
            " and cleanup data for kpm30\n",
            " wmgr service in separate container\n",
            " composites handling in datastore/butler\n",
            " slack section for spie 2018 dm process paper\n",
            " for kubernetes registry\n",
            " tests to fgcmcal using testdata_jointcal\n",
            " ap_pipe to use cmdlinetask primitives\n",
            " version of saving raw files\n",
            " up configuration management test system\n",
            " direct (soft) symmetry\n",
            " docs for the new deblender\n",
            " soft symmetry values\n",
            " hips survey loading framework, implement more control over popular surveys\n",
            " 1db interface for reading/writing afw.table data\n",
            " the coverage more flexible and support hips\n",
            " k8s to 1.9.1 at cc-in2p3\n",
            " version of dm stack tutorial\n",
            " qserv db schema to version 2 at cc-in2p3\n",
            " robust kafka 3-broker cluster\n",
            " minimal butler registry prototype with sqlalchemy core\n",
            " minimal butler registry prototype with sqlalchemy orm\n",
            " butler dataunit packing or hashing\n",
            " initial butler registry hierarchy\n",
            " minimal butler posix datastore prototype\n",
            " butler configuration\n",
            " single example query statement with antlr4 and build query objects as antlr2 would\n",
            " datasettype template to datastore configuration (override)\n",
            " fgcm to use new stack filter transmission curves\n",
            " prior probability distributions for shape parameters\n",
            " kafka tests with multiple partitions\n",
            " : make the hips viewer switch to fits when zoomed in and hips cube support\n",
            " the ways in which shape determination fails\n",
            " predictions of in-focus psf with data\n",
            " and polish dmtn-064\n",
            " hsc wavefronts using pca\n",
            " monitoring stack to all infrastructure\n",
            " version of the classifier\n",
            " gen3 involvement (february 2018)\n",
            " bucket for keeping up with jupyter upstream\n",
            " spatially/wavelength variable filter\n",
            " design for new commandable sal component for the spectrograph\n",
            " prepuller with variant of zero-to-jupyterhub one\n",
            " an expandable python framework for advanced users\n",
            " image dropdown to support hips\n",
            " react and other js libraries to lates\n",
            " mosaic.py into the desdm workflow wcl\n",
            " metaserv v1 api\n",
            " table metadata via metaserv\n",
            " column metadata via metaserv\n",
            " initial butler support for remote put\n",
            " initial butler support for remote get\n",
            " afw classes rfc-209 compliant\n",
            " run metadata from validation runs\n",
            " squash monitor app to allow visualization of multiple verification packages\n",
            " slack channel per jenkins job for notifications\n",
            " jointcal debugging output\n",
            " copyright/license statements to one-liners for rfc-45\n",
            " butler/supertask meeting at princeton\n",
            " gen3 middleware design/hack week\n",
            " pipe_analysis scripts on pdr1 data\n",
            " : query hips server to see what is available.\n",
            " pipeline tools module and cli\n",
            " with comments from review of ldm-592 from butler gen3 review\n",
            " lander metadata.jsonld ingest\n",
            " and ingest json-ld metadata for latex/lander documents\n",
            " global sky subtraction\n",
            " antlr4 and integrate with qserv build\n",
            " simulations with real cosmos galaxies\n",
            " source initialization\n",
            " ap_verify responsible for ingestion\n",
            " with kubernetes for suit and firefly deployment\n",
            " kubernetes 1.9 on whole cc-in2p3 cluster\n",
            " /characterize all the donuts\n",
            " squash data from the current production database to the new database schema\n",
            " up test system\n",
            " development & operational procedures\n",
            " os and database software\n",
            " with dax team on imageserv api v1\n",
            " ml classifier\n",
            " current star/galaxy separation in the stack\n",
            " previous star/galaxyclassification approaches\n",
            " administration and support for kubernetes cluster\n",
            " version of ingestion of delivered raw files\n",
            " system level kubernetes install experience\n",
            " tools to investigate and plot shape failures\n",
            " lsst-dm/donut\n",
            " thread manager to monitor consumer thread heath in devices.\n",
            " cds code into ncsa testbed\n",
            " ocs bridge behavior\n",
            " ocs and sal components to the unit test suite\n",
            " handling, error codes, and fault state generation\n",
            " to k8s 1.9.0 on openstack\n",
            " antlr4 and existing qserv parser code\n",
            " k8s headless service\n",
            " mysql proxy in separate container\n",
            " for header template for atscam\n",
            " into using different seeing in each band to distinguish stars and galaxies\n",
            " example of connecting firefly_client to firefly_widgets\n",
            " discussions at middleware hack week\n",
            " up database services on single node for spectrograph milestone\n",
            " slack build notification messages to jenkins\n",
            " 2.19.4 security issues\n",
            " power - f&s\n",
            " -verify performance of matchpessimistcb with new distorations\n",
            " matcher validation dataset\n",
            " butler/supertask meeting at princeton\n",
            " viewer: support circular selection\n",
            " ldm for butler use cases\n",
            " to use maf and opsim tools\n",
            " down, repackage, and ship hardware\n",
            " up alert consumers\n",
            " interactive qa reproducibility calculations\n",
            " simple propagation of flags for interactive qa work\n",
            " catalog matching in the interactive qa system\n",
            " of obsctio0m9 package\n",
            " code to generate kernel for brighter fatter correction.\n",
            " extract-transform-load workflow for restructuredtext technote metadata\n",
            " paper on deblender\n",
            " and test platforms\n",
            " qserv provisioning scripts to heat\n",
            " unit test testschedulers blendschedulequeryboottasktest fails\n",
            " test specification for ldm-503-2\n",
            " test report for ldm-503-2\n",
            " initial monitoring tasks for base aa systems\n",
            " service management incident/request dashboard(s)\n",
            " weekly service summary\n",
            " : various small image improvements\n",
            " squash qc tier 0 database to allow measurements from different lsst.verify packages\n",
            " minimal viable rest api in flask with test client\n",
            " commandlinetask utility in `ap_pipe`\n",
            " security configurations for suitability for initial spectrograph support\n",
            " whether dataset framework can be made generic\n",
            " document release workflow with lsst the docs\n",
            " integration activity #4\n",
            " the new neowise data to pdac search panel\n",
            " and enhance monitoring\n",
            " and implement aggregated metrics\n",
            " framework\n",
            " new team member\n",
            " implications of task/butler redesign on ap_verify\n",
            " coordination meetings\n",
            " an initial test report for ldm-503-2\n",
            " to dump css information\n",
            " pod for master image\n",
            " dr lockfile code\n",
            " s18 planning\n",
            " internal illumination correction for fgcm\n",
            " command line task to run fgcm\n",
            " container tracking an active table in table group\n",
            " dcr paper during november 2017\n",
            " & db docs (serge)\n",
            " neowise-r year 1 single exposure (l1b) source table into pdac\n",
            " wise n-band catalogs into pdac\n",
            " object count metrics\n",
            " an initial version of the test case specification drp-00-05 in ldm-534\n",
            " elements for initial version\n",
            " initial display elements & architecture\n",
            " processingfw to python 3\n",
            " filemgmt to python 3\n",
            " poc for bundling xrootd as microservice\n",
            " use of k8s setup\n",
            " to docker-hub containers produced by travis continuous integration\n",
            " mariadb configuration process for k8s\n",
            " high-level operations\n",
            " job scheduler\n",
            " jupyter deployment tool\n",
            " : make the zoom give more feedback and other optimizations\n",
            " fringe correction in isr\n",
            " memory usage of one multibanddriver jo\n",
            " that coadd code is \n",
            " for variation in uncertainty in shear recovery\n",
            " configuration\n",
            " position based search on catalogs/tables without position information\n",
            " stubbed out verify_ap\n",
            " configuration\n",
            " getting obs_decam isr working with cbp data\n",
            " calib production and isr with obs_comcam\n",
            " high-level butler design (j)\n",
            " high-level butler design (p)\n",
            " environment\n",
            " column expression to work for all plot\n",
            " afw basecatalog reader & writer as functions that can be  butler.\n",
            " metadata to {{get}} and {{put}} src\n",
            " with and understand the adaptive shape measurement algorithm\n",
            " system for publishing templates of package documentation\n",
            " initial diaobject summary statistics for ap_verify\n",
            " openstack install of kubernetes 1.8.x\n",
            " on kubernetes\n",
            " python api doc (firefly_client) and jsdoc to lsst.io\n",
            " simple distortions in matchpessimisticb\n",
            " the nom.tam.fits java package in firefly\n",
            " camera geometry to use the replacement for xytransform\n",
            " robust coaddition\n",
            " to supertask design documents\n",
            " to identify factors affecting loading (butler/afw) performance in imgsev\n",
            "  recipe that can be executed easily in jupyter notebook\n",
            " mysql connections from worker\n",
            " mysql connections from czar\n",
            " restful interfaces for database (post)\n",
            " up alert producers\n",
            " dialog\n",
            " debugging plots to comarewarpassembletask\n",
            " /ivoa conference meeting in santiago de chile 2017\n",
            " butler wg homework\n",
            " openshift\n",
            " intra & extra focus images to predict optical psf of in-focus images\n",
            " integration test coverage for async queries\n",
            " and configure kubernetes\n",
            " support to fgcm for combining filters\n",
            " the purpose of miscellaneous synpipe scripts\n",
            " katello\n",
            " one plot from huang et al fig 10\n",
            " & present  on the nmf deblender\n",
            " tech note describing dcr algorithm and results\n",
            " how to integrate metrics into tasks\n",
            " 14 pipelines.lsst.io installation guide update\n",
            " butler redesign concepts (p)\n",
            " common schema for butler redesign (p)\n",
            " butler redesign concepts (j)\n",
            " listeners into ocs bridge for visit sequence events.\n",
            " to nebula openstack failure just previous to pathfinder activity\n",
            " prototype bokeh qa system with hsc data\n",
            " up alert distribution tests\n",
            " prototype pipeline script into verify_ap framework\n",
            " prototype pipeline script\n",
            " sqrbot project create command / uservice-ccutter asynchronous with celery\n",
            " and improve dmtn-020\n",
            " drp & cpp plan based on feedback from stakeholders\n",
            " tech note describing detailed project management procedures\n",
            " drp slide deck for lsst director's review\"\n",
            " associationtask for ap_verify\n",
            " better set of simulated data for the deblender\n",
            " matrix of use types and organization\n",
            " db implementation\n",
            " improved jointcal photometric fit\n",
            " pipe_analysis to python 3\n",
            " ability for dax_imgserv to handle multiple repositories and releases.\n",
            " state schema design\n",
            " worker requests\n",
            " master/worker comms improvements\n",
            " master requests\n",
            " framework (master and workers)\n",
            " and choose toolkits to be used for replication framework\n",
            " pakrat\n",
            " configuration\n",
            " requirements for butler wg\n",
            " working group (sep)\n",
            " support for executing async queries through czar\n",
            " support for async query results\n",
            " czar to interact with query metadata\n",
            " selected svn revisions of desdm packages to git repositories\n",
            " accessing slurm accountnig information\n",
            " plot.ly plotting api to handle unrecognized chart types cleanly\n",
            " plotting api and related dispatcher\n",
            " planning document\n",
            " estimates\n",
            " mask plane size to 32 bits\n",
            " jim's lastest supertask design\"\n",
            " \n",
            " configuration\n",
            " final backup of /home\n",
            " information classification policy\n",
            " metric collection\n",
            " data storage component\n",
            " globus transfer tasks\n",
            " plans for shipping, travel, and deployment\n",
            " planning against milestones\n",
            " , start up, and authenticate to ncsa rucio main server\n",
            " distributor to simulator - v2\n",
            " the installation and administrative processes\n",
            " vetting\n",
            " data management sub-project plan and risk table\n",
            " \n",
            " planning for lsst-db refresh\n",
            " /implement and test workflow for data transformation\n",
            " hardware list from requirements\n",
            " vms\n",
            " management for f16 (september)\n",
            " cluster, object store procurement\n",
            " - week ending 11/28/14\n",
            " and placement\n",
            " itsm process for change management\n",
            " catalog dependency mapping\n",
            " out openstack networking (vlan, routing, etc)\n",
            " dmcs and replicator interaction for simulator - v1\n",
            " with deployment effort\n",
            " by stakeholders\n",
            " cluster monitoring\n",
            " monitoring\n",
            " & populate the ea model for known services\n",
            " & authorization conops iteration 3: larger review to produce second draft\n",
            " planning - december: contributions to commissioning plan document\n",
            " -worker issues\n",
            " final quotes & submit for project approval\n",
            " planning - january\n",
            " management for f16 (november)\n",
            " supporting services\n",
            " - week ending 11/21/14\n",
            " of scientific datasets\n",
            " upgrade\n",
            " service architecture with relationship mapping\n",
            " and set up equipment\n",
            " 's mgmt. activities in june\"\n",
            " engineering, chilean itc tiger team, use case traceability (october)\n",
            " webdav with kerberos/ldap on lsst-auth1\n",
            " data backbone scenario: netapp storagegrid webscale\n",
            " - week ending 10/24/14\n",
            " successful restoration of fileset backup\n",
            " framework for reporting and steering meetings\n",
            " vetting\n",
            " - week ending 12/12/14\n",
            " - week ending 10/31/14\n",
            " non-curated data to move to gpfs\n",
            " base dmcs archiver command receiver\n",
            " computation and production of voevents for worker batch jo\n",
            " data backbone scenario: ceph\n",
            " recovery implementation\n",
            " planning for development resources capacity increase\n",
            " service management tool evaluation\n",
            " capabilities and gaps for qserv\n",
            " network needs and procure hardware\n",
            " and processes for shipping hardware to chile\n",
            " and test slurm scripts for htcondor support on verification cluster\n",
            " product pricing\n",
            " - week ending 12/5/14\n",
            " by stakeholders\n",
            " list of concerns for consideration in batch production service design and submit to steering group\n",
            " web services to move\n",
            " new nfs servers\n",
            " environment: procurement\n",
            " value can churn too quickly.\n",
            " vetting\n",
            " vm cluster for elastic services investigation\n",
            " pass through all services possessing concepts of operations to identify main components\n",
            " general acceptable use policy\n",
            " pmo sub-project plan and risk table\n",
            " nebula service items for x16\n",
            " - week ending 11/14/14\n",
            " visualization component\n",
            " refinement and improvement.\n",
            " data backbone scenario: ddn wos\n",
            " /propose storage policies\n",
            " integration\n",
            " replicator\n",
            " project-valued scientific datasets for migration\n",
            " itsm process for incident response\n",
            " alert policies and authorization mappings\n",
            " - week ending 11/07/14\n",
            " distributor\n",
            " htcondor central manager and worker pods to kubernetes\n",
            " draft(s) of the data backbone conops\n",
            " - week ending 12/19/14\n",
            " policy\n",
            " sections for operations use case report\n",
            " 1 base messaging topology.\n",
            " limited test system\n",
            " use of graylog (log monitoring tool)\n",
            " \n",
            " for replan wbs (bcr #1)\n",
            " base dmcs efd replicator command receiver\n",
            " configuration\n",
            " of work\n",
            " monitoring infrastructure with puppet\n",
            " scale efficiency with offered services\n",
            " relevant specification (and their updates) and system engineering documents\n",
            " base dmcs communications library\n",
            " instance and snapshot on nebula for htcondor worker with v11_0 lsst stack\n",
            " \n",
            " setup and knowledge transfer\n",
            " of in-memory database packages used in time critical applications\n",
            " and cost planning packages for pmcs\n",
            " physical systems\n",
            " monitoring conops iteration 2: larger review to produce second draft\n",
            " full set of schemas\n",
            " open stack needs/requirements from dm team\n",
            " development resources capacity increase plans\n",
            " improvements to qserv\n",
            " new nfs servers\n",
            " marshaling code to use json\n",
            " recovery for /home partition\n",
            " non-labor costs to milestones\n",
            " existing tools and packages\n",
            " catalog refinement\n",
            " planning workshop\n",
            " and placement\n",
            " cyber summit talk\n",
            " ceph file system\n",
            " planning - january\n",
            " requirements from commissioning workshop\n",
            " mirantis openstack & fuel\n",
            " gather/scatter mechanism for tasks with generic api\n",
            " monitoring and display modules\n",
            " wbs planning\n",
            " scada security plan\n",
            " file transfer in dr tool\n",
            " and test kubernetes yaml files for htcondor\n",
            " alternative formats\n",
            " and placement\n",
            " base dmcs alert production cluster command receiver\n",
            " additional services into the service catalog\n",
            " validation\n",
            " 's mgmt. activities in march\"\n",
            " diagram for jobs in progress\n",
            " command/event sender\n",
            " and refinement of database needs\n",
            " concerns with source side (t&s)\n",
            " and kpi\n",
            " operations and monitoring\n",
            " requirements\n",
            " recovery for /software partition\n",
            " gathering of requirements for file portion of data backbone\n",
            " -wide replanning - february\n",
            " incident response policy\n",
            " sla templates\n",
            " \n",
            " one htcondor classads scenario running\n",
            " feb tasks\n",
            " \n",
            " ubuntu openstack\n",
            " -order reconciliation of internal service architecture with high-level services\n",
            " performance issues for qserv developers\n",
            " information security plan into service catalog\n",
            " design\n",
            " worker fault tolerance of missing distributor data\n",
            " base dmcs catch-up archiver command receiver\n",
            " by stakeholders\n",
            " and implement data retention and access policy\n",
            " of work\n",
            " epo sub-project plan and risk table\n",
            " and extend monitoring\n",
            " attend jtm 2016 sessions\n",
            " planning for full daq test system - benchmark hardware candidates.\n",
            " dashboard for each authorization mapping\n",
            " - week ending 2/27/15\n",
            " archive controller\n",
            " file system loading tools for file system studies.\n",
            " and test htcondor docker containers\n",
            " the current obs_decam package\n",
            " hsin-fang run ci_hsc-based tests with desdm framework\n",
            " and implement prototype for science cluster needs\n",
            " the pegasus-workflow-generating script to consider multiple patches\n",
            " ccs-daq-ocs-dm workshop iv\n",
            " 1 system evaluation for each job and the appropriate telemetry response\n",
            " , feb 2016\n",
            " to the current document\n",
            " api for reading simulated camera data\n",
            " \n",
            " jupyter and js9 for fits visualization\n",
            " decam camera geometry descriptions for raw data\n",
            " ctrl_stats to support pegasus output\n",
            " wrapper generating daxs for sequential workflows\n",
            " jupyterhub behind https and with gpfs\n",
            " new header templates with camera stand definitions for e2v and itl sensors\n",
            " executor to work with hsc data repository\n",
            " \n",
            " workflow for openstack via python scripts\n",
            " the design in format needed for planning\n",
            " orchestration user guide from confluence\n",
            " structure implementation\n",
            " for december\n",
            " - week ending 1/9/15\n",
            " for alert processing device code\n",
            " towg/opeartions design work\n",
            " set of improvements to prototype\n",
            " of templating to ocs bridge.\n",
            " lsst group at university of washington\n",
            " initial set of key-values pair for lsst exposures\n",
            " site and summit rfp\n",
            " support for parsing user log files\n",
            " planning - december\n",
            " for ocs bridge\n",
            " - week ending 3/13/15\n",
            " generic dax generator\n",
            " large worfklows\n",
            " workshop attendance\n",
            " pegasus' planner performance\"\n",
            " meeting\n",
            " redesign\n",
            " , restatement of dm facilites and functions\n",
            " filesystem volume for persistence\n",
            " drp team, june 2016\n",
            " meeting\n",
            " -to-end telemetry proto for metadata stream #2 resolution\n",
            " refinement #2\n",
            " workshop attendance\n",
            " system state snapshots\n",
            " physical and logical network diagrams for first phase of purchases\n",
            " 1-conops\n",
            " 1 design specification and planning - november\n",
            " dax generator to handle arbitrary workflows\n",
            " logging migration in afw\n",
            " workflows\n",
            " -pilot\n",
            " work to process raw decam data\n",
            " executor's data passing mechanism\"\n",
            " pegasus+stack to create simple workflow\n",
            " with failures\n",
            " meeting in santa cruz\n",
            " lsst.log by having log object and python interface\n",
            " _stats doesn't calculate year to next year progress properly\"\n",
            " draft design\n",
            " - aug 2015\n",
            " 1 service involvement for pcw\n",
            " ap team and work on processing decam data\n",
            " code change to run isr with decam raw data\n",
            " feb tasks\n",
            " pegasus workflow to do hsc  processing\n",
            " telescope and site sub-project plan and risk table\n",
            " message types between ocs bridge and dmcs\n",
            " of ctrl_orca to python 3\n",
            " kubernetes on vm cluster\n",
            " module for dmcs\n",
            " pegasus+stack to make processccd workflow\n",
            " elements of rfc\n",
            " and database setup for l1 test network\n",
            " \n",
            " representations of selected workflows in graph format\n",
            " equipment setup and configuration (week end 10/24/15)\n",
            " the middleware sync up meeting for the upcoming hsc data processing\n",
            " pegasus workflow based on ci_hsc and fall2016 interface\n",
            " installation workshop at ncsa\n",
            " coadd processing with decam data with default config\n",
            " support for importing graphs to the generic dax generator\n",
            " mar tasks\n",
            " - week ending 5/29/15\n",
            " wcs keywords need to be removed from the metadata of raw decam data\n",
            " prototype code and the wan emulator\n",
            " overview of existing pipeline components for workflow discussions\n",
            " jtm\n",
            " shifter+htcondor in processing stripe82 ref data at modest scale\n",
            " loe -- dec 2015\n",
            " changes from events code review\n",
            " to message interaction\n",
            " until end july 215\n",
            " system replication evaluation\n",
            " and replace ctrl_events package dependencies from ctrl_orca\n",
            " end 10/24/15\n",
            " - week ending 3/6/15\n",
            " l1 system - design and wbs plan for construction\n",
            " framework prototype\n",
            " flaws and correct implementation details of xml messaging layer\n",
            " up summer work\n",
            " 3: larger review to produce second draft\n",
            " draft of implementation of l1 system mock\n",
            " executor to work with the new butler\n",
            " refinement for the l1 system\n",
            " -144 costing model update\n",
            " \n",
            " ocs bridge behavior\n",
            " class to mock telemetry stream with metaheader information\n",
            " heirarchical queuing to test image precedence\n",
            " workflow based on conops and review of workflow systems\n",
            " inside ncsa to connect procurement contract modification to ospra contract officet\n",
            " - week ending 5/1/15\n",
            " management\n",
            " ap simulator\n",
            " refinement\n",
            " what is missing to run isr with decam raw data and processccd\n",
            " swim lane diagram for workflow in batch production services\n",
            " astrometry warnings from processing raw decam data\n",
            " hsc rc dataset using stack version chosen for the full s17b reprocessing\n",
            " to ccin2p3 to establish realtionship\n",
            " equipment setup and configuration (week end 11/14/15)\n",
            " /attend dm lt meeting\n",
            " \n",
            " power requirements justification\n",
            " end 2/14/16\n",
            " refinement , in light of development #1\n",
            " sal/ocs python interface integrated with class that mocks telemetry\n",
            " apmock with ocs system\n",
            " tiny test on verification cluster\n",
            " lsst.log with pipeline tasks\n",
            " - week ending 2/13/15\n",
            " to mock file archive with calibrations and raw\n",
            " up condor pool using vms on nebula\n",
            " new worker machine registration\n",
            " lsst::log in pipe_base and pipe_tasks\n",
            " improvements\n",
            " health check code\n",
            " mature version of ocs bridge component - part 1: planning and initial development\n",
            " planning - december: assess reviewers feedback, consider descope options\n",
            " model discovery\n",
            " existing implementation of supertask\n",
            " hsc rc dataset using stack w_2017_w14\n",
            " log messages from different processes\n",
            " tiny set of raw decam stripe 82 data\n",
            " ldm-240\n",
            " - week ending 2/20/15\n",
            " for november\n",
            " run coadddriver and multibanddriver with decam data\n",
            " equipment setup (week end 10/10/15)\n",
            " cat dependency in ctrl_stats\n",
            " validation test for daxgen and executor\n",
            " - week ending 1/23/15\n",
            " planning for archiving\n",
            " - week ending 2/6/15\n",
            " workflow features\n",
            " fix and improvement for decam processing\n",
            " simple pegasus workflow to do processccd with hsc data\n",
            " sal/dss software suite\n",
            " basic afw\n",
            " mechanism doesn't work when logging process is disabled.\"\n",
            " about design principles and usage of data processing tasks.\n",
            " service bus to l1 dm components\n",
            " revised wbs\n",
            " 's mgmt. activities in december\"\n",
            " first implementation to write itl/e2v-like headers for the camera.\n",
            " of requirements for swim lane diagram\n",
            " - week ending 5/8/15\n",
            " draft on the data product sizing\n",
            " framework documentation and refactorization\n",
            " openstack learning\n",
            " of dirac\n",
            " mature version of ocs bridge component - part 2: test sal installation\n",
            " first three phases of batch production services deployment\n",
            " interface to emulate ocs\n",
            " and calibration of tiny set of decam raw data\n",
            " /propose storage procedures\n",
            " pegasus and executor to run processccd\n",
            " and process some public decam cosmos data on verification cluster\n",
            " \n",
            " , moves, change support for dns, network, ip addressing, etc\n",
            " up cluster with kubernetes\n",
            " \n",
            " to support design activities.\n",
            " only read fringe data after checking the filter\n",
            " phase 1 implementation\n",
            " camera sub-project plan and risk table\n",
            " end 09/19/15\n",
            " 1 concept of operations (december work)\n",
            " discussions with dm project engineer about files in lsst\n",
            " dec 2015\n",
            " input/output requirements of process_ccd to facilitate making supertask data-aware\n",
            " up src code\n",
            " equipment setup and regular maintenance (week end 10/17/15)\n",
            " class to mock telemetry stream with random key value pairs\n",
            " an rfc about logging migration\n",
            " selected tasks\n",
            " mock using butler and decam data for diffimage\n",
            " processing proof of concept using desdm framework\n",
            " tests with squash-deployment\n",
            " moving target wcs target match\n",
            " showing the active chart traces\n",
            " image search framework for allow for multiple master image sources\n",
            " support to local deployment with minikube\n",
            " pandoc in metadata extraction pipeline from tex documents for lander & metasrc\n",
            " benchmark test for alert distribution prototype\n",
            " common schema for butler redesign (j)\n",
            " jointcal.py to allow visit id to be calculated using an camera override.\n",
            " detailed content required for authorization and authentication system for suit\n",
            " metadata access to get wcs, visitinfo, and calib from calexp dataset\n",
            " of a&l decorrelation and zogy\n",
            " src; append to src table (or write new one). no metadata.\n",
            " persistence of diaobjects and diasources\n",
            " catalog handling in the backend of the qa dashboard work, in order to enable big data\n",
            " task config defaults sensible for all cameras\n",
            " in al decorrelation and zogy\n",
            " an s3 storageinterface class\n",
            " visualizer porting: support artifacts\n",
            " jupyterlab environment at ncsa\n",
            " running time metric(s)\n",
            " robust coaddition using psf-matched warps for artifact removal\n",
            " donut model in zemax\n",
            " proxy timeout handling and diagnostics\n",
            " tests of squash-db, squash-api, squash-bokeh, squash-dash\n",
            " src (without put), from an ingested src database table. no metadata.\n",
            " supertask-driven data repo design sketch to camera-specific data units\n",
            " use cases for butler wg\n",
            " sphgeom with pybind11 instead of swig\n",
            " with the team at uw\n",
            " in september 2017 lsst joint status review\n",
            " visualizer: support image and drawing layer subgrouping\n",
            " jointcal requirements document\n",
            " sconsutils to use pytest for test execution\n",
            " simple diaobject to diasource matching algorithm and flesh out diacollection\n",
            " database options to support table display functions\n",
            " and implement crosstalk in isr\n",
            " with 'holoviews' plotting package, and use to recreate qa prototype\"\n",
            " math for new photometry model in jointcal.tex\n",
            " mvp for edition and build static dashboards in ltd dasher\n",
            " cancellation code for failed worker or network connection.\n",
            " the squash-bokeh microservice\n",
            " removal of invalid rows more efficient.\n",
            " junit test reporting to jenkins stack-os-matrix jo\n",
            " alert_stream monitoring tool\n",
            " prototype bokeh server implementation to demonstrate desired interactive qa plots\n",
            " qserv to python3\n",
            " -varying zogy option\n",
            " the squash-api microservice\n",
            " command line interface (cli) for imgserv\n",
            " unit tests 1 (expanded to cover all existing cases, in cli mode as integration tests)\n",
            " translation updates\n",
            " pandas to_sql and read_sql, using sqlalchemy, to afw.table\n",
            " assigned sections for science platform design document ldm-542\n",
            " the portal aspect requirement for science platform\n",
            " the suit requirements in magicdraw\n",
            " layout: access plotly support and make another demo\n",
            " retrieval for qserv disconnected queries\n",
            " series data display bugs\n",
            " an outline for firefly testing procedure document\n",
            " the firefly_client python bind for the new blank slate viewer\n",
            " out diaobjectcollection api\n",
            " first experiment (excluding covariance)\n",
            " of obs_comcam\n",
            " reference catalog flux support to photometry fitter\n",
            " return for qserv disconnected queries\n",
            " fits reading/writing out of fgcm code to be stack compatible\n",
            " on glmm paper example\n",
            " at ts8 data using obs_comcam\n",
            " -work dmtn-023 as quick start tutorial\n",
            " coadded images displayed ignored cutout size\n",
            " and process quasar dcr data\n",
            " benefits of ssd and nvme storage technologies for qserv \n",
            " regression in hsc astrometric matching success rate between w_2017_17 and w_2017_25\n",
            " python 3 in scisql\n",
            " management for long running searches\n",
            " (density) plot in multi-trace chart\n",
            " measurement pixels from sourcerecord\n",
            " roodman decam optical psf fitting results\n",
            " strategy for dealing with butler proxies in pybind11\n",
            " ellipticity residuals in hsc rc dataset for s17b.\n",
            " current jupyterlab releases\n",
            " modelpsfmatchtask ablilty to match to all psf types\n",
            " verify_ap\n",
            " fgcm command line task to match stars\n",
            " transformboundedfield\n",
            " /revive cmodel model data residuals display\n",
            " afw table to support variable-length string data\n",
            " designs at supertask hack week\n",
            " draft test plan for l2 drp\n",
            " missing features of command line supertask activator\n",
            " and self-publishing api documentation for imgserv\n",
            " rows from cancelled jobs from the result table\n",
            " source detection and astrometry  in obs_ctio0m9\n",
            " the performance of multi-trace chart updates\n",
            " the results from validation runs\n",
            " one-stop save-shutdown-logout command for jupyterla\n",
            " fake sources on coadds\n",
            " for plotting scatter and lines in multi-trace charts\n",
            " user login page for pdac\n",
            " distortion model to donut fitting code\n",
            " dataset for matcher validation\n",
            " landing page generator for pdf documents on lsst the docs.\n",
            " validate_drp design\n",
            " prototype of the command line framework\n",
            " jobid and retry number to result tables.\n",
            " in multi-trace chart\n",
            " 3 milestones flowdown\n",
            " and display sdss and wise time series data from the object search result\n",
            " some docker files to firefly repository / remove ups and tomcat dirs\n",
            " current and future psf modeling tools\n",
            " microservice\n",
            " for f17 cycle\n",
            " donut fit visualization scripts\n",
            " familiar with auxtel pipeline prototype\n",
            " of cosmics and hot pixels in spectrum footprint\n",
            " afw::math::statistics\n",
            " hsc rc dataset using  lsst stack\n",
            " memory management in jointcal\n",
            " instrument model in camerageom\n",
            " rotator information to hsc visitinfo\n",
            " hsc instrument model\n",
            " two drawing related issues with the new rotation scheme and check regions\n",
            " spanset components used by cmodel\n",
            " react (15.3=>15.5), upgrade other packages if necessary\n",
            " afterburners to clean up aperture correction logic\n",
            " the suit requirements\n",
            " with alert community at ivoa workshop\n",
            " responsive layout in squash\n",
            " ucd and data type item lists as defined by vo to json format.\n",
            " vo meeting in shanghai\n",
            " : document stripe82 loading details\n",
            " distribution and replication design time\n",
            " kubernetes at cc-in2p3\n",
            " study on k8s (kubernetes)\n",
            " hack-week may17\n",
            " repository relationships in butler\n",
            " meetings and discussions apr-may '17\"\n",
            " ivoa 2017 inter-op meeting shanghai\n",
            " for wise data search\n",
            " catalog search processor\n",
            " psf-matched ctes and coadds as independent data products in drp\n",
            " server side image code so that we cut memory size in half\n",
            " : patch  in stripe 82 catalog data\n",
            " css using json-packing, czar kazoo + c++ snapshotting phase 2\n",
            " distribution design v1\n",
            " qserv to c++ geometry primitives\n",
            " for qserv\n",
            " provenance design\n",
            " documentation\n",
            " partnership opportunities\n",
            " dependence of query analysis on parser and antlr\n",
            " qserv code to reworked db/dbpool\n",
            " keys are too fine-grain, consider merging them together (design)\n",
            " db and dbpool, separate connection from utilities\n",
            " qserv code to stream-based logging\n",
            " integration tests using docker+openstack\n",
            " term database work planning\n",
            " -2015 report\n",
            " provenance sizing\n",
            " qserv czar code to the new logging system\n",
            " ddl in metaserv - implementation\n",
            " documentation of code from dm-70\n",
            " alert framework for qserv\n",
            " and document user-facing aspects of async queries\n",
            " interfaces for data access services\n",
            " the log packaging\n",
            " optimizations of provenance querying\n",
            " qserv user guide\n",
            " interfaces for data access services\n",
            " worker-side squashing\n",
            " css using json-packing, czar kazoo + c++ snapshotting phase 1\n",
            " design for qserv front-end rearchitect\n",
            " gathering for metadata store\n",
            " how css exceptions are handled\n",
            " system for tracking existing images/files\n",
            " buffering for czar in row-based result handling\n",
            " and package logging prototype\n",
            " -tune data access interfaces\n",
            " worker scheduler \\xe2\\x80\\x93 code cleanup\n",
            " race condition when creating db (and elsewhere?) in client/qserv_admin_impl.py\n",
            " prototype of provenance\n",
            " new xrdssi interface\n",
            " support for listing (async) queries\n",
            " query metadata implementation\n",
            " abstraction in czar for unit tests\n",
            " \n",
            " loader\n",
            " support for installing qserv on machines without internet\n",
            " / simplify facade\n",
            " qserv authentication and authorization\n",
            " qservadmin.py use with cssaccess\n",
            " c++ geometry primitives for qserv\n",
            " : unit testing (query execution)\n",
            " the design of query metadata\n",
            " scale test planning\n",
            " cancellation-related worker code\n",
            " sqlite-based v01. unit tests for dbserv\n",
            " /qmeta interaction in czar\n",
            " & db docs (brian)\n",
            " & db docs (nate)\n",
            " image search\n",
            " test for query cancellation\n",
            " worker scheduler for shared scans\n",
            " & db docs (john)\n",
            " metaserv with schema browser\n",
            " qserv to fix dependencies between modules in qserv/core\n",
            " unit tests to exercise new scheduler\n",
            " image cutout service implementation\n",
            " support for images produced by pipelines in end-to-end integration test\n",
            " threading issues in css watcher\n",
            " data loader using worker mgmt service\n",
            " qserv modules (python code) to new logging system\n",
            " distributed database deletion\n",
            " mysql proxy alternatives\n",
            " query metadata skeleton\n",
            " & db docs (abh)\n",
            " kvinterface python and c++ interfaces\n",
            " qserv to ssi v2\n",
            " std::lists to std::vectors\n",
            " for supporting small non-partitioned tables\n",
            " store - experimental prototype v2 (datacat)\n",
            " support for async request cancellation to xrdssi\n",
            " shared scans design\n",
            " multi-node qserv\n",
            " memory leak in executive\n",
            " dev test environment\n",
            " existing configuration\n",
            " image stitching\n",
            " result sorting for integration tests\n",
            " data set for large scale tests\n",
            " supporting cutout from images with overlaps\n",
            " /reading for past prototype c++\n",
            " qserv configuration procedure\n",
            " software deployment on the qserv cluster\n",
            " fits header crawler and integrate it with the form\n",
            " interfaces for memory management for shared scans\n",
            " memory mgmt for shared scans\n",
            " support for registry-free repository\n",
            " multiple qserv installations on the same machine\n",
            " async queries in qserv\n",
            " support for type aliases\n",
            " support for ipac table format\n",
            " large scale tests\n",
            " large scale tests\n",
            " basic spatial lookups for the butler\n",
            " error handling for webserv\n",
            " configuration tool refactoring\n",
            " facade api\n",
            " multi-node tests to latest version of qserv / loader\n",
            " c++ api for c++ geometry\n",
            " qserv worker code to the new logging system\n",
            " feasibility of using sqlite as backend to the db module\n",
            " large scale tests\n",
            " off-the-shelf data distribution tools\n",
            " globally unique queryid\n",
            " butler v2 and transfer knowledge to nate\n",
            " scan implementation\n",
            " store - experimental prototype v1\n",
            " exchange between processes - implementation\n",
            " task queuing / runner code\n",
            " qserv code with cancellation-friendly xrdssi\n",
            " spatial image search for butler\n",
            " stitching multiple patches across tract boundaries in coadd v2\n",
            " to logging in xrootd\n",
            " ingest scripts cleanup\n",
            " mysql-based kvinterface\n",
            " czar to support table deletion\n",
            " how to support l3\n",
            " support for large results in xrdssirequest::getresponsedata\n",
            " side histogram for variable bin size\n",
            " supertask and activator interfaces\n",
            " for the python in astronomy talk\n",
            " plotly resize performance by masking and debasing redraws\n",
            " jupyterlab pod spawning work with jl >=0.20\n",
            " difference images from raw hits dataset\n",
            " wise image metadata to pdac\n",
            " needed for webgrid (coordinate grid overlay on image)\n",
            " spatially varying zogy\n",
            " kubespawner to start jupyterlab instances\n",
            " first draft of ldm-151 algorithmic components\n",
            " level of detail and style in ldm-151 algorithmic components\n",
            " of concept filtering system\n",
            " -engineer fgcm workflow\n",
            " client side coloring to mask overlays\n",
            " (august)\n",
            " obs package for 0.9m at ctio\n",
            " single interface to sanitized exposure metadata\n",
            " up and stackify matchpessimisticb code\n",
            " old butler _parent discovery including outputroot\n",
            " travisci flake8 linting using dm python guidelines\n",
            " query columns\n",
            " interface for new footprints class\n",
            " stack code to use new footprint api\n",
            " -line driver and placeholder implementation for psf estimation\n",
            " instrumental inputs to psf estimation\n",
            " for instrumental inputs to psf estimation\n",
            " requirements for psf estimation\n",
            " interface for full-visit psf estimation\n",
            " galaxy templates from existing models\n",
            " hierarchical ordering to deblender\n",
            " refactored deblender\n",
            " \n",
            " \n",
            " plotly.js as replacement to highcharts\n",
            " measurement class integration in lsst.verify framework\n",
            " translation operator\n",
            " cleanup on /qserv partition on in2p3 cluster\n",
            " calexps from raw hits dataset\n",
            " images for coadd based on psf quality.\n",
            " child repo access to parent registries\n",
            " filtering technologies\n",
            " concatenation of transforms\n",
            " fgcm fit parameter format\n",
            " tune ceph for few worker nodes\n",
            " -object search in pdac\n",
            " parallel processing in l1db prototype\n",
            " specifications access api for validate_metrics specs\n",
            " of the lsst workspace concept with jupyterhu\n",
            " hsc dataset to jenkins validate_drp jo\n",
            " bokeh apps helper methods to read data from the squash api\n",
            " jupyterlab container\n",
            " support of evaluation of plotly as replacement to highchartts\n",
            " initial jointcal metrics to validation_metrics\n",
            " psfs before psf-matching\n",
            " second round of robert's ldm-151 comments\"\n",
            " cpp section of ldm-151\n",
            " the content of the docs of two tasks to make them 'user-ready'\"\n",
            " out topic templates\n",
            " spatially varying decorrelation kernel in ip_diffim\n",
            " _decam calibration ingest uses fragile relative paths\n",
            " transforms to be explicitly simplified\n",
            " forced photometry server-side extension in pdac\n",
            " single frame spatial grid mapper processing task\n",
            " prototype warped image comparision\n",
            " matcher needs to load reference objects relative to max shift/rotation\n",
            " integrate interface to boundedfield/chebyshevboundedfield\n",
            " : how to implement spatially varying psf for spatially-varying zogy and al(decorrelated)\n",
            " validation metrics for nmf outputs\n",
            " 13.0 [fall 2016] release\n",
            " and test iterative solution\n",
            " python doc using sphinx\n",
            " option update (input dialog and server support)\n",
            " for irsa time series viewer release\n",
            " obs package for test stand 3\n",
            " psf convolution operator in 2d\n",
            " to plot asymmetric errors\n",
            " technote describing cosmic ray gain results\n",
            " modeling of the ctio observation\n",
            "3rd run at ctio .9-m telescope\n",
            " flaghandler c++ and flagdecorator.py to make flag identification robust\n",
            " jointcal to pybind11\n",
            " jsdoc how-to in https://developer.lsst.io/\n",
            " alert distribution tests\n",
            " monotonicity operator\n",
            " new eups_pkgroot(s) for osx/linux tarballs\n",
            " fixes required\n",
            " matcher prototype\n",
            " tests for single frame spatial grid mapper processing task\n",
            " the lsst tri-view launch the time series viewer with correct data\n",
            " associations::collectrefstars with loadreferenceobjectstask\n",
            "  in psf vs cmodel at bright magnitudes\n",
            " - time series viewer results (part 2, ui work)\n",
            " support for generic time series tables in the ts viewer\n",
            " the work packages\n",
            " metric definitions package\n",
            " initial multifit framework design sketch\n",
            " hsc test data for deblending\n",
            " the way the single exposure request is built from lc table to be generic\n",
            " afw swig to improve build times\n",
            " microservice logging to elk stack\n",
            " butler init to be more incremental when building repositories\n",
            " point2dlist\n",
            " sphpointlist\n",
            " pybind11 interface for point2dlist and relatives\n",
            " point2dlist to all points\n",
            " api issues\n",
            " hsc and lsst processing of rc dataset\n",
            " photometry and better assessments of diffim algorithms on simulations\n",
            " selection issue\n",
            " ltd dasher interaction into ltd keeper\n",
            " print/cout in jointcal with lsst::log\n",
            " support fixes and improvements to remote api\n",
            " mask overlays\n",
            " unit test for imagedata class\n",
            " test for image flip (flipxy)\n",
            " tests that depend on both image and table with pybind11\n",
            " afw::geom with pybind11\n",
            " afw::image with pybind11\n",
            " meas_algorithms with pybind11\n",
            " ctrl_events with pybind11 instead of swig\n",
            " afw::math with pybind11\n",
            " afw dependencies in pybind11\n",
            " ndarray with pybind11\n",
            " meas_astrom with pybind11\n",
            " testsourcetable with pybind11\n",
            " pipe_tasks with pybind11\n",
            " wrapping afw::table with pybind11\n",
            " how to run jointcal with separate astrometry and photometry reference catalogs\n",
            " to plot error bars on xy plot\n",
            " lsst full-stack processing configuration to match best practice from hsc\n",
            " junit test cases for ipac table reading\n",
            " -scargle step method input default values, valid ranges and labels need more work\n",
            " analysis script working for hsc/lsst stack comparisons\n",
            " hsc driver script to validate_drp\n",
            " load f16 part ii\n",
            " cmdlineactivator command line interface\n",
            " is not shown if active table set before table loads\n",
            " lc results area\n",
            " image expanded view so the it is more context specific\n",
            " kubernetes using openstack infrastructure\n",
            " and load 20% dr1 test dataset at in2p3\n",
            " monitor for firefly\n",
            " post-repository-creation hooks to cookiecutter services\n",
            " detail for for drp imchar/jointcal in ldm-151\n",
            " text to algorithmic components sections in ldm-151\n",
            " skeleton words to ldm-151 for ap\n",
            " plan for basic binary distribution\n",
            " unit test for geom class\n",
            " failures of stack code and new code.\n",
            " run on ctio .9-m, january 2017\n",
            " full set of hsc psf-matched temp exps for testing\n",
            " astshim so objects hold unique_ptr to the underlying ast object and are non-copyable\n",
            " in the squash api to upload metrics definition\n",
            " test for image pixel value histogram class\n",
            " test for zscale\n",
            " test for fitsread class\n",
            " ps1 3pi pv3 reference catalogs\n",
            " lsst file group processor for packaging\n",
            " related issues\n",
            " light-curve viewer prototype to display time dependent dataset and compute periodogram\n",
            " new footprints with pybind11 and create python unit test\n",
            " ability for dax_imgserv to retrieve images by ids.\n",
            " to identify red-sequence galaxies in the cores of clusters\n",
            " the deblender using simulations\n",
            " dm collaborative workflow document\n",
            " the psfextractor external library from hsc to lsst\n",
            " jointcal photometry test for cfht\n",
            " support for changing drawlayer symbol and size\n",
            " and add wcs target search to irsaviewer\n",
            " the ds9 interface to follow rfc-42\n",
            " meas_base with pybind11\n",
            " /ldm-240 support chages\n",
            " meas_mosaic working on hsc data with lsst stack\n",
            " of calibration and ingest system\n",
            " gaussian process interpolant to piff\n",
            " more support for fits table display\n",
            " lsstsim test for jointcal photometry\n",
            " 2d chart to client side phase folding dialog\n",
            " 35tb large test scale data in openstack\n",
            " new footprints based on api\n",
            " spansets class with pybind11\n",
            " pipeline test dataset and components to be linked together\n",
            " realistic psfs in simulated images for diffim testing suite\n",
            " out how to run photometric calibration\n",
            " ref config name configurable\n",
            " using nmf for deblender\n",
            " sample alert to include postage stamp\n",
            " basic download dialog based on selected rows.\n",
            " afw port to pybind11\n",
            " should restart jenkins master process\n",
            " validate_drp to validate_base framework\n",
            " bakeoff between the two algorithms in simplified case\n",
            " between algorithms extended to arbitrary rotation.\n",
            " to diffim testing suite\n",
            " validate_drp static plots in bokeh as proof-of-concept for squash\n",
            " prototype on astrometry failure modes\n",
            " v1 deployment\n",
            " jointcal plotting backend\n",
            " segfaults on el capitan compiler\n",
            " imgserv butler configuration\n",
            " afw::display with pybind11\n",
            " an image search processor to access the image from pdac\n",
            " afw::camerageom with pybind11\n",
            " design of resource api for supertask\n",
            " oauth2 authentication to url monitoring\n",
            " pybind11 wrapping tutorial\n",
            " familiar with photometric flat production mechanism with cbp data\n",
            " deblender performance\n",
            " for consistent removal of peaks in the deblender when running multiband.\n",
            " docs pages for all tasks\n",
            " accuracy of psf measurement in the stack\n",
            " dax_imgserve support for stripe82\n",
            " jointcal integration/validation test for decam\n",
            " panopticon to elk 5.0\n",
            " qserv dev container builds\n",
            " subscription system requirement gathering\n",
            " should transparently allow files to be compressed or not\n",
            " metadata system for lsst code and documentation repositories (technote)\n",
            " portability testing\n",
            " : handling server side errors\n",
            " how to rework xytransform guts with ast\n",
            " how to rework afw:wcs guts with ast\n",
            " sdss anti-shredding algorithm to deblender\n",
            " lsst search panel to work for both catalog and image search\n",
            " documentation for processccd\n",
            "  high availabilty features\n",
            " template generation speed improvements\n",
            " _base api refinement\n",
            " display_firefly to new firefly api, and to py3\n",
            " short-to-mid term scientific goals for deblender\n",
            " kolmogorov psf model to piff\n",
            "  at cc-in2p3\n",
            " jointcal integration/validation test for lsstsim\n",
            " requirement flowdown\n",
            " spanset intersection/difference functionality\n",
            " spanset core functionality\n",
            " weekly docker images\n",
            " error handling on external task failure\n",
            " background jobs and statuses beyond browser session.\n",
            " and revise the suit requirement document\n",
            " needs api to add policy to repository.\n",
            " temporary directory configuration in the container-based qserv deployments\n",
            " qserv deploy\n",
            " possibilty of cosmic ray muons (etc) for precision gain calibration\n",
            " sfm housing for psf approximation using ngmix code\n",
            " sphpoint\n",
            " sfm plugin for ngmix fitting\n",
            " use of boost in the stack and remove it where possible\n",
            " robustness tests of ngmix psf approx plugin\n",
            " ngmix psf plugin with cmodel\n",
            " third-party package builds for ngmix dependencies\n",
            " galaxy shear fitting results to cover ngmix\n",
            " , replace, or defer hsc-side provenance of eups products\n",
            " fall outside footprints\n",
            " improve the tan-sip wcs fitter\n",
            " input-only policy keyword support for butler composite datasets\n",
            " dis/assembler\n",
            " 12.0 [winter 2016 / extra 2016] release\n",
            " chart data and generalize actions\n",
            " automation to run conda-lsst.\n",
            " centos5 with gcc 5.2.0\n",
            " centos5 with alternative gcc versions\n",
            " - weakref caching\n",
            " photometrytask take refobjectloader\n",
            " work on firefly viewer layout control\n",
            " the phase folding algorithm to the client side\n",
            " catalog data in qserv using dax api\n",
            " manager for the light curve template\n",
            " up firefly server and posibly jenkins pdac\n",
            " missing rows in queries on the cluster\n",
            " weekly release tags\n",
            " work pack packages\n",
            " : query and display lsst image\n",
            " obs_base and make obs_test work with it\n",
            " from processccd refactor\n",
            " -board science collaborations onto community.lsst.org\n",
            " zogy algorithm in image-space (using convolution)\n",
            " adass xxvi and ivoa meeting\n",
            " search processor(s), set up to use lsst dax api\n",
            " unit tests for dcr template generation code\n",
            " covariance propagation in warping\n",
            " feasibility of pre-convolution with decorrelation for image differencing\n",
            " preconvolution + a&l + decorrelation in the stack\n",
            " diffim decorrelation when preconvolution is enabled\n",
            " lsst catalog search form and general any components from irsa catalog form\n",
            " up time for mandeep\n",
            " calexps into pdac\n",
            " quantitative measurements of diffim failure/success\n",
            " backend to improve visibility\n",
            " new search to get single exposure from lc table\n",
            " ui component to handle the period input and submit button\n",
            " pdac qserv deploy\n",
            " composite dataset work; use cases, requirements, and/or implementation work tbd.\n",
            " stripe82 coadds available in pdacv1\n",
            " drp planning packages\n",
            " image xyflip bug in dealing with fits in integer values\n",
            " multi image viewer support light curve type layout\n",
            " visualizer porting: expanded view : wcs match\n",
            " up the javascript test environment\n",
            " selector and psf determiner are selecting stars that are not valid point sources\n",
            " python 3 porting guide (sqr-014)\n",
            " straw-man plan for drp\n",
            " preconvolution implementation in ip_diffim\n",
            " with slac camera team for visualization discussion\n",
            " through kafka docs and tutorials\n",
            " up unit test for projection in java\n",
            " the new js convertion and projection routines against the java versions\n",
            " queries to different scheduler if too slow\n",
            " afw tests to support pytest\n",
            " image related issues found by irsa integration\n",
            " research on existing voevent-based systems\n",
            " new search that will produce new table called phase folded curve\n",
            " region serializer and data structures from gwt\n",
            " simple dcr correction to 2d\n",
            " rules for jsdoc\n",
            " docs for firefly python api\n",
            " jsdoc generation for the api portion of firefly\n",
            " python coding standard based on rfc-162\n",
            " results of pybind11 porting for discussion\n",
            " htm and q3c indexing to sphgeom\n",
            " how the diffim decorrelation correction works for the case of non-uniform psfs and noise\n",
            " dmtn describing lupton diffim decorrelation\n",
            " competing dcr algorithm\n",
            " documentation presentations for 2016 project & community workshop\n",
            " competing algorithm to arbitrary rotation angles.\n",
            " up notes comparing existing candidate technologies\n",
            " visualizer porting: mouse readout: part 3: lock by click & 3 color support\n",
            " revised slides for joint status review\n",
            " calibration zeropoint offset between hsc vs. lsst processccd.py runs\n",
            " python 3 migration at all hands meeting\n",
            " basictable and add client-side filtering.\n",
            " bokeh views entirely for dashboard\n",
            " visualizer porting: convert mask support\n",
            " performance of the decorrelation correction to a&l\n",
            " track to improve container infrastructure\n",
            " image related issues in firefly viewer\n",
            " docker swarm poc for qserv containers orchestration\n",
            " javascript api documentation to support camera team\n",
            " jointcal integration/validation test for cfht\n",
            " jointcal integration/validation test for hsc\n",
            " fftools api: table\n",
            " api related issues due to irsa integration.\n",
            " (july)\n",
            " jenkins to 2.x\n",
            " esxi on lsst-dm-mac.lsst.org\n",
            " example meas_base plugin in python\n",
            " bugs noticed in the api testing\n",
            " the impact of having spatially invariant decorrelation correction factor to a&l\n",
            " simple 1d dcr correction\n",
            " python 3 jenkins instance\n",
            " ability for workers to switch slow queries to the everything scan.\n",
            " dax containers\n",
            " slot and alias system\n",
            " script to simulate ap workflow\n",
            " and ensure variance plane compliance with diffim decorrelation\n",
            " improvements to butler config system\n",
            " tech note on modifications required to use py.test framework\n",
            " statistics about user queries and tasks running on chunks\n",
            " test of lmsimpleshape using high snr objects\n",
            " effects of turning on the brighter-fatter correction for single-frame processing of hsc data\n",
            " input based on catalog dd table\n",
            " together requirements to model refraction/dcr for given source\n",
            " codr preparation\n",
            " chart and other optimizations\n",
            " single frame processing astrometry failures/poor solutions on some hsc chip/visits.\n",
            " should support selecting columns from table\n",
            " measurement afterburners into new plugin system\n",
            " in2p3 student in using openstack and following lsst coding standards\n",
            " (june)\n",
            " sbag meeting\n",
            " spie conference\n",
            " simple 1d dcr correction on simulated data\n",
            " 1 db prototype (june)\n",
            " with xrootd for secondary index\n",
            " with light-weight sql databases for secondary index\n",
            " with bulk updates to secondary index\n",
            " with memcached for secondary index\n",
            " offset in baseline zeropoint between lsst vs. hsc stack reductions for some hsc visits\n",
            " worker configuration files.\n",
            " diffim decorrelation as task\n",
            " scheduler delays caused by mlock call in memman.\n",
            " editor\n",
            " search panel\n",
            " monocam reduction\n",
            " and test the new api\n",
            " overscan correction\n",
            " qa analysis script for lsst vs. hsc single visit processing comparison\n",
            " jointcal buildable under ci\n",
            " support for pybind11 to build system\n",
            " forced tasks into two tasks\n",
            " visualizer porting: marker tool\n",
            " api and rfc design\n",
            " handling of extremely large blends\n",
            " masking in coaddpsf\n",
            " distest package into obs_subaru\n",
            " proper functioning of hsc distortion correction within obs_subaru\n",
            " backport: multiband processing for coadds\n",
            " aperture-correction measurement code to the end of calibrate\n",
            " hsc improvements to colorterm\n",
            " hsc issues to hsc-jira.astro.princeton.edu\n",
            " aperture corrections in measurement tasks\n",
            " example-based documentation for multiband processing\n",
            " backport: convert peak to peakrecord\n",
            " hsc curve-of-growth code\n",
            " backport: allow for use of approximate model in background estimation\n",
            " qmeta::queryid and use global qserv::queryid\n",
            " the heap in scanscheduler with list.\n",
            " irsaviewer to react.js\n",
            " sbag prep meeting at uw\n",
            " planned implementation of toy model of lupton(zogy)\n",
            " planned implementation of lupton(zogy) algorithm in real space\n",
            " , coverage api, imagemetadata api\n",
            " mouse readout to use supports mousereadoutcntlr & add an api readout\n",
            " api interaction with regions\n",
            " lsst and hsc pipelines through through single-frame processing\n",
            " requirements and design for fall 2016 suit deployments\n",
            " and robustify shapelet psf approximations\n",
            " backport: countinputs and per object variance functions\n",
            " plugin errors\n",
            " hsc mpi driver for single-visit processing\n",
            " wcs object copying does not copy exactly\n",
            " for the lsst vs. hsc pipeline comparison through single-frame processing\n",
            " use of boost smart pointers throughout the science pipelines\n",
            " gwt projection and coorindate conversion routine to javascript\n",
            " design proposal document\n",
            " of current state-of-the-stack diffim implementation\n",
            " code to the czar to throttle incoming large results.\n",
            " job to execute validate_drp and push results to qa dashboard\n",
            " schema for metric data from validate_drp to be ingested by the qa dashboard app\n",
            " dcr metric using new dipole measurement\n",
            " packer automation for elk\n",
            " production database next steps (may)\n",
            " specs within vo stack which should be implemented by database team\n",
            " fftools api: xyplots and histgram\n",
            " dm stack, get familiar with the current dm task concept\n",
            " document describing flavors of coadds\n",
            " jenkins support for running builds in docker containers\n",
            " stretch algorithm corerction\n",
            " document describing drp parallelization use cases\n",
            " for qa information\n",
            " dashboard prototype design\n",
            " c++/python exception translation\n",
            " basic oauth2 authentication for qa-dashboard\n",
            " side hardcopy support for png with drawing layer overlay\n",
            " out the level 1 processing diagram\n",
            " copy support- saving regions\n",
            " new build based on the converted firefly code.\n",
            " viewer launching api\n",
            " fftools api: image viewer plus foundational work\n",
            " research on image subtraction algorithms\n",
            " discussions (andys, may)\n",
            " discussions (nate, may)\n",
            " discussions (john, may)\n",
            " discussions (fritz, may)\n",
            " result view architecture/component\n",
            " scipi wg meeting\n",
            " the first result set is returned, have the thread leave the pool.\n",
            " error handling to psffitter in meas::modelfit\n",
            " new dipolefittask into imagedifference command-line task alongside existing dipolemeasurementtask\n",
            " obs_monocam\n",
            " the worker thread pool to allow threads to leave the pool and continue.\n",
            " cloudbees-folder support to puppet-jenkins\n",
            " simple simulator\n",
            " api interactions for lsst the docs\n",
            " visualizer porting: region drawing\n",
            " wcs requirements document\n",
            " unit tests for new dipole measurement task\n",
            " way to pass more than one exposure to singleframemeasurement (dipolemeasurementtask)\n",
            " new dipole fitting algorithm as simplealgorithm\n",
            " production database next steps (april)\n",
            " lock plot button on toolbar\n",
            " discussions (nate, april)\n",
            " technical note describing galaxy shear fitting experiments\n",
            " dipolemeasurement: dipole classification to plugin\n",
            " visualizer porting: grid drawing\n",
            " starfast interface to processccd\n",
            " expression parsing library\n",
            "3 color and fits header clean up\n",
            " error and working feedback to fits visualizer\n",
            " shared scan implementation on in2p3 cluster\n",
            " discussions (john, april)\n",
            " discussions (fritz, april)\n",
            " discussions (andys, april)\n",
            " example c++ code with pybind11\n",
            " example c++ code with cython\n",
            " data set info converter, part2\n",
            " select panel: 3 color support\n",
            " visualizer porting: show fits header\n",
            " new model in ast/gwcs to represent complex distortion\n",
            " meas_simastrom stack package\n",
            " detailed l2 plan\n",
            " select panel: support add or modify of plot\n",
            " performance on firefly\n",
            " new image stretch algorithm to firefly visualization\n",
            " example code with cffi\n",
            " ltd-keeper as docker container\n",
            " performance of ast/gwcs over range of numbers of pixels\n",
            " data set info converter achitechture\n",
            " box widget\n",
            " .py is failing on some cfht band images\n",
            " dipole measurement (dipole fitting)\n",
            " high volume test script working again at in2p3 cluster\n",
            " select panel: finish tabs\n",
            " plot view of table (js) - density plot zoom support\n",
            " visualizer porting: catalog drawing\n",
            " memmanreal implementation per design discussion w/ john\n",
            " plot viewer (js) - density plot\n",
            " group updates\n",
            " multi image viewer\n",
            " astropy and lsst functionality\n",
            " up help system\n",
            " plot view of table (js) - toolbar\n",
            " (js): large table handling\n",
            " (js): filtering\n",
            " scatter plot options (js)\n",
            " visualizer porting: expanded view: grid\n",
            " plot view of table (js) - selection support\n",
            " to reverse the axis\n",
            " visualizer porting: north/east arrow\n",
            " supertask design to dmlt\n",
            " existing cmdlinetask instances' inputs and outputs\"\n",
            " catalog-comparison cmdlinetasks\n",
            " and monthly releases\n",
            " lsst.astrometry task in bulge survey processing\n",
            " hsc code for generation of calibration products\n",
            " support in butler for multiple repositories\n",
            " software to match up and combine data for sources in processed data repository\n",
            " image select panel/dialog\n",
            " exploration of the cbp/decam data\n",
            " error estimation with bootstrap resampling\n",
            " to confluence questions\n",
            " community.lsst.org (discourse) notifications to existing mailman lists\n",
            " evaluation (part 2)\n",
            " lsst and hsc pipelines through isr\n",
            " technote on the new technical note platform\n",
            " consistency of shear measurements with different psfs\n",
            " number/order of shapelet expansions needed to approximate psf\n",
            " conversion: table results container\n",
            " dc base dseign\n",
            " visualizer porting: statistics - part 2 - drawing overlay & 3 color support\n",
            " decomposition of stack build into independent packages\n",
            " -level overview of drp processing\n",
            " mvp of ltd-keeper web app covering ltd-mason interface\n",
            " memsql\n",
            " git repositories to stash\n",
            " -build updates based on feedback from 1st month of use\n",
            " co-add example in software user guide\n",
            " lsstsim processing example for sw user guide\n",
            " how to create an astrometry_net_data repository\n",
            " the content of the dm developer guide\n",
            " for butler support of multiple repositories\n",
            " github oauth integration for jenkins\n",
            " imageorigin = parent in all cases\n",
            " methods that return pixel iterators and locators in image-like classes, and change to use parent indexing\n",
            " code to always specify image origin (temporary)\n",
            " obs_decam for new camerageom\n",
            " shear bias errors from dm-1135\n",
            " tests of dm-1135 with larger number of galaxies\n",
            " logger use in qserv\n",
            " prototype supertask code to upstream repository\n",
            " visualizer porting: add canvas drawing infrastructure\n",
            "  nebula images & docker containers\n",
            " xml-rpc with in-process communication\n",
            " multinode test using docker on one unique host\n",
            " parameterized psfs from phosim\n",
            " the refactoring for processccd\n",
            " corrections for isr.\n",
            " task api\n",
            " scatter plot (js)\n",
            " websocket messaging into flux\n",
            " plot view of table (js)\n",
            " and document multinode integration tests on openstack+docker\n",
            " plot action and reducers\n",
            " : change configuration from .paf to something else\n",
            " tests of shapeletapprox\n",
            " orchestration environment at lsstdev for bulge survey processing\n",
            " firefly example for image visualization\n",
            " lsst stack for verification datasets work\n",
            " save dialog\n",
            " visualizer porting: create toolbar\n",
            " (js): selection feature.\n",
            " conversion: advance resizable layout panel\n",
            " table with histogram viewer\n",
            " visualizer porting: layer control popup\n",
            " view of table\n",
            " to the latest react-highcharts library\n",
            " next gen firefly javascript api tools\n",
            " javascript code into firefly repo and begin creating real input form\n",
            " deployable installation package for firefly\n",
            " lsst firefly standalone releases using jenkins\n",
            " javascript, read up on react\n",
            " developer workflow documentation\n",
            " input to calibratetask design work\n",
            " mouse interaction with the drawing infrastructure\n",
            " scope and requirements for calibratetask redesign\n",
            " predefined catalogs via data access api\n",
            " visualizer porting: zooming: group zooming, zoom fit, zoom fill, active plot selection\n",
            " visualizer porting: group, group scrolling\n",
            " banner and menu to react/flux\n",
            " actual conversion of parts of firefly to pure javascript\n",
            " options\n",
            " for shear bias fits\n",
            " : move configuration (.paf) file into repository\n",
            " developer code on in2p3 cluster in docker images\n",
            " statistics needed for cmodel studies\n",
            " side preparation for histogram plot (2)\n",
            " skeleton framework for firefly using redux and react.\n",
            " web authentication and authorization and gather usage stories\n",
            " react component which manages tabs\n",
            " eslint rules for javascript code quality control\n",
            " prototype: test fixture rework\n",
            " prototype: http server library refactor/cleanup\n",
            " -implement watcher based on new css implementation\n",
            " next-generation stack doc writing guide\n",
            " the firefly conversion from gwt to react/flux design meeting\n",
            " conversion from gwt to react/flux design meeting\n",
            " conversion from gwt to react/flux design meeting\n",
            " docker images on ccqserv124/149\n",
            " fits viewer scrolling to stop using large div\n",
            " code- and object-duplication in aperture correction and psf coaddition\n",
            " xssi api to send few bytes with the message informing the client that response is available on the server\n",
            " imagedifferencetask running again\n",
            " design of firefly core using react and flux framework\n",
            " _astrom bugs exposed by new eigen\n",
            " pastry dht implementation\n",
            " existing dht-based fs approaches\n",
            " qserv install procedure: step 1 build docker container for master/worker instance and development version\n",
            " side preparation for histogram plot (1)\n",
            "  clause to lua sql query on result table\n",
            " verification approach at ahm\n",
            " candidates for verification datasets and identify collaborators\n",
            " -ccs-daq-dm workshop iii, may 2015\n",
            " -dm-ccs-daq workshop\n",
            " -dm-ccs-daq workshop ii\n",
            " document for ccb review of lcr-357\n",
            " side plot display for histogram\n",
            " with jupyter widget technology and firefly tools\n",
            " new footprint api\n",
            " scipy 2015 conference\n",
            " external task launcher\n",
            " to the camera team development\n",
            " about ipython / jupyter internals\n",
            " sip fitting\n",
            " react component to use new flux environment\n",
            " simple firefly release for s15\n",
            " next gen firefly javascript api tools for beta\n",
            " with prospective dwdm vendors for chile national networks\n",
            " in-memory support of old-version afw::table objects\n",
            " demo system for camera team to use the firefly external task launcher\n",
            " analysis code for constant shear tests\n",
            " simple demo version to use firefly in ipython notebook\n",
            " bias vs. postage stamp size of galaxies\n",
            " hsc camera in new camera framework\n",
            " shear measurement driver for simulations\n",
            " integration test to multi-node setup v2\n",
            " with vendors in vina\n",
            " of fits binary table extension to ipac table format.\n",
            " command line tasks for pre-ingest transformation\n",
            " -processing capability for shear test measurements\n",
            " unit tests for lsst-build\n",
            " xyplot to python interface\n",
            " processors to get image, table, or json from an external task\n",
            " v10_1_rc3 release candidate\n",
            " apis for firefly\n",
            " data distribution/replication plan\n",
            " existing theory and prior art\n",
            " and testing for firefly javascript and python api\n",
            " communication between javascript component and java server\n",
            " of web socket for two-way communication between client and web server\n",
            " -implement data loading scripts based on new worker control service\n",
            " api for new worker management service\n",
            " into current transient alert event systems.\n",
            " in design discussion\n",
            " in design discussion\n",
            " in design discussion\n",
            " support for transmitting [var]binary column data\n",
            " simulation script with different constant psf per galaxy.\n",
            " strategy for adding and removing data\n",
            " faulty/consistent states and recovery process\n",
            " transport mechanism for data distribution\n",
            " of concept python apis to access firefly components\n",
            " psf simulations for shapelet approximation test\n",
            " websocket for communication between client and web server, proof of concept\n",
            " sui design discussions\n",
            " in design process\n",
            " in april design process\n",
            " external http api that can control firefly viewer\n",
            " the image stretch code for better, simplified organization\n",
            " data loading in worker manager service\n",
            " management service - impl\n",
            " to gwt 2.7\n",
            " components for form\n",
            " firefly for githu\n",
            " with camera & pipeline team to spec out proof of concept tools\n",
            " form framework in react\n",
            " simple build for firefly package\n",
            " transformations for  measurements\n",
            " integration test to multi-node setup v1\n",
            " primary calibration plugins\n",
            " v10_1 release candidate\n",
            " lsstswbuild.sh under jenkins on el6\n",
            " sdssshape\n",
            " lsstswbuild.sh in clean sandbox\n",
            " astrometrytask interface\n",
            " use of measurementdataflags\n",
            " auto build tool to work with new split repositories\n",
            " transition for dm\n",
            " sui requirement and summarize all the input from other team memebers\n",
            " validation of lsst pipeline on hsc data\n",
            " the api\n",
            " the workspace discussion and present good proposal\n",
            " : study other plot packages\n",
            " integration test case using data duplicator\n",
            " distributed table creation\n",
            " tool to generate camera from fits images\n",
            " unit test and validation classes to validate the fitsreader refactoring\n",
            " shapehsm wrappers to latest external version\n",
            " distributed database creation\n",
            " command interaction with firefly\n",
            " speed will detect and optimize for large datasets\n",
            " qserv database configuration/connectivity issues\n",
            " sdss catalog access\n",
            " drawing only active tab with new data model\n",
            " better coordinate grid overlay\n",
            " with the database group to define initial concepts for backend interface api\n",
            " javascript frameworks: general overview\n",
            " javascript frameworks: understand angular & react\n",
            " build process for firefly opensource\n",
            " popular web development technologies\n",
            " fftools viewer to have derived viewers / start lsst sui git repo\n",
            " library for accessing distributed database/table information from css\n",
            " multiband processing changes from hsc\n",
            " search processor to do cone/box search on qserv catalog\n",
            " -error utility class\n",
            " firefly repository\n",
            " and use catalog dd (data definition)\n",
            " an ir node tree should produce properly parenthesized output\n",
            " use of the tool with the camera team\n",
            " the lsst data products document and give summary to the team\n",
            " lse-130 impact of collimated projector calibration plan\n",
            " v10_0 release\n",
            " transition plan: write document for ccb\n",
            " out firefly package, build and run an applicaiton\n",
            " c++ algorithm classes\n",
            " queries for qserv database.\n",
            " friendly single node loading script\n",
            " data loading script to support multi-node setup\n",
            " install qserv and test db, enable access to catalogs for sui team members\n",
            " to stash\n",
            " work for firefly open source\n",
            " -based grow operations for footprint\n",
            " designed tests for processccd\n",
            " array fields for table version 1\n",
            " shapelet psf approximations\n",
            " _base plugins for cmodel magnitudes\n",
            " adding aliases to afw::table::schema\n",
            " derivatives-based optimizer to meas_multifit\n",
            " pipe_tasks, obs*, and other packages are compatible with meas_base\n",
            " obs_test\n",
            " use case\n",
            " test data headers with standards\n",
            " qserv_run_dir scripts able to detect qserv install paths using eups\n",
            " meas_algorithms unit tests for plugins\n",
            " prototypes for c++ algorithm api\n",
            " define local hardware needs to host the test db and application servers\n",
            " swig 3.x work with dm stack?\n",
            " scisql in eups\n",
            " test differences after css migration\n",
            " template quality as function of variable seeing\n",
            "1st draft of \n",
            " with the dark energy science collaboration\n",
            " and attend lsst@asia workshop\n",
            " and attend workshop\n",
            " task plan\n",
            " , schedule, and staff tasks\n",
            " on obs_subaru\n",
            " first version of defect finding task\n",
            " circle, range, polygon in imgserv soda\n",
            " insertfakeobjectstask to add fake sources for qa purposes.\n",
            " 19 received equipment\n",
            " the multi-cast alternate recommended by dm-17601\n",
            " jupyter extension to start firefly slate in ta\n",
            " the jupyter fits viewer mime extension to be full extension\n",
            " input vs. output mag offsets in first draft of tasks to insert fakes\n",
            " apache cassandra as ppdb back-end option\n",
            " up log aggregation for the kubernetes clusters\n",
            " , attend, & present soda status to next ivoa interop\n",
            " and produce dataset for ops rehearsal #1\n",
            " afw detection code to identify n-sigma candidate defects in auxtel and ts8 data\n",
            " of mpc pytrax\n",
            " lsst data rates for mpc\n",
            " jenkins agents to run on k8s@ncsa\n",
            " varying photometric zeropoints in hits processing\n",
            " alert_stream working on ncsa kubernetes machine\n",
            " dia -> alert converter\n",
            " feedback on dr backup software\n",
            " tests\n",
            " obscore support\n",
            " assessment of coadds created using jointcal calibrations\n",
            " autograd for derivatives in scarlet\n",
            " lsp review\n",
            " header translation infrastructure for butler gen 3\n",
            " and publish soda 1.0 in imgserv through vo service interface\n",
            " pos parameter of soda in imgserv\n",
            " , schedule, and scope activities\n",
            " oracle storage architecture to balance between storage arrays\n",
            " test plan for new storage: performance and burn-in\n",
            " initial activity plan\n",
            " ctrl_iip into dm standard repo\n",
            " 3 middleware support fy19a-2 march\n",
            " atmospec development work\n",
            " rest services for monitoring and managing the replication system\n",
            " adql and rewrite it as qserv\n",
            " query dispatch for multi-master support\n",
            " installation on aura property from gate to pachon\n",
            " traffic utilizing the fiber link at 10gbps\n",
            " lay between gate to tololo\n",
            " install from tololo to pachon\n",
            " 10gbs transceivers at the ends of the fibers and test\n",
            " initial planning input\n",
            " 3 middleware support fy19a-2 february\n",
            " basic kafka, kubernetes, docker to run ap simulator\n",
            " dm requirements for processing crowded fields\n",
            " serena - santiago fiber tests over 3t cable\n",
            " separate programs for master, worker, and client.\n",
            " samples and other many-to-one outputs in sourcerecord\n",
            " security and network configurations at base and summit\n",
            " future needs\n",
            " 3 middleware support fy19a-2 january\n",
            " jellybean\n",
            " design plan for l1 handoff system\n",
            " bf kernel measurement code fully stack compliant\n",
            " donut on decam data\n",
            " summary of sensor effects and strategies to mitigate\n",
            " and test customizable galaxy fitting workflow\n",
            " up cadc tap service to qserv\n",
            " draft of final plan\n",
            " gen3 work for december 2018\n",
            " secondary index builder in loader services\n",
            " mitigations for single points of failure\n",
            " prior for regularizing moments\n",
            " initial team planning meetings\n",
            " the jupyter widgets to start working using firefly_client\n",
            " module for mapping json to xml output at service endpoints\n",
            " replication service at pdac\n",
            " gen3 work for november 2018\n",
            " up with jupyter development\n",
            " uptime needs for oracle rac and identify single points of failure\n",
            " draft of batch processing requirements\n",
            " inotify interfaces\n",
            " hardware boots up\n",
            " configuration options\n",
            " testing framework\n",
            " qa_explorer visualization code to use the new parquettable datasets\n",
            " upload function\n",
            " gen3 work for october 2018\n",
            " investigations\n",
            " for slac bootcamp\n",
            " and preparation for october pm\n",
            " cp_pipe\n",
            " realism of cbp toy modelling of photometric flat production\n",
            " remaining unit test queries to execute using antlr4 parser\n",
            " on reading votable in firefly\n",
            " debt addressed in september\n",
            " is not valid cmdlinetask\n",
            " planning meetings\n",
            " multiband classes\n",
            " directive for auto-documenting task configuration\n",
            " lupton (2004) algorithm for rgb composites\n",
            " dax containers built off of stack containers\n",
            " integration of spectrograph image creation components\n",
            " debt addressed in july\n",
            " debt addressed in august\n",
            " preparation and planning for ffy19 contract continued\n",
            "  in the stack software\n",
            " performance test on ncsa oracle instances\n",
            " assisting kpm30 tests\n",
            " moc overlay\n",
            " work for ffy19 acquisition plan\n",
            " fixme queries\n",
            " support for kubernetes cluster (june)\n",
            " the headerservice configurable\n",
            " antlr4 integration test query parity\n",
            " facility planning and high-level engineering for june\n",
            " and write analysis and use case document\n",
            " oradb nodes\n",
            " support for kubernetes cluster (may)\n",
            " safe coadd clipping from hsc\n",
            " should return the metadata for wise tables\n",
            " data backbone services requirements from lse-61\n",
            " -to-end testing of the science-pipelines release process\n",
            " qa-related work in s18\n",
            " wise catalog data in pdac\n",
            " facility planning and high-level engineering for may\n",
            " generation of osx/linux tarball packages\n",
            " all use of coord and subclasses with spherepoint\n",
            " cluster exploration/configuration\n",
            " function to capture camera geometry event parameters and understanding camera geometry\n",
            " optics wavefront jupyter explorations into python module.\n",
            " possibilities for modeling field-of-view dependence of optical psf wavefront\n",
            " dax metaserv to properly handle multiple databases in pdac\n",
            " facility planning and high-level engineering for april\n",
            " the python sal classes and tools created as part of the headerservice.\n",
            " , set up, execute, and write up precursor tests\n",
            " ltd keeper patch /builds/<id> asynchronous\n",
            " at noao existing base site in chile\n",
            " , discussions, and feedback (march 2018)\n",
            " planning and high-level engineering for march\n",
            " jointcal's astrometry output\"\n",
            " initial testing & debugging of python 3 desdm packages (march)\n",
            " third-party copy alternatives\n",
            " initial testing & debugging of python 3 desdm packages (february)\n",
            " foreman\n",
            " management fy18a work for march\n",
            " management fy18a work for february\n",
            " management fy18a work for january\n",
            " planning and high-level engineering for february\n",
            " all hands meeting in march, 2018\n",
            " chris and robert happy.\n",
            " * from object on pdac swamps czar before tripping 5g result limit\n",
            " planning and high-level engineering for january\n",
            " kubernetes 1.9.x install\n",
            " use of daq api subscribe function.\n",
            " messaging to daq support code.\n",
            " out image re-assembly section of daq support code.\n",
            " initial testing & debugging of python 3 desdm packages (january)\n",
            " and load 30% dr1 test dataset at in2p3\n",
            " middleware design/hack week\n",
            " integration activity #4\n",
            " planning & management - december 2017\n",
            " vm install of kubernetes 1.8.3\n",
            " skywcs\n",
            " planning & management - october '17\"\n",
            " tech note\n",
            " butler wg requirements into magicdraw ldm-556\n",
            " lsp workshop\n",
            " planning & management - november '17\"\n",
            " jenkins jobs to devtoolset-6\n",
            " the headerservice sal compliant by adding power up/down commands\n",
            " complexity of coadds used for shear measurement\n",
            " hips viewing in firefly\n",
            " command line task for nmf deblender\n",
            " for accessing user workspace\n",
            " support for july review\n",
            " and present design review\n",
            " meeting and subsequent design mods\n",
            " embedded db in table data support\n",
            " resource loaded plan for executing drp sections of ldm-151\n",
            " -trace charts in tri-view concept\n",
            " and prototype api v1 for imageserv (including cutouts)\n",
            " new unit tests for principle components\n",
            " - september\n",
            " query cancellation\n",
            " out fetch section of forwarder component\n",
            " header client design\n",
            " iam recommendations\n",
            " to magicdraw transition\n",
            " concerns with source side (t&s) and etl side\n",
            " first of the nfs servers\n",
            " acceptance\n",
            " planning review and response\n",
            " ldm-144 and ldm-143\n",
            " activities - june\n",
            " -wide replanning - december: further development of ncsa wbs\n",
            " validation\n",
            " to racking\n",
            " site additions to simulator\n",
            " , prototype, and plan distribution and administration in the data backbone\n",
            " design\n",
            " full daq test system plan\n",
            " roadmap of milestones\n",
            " \n",
            " dax web app with kerberos authentication in iam test vm\n",
            " activities - august\n",
            " planning and prep for november review\n",
            " configuration\n",
            " out openstack integration with ldap\n",
            " round of requirements mapped to vendor products\n",
            " current work with past work packages\n",
            " final evaluation report\n",
            " issue investigation for the nebula openstack\n",
            " by stakeholders\n",
            " \n",
            " activities - april\n",
            " 's mgmt. activities in july\"\n",
            " activities - may\n",
            " delivery to racking\n",
            " dm message appender class\n",
            " deployment preparation\n",
            " activities - july\n",
            " planning - february\n",
            " \n",
            "- wbs for batch production, all level 1, data backbone, network-based it security, and aa service software\n",
            " environment: top level design\n",
            " deployment\n",
            " -wide replanning - january\n",
            " drawings, specification writing, and info gathering\n",
            " openstack systems\n",
            " planning with chuck and mario\n",
            " \n",
            " recovery implementation\n",
            " recovery implementation\n",
            " spare test hardware for openstack testing\n",
            " cleanup of events package\n",
            " \n",
            " small openshift test bed\n",
            " validation\n",
            " new nfs servers\n",
            " activities - march\n",
            " one to influx db work\n",
            " of portable system\n",
            " bridge messaging publisher and consumer for dm side of the wall\n",
            " htcondor week\n",
            " l1 system work for november\n",
            " install of ocs software on centos vms\n",
            " butler access to calibration data in obs_decam\n",
            " 's mgmt. activities in may\"\n",
            " 's mgmt. activities in november\"\n",
            " l1 system work for october\n",
            " pilot condor jobs\n",
            " pegasus plugin for orca\n",
            " 1 messaging path status\n",
            " messaging components and glossary.\n",
            " puppet with base configuration manifests\n",
            " file corruption in irods 3.3.1\n",
            " audit capability to prompt processing\n",
            " planning for integrating separate streams for file header metadata\n",
            " archiving system in prep for this integration activity\n",
            " threads in archive dmcs\n",
            " 's mgmt. activities in april\"\n",
            " ctrl_platform_nebula package to exercise ctrl_orca orchestration on nebula\n",
            " planning\n",
            " ocs hierarchy\n",
            " management\n",
            " tasks\n",
            " - week ending 4/24/15\n",
            " and participation in daq workshop\n",
            " the processccd dag from the workflow management system\n",
            " support for slurm to allocatenodes.py\n",
            " mechanism and services for gathering metadata header information for lsst images\n",
            " ceph deployment\n",
            " - week ending 3/20/15\n",
            " - week ending 4/3/15\n",
            " learning middleware\n",
            " c++ for ocs bridge to dmcs subscribe as well as publish\n",
            " - week ending 4/17/15\n",
            " processccd pipeline at the level of executor and beyond\n",
            " ocs bridge refactor\n",
            " - week ending 3/27/15\n",
            " component refactors\n",
            " work for conops\n",
            " new test cluster with scripts and public keys, etc.\n",
            " 1 entity prototypes\n",
            " publisher\n",
            " command and event listeners that integrate with level one messaging topology\n",
            " 1 system functions and responsibilities\n",
            " python threading into while loops for checking messages\n",
            " 17b \\xc2\\xa0full hsc reprocessing with the ssp pdr1 data\n",
            " \n",
            " 's mgmt. activities in august\"\n",
            " 1 test network\n",
            " launch of htcondor pool on nebula openstack\n",
            " - week ending 4/10/15\n",
            " update for prompt processing with multiple devices\n",
            " cilogon authenticator for jl\n",
            " mvp for edition and build static dashboards in ltd dasher\n",
            " sphinx docs for pipe_base\n",
            " into issues with large results on czar.\n",
            " general dax functions to support implementation of vo api interfaces\n",
            " sha256 hashing framework for vo api and content signatures\n",
            " robust coaddition using psf-matched warps for artifact removal\n",
            " macpro/esxi nodes to noao dc\n",
            " firefly grid view entry point\n",
            " nmf deblender performance\n",
            " repository properties are dropped when loaded via child repositories.\n",
            " ltd-mason for running multi-package software documentation build\n",
            " prototype calibration telescope pipeline to use stack conventions\n",
            " on out-of-focus donut images\n",
            " hsc wavefront from individual out-of-focus exposures\n",
            " donut fit pipeline\n",
            " and create multiple plot component based on plotly\n",
            " the performance of new matchpessimisticb code on selected test fields\n",
            " scatter plot for multi-trace chart architecture with plotly.js\n",
            " rabbitmq deployment for panopticon\n",
            " on swift butler storage trial\n",
            " the time it takes to send user query to workers.\n",
            " xrootd-facing code\n",
            " metaserv, imgserv and dbserv with data access services\n",
            " new master-worker result system\n",
            " provenance design / built proof-of-concept prototype\n",
            " 4cxx-based logging prototype - v2\n",
            " in rio\n",
            " query killing through ctrl-c\n",
            " -based css (v1)\n",
            " distrib proto (jan)\n",
            " with datacat foreign tables\n",
            " join support, including ref*match tables\n",
            " worker scheduler for shared scans\n",
            " problems with qserv at scale\n",
            " new (async) xrootd client\n",
            " distrib proto (nov)\n",
            " distrib proto (dec)\n",
            " executor code\n",
            " hash table prototyping\n",
            "  result size handling\n",
            " capabilities of python bokeh plotting library for making interactive plots - i\n",
            " complete database with s13 drp catalogs\n",
            " tech lead -- bring alg components up to date\n",
            " tarball production to weekly tag/release jenkins' job\"\n",
            " new wcs class\n",
            " new spatially-variable photocalib model\n",
            " and begin work on client side rotation and flipping\n",
            " butler dispatch (object serialization) to be pluggable.\n",
            " science lead -- bring alg components up to date\n",
            " plotly version of scatter and density charts\n",
            " plotly version of histogram chart\n",
            " dpdd requirements to lse-61\n",
            " camera mapper for storage abstraction\n",
            " wrapper on astshim to take point lists\n",
            " nmf deblender plugin\n",
            " ingest of s13 drp data to pdac\n",
            " posible matcher improvements\n",
            " footprint support\n",
            " afw::table with pybind11\n",
            " - time series viewer results (part 1, server side work)\n",
            " processccdtask and sub-tasks\n",
            " requirement annotations to dpdd\n",
            " draft of ldm-493: taxonomy of documentation\n",
            " skeleton in ldm-151\n",
            " calibration products production section of ldm-151\n",
            " section of ldm-151\n",
            " making psf-matched coadds, warp first then psf-match\n",
            " period finder panel and do lcmanager changes for lc ui\n",
            " pipelines documentation implementation plan technote\n",
            " _drp: design and implement an api for metric measurements and serializations\n",
            " pdac data base enough to determine the queries we need to do.\n",
            " pipelines descriptions\n",
            " draft document of suit requirements\n",
            " the code changes from job to job and link the package names with the corresponding git url\n",
            " (xy plot, histogram) container\n",
            " an api for the new wcs and transform system\n",
            " remote (python) api support\n",
            " javascript frameworks: work toward future proposal\n",
            " -based topological set operations for footprint\n",
            " \n",
            " refine alert generation pipelines sections\n",
            " vo search panel\n",
            " implementation of lupton(zogy) in stack\n",
            " backport: deblended heavyfootprints in forced photometry\n",
            " and rfc for repository refactor\n",
            " lsst and hsc pipelines through through multi-band coadd processing\n",
            " photometric and astrometric precision for decam cosmos dataset\n",
            " and deploy conda binaries for v12.0 release build\n",
            " and deploy an elk system\n",
            " , design, and rfc repository refactor.\n",
            " report on astropy integration proposals\n",
            " dc network design\n",
            " deployment of qa dashboard server and database instance\n",
            " the qa visualization needs\n",
            " existing wcs libraries and report on our options\n",
            " wrappers for sphgeom\n",
            " visualizer porting: mouse readout: part 1: projection\n",
            " supertask design proposal\n",
            " of cosmos data - part ii\n",
            " script to derive and collate qa metrics from data repository of processed data\n",
            " simulations for testing image differencing.\n",
            " logging, monitoring and metrics technologies and architecture\n",
            " jenkins builds on multiple platforms\n",
            " - base contract and execution\n",
            " negotiations for chilean links\n",
            " of multiple repositories v2\n",
            " approaches to dcr\n",
            " the new buildbot ci system\n",
            " and deploy git-lfs prototype\n",
            " of multiple repositories v1\n",
            " types & providers for puppet security management\n",
            " of concept types and providers for managing jenkins security settings\n",
            " code that uses pixel iterators and accessors\n",
            " replacement solver to the current a.net solver\n",
            " distributing automated lsst_apps builds\n",
            " to memmanreal in the worker scheduler\n",
            " the report on dcr\n",
            " decam data with collimated beam projector\n",
            " visualizer porting: begin\n",
            " distributing automated lsst_apps builds via docker containers\n",
            " basic table functionalities to js.\n",
            " search for dcr -- reiss\n",
            " search for dcr -- sullivan\n",
            " of decam cosmos field - part i\n",
            " 11.0 release\n",
            " prototype c++\n",
            " puppet jenkins native type implimentation and merge upstream\n",
            " gitlfs\n",
            " images for the mask bits at server side\n",
            " client side of mask layers in fits image viewer\n",
            " how large pixel region used in galaxy fitting needs to be\n",
            " , understand, and define more use cases\n",
            " functions specification document\n",
            " data management long range planning project\n",
            " -240 long range planning\n",
            " new footprint api\n",
            " flux environment for input panels\n",
            " more research into flux modules and bring one in\n",
            " jenkins  for usage as an interim ci system\n",
            " external http api for firefly viewer for beta use\n",
            " galaxy simulations for shapelet approximation and truncation tests\n",
            " for failure detection and resolution\n",
            " deblending in one band followed by linear fits of models\n",
            " deblending in one band followed by using the resulting templates in all bands\n",
            " javascript frameworks: finish new framework proposal\n",
            " automated system for release preparation builds\n",
            " doxygen documentation on rebuilds\n",
            " htm-based spatial binning to visualize large number of catalog sources\n",
            " up git hub for ipac firefly\n",
            " existing fits reader class needs to be refactored to improve the performance(2)\n",
            " existing fits reader class needs to be refactored to improve the performance(1)\n",
            " /learn what others are doing in astronomy software\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pmSJd7F9ehA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}